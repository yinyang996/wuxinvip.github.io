<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>上善若水の技术簿</title>
  
  <subtitle>时光荏苒、不浮青春.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.wuxinvip.com/"/>
  <updated>2018-12-22T11:57:02.905Z</updated>
  <id>https://www.wuxinvip.com/</id>
  
  <author>
    <name>上善若水</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>TOGAF架构认证</title>
    <link href="https://www.wuxinvip.com/2018/12/22/essay/essay-19/"/>
    <id>https://www.wuxinvip.com/2018/12/22/essay/essay-19/</id>
    <published>2018-12-22T00:00:00.000Z</published>
    <updated>2018-12-22T11:57:02.905Z</updated>
    
    <content type="html"><![CDATA[<ul><li>一入架构深似海啊</li></ul><p><img src="/img/essay/19/19.jpg" alt="TOGAF"></p><a id="more"></a><ul><li><p>没有梦想和咸鱼有什么区别</p></li><li><p><a href="https://www.opengroup.org/togaf" target="_blank" rel="noopener">open group网站</a></p></li><li><p><a href="https://zh.wikipedia.org/wiki/%E5%BC%80%E6%94%BE%E7%BB%84%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E6%A1%86%E6%9E%B6" target="_blank" rel="noopener">wiki</a></p></li><li><p><a href="http://www.opengroup.org.cn/resources?field_download_category_value=1" target="_blank" rel="noopener">TOGAF图书馆</a></p></li><li><p><a href="http://pubs.opengroup.org/architecture/togaf9-doc/arch/" target="_blank" rel="noopener">TOGAF9.2</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;一入架构深似海啊&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/img/essay/19/19.jpg&quot; alt=&quot;TOGAF&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="essay" scheme="https://www.wuxinvip.com/categories/essay/"/>
    
    
      <category term="随笔" scheme="https://www.wuxinvip.com/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>编程的套路</title>
    <link href="https://www.wuxinvip.com/2018/12/12/essay/essay-18/"/>
    <id>https://www.wuxinvip.com/2018/12/12/essay/essay-18/</id>
    <published>2018-12-12T00:00:00.000Z</published>
    <updated>2018-12-11T16:32:58.179Z</updated>
    
    <content type="html"><![CDATA[<ul><li>有人讲linux底层原理是一切编程原理所在</li></ul><a id="more"></a><h2 id="注册表"><a href="#注册表" class="headerlink" title="注册表"></a>注册表</h2><ul><li>Kafka中消息序列化使用avro序列化、avro使用注册表机制</li><li>spring 容器初始化中的bean初始化使用注册表机制</li><li><p>win系统启动也是采用了注册表机制</p></li><li><p><a href="https://www.wuxinvip.com/2018/11/10/essay/avro/">avro 详解</a></p></li><li>avro 使用注册表来存储 协议schema、以便于消费者和生产者采用双方认可解析协议 解析数据</li><li>spring bean注册中、注册每一个bean类初始化类信息、方法、常量等等、在使用的时候注入应用中使用</li><li>windows的注册表是二进制的数据库、作为整个系统和应用上的核心数据库在各个应用中共享数据</li></ul><p>套路：注册表:数据唯一识别、也可以作为协议、也可以作为数据库、<br>共同点：数据特征识别、</p><h2 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h2><ul><li>主副本数据存储</li></ul><h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><ul><li>hash索引【mysql】</li><li>btree索引【mysql】</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;有人讲linux底层原理是一切编程原理所在&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="essay" scheme="https://www.wuxinvip.com/categories/essay/"/>
    
    
      <category term="随笔" scheme="https://www.wuxinvip.com/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>Java NIO浅析【转】</title>
    <link href="https://www.wuxinvip.com/2018/12/11/jdk/jdk-nio/"/>
    <id>https://www.wuxinvip.com/2018/12/11/jdk/jdk-nio/</id>
    <published>2018-12-11T00:00:00.000Z</published>
    <updated>2018-12-11T02:45:12.717Z</updated>
    
    <content type="html"><![CDATA[<ul><li>写的很不错 从浅入深、还有代码示例、还有模型示例</li></ul><h2 id="转-美团技术团队-以示版权"><a href="#转-美团技术团队-以示版权" class="headerlink" title="转-美团技术团队-以示版权"></a><a href="https://tech.meituan.com/nio.html" target="_blank" rel="noopener">转-美团技术团队-以示版权</a></h2><p>NIO（Non-blocking I/O，在Java领域，也称为New I/O），是一种同步非阻塞的I/O模型，也是I/O多路复用的基础，已经被越来越多地应用到大型应用服务器，成为解决高并发与大量连接、I/O处理问题的有效方式。</p><p>那么NIO的本质是什么样的呢？它是怎样与事件模型结合来解放线程、提高系统吞吐的呢？</p><p>本文会从传统的阻塞I/O和线程池模型面临的问题讲起，然后对比几种常见I/O模型，一步步分析NIO怎么利用事件模型处理I/O，解决线程池瓶颈处理海量连接，包括利用面向事件的方式编写服务端/客户端程序。最后延展到一些高级主题，如Reactor与Proactor模型的对比、Selector的唤醒、Buffer的选择等。</p><p>注：本文的代码都是伪代码，主要是为了示意，不可用于生产环境。</p><a id="more"></a><h2 id="传统BIO模型分析"><a href="#传统BIO模型分析" class="headerlink" title="传统BIO模型分析"></a>传统BIO模型分析</h2><p>让我们先回忆一下传统的服务器端同步阻塞I/O处理（也就是BIO，Blocking I/O）的经典编程模型：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> ExecutorService executor = Excutors.newFixedThreadPollExecutor(100);//线程池</span><br><span class="line"></span><br><span class="line"> ServerSocket serverSocket = new ServerSocket();</span><br><span class="line"> serverSocket.bind(8088);</span><br><span class="line"> while(!Thread.currentThread.isInturrupted())&#123;//主线程死循环等待新连接到来</span><br><span class="line"> Socket socket = serverSocket.accept();</span><br><span class="line"> executor.submit(new ConnectIOnHandler(socket));//为新的连接创建新的线程</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">class ConnectIOnHandler extends Thread&#123;</span><br><span class="line">    private Socket socket;</span><br><span class="line">    public ConnectIOnHandler(Socket socket)&#123;</span><br><span class="line">       this.socket = socket;</span><br><span class="line">    &#125;</span><br><span class="line">    public void run()&#123;</span><br><span class="line">      while(!Thread.currentThread.isInturrupted()&amp;&amp;!socket.isClosed())&#123;死循环处理读写事件</span><br><span class="line">          String someThing = socket.read()....//读取数据</span><br><span class="line">          if(someThing!=null)&#123;</span><br><span class="line">             ......//处理数据</span><br><span class="line">             socket.write()....//写数据</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这是一个经典的每连接每线程的模型，之所以使用多线程，主要原因在于socket.accept()、socket.read()、socket.write()三个主要函数都是同步阻塞的，当一个连接在处理I/O的时候，系统是阻塞的，如果是单线程的话必然就挂死在那里；但CPU是被释放出来的，开启多线程，就可以让CPU去处理更多的事情。其实这也是所有使用多线程的本质：</p><ul><li>利用多核。</li><li>当I/O阻塞系统，但CPU空闲的时候，可以利用多线程使用CPU资源。</li></ul><p>现在的多线程一般都使用线程池，可以让线程的创建和回收成本相对较低。在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的I/O并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。</p><p>不过，这个模型最本质的问题在于，严重依赖于线程。但线程是很”贵”的资源，主要表现在：</p><ul><li>线程的创建和销毁成本很高，在Linux这样的操作系统中，线程本质上就是一个进程。创建和销毁都是重量级的系统函数。</li><li>线程本身占用较大内存，像Java的线程栈，一般至少分配512K～1M的空间，如果系统中的线程数过千，恐怕整个JVM的内存都会被吃掉一半。</li><li>线程的切换成本是很高的。操作系统发生线程切换的时候，需要保留线程的上下文，然后执行系统调用。如果线程数过高，可能执行线程切换的时间甚至会大于线程执行的时间，这时候带来的表现往往是系统load偏高、CPU sy使用率特别高（超过20%以上)，导致系统几乎陷入不可用的状态。</li><li>容易造成锯齿状的系统负载。因为系统负载是用活动线程数或CPU核心数，一旦线程数量高但外部网络环境不是很稳定，就很容易造成大量请求的结果同时返回，激活大量阻塞线程从而使系统负载压力过大。</li></ul><p>所以，当面对十万甚至百万级连接的时候，传统的BIO模型是无能为力的。随着移动端应用的兴起和各种网络游戏的盛行，百万级长连接日趋普遍，此时，必然需要一种更高效的I/O处理模型。</p><h2 id="NIO是怎么工作的"><a href="#NIO是怎么工作的" class="headerlink" title="NIO是怎么工作的"></a>NIO是怎么工作的</h2><p>很多刚接触NIO的人，第一眼看到的就是Java相对晦涩的API，比如：Channel，Selector，Socket什么的；然后就是一坨上百行的代码来演示NIO的服务端Demo……瞬间头大有没有？</p><p>我们不管这些，抛开现象看本质，先分析下NIO是怎么工作的。</p><h3 id="常见I-O模型对比"><a href="#常见I-O模型对比" class="headerlink" title="常见I/O模型对比"></a>常见I/O模型对比</h3><p>所有的系统I/O都分为两个阶段：等待就绪和操作。举例来说，读函数，分为等待系统可读和真正的读；同理，写函数分为等待网卡可以写和真正的写。</p><p>需要说明的是等待就绪的阻塞是不使用CPU的，是在“空等”；而真正的读写操作的阻塞是使用CPU的，真正在”干活”，而且这个过程非常快，属于memory copy，带宽通常在1GB/s级别以上，可以理解为基本不耗时。</p><p>下图是几种常见I/O模型的对比：</p><p><img src="/img/jdk/nio2.jpg" alt="NIO模型对比"></p><p>以socket.read()为例子：</p><p>传统的BIO里面socket.read()，如果TCP RecvBuffer里没有数据，函数会一直阻塞，直到收到数据，返回读到的数据。</p><p>对于NIO，如果TCP RecvBuffer有数据，就把数据从网卡读到内存，并且返回给用户；反之则直接返回0，永远不会阻塞。</p><p>最新的AIO(Async I/O)里面会更进一步：不但等待就绪是非阻塞的，就连数据从网卡到内存的过程也是异步的。</p><p>换句话说，BIO里用户最关心“我要读”，NIO里用户最关心”我可以读了”，在AIO模型里用户更需要关注的是“读完了”。</p><p>NIO一个重要的特点是：socket主要的读、写、注册和接收函数，在等待就绪阶段都是非阻塞的，真正的I/O操作是同步阻塞的（消耗CPU但性能非常高）。</p><h2 id="如何结合事件模型使用NIO同步非阻塞特性"><a href="#如何结合事件模型使用NIO同步非阻塞特性" class="headerlink" title="如何结合事件模型使用NIO同步非阻塞特性"></a>如何结合事件模型使用NIO同步非阻塞特性</h2><p>回忆BIO模型，之所以需要多线程，是因为在进行I/O操作的时候，一是没有办法知道到底能不能写、能不能读，只能”傻等”，即使通过各种估算，算出来操作系统没有能力进行读写，也没法在socket.read()和socket.write()函数中返回，这两个函数无法进行有效的中断。所以除了多开线程另起炉灶，没有好的办法利用CPU。</p><p>NIO的读写函数可以立刻返回，这就给了我们不开线程利用CPU的最好机会：如果一个连接不能读写（socket.read()返回0或者socket.write()返回0），我们可以把这件事记下来，记录的方式通常是在Selector上注册标记位，然后切换到其它就绪的连接（channel）继续进行读写。</p><p>下面具体看下如何利用事件模型单线程处理所有I/O请求：</p><p>NIO的主要事件有几个：读就绪、写就绪、有新连接到来。</p><p>我们首先需要注册当这几个事件到来的时候所对应的处理器。然后在合适的时机告诉事件选择器：我对这个事件感兴趣。对于写操作，就是写不出去的时候对写事件感兴趣；对于读操作，就是完成连接和系统没有办法承载新读入的数据的时；对于accept，一般是服务器刚启动的时候；而对于connect，一般是connect失败需要重连或者直接异步调用connect的时候。</p><p>其次，用一个死循环选择就绪的事件，会执行系统调用（Linux 2.6之前是select、poll，2.6之后是epoll，Windows是IOCP），还会阻塞的等待新事件的到来。新事件到来的时候，会在selector上注册标记位，标示可读、可写或者有连接到来。</p><p>注意，select是阻塞的，无论是通过操作系统的通知（epoll）还是不停的轮询(select，poll)，这个函数是阻塞的。所以你可以放心大胆地在一个while(true)里面调用这个函数而不用担心CPU空转。</p><p>所以我们的程序大概的模样是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">interface ChannelHandler&#123;</span><br><span class="line">    void channelReadable(Channel channel);</span><br><span class="line">    void channelWritable(Channel channel);</span><br><span class="line"> &#125;</span><br><span class="line"> class Channel&#123;</span><br><span class="line">   Socket socket;</span><br><span class="line">   Event event;//读，写或者连接</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> //IO线程主循环:</span><br><span class="line"> class IoThread extends Thread&#123;</span><br><span class="line"> public void run()&#123;</span><br><span class="line"> Channel channel;</span><br><span class="line"> while(channel=Selector.select())&#123;//选择就绪的事件和对应的连接</span><br><span class="line">    if(channel.event==accept)&#123;</span><br><span class="line">       registerNewChannelHandler(channel);//如果是新连接，则注册一个新的读写处理器</span><br><span class="line">    &#125;</span><br><span class="line">    if(channel.event==write)&#123;</span><br><span class="line">       getChannelHandler(channel).channelWritable(channel);//如果可以写，则执行写事件</span><br><span class="line">    &#125;</span><br><span class="line">    if(channel.event==read)&#123;</span><br><span class="line">        getChannelHandler(channel).channelReadable(channel);//如果可以读，则执行读事件</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> Map&lt;Channel，ChannelHandler&gt; handlerMap;//所有channel的对应事件处理器</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个程序很简短，也是最简单的Reactor模式：注册所有感兴趣的事件处理器，单线程轮询选择就绪事件，执行事件处理器。</p><h2 id="优化线程模型"><a href="#优化线程模型" class="headerlink" title="优化线程模型"></a>优化线程模型</h2><p>由上面的示例我们大概可以总结出NIO是怎么解决掉线程的瓶颈并处理海量连接的：</p><p>NIO由原来的阻塞读写（占用线程）变成了单线程轮询事件，找到可以进行读写的网络描述符进行读写。除了事件的轮询是阻塞的（没有可干的事情必须要阻塞），剩余的I/O操作都是纯CPU操作，没有必要开启多线程。</p><p>并且由于线程的节约，连接数大的时候因为线程切换带来的问题也随之解决，进而为处理海量连接提供了可能。</p><p>单线程处理I/O的效率确实非常高，没有线程切换，只是拼命的读、写、选择事件。但现在的服务器，一般都是多核处理器，如果能够利用多核心进行I/O，无疑对效率会有更大的提高。</p><p>仔细分析一下我们需要的线程，其实主要包括以下几种：</p><ul><li>事件分发器，单线程选择就绪的事件。</li><li>I/O处理器，包括connect、read、write等，这种纯CPU操作，一般开启CPU核心个线程就可以。</li><li>业务线程，在处理完I/O后，业务一般还会有自己的业务逻辑，有的还会有其他的阻塞I/O，如DB操作，RPC等。只要有阻塞，就需要单独的线程。</li></ul><p>Java的Selector对于Linux系统来说，有一个致命限制：同一个channel的select不能被并发的调用。因此，如果有多个I/O线程，必须保证：一个socket只能属于一个IoThread，而一个IoThread可以管理多个socket。</p><p>另外连接的处理和读写的处理通常可以选择分开，这样对于海量连接的注册和读写就可以分发。虽然read()和write()是比较高效无阻塞的函数，但毕竟会占用CPU，如果面对更高的并发则无能为力。</p><p><img src="/img/jdk/reactor.png" alt=""></p><h2 id="NIO在客户端的魔力"><a href="#NIO在客户端的魔力" class="headerlink" title="NIO在客户端的魔力"></a>NIO在客户端的魔力</h2><p>通过上面的分析，可以看出NIO在服务端对于解放线程，优化I/O和处理海量连接方面，确实有自己的用武之地。那么在客户端上，NIO又有什么使用场景呢?</p><p>常见的客户端BIO+连接池模型，可以建立n个连接，然后当某一个连接被I/O占用的时候，可以使用其他连接来提高性能。</p><p>但多线程的模型面临和服务端相同的问题：如果指望增加连接数来提高性能，则连接数又受制于线程数、线程很贵、无法建立很多线程，则性能遇到瓶颈。</p><h3 id="每连接顺序请求的Redis"><a href="#每连接顺序请求的Redis" class="headerlink" title="每连接顺序请求的Redis"></a>每连接顺序请求的Redis</h3><p>对于Redis来说，由于服务端是全局串行的，能够保证同一连接的所有请求与返回顺序一致。这样可以使用单线程＋队列，把请求数据缓冲。然后pipeline发送，返回future，然后channel可读时，直接在队列中把future取回来，done()就可以了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">伪代码如下：</span><br><span class="line">class RedisClient Implements ChannelHandler&#123;</span><br><span class="line">     private BlockingQueue CmdQueue;</span><br><span class="line">     private EventLoop eventLoop;</span><br><span class="line">     private Channel channel;</span><br><span class="line">     class Cmd&#123;</span><br><span class="line">      String cmd;</span><br><span class="line">      Future result;</span><br><span class="line">     &#125;</span><br><span class="line">     public Future get(String key)&#123;</span><br><span class="line">       Cmd cmd= new Cmd(key);</span><br><span class="line">       queue.offer(cmd);</span><br><span class="line">       eventLoop.submit(new Runnable()&#123;</span><br><span class="line">            List list = new ArrayList();</span><br><span class="line">            queue.drainTo(list);</span><br><span class="line">            if(channel.isWritable())&#123;</span><br><span class="line">             channel.writeAndFlush(list);</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">     public void ChannelReadFinish(Channel channel，Buffer Buffer)&#123;</span><br><span class="line">        List result = handleBuffer();//处理数据</span><br><span class="line">        //从cmdQueue取出future，并设值，future.done();</span><br><span class="line">    &#125;</span><br><span class="line">     public void ChannelWritable(Channel channel)&#123;</span><br><span class="line">       channel.flush();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样做，能够充分的利用pipeline来提高I/O能力，同时获取异步处理能力。</p><h3 id="多连接短连接的HttpClient"><a href="#多连接短连接的HttpClient" class="headerlink" title="多连接短连接的HttpClient"></a>多连接短连接的HttpClient</h3><p>类似于竞对抓取的项目，往往需要建立无数的HTTP短连接，然后抓取，然后销毁，当需要单机抓取上千网站线程数又受制的时候，怎么保证性能呢?</p><p>何不尝试NIO，单线程进行连接、写、读操作？如果连接、读、写操作系统没有能力处理，简单的注册一个事件，等待下次循环就好了。</p><p>如何存储不同的请求/响应呢？由于http是无状态没有版本的协议，又没有办法使用队列，好像办法不多。比较笨的办法是对于不同的socket，直接存储socket的引用作为map的key。</p><h3 id="常见的RPC框架，如Thrift，Dubbo"><a href="#常见的RPC框架，如Thrift，Dubbo" class="headerlink" title="常见的RPC框架，如Thrift，Dubbo"></a>常见的RPC框架，如Thrift，Dubbo</h3><p>这种框架内部一般维护了请求的协议和请求号，可以维护一个以请求号为key，结果的result为future的map，结合NIO+长连接，获取非常不错的性能。</p><h2 id="NIO高级主题"><a href="#NIO高级主题" class="headerlink" title="NIO高级主题"></a>NIO高级主题</h2><h3 id="Proactor与Reactor"><a href="#Proactor与Reactor" class="headerlink" title="Proactor与Reactor"></a>Proactor与Reactor</h3><p>一般情况下，I/O 复用机制需要事件分发器（event dispatcher）。 事件分发器的作用，即将那些读写事件源分发给各读写事件的处理者，就像送快递的在楼下喊: 谁谁谁的快递到了， 快来拿吧！开发人员在开始的时候需要在分发器那里注册感兴趣的事件，并提供相应的处理者（event handler)，或者是回调函数；事件分发器在适当的时候，会将请求的事件分发给这些handler或者回调函数。</p><p>涉及到事件分发器的两种模式称为：Reactor和Proactor。 Reactor模式是基于同步I/O的，而Proactor模式是和异步I/O相关的。在Reactor模式中，事件分发器等待某个事件或者可应用或个操作的状态发生（比如文件描述符可读写，或者是socket可读写），事件分发器就把这个事件传给事先注册的事件处理函数或者回调函数，由后者来做实际的读写操作。</p><p>而在Proactor模式中，事件处理者（或者代由事件分发器发起）直接发起一个异步读写操作（相当于请求），而实际的工作是由操作系统来完成的。发起时，需要提供的参数包括用于存放读到数据的缓存区、读的数据大小或用于存放外发数据的缓存区，以及这个请求完后的回调函数等信息。事件分发器得知了这个请求，它默默等待这个请求的完成，然后转发完成事件给相应的事件处理者或者回调。举例来说，在Windows上事件处理者投递了一个异步IO操作（称为overlapped技术），事件分发器等IO Complete事件完成。这种异步模式的典型实现是基于操作系统底层异步API的，所以我们可称之为“系统级别”的或者“真正意义上”的异步，因为具体的读写是由操作系统代劳的。</p><p>举个例子，将有助于理解Reactor与Proactor二者的差异，以读操作为例（写操作类似）。</p><h4 id="在Reactor中实现读"><a href="#在Reactor中实现读" class="headerlink" title="在Reactor中实现读"></a>在Reactor中实现读</h4><ul><li>注册读就绪事件和相应的事件处理器。</li><li>事件分发器等待事件。</li><li>事件到来，激活分发器，分发器调用事件对应的处理器。</li><li>事件处理器完成实际的读操作，处理读到的数据，注册新的事件，然后返还控制权。</li></ul><h4 id="在Proactor中实现读："><a href="#在Proactor中实现读：" class="headerlink" title="在Proactor中实现读："></a>在Proactor中实现读：</h4><ul><li>处理器发起异步读操作（注意：操作系统必须支持异步IO）。在这种情况下，处理器无视IO就绪事件，它关注的是完成事件。</li><li>事件分发器等待操作完成事件。</li><li>在分发器等待过程中，操作系统利用并行的内核线程执行实际的读操作，并将结果数据存入用户自定义缓冲区，最后通知事件分发器读操作完成。</li><li>事件分发器呼唤处理器。</li><li>事件处理器处理用户自定义缓冲区中的数据，然后启动一个新的异步操作，并将控制权返回事件分发器。</li></ul><p>可以看出，两个模式的相同点，都是对某个I/O事件的事件通知（即告诉某个模块，这个I/O操作可以进行或已经完成)。在结构上，两者也有相同点：事件分发器负责提交IO操作（异步)、查询设备是否可操作（同步)，然后当条件满足时，就回调handler；不同点在于，异步情况下（Proactor)，当回调handler时，表示I/O操作已经完成；同步情况下（Reactor)，回调handler时，表示I/O设备可以进行某个操作（can read 或 can write)。</p><p>下面，我们将尝试应对为Proactor和Reactor模式建立可移植框架的挑战。在改进方案中，我们将Reactor原来位于事件处理器内的Read/Write操作移至分发器（不妨将这个思路称为“模拟异步”），以此寻求将Reactor多路同步I/O转化为模拟异步I/O。以读操作为例子，改进过程如下：</p><ul><li>注册读就绪事件和相应的事件处理器。并为分发器提供数据缓冲区地址，需要读取数据量等信息。</li><li>分发器等待事件（如在select()上等待）。</li><li>事件到来，激活分发器。分发器执行一个非阻塞读操作（它有完成这个操作所需的全部信息），最后调用对应处理器。</li><li>事件处理器处理用户自定义缓冲区的数据，注册新的事件（当然同样要给出数据缓冲区地址，需要读取的数据量等信息），最后将控制权返还分发器。</li></ul><p>如我们所见，通过对多路I/O模式功能结构的改造，可将Reactor转化为Proactor模式。改造前后，模型实际完成的工作量没有增加，只不过参与者间对工作职责稍加调换。没有工作量的改变，自然不会造成性能的削弱。对如下各步骤的比较，可以证明工作量的恒定：</p><h4 id="标准-典型的Reactor："><a href="#标准-典型的Reactor：" class="headerlink" title="标准/典型的Reactor："></a>标准/典型的Reactor：</h4><ul><li>步骤1：等待事件到来（Reactor负责）。</li><li>步骤2：将读就绪事件分发给用户定义的处理器（Reactor负责）。</li><li>步骤3：读数据（用户处理器负责）。</li><li>步骤4：处理数据（用户处理器负责）。</li></ul><h4 id="标准-改进实现的模拟Proactor："><a href="#标准-改进实现的模拟Proactor：" class="headerlink" title="标准/改进实现的模拟Proactor："></a>标准/改进实现的模拟Proactor：</h4><ul><li>步骤1：等待事件到来（Proactor负责）。</li><li>步骤2：得到读就绪事件，执行读数据（现在由Proactor负责）。</li><li>步骤3：将读完成事件分发给用户处理器（Proactor负责）。</li><li>步骤4：处理数据（用户处理器负责）。</li></ul><p>对于不提供异步I/O API的操作系统来说，这种办法可以隐藏Socket API的交互细节，从而对外暴露一个完整的异步接口。借此，我们就可以进一步构建完全可移植的，平台无关的，有通用对外接口的解决方案。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">代码示例如下：</span><br><span class="line"></span><br><span class="line">interface ChannelHandler&#123;</span><br><span class="line">      void channelReadComplate(Channel channel，byte[] data);</span><br><span class="line">      void channelWritable(Channel channel);</span><br><span class="line">   &#125;</span><br><span class="line">   class Channel&#123;</span><br><span class="line">     Socket socket;</span><br><span class="line">     Event event;//读，写或者连接</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   //IO线程主循环：</span><br><span class="line">   class IoThread extends Thread&#123;</span><br><span class="line">   public void run()&#123;</span><br><span class="line">   Channel channel;</span><br><span class="line">   while(channel=Selector.select())&#123;//选择就绪的事件和对应的连接</span><br><span class="line">      if(channel.event==accept)&#123;</span><br><span class="line">         registerNewChannelHandler(channel);//如果是新连接，则注册一个新的读写处理器</span><br><span class="line">         Selector.interested(read);</span><br><span class="line">      &#125;</span><br><span class="line">      if(channel.event==write)&#123;</span><br><span class="line">         getChannelHandler(channel).channelWritable(channel);//如果可以写，则执行写事件</span><br><span class="line">      &#125;</span><br><span class="line">      if(channel.event==read)&#123;</span><br><span class="line">          byte[] data = channel.read();</span><br><span class="line">          if(channel.read()==0)//没有读到数据，表示本次数据读完了</span><br><span class="line">          &#123;</span><br><span class="line">          getChannelHandler(channel).channelReadComplate(channel，data;//处理读完成事件</span><br><span class="line">          &#125;</span><br><span class="line">          if(过载保护)&#123;</span><br><span class="line">          Selector.interested(read);</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line">     &#125;</span><br><span class="line">    &#125;</span><br><span class="line">   Map&lt;Channel，ChannelHandler&gt; handlerMap;//所有channel的对应事件处理器</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h3 id="Selector-wakeup"><a href="#Selector-wakeup" class="headerlink" title="Selector.wakeup()"></a>Selector.wakeup()</h3><h4 id="主要作用"><a href="#主要作用" class="headerlink" title="主要作用"></a>主要作用</h4><ul><li><p>解除阻塞在Selector.select()/select(long)上的线程，立即返回。</p></li><li><p>两次成功的select之间多次调用wakeup等价于一次调用。</p></li><li><p>如果当前没有阻塞在select上，则本次wakeup调用将作用于下一次select——“记忆”作用。</p></li><li><p>为什么要唤醒？</p></li><li><p>注册了新的channel或者事件。</p></li><li><p>channel关闭，取消注册。</p></li></ul><p>优先级更高的事件触发（如定时器事件），希望及时处理。</p><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>Linux上利用pipe调用创建一个管道，Windows上则是一个loopback的tcp连接。这是因为win32的管道无法加入select的fd set，将管道或者TCP连接加入select fd set。</p><p>wakeup往管道或者连接写入一个字节，阻塞的select因为有I/O事件就绪，立即返回。可见，wakeup的调用开销不可忽视。</p><h3 id="Buffer的选择"><a href="#Buffer的选择" class="headerlink" title="Buffer的选择"></a>Buffer的选择</h3><p>通常情况下，操作系统的一次写操作分为两步：</p><ul><li>将数据从用户空间拷贝到系统空间。</li><li>从系统空间往网卡写。同理，读操作也分为两步：<ul><li>① 将数据从网卡拷贝到系统空间；</li><li>② 将数据从系统空间拷贝到用户空间。</li></ul></li></ul><p>对于NIO来说，缓存的使用可以使用DirectByteBuffer和HeapByteBuffer。如果使用了DirectByteBuffer，一般来说可以减少一次系统空间到用户空间的拷贝。但Buffer创建和销毁的成本更高，更不宜维护，通常会用内存池来提高性能。</p><p>如果数据量比较小的中小应用情况下，可以考虑使用heapBuffer；反之可以用directBuffer。</p><h3 id="NIO存在的问题"><a href="#NIO存在的问题" class="headerlink" title="NIO存在的问题"></a>NIO存在的问题</h3><p>使用NIO != 高性能，当连接数&lt;1000，并发程度不高或者局域网环境下NIO并没有显著的性能优势。</p><p>NIO并没有完全屏蔽平台差异，它仍然是基于各个操作系统的I/O系统实现的，差异仍然存在。使用NIO做网络编程构建事件驱动模型并不容易，陷阱重重。</p><p>推荐大家使用成熟的NIO框架，如Netty，MINA等。解决了很多NIO的陷阱，并屏蔽了操作系统的差异，有较好的性能和编程模型。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最后总结一下到底NIO给我们带来了些什么：</p><ul><li>事件驱动模型</li><li>避免多线程</li><li>单线程处理多任务</li><li>非阻塞I/O，I/O读写不再阻塞，而是返回0</li><li>基于block的传输，通常比基于流的传输更高效</li><li>更高级的IO函数，zero-copy</li><li>IO多路复用大大提高了Java网络应用的可伸缩性和实用性</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;写的很不错 从浅入深、还有代码示例、还有模型示例&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;转-美团技术团队-以示版权&quot;&gt;&lt;a href=&quot;#转-美团技术团队-以示版权&quot; class=&quot;headerlink&quot; title=&quot;转-美团技术团队-以示版权&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://tech.meituan.com/nio.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;转-美团技术团队-以示版权&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;NIO（Non-blocking I/O，在Java领域，也称为New I/O），是一种同步非阻塞的I/O模型，也是I/O多路复用的基础，已经被越来越多地应用到大型应用服务器，成为解决高并发与大量连接、I/O处理问题的有效方式。&lt;/p&gt;
&lt;p&gt;那么NIO的本质是什么样的呢？它是怎样与事件模型结合来解放线程、提高系统吞吐的呢？&lt;/p&gt;
&lt;p&gt;本文会从传统的阻塞I/O和线程池模型面临的问题讲起，然后对比几种常见I/O模型，一步步分析NIO怎么利用事件模型处理I/O，解决线程池瓶颈处理海量连接，包括利用面向事件的方式编写服务端/客户端程序。最后延展到一些高级主题，如Reactor与Proactor模型的对比、Selector的唤醒、Buffer的选择等。&lt;/p&gt;
&lt;p&gt;注：本文的代码都是伪代码，主要是为了示意，不可用于生产环境。&lt;/p&gt;
    
    </summary>
    
      <category term="java" scheme="https://www.wuxinvip.com/categories/java/"/>
    
      <category term="jdk" scheme="https://www.wuxinvip.com/categories/java/jdk/"/>
    
    
      <category term="jdk" scheme="https://www.wuxinvip.com/tags/jdk/"/>
    
  </entry>
  
  <entry>
    <title>rocketmq使用示例</title>
    <link href="https://www.wuxinvip.com/2018/12/08/message-queue/rocketmq/04/"/>
    <id>https://www.wuxinvip.com/2018/12/08/message-queue/rocketmq/04/</id>
    <published>2018-12-08T00:00:00.000Z</published>
    <updated>2018-12-09T14:03:41.724Z</updated>
    
    <content type="html"><![CDATA[<ul><li>spring cloud中集成rocketmq</li></ul><a id="more"></a><h2 id="spring-cloud中集成rocketmq"><a href="#spring-cloud中集成rocketmq" class="headerlink" title="spring cloud中集成rocketmq"></a>spring cloud中集成rocketmq</h2><p><a href="https://github.com/wuxinvip/base-cloud/tree/2.0.X-boot/message-queue" target="_blank" rel="noopener">代码地址</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> *  接收bean 将消息发送到spring event事件中进行处理 解耦数据处理</span><br><span class="line"> *  屏蔽rockemq的依赖性 可以不影响业务转换别的消息组件</span><br><span class="line"> */</span><br><span class="line">@Component</span><br><span class="line">public class ConsumerMessageListener implements MessageListener &#123;</span><br><span class="line"></span><br><span class="line">    private static final Logger logger = LoggerFactory.getLogger(ConsumerMessageListener.class);</span><br><span class="line">    @Autowired</span><br><span class="line">    ApplicationContext applicationContext;</span><br><span class="line"></span><br><span class="line">    public Action consume(Message message, ConsumeContext context) &#123;</span><br><span class="line">        System.out.println(&quot;Receive: &quot; + message);</span><br><span class="line">        try &#123;</span><br><span class="line">            logger.info(&quot;rocket 接收到消息:&#123;&#125;&quot;,message);</span><br><span class="line">            //do something..</span><br><span class="line">            applicationContext.publishEvent(new RocketmqEvent(message));</span><br><span class="line"></span><br><span class="line">            return Action.CommitMessage; //消息处理正常</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            //消费失败</span><br><span class="line">            logger.error(&quot;rocket 消息处理失败 ：&#123;&#125;&quot;,message);</span><br><span class="line">            return Action.ReconsumeLater;//消息加入重试</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 接收示例</span><br><span class="line">     */</span><br><span class="line"></span><br><span class="line">    @EventListener(condition = &quot;#event.topic==&apos;your.topic&apos; &amp;&amp; #event.tag==&apos;your.tag&apos;&quot;)</span><br><span class="line">    public void MessageListener(RocketmqEvent rocketmqEvent) throws IOException &#123;</span><br><span class="line">        String string = rocketmqEvent.getMsg();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 发送bean类</span><br><span class="line"> *  引用统一发送 解耦数据处理 </span><br><span class="line"> *  屏蔽rockemq的依赖性 可以不影响业务转换别的消息组件</span><br><span class="line"> */</span><br><span class="line">@Component</span><br><span class="line">public class MessageQueueTemplate &#123;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    ProducerBean producerBean;</span><br><span class="line"></span><br><span class="line">    public void send(RocketmqEvent rocketmqEvent)&#123;</span><br><span class="line"></span><br><span class="line">        Message message = new Message();</span><br><span class="line">        message.setTopic(rocketmqEvent.getTopic());</span><br><span class="line">        message.setTag(rocketmqEvent.getTag());</span><br><span class="line">        message.setBody(rocketmqEvent.getMsg().getBytes());</span><br><span class="line">        producerBean.send(message);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;spring cloud中集成rocketmq&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="java" scheme="https://www.wuxinvip.com/categories/java/"/>
    
      <category term="message-queue" scheme="https://www.wuxinvip.com/categories/java/message-queue/"/>
    
      <category term="rocketmq" scheme="https://www.wuxinvip.com/categories/java/message-queue/rocketmq/"/>
    
    
      <category term="RocketMQ" scheme="https://www.wuxinvip.com/tags/RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>rocketmq图解</title>
    <link href="https://www.wuxinvip.com/2018/12/07/message-queue/rocketmq/03/"/>
    <id>https://www.wuxinvip.com/2018/12/07/message-queue/rocketmq/03/</id>
    <published>2018-12-07T00:00:00.000Z</published>
    <updated>2018-12-09T13:57:54.285Z</updated>
    
    <content type="html"><![CDATA[<ul><li>组件结构图</li></ul><a id="more"></a><h2 id="RocketMQ-各个角色关系"><a href="#RocketMQ-各个角色关系" class="headerlink" title="RocketMQ 各个角色关系"></a>RocketMQ 各个角色关系</h2><p><img src="/img/rocketmq/01.jpg" alt="rocketmq组件结构图"></p><ul><li>与kafka区别就是 kafka使用zk来管理服务注册、rocketmq用的自己的rpc【nameserver】</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;组件结构图&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="java" scheme="https://www.wuxinvip.com/categories/java/"/>
    
      <category term="message-queue" scheme="https://www.wuxinvip.com/categories/java/message-queue/"/>
    
      <category term="rocketmq" scheme="https://www.wuxinvip.com/categories/java/message-queue/rocketmq/"/>
    
    
      <category term="RocketMQ" scheme="https://www.wuxinvip.com/tags/RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>rocketmq安装</title>
    <link href="https://www.wuxinvip.com/2018/12/06/message-queue/rocketmq/02/"/>
    <id>https://www.wuxinvip.com/2018/12/06/message-queue/rocketmq/02/</id>
    <published>2018-12-06T00:00:00.000Z</published>
    <updated>2018-12-09T13:40:17.862Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#   基础环境</span><br><span class="line">64bit OS, Linux/Unix/Mac is recommended;</span><br><span class="line">64bit JDK 1.8+;</span><br><span class="line">Maven 3.2.x;</span><br><span class="line">Git;</span><br><span class="line">4g+ free disk for Broker server</span><br><span class="line"></span><br><span class="line">curl -L -O https://www.apache.org/dyn/closer.cgi?path=rocketmq/4.3.2/rocketmq-all-4.3.2-bin-release.zip</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; unzip rocketmq-all-4.3.2-source-release.zip</span><br><span class="line">  &gt; cd rocketmq-all-4.3.2/</span><br><span class="line">  &gt; mvn -Prelease-all -DskipTests clean install -U</span><br><span class="line">  &gt; cd distribution/target/apache-rocketmq</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#启动nameserver</span><br><span class="line"></span><br><span class="line">&gt; nohup sh bin/mqnamesrv &amp;</span><br><span class="line">&gt; tail -f ~/logs/rocketmqlogs/namesrv.log</span><br><span class="line">The Name Server boot success...</span><br><span class="line">#启动broker</span><br><span class="line">&gt; nohup sh bin/mqbroker -n localhost:9876 &amp;</span><br><span class="line">&gt; tail -f ~/logs/rocketmqlogs/broker.log </span><br><span class="line">The broker[%s, 172.30.30.233:10911] boot success...</span><br><span class="line"></span><br><span class="line">#发送消息</span><br><span class="line">&gt; export NAMESRV_ADDR=localhost:9876</span><br><span class="line">&gt; sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer</span><br><span class="line">SendResult [sendStatus=SEND_OK, msgId= ...</span><br><span class="line"></span><br><span class="line">&gt; sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer</span><br><span class="line">ConsumeMessageThread_%d Receive New Messages: [MessageExt...</span><br></pre></td></tr></table></figure><h2 id="关闭"><a href="#关闭" class="headerlink" title="关闭"></a>关闭</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt; sh bin/mqshutdown broker</span><br><span class="line">The mqbroker(36695) is running...</span><br><span class="line">Send shutdown request to mqbroker(36695) OK</span><br><span class="line"></span><br><span class="line">&gt; sh bin/mqshutdown namesrv</span><br><span class="line">The mqnamesrv(36664) is running...</span><br><span class="line">Send shutdown request to mqnamesrv(36664) OK</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;#   基础环境&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;64bit OS, Linux/Unix/Mac is recommended;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;64bit JDK 1.8+;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Maven 3.2.x;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Git;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4g+ free disk for Broker server&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;curl -L -O https://www.apache.org/dyn/closer.cgi?path=rocketmq/4.3.2/rocketmq-all-4.3.2-bin-release.zip&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;gt; unzip rocketmq-all-4.3.2-source-release.zip&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;gt; cd rocketmq-all-4.3.2/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;gt; mvn -Prelease-all -DskipTests clean install -U&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;gt; cd distribution/target/apache-rocketmq&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="java" scheme="https://www.wuxinvip.com/categories/java/"/>
    
      <category term="message-queue" scheme="https://www.wuxinvip.com/categories/java/message-queue/"/>
    
      <category term="rocketmq" scheme="https://www.wuxinvip.com/categories/java/message-queue/rocketmq/"/>
    
    
      <category term="RocketMQ" scheme="https://www.wuxinvip.com/tags/RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>rocketmq简介</title>
    <link href="https://www.wuxinvip.com/2018/12/05/message-queue/rocketmq/01/"/>
    <id>https://www.wuxinvip.com/2018/12/05/message-queue/rocketmq/01/</id>
    <published>2018-12-05T00:00:00.000Z</published>
    <updated>2018-12-09T13:40:17.866Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><ul><li>互联网应用拆分为微服务、解决各个微服务模块的互相通信问题、并能够提供大流量技术支撑</li></ul><a id="more"></a><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><ul><li>微服务之间的通信问题<ul><li>具体的业务场景有很多、比如、支付完成后的订单状态修改、用户充值后的vip等级提升、物流信息等等</li><li>各个微服务之间的消息、业务场景有：按实时性可分为实时消息、非实时消息；</li></ul></li></ul><h2 id="组成部件"><a href="#组成部件" class="headerlink" title="组成部件"></a>组成部件</h2><ul><li>rocketmq 有两个部件 nameserver：服务管理中心、broker：消息存储中心<ul><li>nameserver管理业务服务注册、保证服务稳定运行</li><li>broker负责消息的持久化、保证消息不丢失</li></ul></li></ul><h2 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h2><ul><li>应用解耦<ul><li>替换应用上的https协议、又能保证服务之间的动态性</li></ul></li><li>流量削峰<ul><li>非即时消息、延后处理</li></ul></li><li>消息分发<ul><li>消息生产者只负责消息生产、消息消费者只负责消息消费、只管把消息发到消息队列、而不关心、哪台服务消费这个消息</li><li>消息轮询消费、不会造成只在某一台机器上消费、压跨服务器</li></ul></li><li>保证分布式事务的最终一致性</li><li>动态扩容</li></ul><h2 id="发展"><a href="#发展" class="headerlink" title="发展"></a>发展</h2><ul><li>目前已是apache的顶级项目、</li><li>2017年双十一的主要驱动力、处理消息万亿级别、tps:5600万</li><li>java语言开发、对java开发者亲和度较高</li></ul><h2 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h2><ul><li><p>rocketmq、rabbitmq、kafka</p><ul><li>没有谁好谁坏</li><li>kafka起源最早、解决消息流处理问题、最早解决监控平台对各个服务模块的消息监控、</li><li>rabbitmq、采用AMQP协议开发、建立了最早的消息模型、定义了消息驱动模式、</li><li>rocketmq、类似于kafka、不过语言是java、经历了阿里的双十一足以证明它的性能。</li></ul></li><li><p>个人见解</p><ul><li>吞吐量优先、消息丢失小事、选择kafka、kafka的吞吐量要强一个量级</li><li>稳定不丢消息：rocketmq、tabbitmq、</li><li>rabbitmq底层是erlang语言、erlang语言特性、并发性能优秀、</li><li>rocketmq底层netty、异步机制优秀</li><li>实时性要求高、同时又要求高的吞吐量 rabbitmq</li><li>非实时性要求高、同时又要求高吞吐量 rocketmq</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;互联网应用拆分为微服务、解决各个微服务模块的互相通信问题、并能够提供大流量技术支撑&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="java" scheme="https://www.wuxinvip.com/categories/java/"/>
    
      <category term="message-queue" scheme="https://www.wuxinvip.com/categories/java/message-queue/"/>
    
      <category term="rocketmq" scheme="https://www.wuxinvip.com/categories/java/message-queue/rocketmq/"/>
    
    
      <category term="RocketMQ" scheme="https://www.wuxinvip.com/tags/RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>app版本更新</title>
    <link href="https://www.wuxinvip.com/2018/12/04/version/version-1/"/>
    <id>https://www.wuxinvip.com/2018/12/04/version/version-1/</id>
    <published>2018-12-04T00:00:00.000Z</published>
    <updated>2018-12-10T02:27:09.033Z</updated>
    
    <content type="html"><![CDATA[<p>app版本更新 </p><h2 id="v1-1-0"><a href="#v1-1-0" class="headerlink" title="v1.1.0"></a>v1.1.0</h2><ul><li><a href="https://github.com/wuxinvip/wuxinvip.github.io/releases/download/1.1.0/com.wuxinvip.blog_v1.1.0.apk" target="_blank" rel="noopener">下载地址</a></li><li>新增分享功能</li><li>更新微信分享 选择性微信朋友圈和微信好友分享</li><li>修复返回直接退出问题</li></ul><h2 id="v1-0-0"><a href="#v1-0-0" class="headerlink" title="v1.0.0"></a>v1.0.0</h2><ul><li><a href="https://github.com/wuxinvip/wuxinvip.github.io/releases/download/1.0.0/com.wuxinvip.blog.apk" target="_blank" rel="noopener">下载地址</a></li></ul><p><a href="https://gra.u2sk.com/?url=https://github.com/wuxinvip/wuxinvip.github.io" target="_blank" rel="noopener">下载次数</a></p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;app版本更新 &lt;/p&gt;
&lt;h2 id=&quot;v1-1-0&quot;&gt;&lt;a href=&quot;#v1-1-0&quot; class=&quot;headerlink&quot; title=&quot;v1.1.0&quot;&gt;&lt;/a&gt;v1.1.0&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/wuxinvip/wuxinvip.github.io/releases/download/1.1.0/com.wuxinvip.blog_v1.1.0.apk&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;下载地址&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;新增分享功能&lt;/li&gt;
&lt;li&gt;更新微信分享 选择性微信朋友圈和微信好友分享&lt;/li&gt;
&lt;li&gt;修复返回直接退出问题&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;v1-0-0&quot;&gt;&lt;a href=&quot;#v1-0-0&quot; class=&quot;headerlink&quot; title=&quot;v1.0.0&quot;&gt;&lt;/a&gt;v1.0.0&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/wuxinvip/wuxinvip.github.io/releases/download/1.0.0/com.wuxinvip.blog.apk&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;下载地址&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&quot;https://gra.u2sk.com/?url=https://github.com/wuxinvip/wuxinvip.github.io&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;下载次数&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="app" scheme="https://www.wuxinvip.com/categories/app/"/>
    
      <category term="version" scheme="https://www.wuxinvip.com/categories/app/version/"/>
    
    
      <category term="app版本更新" scheme="https://www.wuxinvip.com/tags/app%E7%89%88%E6%9C%AC%E6%9B%B4%E6%96%B0/"/>
    
  </entry>
  
  <entry>
    <title>kafka构建数据管道需要注意的问题</title>
    <link href="https://www.wuxinvip.com/2018/12/01/message-queue/kafka/09/"/>
    <id>https://www.wuxinvip.com/2018/12/01/message-queue/kafka/09/</id>
    <published>2018-12-01T00:00:00.000Z</published>
    <updated>2018-12-09T12:54:33.514Z</updated>
    
    <content type="html"><![CDATA[<h2 id="kafka构建数据管道需要注意的问题"><a href="#kafka构建数据管道需要注意的问题" class="headerlink" title="kafka构建数据管道需要注意的问题"></a>kafka构建数据管道需要注意的问题</h2><ul><li>及时性</li><li>可靠性</li><li>高吞吐量和动态吞吐量</li><li>数据格式</li><li>转换</li><li>安全性</li><li>故障处理能力</li><li>耦合性和灵活性</li></ul><a id="more"></a><h2 id="及时性"><a href="#及时性" class="headerlink" title="及时性"></a>及时性</h2><ul><li>在业务需求变更时、具有不同及时性需求的数据之间可以方便的进行迁移</li><li>数据支持实时性处理、也支持延迟批处理</li><li>消费者可以实时拉取处理、也可以延迟批量处理一批数据</li></ul><h2 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h2><ul><li>能够在各种故障中快速回复</li><li>支持、至少一次传递【本身支持】</li><li>支持、仅一次传递、避免幂等消费【需结合实物模型或者唯一键特性的外部存储系统】</li></ul><h2 id="高吞吐量和动态吞吐量"><a href="#高吞吐量和动态吞吐量" class="headerlink" title="高吞吐量和动态吞吐量"></a>高吞吐量和动态吞吐量</h2><ul><li>自动伸缩功能</li><li>管理员可以调整压缩来网络和存储资源的使用【支持多种类型压缩】</li></ul><h2 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h2><ul><li>avro、xml也可以使用自定义</li><li>读取数据源schema载入数据</li></ul><h2 id="转换"><a href="#转换" class="headerlink" title="转换"></a>转换</h2><ul><li>ETL【提取、转换、加载】<ul><li>过滤掉部分数据、为下游服务过滤不必要数据信息</li><li>缺点、下游的调整可能需要重新调整数据管道</li></ul></li><li>ELT【提取、加载、转换】<ul><li>高保真数据管道、数据湖结构</li><li>占用了目标系统太多的CPU和存储资源、使得目标系统造价高昂、不过也给下游保证了最原始的数据、利于调整需求</li></ul></li></ul><h2 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h2><ul><li>支持加密数据、</li><li>支持认证【SASL实现】、授权消费</li><li>支持数据追踪、时间来源、事件修改者、日志审计、访问记录</li></ul><h2 id="故障处理能力"><a href="#故障处理能力" class="headerlink" title="故障处理能力"></a>故障处理能力</h2><ul><li>数据保留一周、一月、任意时间以便于追溯</li></ul><h2 id="耦合性和灵活性"><a href="#耦合性和灵活性" class="headerlink" title="耦合性和灵活性"></a>耦合性和灵活性</h2><ul><li><p>临时数据管道</p><ul><li>常用数据管道<ul><li>logstash—–&gt; elasticsearch</li><li>flume——&gt; HDFS</li><li>GoldenGate——&gt;Oracle</li><li>mysql【xml】——–&gt;Informatica——-&gt;oracle</li><li>当有新的需求时候有需要重新构建新的管道、增加新技术成本</li></ul></li></ul></li><li><p>元数据丢失</p><ul><li>元数据没有保留schema数据、导致数据交换过程中、没有处理元数据新增字段【因为新的schema中没有该字段】</li><li>而如果数据管道允许修改schema信息、那么双方只需要修改内部数据处理就可以了</li></ul></li><li><p>末端处理</p><ul><li>让下端可以自己决定数据处理、而不是数据管道直接处理、直接处理会对下游数据的完整性造成破坏<br>同时新的需求更迭、也会造成成本提升</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;kafka构建数据管道需要注意的问题&quot;&gt;&lt;a href=&quot;#kafka构建数据管道需要注意的问题&quot; class=&quot;headerlink&quot; title=&quot;kafka构建数据管道需要注意的问题&quot;&gt;&lt;/a&gt;kafka构建数据管道需要注意的问题&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;及时性&lt;/li&gt;
&lt;li&gt;可靠性&lt;/li&gt;
&lt;li&gt;高吞吐量和动态吞吐量&lt;/li&gt;
&lt;li&gt;数据格式&lt;/li&gt;
&lt;li&gt;转换&lt;/li&gt;
&lt;li&gt;安全性&lt;/li&gt;
&lt;li&gt;故障处理能力&lt;/li&gt;
&lt;li&gt;耦合性和灵活性&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="java" scheme="https://www.wuxinvip.com/categories/java/"/>
    
      <category term="message-queue" scheme="https://www.wuxinvip.com/categories/java/message-queue/"/>
    
      <category term="kafka" scheme="https://www.wuxinvip.com/categories/java/message-queue/kafka/"/>
    
    
      <category term="kafka" scheme="https://www.wuxinvip.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka集群复制</title>
    <link href="https://www.wuxinvip.com/2018/11/30/message-queue/kafka/08/"/>
    <id>https://www.wuxinvip.com/2018/11/30/message-queue/kafka/08/</id>
    <published>2018-11-30T00:00:00.000Z</published>
    <updated>2018-12-07T08:29:04.669Z</updated>
    
    <content type="html"><![CDATA[<ul><li>kafka集群复制</li><li>kafka数据结构</li><li>kafka请求处理流程</li><li>kafka消息格式</li></ul><a id="more"></a><h2 id="kafka集群复制"><a href="#kafka集群复制" class="headerlink" title="kafka集群复制"></a>kafka集群复制</h2><h3 id="kafka数据结构"><a href="#kafka数据结构" class="headerlink" title="kafka数据结构"></a>kafka数据结构</h3><ul><li>kafka是以主题来组织数据</li><li>每个主题下有多个分区、每个分区下有多个副本【数据元】、</li><li>【玩过 mongodb 和 elasticsearch 的一看就懂、一个东西】</li><li>每个broker可以存储不同主题和不同分区的副本</li><li>副本分为两种<ul><li>首领副本【数据存储、对接客户端请求、消费】</li><li>跟随者副本【数据备份、不处理来自客户端的任何请求、待首领挂掉、迅速顶上】</li><li>另、首领还会处理副本的备份请求、以判断哪个副本是最新的、最新的版本才可以当“储君”</li></ul></li></ul><h4 id="图纸解说"><a href="#图纸解说" class="headerlink" title="图纸解说"></a>图纸解说</h4><p><img src="/img/kafka/04.png" alt="kafka储存结构"></p><ul><li>照了一张差不多的图、不是kafka的、是es的 不过解释起来足够了</li><li>主节点 node3、为broker协调者</li><li>所有数据都是一个主题topic通过tag来区分数据【一般一个应用要给同topic、这里就当1个多个tag、】</li><li>每个tag下有很多数据、每个数据有多个副本、【这里配置就2个、一个首领副本、一个跟随着副本】</li></ul><h3 id="kafka请求处理流程"><a href="#kafka请求处理流程" class="headerlink" title="kafka请求处理流程"></a>kafka请求处理流程</h3><h4 id="图纸解说-1"><a href="#图纸解说-1" class="headerlink" title="图纸解说"></a>图纸解说</h4><p><img src="/img/kafka/05.jpg" alt="kafka请求流程"></p><ul><li>请求通过processor线程发向请求队列、处理IO逻辑、将响应发向响应队列</li></ul><h3 id="kafka消息格式"><a href="#kafka消息格式" class="headerlink" title="kafka消息格式"></a>kafka消息格式</h3><ul><li>Request type 【API key】</li><li>Request version 【version版本号】</li><li>Correlation ID【消息唯一id】</li><li>Client ID【客户端唯一id】</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;kafka集群复制&lt;/li&gt;
&lt;li&gt;kafka数据结构&lt;/li&gt;
&lt;li&gt;kafka请求处理流程&lt;/li&gt;
&lt;li&gt;kafka消息格式&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="java" scheme="https://www.wuxinvip.com/categories/java/"/>
    
      <category term="message-queue" scheme="https://www.wuxinvip.com/categories/java/message-queue/"/>
    
      <category term="kafka" scheme="https://www.wuxinvip.com/categories/java/message-queue/kafka/"/>
    
    
      <category term="kafka" scheme="https://www.wuxinvip.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka消费者接收和配置</title>
    <link href="https://www.wuxinvip.com/2018/11/29/message-queue/kafka/07/"/>
    <id>https://www.wuxinvip.com/2018/11/29/message-queue/kafka/07/</id>
    <published>2018-11-29T00:00:00.000Z</published>
    <updated>2018-12-07T07:50:05.892Z</updated>
    
    <content type="html"><![CDATA[<ul><li>kafka消息接收方式</li><li>kafka消息偏移量提交</li><li><p>kafka序列化</p></li><li><p>kafka消费者配置</p></li></ul><a id="more"></a><h2 id="kafka消息接收方式"><a href="#kafka消息接收方式" class="headerlink" title="kafka消息接收方式"></a>kafka消息接收方式</h2><ul><li>kafka有两种消息接收方式、1:主动拉取、2:服务器端推送</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * kafka消费者</span><br><span class="line"> */</span><br><span class="line">public void test04() &#123;</span><br><span class="line">    Properties properties = new Properties();</span><br><span class="line">    properties.put(&quot;bootstrap.servers&quot;, &quot;broker1:9002,broker2:9002&quot;);</span><br><span class="line">    properties.put(&quot;group.id&quot;, &quot;CountryCounter&quot;);</span><br><span class="line">    properties.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span><br><span class="line">    properties.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span><br><span class="line">    KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">    //订阅主题</span><br><span class="line">    consumer.subscribe(Collections.singletonList(&quot;customerCountries&quot;));</span><br><span class="line">    //订阅所有主题</span><br><span class="line">    consumer.subscribe(Collections.singletonList(&quot;test.*&quot;));</span><br><span class="line"></span><br><span class="line">    try &#123;</span><br><span class="line">        while (true) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);</span><br><span class="line">            for (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                logger.debug(&quot;topic=%s,partition=%s,offset=%d,constomer=%s,country=%s\n&quot;,</span><br><span class="line">                        record.topic(),record.partition(),record.offset(),record.key(),record.value());</span><br><span class="line"></span><br><span class="line">                //todo 执行消费逻辑</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="kafka消息偏移量提交"><a href="#kafka消息偏移量提交" class="headerlink" title="kafka消息偏移量提交"></a>kafka消息偏移量提交</h2><ul><li>提交已处理消息标记位</li></ul><h2 id="kafka序列化"><a href="#kafka序列化" class="headerlink" title="kafka序列化"></a>kafka序列化</h2><ul><li>kafka使用avro序列化</li><li>可以看这边文章、<a href="https://www.wuxinvip.com/2018/11/10/essay/avro/">Apache Avro</a></li></ul><h2 id="kafka消费者配置"><a href="#kafka消费者配置" class="headerlink" title="kafka消费者配置"></a>kafka消费者配置</h2><ul><li>fetch.min.bytes<ul><li>指定消费者从服务器获取记录的最小字节数</li></ul></li><li>fetch.max.wait.ms<ul><li>累积多少时间把数据返还给消费者</li><li>数值大、吞吐量大、延迟高、</li><li>数值小、吞吐量小、延迟低、</li></ul></li><li><p>max.partition.fetch.bytes</p><ul><li>指定每个分区返给消费者的最大字节数、默认值1MB</li><li>如果有20个分区、5个消费者、那么这里就可以配置4MB</li><li>该值一定要大于broker能够接收数据最大值、否则会一直挂起重试</li></ul></li><li><p>session.timeout.ms</p><ul><li>指定消费者在被认为死亡之前可以与服务器断开连接时间、默认3s</li><li>如果规定时间内没有发送心跳、认为死亡、触发再均衡</li></ul></li><li><p>auto.offset.reset</p><ul><li>指定 消费者在读取一个没有偏移量的分区或者偏移量无效情况下（因消费者长时间失效、包含偏移量的记录已经过时并被删除）该如何处理</li><li>默认值 latest、最新数据</li><li>earliest 在偏移量无效情况下、消费者将从起始位置读取分区记录【幂等消费？】</li></ul></li><li><p>enable.auto.commit</p><ul><li>指定消费者是否自动提交偏移量 默认值true</li></ul></li><li><p>partition.assignment.strategy</p><ul><li>指定分配主题分区给消费者的分配策略</li><li>Range   轮询、如果分区数量大于消费者数量、那么排在前面的消费者会被分配到更多的分区</li><li>RoundRobin  给消费者分配更加平等数量的分区、或者最多小差一个分区</li></ul></li><li><p>client.id</p><ul><li>分区id 标识分区唯一、以及客户端、识别消息、也被用在日志和度量指标和配额里</li></ul></li><li><p>max.poll.records</p><ul><li>指定单次调用call()方法能够返回的记录数量</li></ul></li><li><p>receive.buffer.bytes、send.buffer.bytes</p><ul><li>socket在读写数据时用到的TCP缓冲区 -1使用系统默认值</li><li>如果消费者和生产者不再统一数据中心内、可以适当增大该值</li></ul></li></ul><h2 id="kafka消费者注意点"><a href="#kafka消费者注意点" class="headerlink" title="kafka消费者注意点"></a>kafka消费者注意点</h2><ul><li>消费者数量大于主题分区数量、否则消费者会被闲置；比如5个主题分区、4个消费者、那么会有一个主题分区会被闲置</li></ul><ul><li>再均衡<ul><li>分区所有权从一个消费者转移到另一个消费者、这样的行为被称为再均衡</li><li>再均衡期间、消费者不能消费消息</li><li>也是这样的设置、能是消费者分区能动态增减</li><li>维持：消费者通过向消费者协调者broker发送心跳、来维持他们与群组的从属关系以及他们对分区的所有权关系</li><li>消费者死亡、消费协调者broker会等待几秒钟、确认死亡后会触发再均衡</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;kafka消息接收方式&lt;/li&gt;
&lt;li&gt;kafka消息偏移量提交&lt;/li&gt;
&lt;li&gt;&lt;p&gt;kafka序列化&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;kafka消费者配置&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="java" scheme="https://www.wuxinvip.com/categories/java/"/>
    
      <category term="message-queue" scheme="https://www.wuxinvip.com/categories/java/message-queue/"/>
    
      <category term="kafka" scheme="https://www.wuxinvip.com/categories/java/message-queue/kafka/"/>
    
    
      <category term="kafka" scheme="https://www.wuxinvip.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka生产者发送和配置</title>
    <link href="https://www.wuxinvip.com/2018/11/28/message-queue/kafka/06/"/>
    <id>https://www.wuxinvip.com/2018/11/28/message-queue/kafka/06/</id>
    <published>2018-11-28T00:00:00.000Z</published>
    <updated>2018-12-06T08:59:54.351Z</updated>
    
    <content type="html"><![CDATA[<ul><li>kafka消息发送</li><li>kafka消息同步发送</li><li><p>kafka消息异步发送</p></li><li><p>kafka生产者配置</p></li></ul><a id="more"></a><h2 id="kafka消息发送"><a href="#kafka消息发送" class="headerlink" title="kafka消息发送"></a>kafka消息发送</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">     * 最简单发送</span><br><span class="line">     */</span><br><span class="line">    public void test01() &#123;</span><br><span class="line">        ProducerRecord&lt;String, String&gt; record =</span><br><span class="line">                new ProducerRecord&lt;&gt;(&quot;CustomerCountory&quot;, &quot;Precision Products&quot;, &quot;France&quot;);</span><br><span class="line">        try &#123;</span><br><span class="line">            producer.send(record);</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="kafka消息同步发送"><a href="#kafka消息同步发送" class="headerlink" title="kafka消息同步发送"></a>kafka消息同步发送</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * kafka同步发送</span><br><span class="line"> */</span><br><span class="line">public void test02() &#123;</span><br><span class="line">    ProducerRecord&lt;String, String&gt; record =</span><br><span class="line">            new ProducerRecord&lt;&gt;(&quot;CustomerCountory&quot;, &quot;Precision Products&quot;, &quot;France&quot;);</span><br><span class="line">    try &#123;</span><br><span class="line">        Future result = producer.send(record);</span><br><span class="line">        result.get();</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="kafka消息异步发送"><a href="#kafka消息异步发送" class="headerlink" title="kafka消息异步发送"></a>kafka消息异步发送</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * kafka 异步发送</span><br><span class="line"> */</span><br><span class="line">public void test03()&#123;</span><br><span class="line">    ProducerRecord&lt;String, String&gt; record =</span><br><span class="line">            new ProducerRecord&lt;&gt;(&quot;CustomerCountory&quot;, &quot;Precision Products&quot;, &quot;France&quot;);</span><br><span class="line">    try&#123;</span><br><span class="line">        Future result = producer.send(record,new DemoProducerCallback());</span><br><span class="line">        result.get();</span><br><span class="line">    &#125;catch(Exception e)&#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class DemoProducerCallback implements Callback &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public void onCompletion(RecordMetadata recordMetadata, Exception e) &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="kafka生产者配置"><a href="#kafka生产者配置" class="headerlink" title="kafka生产者配置"></a>kafka生产者配置</h2><ul><li><p>acks</p><ul><li>acks = 0<ul><li>不回调通知</li></ul></li><li>acks = a<ul><li>只保存首领节点、即返回消息确认</li></ul></li><li>acks = all<ul><li>保存首领节点和所有副节点后、即返回消息确认</li></ul></li></ul></li><li><p>buffer.memory</p><ul><li>设置生产者内存缓存大小、生产者又来缓冲发送到服务器的消息、</li><li>0.9.00版本中、被替换为max.block.ms 表示抛出异常前可以阻塞一段时间</li></ul></li><li><p>compression.type</p><ul><li>消息压缩、可设置为snappy、gzip、lz4</li><li>指定消息被发送给broker之前使用哪一种压缩算法进行压缩</li></ul></li><li><p>retries</p><ul><li>重试次数</li><li>默认每次重试等待100ms、可以通过retry.backoff.ms 设置</li><li>一般首领选举中易发生重试、建议该时间大于选举时间、崩溃恢复时间长等</li></ul></li><li><p>batch.size</p><ul><li>消息批次大小、累积到一定大小发送消息</li></ul></li><li><p>linger.ms</p><ul><li>指定生产者在发送批次之前等待更多消息加入批次时间</li><li>消息发送两个控制点、一个是累计大小、一个是这个时间、规定时间内没有达到累积值、也要发送消息</li></ul></li><li><p>client.id</p><ul><li>可以设置任意字符串</li><li>服务器用来判断消息来源、用来标记消息</li></ul></li><li><p>max.in.flight.requests.pre.connection</p><ul><li>指定、生产者在受到服务器响应之前可以发送多少个消息、</li><li>值越高、就会占用更多内存、也会提升吞吐量、</li><li>设置为1 可保证消息桉顺序写入broker服务器</li></ul></li><li><p>timeout.ms、request.timeout.ms、metadata.fetch.timeout.ms</p><ul><li>timeout.ms 生产者发送数据时等待服务器返回响应时间</li><li>request.timeout.ms 指定生产者在获取元数据（比如broker首领是谁）等待服务器返回响应时间、超时重试</li><li>metadata.fetch.timeout.ms 指定 broker等待同步副本返回消息确认时间、超时认为失败</li></ul></li></ul><ul><li><p>max.block.ms</p><ul><li>指定调用send方法或者使用partitionFor()方法获取元数据生产者的阻塞时间</li><li>超时抛出异常</li></ul></li><li><p>max.request.size</p><ul><li>控制生产者发送消息大小、单个请求大小、单个请求中一个批次消息的总大小</li></ul></li><li><p>receive.buffer.bytes、send.buffer.bytes</p><ul><li>tcp、socket的接收和发送缓冲区大小</li></ul></li></ul><ul><li>kafka顺序<ul><li>可设置max.in.flight.request.pre.connection = 1、但会严重影响吞吐量</li><li>这点或许rabbitmq和rocketmq做的更好</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;kafka消息发送&lt;/li&gt;
&lt;li&gt;kafka消息同步发送&lt;/li&gt;
&lt;li&gt;&lt;p&gt;kafka消息异步发送&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;kafka生产者配置&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="java" scheme="https://www.wuxinvip.com/categories/java/"/>
    
      <category term="message-queue" scheme="https://www.wuxinvip.com/categories/java/message-queue/"/>
    
      <category term="kafka" scheme="https://www.wuxinvip.com/categories/java/message-queue/kafka/"/>
    
    
      <category term="kafka" scheme="https://www.wuxinvip.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka数据流向图</title>
    <link href="https://www.wuxinvip.com/2018/11/27/message-queue/kafka/05/"/>
    <id>https://www.wuxinvip.com/2018/11/27/message-queue/kafka/05/</id>
    <published>2018-11-27T00:00:00.000Z</published>
    <updated>2018-12-06T07:29:54.724Z</updated>
    
    <content type="html"><![CDATA[<ul><li>kafka简单集群</li><li>kafka生产者</li><li>kafka消费者</li></ul><a id="more"></a><h2 id="kafka简单集群"><a href="#kafka简单集群" class="headerlink" title="kafka简单集群"></a>kafka简单集群</h2><p><img src="/img/kafka/01.jpg" alt="kafka简单集群"></p><h2 id="kafka生产者"><a href="#kafka生产者" class="headerlink" title="kafka生产者"></a>kafka生产者</h2><p><img src="/img/kafka/02.jpg" alt="kafka简单集群"></p><h2 id="kafka消费者"><a href="#kafka消费者" class="headerlink" title="kafka消费者"></a>kafka消费者</h2><p><img src="/img/kafka/03.jpg" alt="kafka简单集群"></p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;kafka简单集群&lt;/li&gt;
&lt;li&gt;kafka生产者&lt;/li&gt;
&lt;li&gt;kafka消费者&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="java" scheme="https://www.wuxinvip.com/categories/java/"/>
    
      <category term="message-queue" scheme="https://www.wuxinvip.com/categories/java/message-queue/"/>
    
      <category term="kafka" scheme="https://www.wuxinvip.com/categories/java/message-queue/kafka/"/>
    
    
      <category term="kafka" scheme="https://www.wuxinvip.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka集群</title>
    <link href="https://www.wuxinvip.com/2018/11/26/message-queue/kafka/04/"/>
    <id>https://www.wuxinvip.com/2018/11/26/message-queue/kafka/04/</id>
    <published>2018-11-26T00:00:00.000Z</published>
    <updated>2018-12-06T08:58:52.997Z</updated>
    
    <content type="html"><![CDATA[<ul><li>需要多少个broker</li><li>broker配置</li><li>操作系统调优<ul><li>虚拟内存</li><li>磁盘</li><li>网络</li></ul></li></ul><a id="more"></a><h2 id="需要多少个broker"><a href="#需要多少个broker" class="headerlink" title="需要多少个broker"></a>需要多少个broker</h2><ul><li>两个因素：需要多少磁盘空间来保留数据、单个broker有多少空间可用</li><li>例：复制系数为1，整个集群要保留10TB数据、每个broker可以保留2TB、那么需要5个broker、复制系数为2，那就需要10个broker</li></ul><h2 id="broker配置"><a href="#broker配置" class="headerlink" title="broker配置"></a>broker配置</h2><ul><li>两个必须配置项：zookeeper.connect 、broker.id </li><li>整个集群连接一个服务管理中心、每个broker.id 集群内唯一、如果重复第二个启动会失败</li></ul><h2 id="操作系统调优"><a href="#操作系统调优" class="headerlink" title="操作系统调优"></a>操作系统调优</h2><ul><li><p>虚拟内存</p><ul><li>kafkaa会利用虚拟机内存做页面缓存、减少与磁盘交互数据、减小延迟</li><li>一般虚拟内存都会根据软件所需内存分配内存、如果分配不到了就是没有更多内存了</li></ul></li><li><p>磁盘</p><ul><li>EXT4</li><li>XFS：提供更好的性能、不需要额外的调优、批量磁盘写入具有更高的效率、可以提升整体IO吞吐量,现linux发行版多采用该磁盘、较少的调优可以获取更大的工作负荷</li></ul></li><li><p>网络</p><ul><li>tcp缓冲区</li><li>socket缓冲区</li><li>tcp时间窗 可以增加客户端传输数据效率、</li><li>net.ipv4.tcp_max_syn_backlog设置大于1024 可以接收更多的并发连接</li><li>net.core.netdev_max_backlog设置大于1000 有助于应对网络流量爆发、能允许更多的数据包排队等待内核处理</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;需要多少个broker&lt;/li&gt;
&lt;li&gt;broker配置&lt;/li&gt;
&lt;li&gt;操作系统调优&lt;ul&gt;
&lt;li&gt;虚拟内存&lt;/li&gt;
&lt;li&gt;磁盘&lt;/li&gt;
&lt;li&gt;网络&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="java" scheme="https://www.wuxinvip.com/categories/java/"/>
    
      <category term="message-queue" scheme="https://www.wuxinvip.com/categories/java/message-queue/"/>
    
      <category term="kafka" scheme="https://www.wuxinvip.com/categories/java/message-queue/kafka/"/>
    
    
      <category term="kafka" scheme="https://www.wuxinvip.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka硬件选择</title>
    <link href="https://www.wuxinvip.com/2018/11/25/message-queue/kafka/03/"/>
    <id>https://www.wuxinvip.com/2018/11/25/message-queue/kafka/03/</id>
    <published>2018-11-25T00:00:00.000Z</published>
    <updated>2018-12-06T08:58:26.674Z</updated>
    
    <content type="html"><![CDATA[<ul><li>磁盘吞吐量</li><li>磁盘容量</li><li>内存</li><li>网络</li><li>CPU</li></ul><a id="more"></a><h2 id="磁盘吞吐量"><a href="#磁盘吞吐量" class="headerlink" title="磁盘吞吐量"></a>磁盘吞吐量</h2><ul><li>直接因素-影响生产者</li><li>磁盘写入越快、生成消息延迟越低</li></ul><h2 id="磁盘容量"><a href="#磁盘容量" class="headerlink" title="磁盘容量"></a>磁盘容量</h2><ul><li>如果每天存储消息量为1TB 、保存周期为7天、那么就需要7TB</li><li>除此之外还要保留10%额外空间</li></ul><h2 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h2><ul><li>直接因素-影像消费者</li><li>运行kafka不需要jvm太大内存、大部分内存作为页面缓存、或者kafka日志片段</li><li>内存过低会影响消费者性能</li></ul><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><ul><li>直接因素-影响吞吐量</li><li>当内存瓶颈和磁盘瓶颈不存在的时候、如果网络服务接口成为瓶颈也会大大降低消费者和生产者的性能</li></ul><h2 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h2><ul><li>kafka对cpu性能要求较低、但也不是随便就能糊弄</li><li>kafka有自己的消息压缩和解压、都需要使用cpu进行计算</li><li>另 无论什么时候cpu都涉及到并发性能</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;磁盘吞吐量&lt;/li&gt;
&lt;li&gt;磁盘容量&lt;/li&gt;
&lt;li&gt;内存&lt;/li&gt;
&lt;li&gt;网络&lt;/li&gt;
&lt;li&gt;CPU&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="java" scheme="https://www.wuxinvip.com/categories/java/"/>
    
      <category term="message-queue" scheme="https://www.wuxinvip.com/categories/java/message-queue/"/>
    
      <category term="kafka" scheme="https://www.wuxinvip.com/categories/java/message-queue/kafka/"/>
    
    
      <category term="kafka" scheme="https://www.wuxinvip.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka安装</title>
    <link href="https://www.wuxinvip.com/2018/11/24/message-queue/kafka/02/"/>
    <id>https://www.wuxinvip.com/2018/11/24/message-queue/kafka/02/</id>
    <published>2018-11-24T00:00:00.000Z</published>
    <updated>2018-12-05T09:58:10.323Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://kafka.apache.org/" target="_blank" rel="noopener">官网</a></p><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">##前置</span><br><span class="line">java、zookeeper</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">wget http://mirror.bit.edu.cn/apache/kafka/2.1.0/kafka_2.12-2.1.0.tgz</span><br><span class="line"></span><br><span class="line">or</span><br><span class="line"></span><br><span class="line">curl -L -O http://mirror.bit.edu.cn/apache/kafka/2.1.0/kafka_2.12-2.1.0.tgz</span><br><span class="line"></span><br><span class="line">tar -zxvf kafka_2.12-2.1.0.tgz</span><br><span class="line"></span><br><span class="line">cd kafka_2.12-2.1.0/bin</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">./kafka-server-start.sh -daemon</span><br><span class="line"></span><br><span class="line">./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#test 主题上发布消息</span><br><span class="line">./kafka-console-producer.sh --broker-list localhost:9092 --topic test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#test 主题上接收消息</span><br><span class="line">./kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning</span><br></pre></td></tr></table></figure><h2 id="broker配置"><a href="#broker配置" class="headerlink" title="broker配置"></a>broker配置</h2><p>1、broker.id</p><ul><li>集群唯一 整数</li></ul><p>2、port</p><ul><li>端口</li></ul><p>3、zookeeper.connect</p><ul><li>zk连接地址</li></ul><p>4、log.dirs</p><ul><li>log地址</li></ul><p>5、num.recovery.threads.pre.data.dir</p><ul><li>配置线程处理日志片段<ul><li>服务器正常启动、用于打开每个分区的日志片段</li><li>服务器崩溃后重启、用于检查和截短每个分区的日志片段</li><li>服务器正常关闭、用于关闭日志片段</li></ul></li></ul><p>默认每个日志目录只用一个线程、如果配置了num.recovery.threads.pre.data.dir=8<br>那么如果有3个log.dir 那么就需要24个线程</p><p>6、auto.create.topics.enable</p><ul><li>默认情况下、kafka会在以下三种情况下自动创建主题<ul><li>当一个生产者开始往主题写入消息时</li><li>当一个消费者开始从主题读取消息时</li><li>当任意一个客户端向主题发送元数据请求时</li></ul></li></ul><p>如果已经显示的创建主题、那么这里可以配置为auto.create.topics.enable=false</p><h2 id="topic默认配置"><a href="#topic默认配置" class="headerlink" title="topic默认配置"></a>topic默认配置</h2><p>1、num.partitions</p><ul><li>选定分区数量</li></ul><p>2、log.retention.ms</p><ul><li>根据时间保留数据和最后修改时间</li></ul><p>3、log.retention.bytes</p><ul><li>根据字节大小和时间保留数据</li></ul><p>4、log.segment.bytes</p><ul><li>使用时间戳获取偏移量</li></ul><p>5、log.segment.ms</p><ul><li>基于时间的日志片段和磁盘性能的影响</li></ul><p>6、message.max.bytes</p><ul><li>在服务端和客户端之间协调消息大小的配置</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://kafka.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官网&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;下载&quot;&gt;&lt;a href=&quot;#下载&quot; class=&quot;headerlink&quot; title=&quot;下载&quot;&gt;&lt;/a&gt;下载&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;##前置&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;java、zookeeper&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;wget http://mirror.bit.edu.cn/apache/kafka/2.1.0/kafka_2.12-2.1.0.tgz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;or&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;curl -L -O http://mirror.bit.edu.cn/apache/kafka/2.1.0/kafka_2.12-2.1.0.tgz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tar -zxvf kafka_2.12-2.1.0.tgz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cd kafka_2.12-2.1.0/bin&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="java" scheme="https://www.wuxinvip.com/categories/java/"/>
    
      <category term="message-queue" scheme="https://www.wuxinvip.com/categories/java/message-queue/"/>
    
      <category term="kafka" scheme="https://www.wuxinvip.com/categories/java/message-queue/kafka/"/>
    
    
      <category term="kafka" scheme="https://www.wuxinvip.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>rabbitmq简介</title>
    <link href="https://www.wuxinvip.com/2018/11/23/message-queue/rabbitmq/01/"/>
    <id>https://www.wuxinvip.com/2018/11/23/message-queue/rabbitmq/01/</id>
    <published>2018-11-23T00:00:00.000Z</published>
    <updated>2018-12-05T01:55:13.806Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h2 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h2><ul><li><p>rocketmq、rabbitmq、kafka</p><ul><li>没有谁好谁坏</li><li>kafka起源最早、解决消息流处理问题、最早解决监控平台对各个服务模块的消息监控、</li><li>rabbitmq、采用AMQP协议开发、建立了最早的消息模型、定义了消息驱动模式、</li><li>rocketmq、类似于kafka、不过语言是java、经历了阿里的双十一足以证明它的性能。</li></ul></li><li><p>个人见解</p><ul><li>吞吐量优先、消息丢失小事、选择kafka、kafka的吞吐量要强一个量级</li><li>稳定不丢消息：rocketmq、tabbitmq、</li><li>rabbitmq底层是erlang语言、erlang语言特性、并发性能优秀、</li><li>rocketmq底层netty、异步机制优秀</li><li>实时性要求高、同时又要求高的吞吐量 rabbitmq</li><li>非实时性要求高、同时又要求高吞吐量 rocketmq</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h2 id=&quot;技术选型&quot;&gt;&lt;a href=&quot;#技术选型&quot; class=&quot;headerlink&quot; title=&quot;技术选型&quot;&gt;&lt;/a&gt;技术选型&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;rocketmq、rabbitmq、kafka&lt;/p&gt;
&lt;ul&gt;
&lt;l
      
    
    </summary>
    
      <category term="java" scheme="https://www.wuxinvip.com/categories/java/"/>
    
      <category term="message-queue" scheme="https://www.wuxinvip.com/categories/java/message-queue/"/>
    
      <category term="rabbitmq" scheme="https://www.wuxinvip.com/categories/java/message-queue/rabbitmq/"/>
    
    
      <category term="RabbitMQ" scheme="https://www.wuxinvip.com/tags/RabbitMQ/"/>
    
  </entry>
  
  <entry>
    <title>kafka简介</title>
    <link href="https://www.wuxinvip.com/2018/11/23/message-queue/kafka/01/"/>
    <id>https://www.wuxinvip.com/2018/11/23/message-queue/kafka/01/</id>
    <published>2018-11-23T00:00:00.000Z</published>
    <updated>2018-12-06T08:57:46.316Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><ul><li>kafka最初为limkedIn的一个内部基础服务</li><li>最早的设计观念是、把数据看作流、消费者、订阅和发布各种各样的消息、这在大数据上应用非常广泛</li></ul><h2 id="组成部件"><a href="#组成部件" class="headerlink" title="组成部件"></a>组成部件</h2><ul><li>一个部件broker、每一个broker就是一个单独的服务器</li><li>每一个集群有一个broker作为集群控制器角色【分区选举】、与rocketmq区别是、rocketmq使用了nameserver作为注册中心</li><li>多级群中、kafka提供了一个mirrorMaker工具实现集群间消息复制</li><li>mirroMaker核心部分是一个生产者一个消费者、中间是一个队列、也是kafka的最基本原理、实际上在复杂的集群环境中、对于数据的可靠性更复杂些</li></ul><a id="more"></a><h2 id="发展"><a href="#发展" class="headerlink" title="发展"></a>发展</h2><ul><li>kafka的愿景做一个数据生态系统、提供消息发布和消息订阅、</li></ul><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><ul><li>活动跟踪、点击量</li><li>传递消息</li><li>度量指标和日志记录</li><li>提交日志</li><li>流处理<ul><li>结合hadoop做数据流的队列</li></ul></li></ul><h2 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h2><ul><li>rocketmq、rabbitmq、kafka<ul><li>没有谁好谁坏</li><li>kafka起源最早、解决消息流处理问题、最早解决监控平台对各个服务模块的消息监控、</li><li>rabbitmq、采用AMQP协议开发、建立了最早的消息模型、定义了消息驱动模式、</li><li>rocketmq、类似于kafka、不过语言是java、经历了阿里的双十一足以证明它的性能。</li></ul></li></ul><h2 id="个人见解"><a href="#个人见解" class="headerlink" title="个人见解"></a>个人见解</h2><ul><li>吞吐量优先、消息丢失小事、选择kafka、kafka的吞吐量要强一个量级</li><li>稳定不丢消息：rocketmq、tabbitmq、</li><li>rabbitmq底层是erlang语言、erlang语言特性、并发性能优秀、</li><li>rocketmq底层netty、异步机制优秀</li><li>实时性要求高、同时又要求高的吞吐量 rabbitmq</li><li>非实时性要求高、同时又要求高吞吐量 rocketmq</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;kafka最初为limkedIn的一个内部基础服务&lt;/li&gt;
&lt;li&gt;最早的设计观念是、把数据看作流、消费者、订阅和发布各种各样的消息、这在大数据上应用非常广泛&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;组成部件&quot;&gt;&lt;a href=&quot;#组成部件&quot; class=&quot;headerlink&quot; title=&quot;组成部件&quot;&gt;&lt;/a&gt;组成部件&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;一个部件broker、每一个broker就是一个单独的服务器&lt;/li&gt;
&lt;li&gt;每一个集群有一个broker作为集群控制器角色【分区选举】、与rocketmq区别是、rocketmq使用了nameserver作为注册中心&lt;/li&gt;
&lt;li&gt;多级群中、kafka提供了一个mirrorMaker工具实现集群间消息复制&lt;/li&gt;
&lt;li&gt;mirroMaker核心部分是一个生产者一个消费者、中间是一个队列、也是kafka的最基本原理、实际上在复杂的集群环境中、对于数据的可靠性更复杂些&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="java" scheme="https://www.wuxinvip.com/categories/java/"/>
    
      <category term="message-queue" scheme="https://www.wuxinvip.com/categories/java/message-queue/"/>
    
      <category term="kafka" scheme="https://www.wuxinvip.com/categories/java/message-queue/kafka/"/>
    
    
      <category term="kafka" scheme="https://www.wuxinvip.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>linux 删除命令 rm 改为 mv</title>
    <link href="https://www.wuxinvip.com/2018/11/15/shell/shell-5/"/>
    <id>https://www.wuxinvip.com/2018/11/15/shell/shell-5/</id>
    <published>2018-11-15T00:00:00.000Z</published>
    <updated>2018-11-22T03:14:15.079Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>非常实用</p></li><li><p>rm </p></li><li><p>Linux下修改rm命令为mv，使rm命令原有功能失效</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p ~/.trash   #在家目录下创建一个.trash文件夹</span><br><span class="line">alias rm=del        #使用别名del代替rm   </span><br><span class="line">del()               #函数del，作用：将rm命令修改为mv命令</span><br><span class="line">&#123;  </span><br><span class="line">  mv $@ ~/.trash/  </span><br><span class="line">&#125;  </span><br><span class="line">cleardel()          #函数cleardel，作用：清空回收站.trash文件夹，y或Y表示确认，n表示取消</span><br><span class="line">&#123;  </span><br><span class="line">    read -p &quot;clear sure?[Input &apos;y&apos; or &apos;Y&apos; to confirm. &amp;&amp; Input &apos;n&apos; to cancel.]&quot; confirm   </span><br><span class="line">    [ $confirm == &apos;y&apos; ] || [ $confirm == &apos;Y&apos; ]  &amp;&amp; /bin/rm -rf ~/.trash/*   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><a id="more"></a><p>然后 加载配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure><ul><li>清空回收站<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cleardel</span><br></pre></td></tr></table></figure></li></ul><p>注：rm命令已经删除，所以要彻底删除文件的话，可以先del删除文件到垃圾箱，然后进入~/.trash文件夹使用cleardel命令来彻底清除垃圾箱里的所有文件。</p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;&lt;p&gt;非常实用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;rm &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Linux下修改rm命令为mv，使rm命令原有功能失效&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;vim ~/.bashrc&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mkdir -p ~/.trash   #在家目录下创建一个.trash文件夹&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;alias rm=del        #使用别名del代替rm   &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;del()               #函数del，作用：将rm命令修改为mv命令&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  mv $@ ~/.trash/  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cleardel()          #函数cleardel，作用：清空回收站.trash文件夹，y或Y表示确认，n表示取消&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    read -p &amp;quot;clear sure?[Input &amp;apos;y&amp;apos; or &amp;apos;Y&amp;apos; to confirm. &amp;amp;&amp;amp; Input &amp;apos;n&amp;apos; to cancel.]&amp;quot; confirm   &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    [ $confirm == &amp;apos;y&amp;apos; ] || [ $confirm == &amp;apos;Y&amp;apos; ]  &amp;amp;&amp;amp; /bin/rm -rf ~/.trash/*   &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="shell" scheme="https://www.wuxinvip.com/categories/shell/"/>
    
    
      <category term="shell" scheme="https://www.wuxinvip.com/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>apache avro 序列化</title>
    <link href="https://www.wuxinvip.com/2018/11/10/essay/avro/"/>
    <id>https://www.wuxinvip.com/2018/11/10/essay/avro/</id>
    <published>2018-11-10T00:00:00.000Z</published>
    <updated>2018-11-21T06:23:20.444Z</updated>
    
    <content type="html"><![CDATA[<h2 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h2><p>当前序列化最常用的两种数据格式 json xml</p><h2 id="json"><a href="#json" class="headerlink" title="json"></a>json</h2><p><a href="https://zh.wikipedia.org/wiki/JSON" target="_blank" rel="noopener">wiki</a></p><p>常用包 jackson 、gson 【google】、fastjson【alibaba】</p><h2 id="xml"><a href="#xml" class="headerlink" title="xml"></a>xml</h2><p><a href="https://zh.wikipedia.org/wiki/XML" target="_blank" rel="noopener">XML</a><br>现在用的比较少、起源比json要早很多、有点类似与html<br>应该是依据html的dom树形式创建的一套信息序列化</p><p>现在不常用了，原因是占用文件大部分内容的都是标签语言、实际有效信息占比太少 </p><a id="more"></a><h2 id="Avro"><a href="#Avro" class="headerlink" title="Avro"></a>Avro</h2><p>最近看kafka 组件 解决 服务端与客户端序列化问题是 看到这种解决方案 avro</p><p>文中也提到要想实现一种自己的序列化格式太难、需要考虑版本兼容、服务消费端和服务提供者都对序列化样式兼容<br>文中推荐了这个序列化方式 Avro</p><p>另 之前在研究 es搜索引擎 对于es的sql也是使用avro序列化方式</p><p>可以说是比较不错的一种解决方案</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;namespace&quot;: &quot;com.wuxinvip.data&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;record&quot;,</span><br><span class="line">  &quot;name&quot;: &quot;User&quot;,</span><br><span class="line">  &quot;fields&quot;: [</span><br><span class="line">    &#123;&quot;name&quot;: &quot;name&quot;, &quot;type&quot;: &quot;string&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;: &quot;address&quot;, &quot;type&quot;: [&quot;string&quot;, &quot;null&quot;]&#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种序列化 采用了一种注册表方式 双方都从注册表中获取一个schema 标准<br>然后采用这种标准来解析数据<br>形式类似于json 不过补充了json在迭代上的不足</p><p><img src="/img/essay/img/avro.webp" alt="图片"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;序列化&quot;&gt;&lt;a href=&quot;#序列化&quot; class=&quot;headerlink&quot; title=&quot;序列化&quot;&gt;&lt;/a&gt;序列化&lt;/h2&gt;&lt;p&gt;当前序列化最常用的两种数据格式 json xml&lt;/p&gt;
&lt;h2 id=&quot;json&quot;&gt;&lt;a href=&quot;#json&quot; class=&quot;headerlink&quot; title=&quot;json&quot;&gt;&lt;/a&gt;json&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://zh.wikipedia.org/wiki/JSON&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;wiki&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;常用包 jackson 、gson 【google】、fastjson【alibaba】&lt;/p&gt;
&lt;h2 id=&quot;xml&quot;&gt;&lt;a href=&quot;#xml&quot; class=&quot;headerlink&quot; title=&quot;xml&quot;&gt;&lt;/a&gt;xml&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://zh.wikipedia.org/wiki/XML&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;XML&lt;/a&gt;&lt;br&gt;现在用的比较少、起源比json要早很多、有点类似与html&lt;br&gt;应该是依据html的dom树形式创建的一套信息序列化&lt;/p&gt;
&lt;p&gt;现在不常用了，原因是占用文件大部分内容的都是标签语言、实际有效信息占比太少 &lt;/p&gt;
    
    </summary>
    
      <category term="java" scheme="https://www.wuxinvip.com/categories/java/"/>
    
      <category term="序列化" scheme="https://www.wuxinvip.com/categories/java/%E5%BA%8F%E5%88%97%E5%8C%96/"/>
    
    
      <category term="随笔" scheme="https://www.wuxinvip.com/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
</feed>
